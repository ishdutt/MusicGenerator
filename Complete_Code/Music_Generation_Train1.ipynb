{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Problem\n",
    "\n",
    "This case-study focuses on generating music automatically using Recurrent Neural Network(RNN).<br> \n",
    "We do not necessarily have to be a music expert in order to generate music. Even a non expert can generate a decent quality music using RNN.<br>\n",
    "We all like to listen interesting music and if there is some way to generate music automatically, particularly decent quality music then it's a big leap in the world of music industry.<br><br>\n",
    "<b>Task:</b> Our task here is to take some existing music data then train a model using this existing data. The model has to learn the patterns in music that we humans enjoy. Once it learns this, the model should be able to generate new music for us. It cannot simply copy-paste from the training data. It has to understand the patterns of music to generate new music. We here are not expecting our model to generate new music which is of professional quality, but we want it to generate a decent quality music which should be melodious and good to hear.<br><br>\n",
    "Now, what is music? In short music is nothing but a sequence of musical notes. Our input to the model is a sequence of musical events/notes. Our output will be new sequence of musical events/notes. In this case-study we have limited our self to single instrument music as this is our first cut model. In future, we will extend this to multiple instrument music. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source:\n",
    "1. http://abc.sourceforge.net/NMD/\n",
    "2. http://trillian.mit.edu/~jc/music/book/oneills/1850/X/\n",
    "\n",
    "### From first data-source, we have downloaded first two files:\n",
    "* Jigs (340 tunes)\n",
    "* Hornpipes (65 tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 80):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 128)             197120    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 128)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              11223     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,040,343\n",
      "Trainable params: 1,040,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishdutt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 4.46358585357666, Accuracy: 0.0244140625\n",
      "Batch: 2, Loss: 4.436729907989502, Accuracy: 0.17578125\n",
      "Batch: 3, Loss: 4.403998374938965, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.350777626037598, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 4.109460830688477, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 3.847993850708008, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.7958757877349854, Accuracy: 0.1630859375\n",
      "Batch: 8, Loss: 3.784571409225464, Accuracy: 0.142578125\n",
      "Batch: 9, Loss: 3.7929766178131104, Accuracy: 0.13671875\n",
      "Batch: 10, Loss: 3.6339097023010254, Accuracy: 0.1484375\n",
      "Batch: 11, Loss: 3.431927442550659, Accuracy: 0.15234375\n",
      "Batch: 12, Loss: 3.5604872703552246, Accuracy: 0.123046875\n",
      "Batch: 13, Loss: 3.766331672668457, Accuracy: 0.1162109375\n",
      "Batch: 14, Loss: 3.5170960426330566, Accuracy: 0.1455078125\n",
      "Batch: 15, Loss: 3.7265844345092773, Accuracy: 0.1298828125\n",
      "Batch: 16, Loss: 3.4580650329589844, Accuracy: 0.1572265625\n",
      "Batch: 17, Loss: 3.3670132160186768, Accuracy: 0.1767578125\n",
      "Batch: 18, Loss: 3.354898452758789, Accuracy: 0.173828125\n",
      "Batch: 19, Loss: 3.628655433654785, Accuracy: 0.1298828125\n",
      "Batch: 20, Loss: 3.700364112854004, Accuracy: 0.109375\n",
      "Batch: 21, Loss: 3.576378107070923, Accuracy: 0.125\n",
      "Batch: 22, Loss: 3.3202457427978516, Accuracy: 0.1650390625\n",
      "Batch: 23, Loss: 3.435122013092041, Accuracy: 0.1357421875\n",
      "Batch: 24, Loss: 3.6073482036590576, Accuracy: 0.103515625\n",
      "Batch: 25, Loss: 3.5041356086730957, Accuracy: 0.1328125\n",
      "Batch: 26, Loss: 3.484297513961792, Accuracy: 0.126953125\n",
      "Batch: 27, Loss: 3.456220865249634, Accuracy: 0.1337890625\n",
      "Batch: 28, Loss: 3.2957963943481445, Accuracy: 0.1533203125\n",
      "Batch: 29, Loss: 3.479982376098633, Accuracy: 0.1259765625\n",
      "Batch: 30, Loss: 3.802619695663452, Accuracy: 0.087890625\n",
      "Batch: 31, Loss: 3.6863646507263184, Accuracy: 0.1142578125\n",
      "Batch: 32, Loss: 3.4361319541931152, Accuracy: 0.130859375\n",
      "Batch: 33, Loss: 3.433464527130127, Accuracy: 0.1494140625\n",
      "Batch: 34, Loss: 3.4217588901519775, Accuracy: 0.142578125\n",
      "Batch: 35, Loss: 3.5056257247924805, Accuracy: 0.1171875\n",
      "Batch: 36, Loss: 3.6450862884521484, Accuracy: 0.0966796875\n",
      "Batch: 37, Loss: 3.4993629455566406, Accuracy: 0.1162109375\n",
      "Batch: 38, Loss: 3.4160685539245605, Accuracy: 0.134765625\n",
      "Batch: 39, Loss: 3.486456871032715, Accuracy: 0.1259765625\n",
      "Batch: 40, Loss: 3.615328311920166, Accuracy: 0.1103515625\n",
      "Batch: 41, Loss: 3.5881118774414062, Accuracy: 0.1259765625\n",
      "Batch: 42, Loss: 3.4650015830993652, Accuracy: 0.142578125\n",
      "Batch: 43, Loss: 3.3227264881134033, Accuracy: 0.16015625\n",
      "Batch: 44, Loss: 3.332376480102539, Accuracy: 0.166015625\n",
      "Batch: 45, Loss: 3.358581781387329, Accuracy: 0.15234375\n",
      "Batch: 46, Loss: 3.660964012145996, Accuracy: 0.111328125\n",
      "Batch: 47, Loss: 3.6435632705688477, Accuracy: 0.103515625\n",
      "Batch: 48, Loss: 3.4373574256896973, Accuracy: 0.1376953125\n",
      "Batch: 49, Loss: 3.3914453983306885, Accuracy: 0.1357421875\n",
      "Batch: 50, Loss: 3.3591129779815674, Accuracy: 0.142578125\n",
      "Batch: 51, Loss: 3.358827829360962, Accuracy: 0.140625\n",
      "Batch: 52, Loss: 3.450453519821167, Accuracy: 0.1201171875\n",
      "Batch: 53, Loss: 3.4409403800964355, Accuracy: 0.1240234375\n",
      "Batch: 54, Loss: 3.5051136016845703, Accuracy: 0.130859375\n",
      "Batch: 55, Loss: 3.406245231628418, Accuracy: 0.13671875\n",
      "Batch: 56, Loss: 3.438364267349243, Accuracy: 0.1533203125\n",
      "Batch: 57, Loss: 3.4758572578430176, Accuracy: 0.12890625\n",
      "Batch: 58, Loss: 3.3494081497192383, Accuracy: 0.1416015625\n",
      "Batch: 59, Loss: 3.639573574066162, Accuracy: 0.115234375\n",
      "Batch: 60, Loss: 3.417316436767578, Accuracy: 0.1416015625\n",
      "Batch: 61, Loss: 3.4004080295562744, Accuracy: 0.1494140625\n",
      "Batch: 62, Loss: 3.4886646270751953, Accuracy: 0.1357421875\n",
      "Batch: 63, Loss: 3.4205987453460693, Accuracy: 0.1396484375\n",
      "Batch: 64, Loss: 3.4675145149230957, Accuracy: 0.142578125\n",
      "Batch: 65, Loss: 3.4195733070373535, Accuracy: 0.146484375\n",
      "Batch: 66, Loss: 3.404048442840576, Accuracy: 0.150390625\n",
      "Batch: 67, Loss: 3.2601394653320312, Accuracy: 0.1748046875\n",
      "Batch: 68, Loss: 3.330867052078247, Accuracy: 0.185546875\n",
      "Batch: 69, Loss: 3.4004735946655273, Accuracy: 0.1494140625\n",
      "Batch: 70, Loss: 3.379445791244507, Accuracy: 0.169921875\n",
      "Batch: 71, Loss: 3.289340019226074, Accuracy: 0.16796875\n",
      "Batch: 72, Loss: 3.2947874069213867, Accuracy: 0.166015625\n",
      "Batch: 73, Loss: 3.420726776123047, Accuracy: 0.1513671875\n",
      "Batch: 74, Loss: 3.3627371788024902, Accuracy: 0.1513671875\n",
      "Batch: 75, Loss: 3.186206340789795, Accuracy: 0.1748046875\n",
      "Batch: 76, Loss: 3.080202579498291, Accuracy: 0.1953125\n",
      "Batch: 77, Loss: 3.18571138381958, Accuracy: 0.1923828125\n",
      "Batch: 78, Loss: 3.658949851989746, Accuracy: 0.130859375\n",
      "Batch: 79, Loss: 3.6032488346099854, Accuracy: 0.1396484375\n",
      "Batch: 80, Loss: 3.2081401348114014, Accuracy: 0.20703125\n",
      "Batch: 81, Loss: 3.047745704650879, Accuracy: 0.240234375\n",
      "Batch: 82, Loss: 3.1512451171875, Accuracy: 0.2080078125\n",
      "Batch: 83, Loss: 3.1984212398529053, Accuracy: 0.203125\n",
      "Batch: 84, Loss: 3.324148654937744, Accuracy: 0.171875\n",
      "Batch: 85, Loss: 3.286198139190674, Accuracy: 0.1591796875\n",
      "Batch: 86, Loss: 3.1111440658569336, Accuracy: 0.2099609375\n",
      "Batch: 87, Loss: 3.1668925285339355, Accuracy: 0.2060546875\n",
      "Batch: 88, Loss: 3.091162919998169, Accuracy: 0.208984375\n",
      "Batch: 89, Loss: 3.107691526412964, Accuracy: 0.2138671875\n",
      "Batch: 90, Loss: 3.1944775581359863, Accuracy: 0.19921875\n",
      "Batch: 91, Loss: 3.1802797317504883, Accuracy: 0.1923828125\n",
      "Batch: 92, Loss: 3.0858592987060547, Accuracy: 0.2158203125\n",
      "Batch: 93, Loss: 3.0854508876800537, Accuracy: 0.2099609375\n",
      "Batch: 94, Loss: 2.9901931285858154, Accuracy: 0.248046875\n",
      "Batch: 95, Loss: 2.84053897857666, Accuracy: 0.267578125\n",
      "Batch: 96, Loss: 3.1157262325286865, Accuracy: 0.2216796875\n",
      "Batch: 97, Loss: 3.094085931777954, Accuracy: 0.224609375\n",
      "Batch: 98, Loss: 3.1109390258789062, Accuracy: 0.2119140625\n",
      "Batch: 99, Loss: 2.907475471496582, Accuracy: 0.2509765625\n",
      "Batch: 100, Loss: 2.782823085784912, Accuracy: 0.2529296875\n",
      "Batch: 101, Loss: 2.9059340953826904, Accuracy: 0.2392578125\n",
      "Batch: 102, Loss: 2.8985893726348877, Accuracy: 0.2451171875\n",
      "Batch: 103, Loss: 3.117239475250244, Accuracy: 0.2138671875\n",
      "Batch: 104, Loss: 2.8700385093688965, Accuracy: 0.236328125\n",
      "Batch: 105, Loss: 2.85294246673584, Accuracy: 0.2529296875\n",
      "Batch: 106, Loss: 2.9461472034454346, Accuracy: 0.2431640625\n",
      "Batch: 107, Loss: 2.9418423175811768, Accuracy: 0.2509765625\n",
      "Batch: 108, Loss: 2.953155040740967, Accuracy: 0.244140625\n",
      "Batch: 109, Loss: 2.839298725128174, Accuracy: 0.248046875\n",
      "Batch: 110, Loss: 2.8206934928894043, Accuracy: 0.2529296875\n",
      "Batch: 111, Loss: 2.7396910190582275, Accuracy: 0.2744140625\n",
      "Batch: 112, Loss: 2.975642442703247, Accuracy: 0.2412109375\n",
      "Batch: 113, Loss: 2.9752187728881836, Accuracy: 0.240234375\n",
      "Batch: 114, Loss: 2.76116681098938, Accuracy: 0.2841796875\n",
      "Batch: 115, Loss: 2.8248682022094727, Accuracy: 0.2734375\n",
      "Batch: 116, Loss: 2.8894309997558594, Accuracy: 0.251953125\n",
      "Batch: 117, Loss: 2.994887351989746, Accuracy: 0.2431640625\n",
      "Batch: 118, Loss: 2.9751055240631104, Accuracy: 0.240234375\n",
      "Batch: 119, Loss: 2.954641819000244, Accuracy: 0.2509765625\n",
      "Batch: 120, Loss: 2.721500873565674, Accuracy: 0.2861328125\n",
      "Batch: 121, Loss: 2.7450008392333984, Accuracy: 0.2978515625\n",
      "Batch: 122, Loss: 2.999901294708252, Accuracy: 0.2294921875\n",
      "Batch: 123, Loss: 2.9344186782836914, Accuracy: 0.2412109375\n",
      "Batch: 124, Loss: 2.8868536949157715, Accuracy: 0.265625\n",
      "Batch: 125, Loss: 2.7446537017822266, Accuracy: 0.28125\n",
      "Batch: 126, Loss: 2.7161383628845215, Accuracy: 0.2646484375\n",
      "Batch: 127, Loss: 2.9031381607055664, Accuracy: 0.240234375\n",
      "Batch: 128, Loss: 2.857313632965088, Accuracy: 0.2626953125\n",
      "Batch: 129, Loss: 2.7989914417266846, Accuracy: 0.265625\n",
      "Batch: 130, Loss: 2.8012478351593018, Accuracy: 0.2744140625\n",
      "Batch: 131, Loss: 2.8344831466674805, Accuracy: 0.26171875\n",
      "Batch: 132, Loss: 2.9006221294403076, Accuracy: 0.2646484375\n",
      "Batch: 133, Loss: 2.762739658355713, Accuracy: 0.2734375\n",
      "Batch: 134, Loss: 2.6987390518188477, Accuracy: 0.2890625\n",
      "Batch: 135, Loss: 2.630687713623047, Accuracy: 0.302734375\n",
      "Batch: 136, Loss: 2.6094400882720947, Accuracy: 0.3076171875\n",
      "Batch: 137, Loss: 2.463498115539551, Accuracy: 0.34375\n",
      "Batch: 138, Loss: 2.5695853233337402, Accuracy: 0.337890625\n",
      "Batch: 139, Loss: 2.56777286529541, Accuracy: 0.314453125\n",
      "Batch: 140, Loss: 2.662929058074951, Accuracy: 0.291015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 2.682910919189453, Accuracy: 0.302734375\n",
      "Batch: 142, Loss: 2.6132988929748535, Accuracy: 0.3076171875\n",
      "Batch: 143, Loss: 2.7360193729400635, Accuracy: 0.2841796875\n",
      "Batch: 144, Loss: 2.7229232788085938, Accuracy: 0.29296875\n",
      "Batch: 145, Loss: 2.580122709274292, Accuracy: 0.3076171875\n",
      "Batch: 146, Loss: 2.685756206512451, Accuracy: 0.2802734375\n",
      "Batch: 147, Loss: 2.6744112968444824, Accuracy: 0.28515625\n",
      "Batch: 148, Loss: 2.5625901222229004, Accuracy: 0.30078125\n",
      "Batch: 149, Loss: 2.6719813346862793, Accuracy: 0.28515625\n",
      "Batch: 150, Loss: 2.6039376258850098, Accuracy: 0.3017578125\n",
      "Batch: 151, Loss: 2.7212376594543457, Accuracy: 0.28515625\n",
      "Epoch 2/80\n",
      "Batch: 1, Loss: 2.451472043991089, Accuracy: 0.32421875\n",
      "Batch: 2, Loss: 2.351924180984497, Accuracy: 0.337890625\n",
      "Batch: 3, Loss: 2.5833945274353027, Accuracy: 0.31640625\n",
      "Batch: 4, Loss: 2.6778080463409424, Accuracy: 0.294921875\n",
      "Batch: 5, Loss: 2.5320940017700195, Accuracy: 0.33203125\n",
      "Batch: 6, Loss: 2.3889882564544678, Accuracy: 0.3271484375\n",
      "Batch: 7, Loss: 2.403703451156616, Accuracy: 0.3359375\n",
      "Batch: 8, Loss: 2.472212314605713, Accuracy: 0.337890625\n",
      "Batch: 9, Loss: 2.511093854904175, Accuracy: 0.330078125\n",
      "Batch: 10, Loss: 2.42210054397583, Accuracy: 0.341796875\n",
      "Batch: 11, Loss: 2.254314422607422, Accuracy: 0.3701171875\n",
      "Batch: 12, Loss: 2.461894989013672, Accuracy: 0.3251953125\n",
      "Batch: 13, Loss: 2.5604543685913086, Accuracy: 0.3203125\n",
      "Batch: 14, Loss: 2.455069065093994, Accuracy: 0.3486328125\n",
      "Batch: 15, Loss: 2.6210269927978516, Accuracy: 0.310546875\n",
      "Batch: 16, Loss: 2.3862617015838623, Accuracy: 0.3486328125\n",
      "Batch: 17, Loss: 2.39454984664917, Accuracy: 0.3564453125\n",
      "Batch: 18, Loss: 2.3618364334106445, Accuracy: 0.33984375\n",
      "Batch: 19, Loss: 2.5287842750549316, Accuracy: 0.3271484375\n",
      "Batch: 20, Loss: 2.588322639465332, Accuracy: 0.3154296875\n",
      "Batch: 21, Loss: 2.428354024887085, Accuracy: 0.3427734375\n",
      "Batch: 22, Loss: 2.3599629402160645, Accuracy: 0.35546875\n",
      "Batch: 23, Loss: 2.3321382999420166, Accuracy: 0.3603515625\n",
      "Batch: 24, Loss: 2.5228254795074463, Accuracy: 0.3271484375\n",
      "Batch: 25, Loss: 2.3895998001098633, Accuracy: 0.337890625\n",
      "Batch: 26, Loss: 2.3384642601013184, Accuracy: 0.369140625\n",
      "Batch: 27, Loss: 2.419576644897461, Accuracy: 0.337890625\n",
      "Batch: 28, Loss: 2.2929861545562744, Accuracy: 0.369140625\n",
      "Batch: 29, Loss: 2.3798112869262695, Accuracy: 0.3388671875\n",
      "Batch: 30, Loss: 2.584737777709961, Accuracy: 0.3212890625\n",
      "Batch: 31, Loss: 2.574625015258789, Accuracy: 0.326171875\n",
      "Batch: 32, Loss: 2.339334487915039, Accuracy: 0.376953125\n",
      "Batch: 33, Loss: 2.4170961380004883, Accuracy: 0.361328125\n",
      "Batch: 34, Loss: 2.445979595184326, Accuracy: 0.33984375\n",
      "Batch: 35, Loss: 2.4193692207336426, Accuracy: 0.349609375\n",
      "Batch: 36, Loss: 2.544985294342041, Accuracy: 0.333984375\n",
      "Batch: 37, Loss: 2.4413065910339355, Accuracy: 0.33984375\n",
      "Batch: 38, Loss: 2.345890998840332, Accuracy: 0.3583984375\n",
      "Batch: 39, Loss: 2.4151601791381836, Accuracy: 0.33984375\n",
      "Batch: 40, Loss: 2.471740245819092, Accuracy: 0.3828125\n",
      "Batch: 41, Loss: 2.4007396697998047, Accuracy: 0.3662109375\n",
      "Batch: 42, Loss: 2.206477642059326, Accuracy: 0.396484375\n",
      "Batch: 43, Loss: 2.1486620903015137, Accuracy: 0.4033203125\n",
      "Batch: 44, Loss: 2.151242971420288, Accuracy: 0.4091796875\n",
      "Batch: 45, Loss: 2.146972179412842, Accuracy: 0.427734375\n",
      "Batch: 46, Loss: 2.400839328765869, Accuracy: 0.3720703125\n",
      "Batch: 47, Loss: 2.4324288368225098, Accuracy: 0.3720703125\n",
      "Batch: 48, Loss: 2.3877413272857666, Accuracy: 0.365234375\n",
      "Batch: 49, Loss: 2.3517374992370605, Accuracy: 0.361328125\n",
      "Batch: 50, Loss: 2.3420374393463135, Accuracy: 0.3720703125\n",
      "Batch: 51, Loss: 2.3520164489746094, Accuracy: 0.37109375\n",
      "Batch: 52, Loss: 2.3800010681152344, Accuracy: 0.3779296875\n",
      "Batch: 53, Loss: 2.2151095867156982, Accuracy: 0.40234375\n",
      "Batch: 54, Loss: 2.3111443519592285, Accuracy: 0.3994140625\n",
      "Batch: 55, Loss: 2.1761109828948975, Accuracy: 0.4052734375\n",
      "Batch: 56, Loss: 2.3175649642944336, Accuracy: 0.3720703125\n",
      "Batch: 57, Loss: 2.266491413116455, Accuracy: 0.388671875\n",
      "Batch: 58, Loss: 2.2974157333374023, Accuracy: 0.3837890625\n",
      "Batch: 59, Loss: 2.2418510913848877, Accuracy: 0.421875\n",
      "Batch: 60, Loss: 2.1249661445617676, Accuracy: 0.4169921875\n",
      "Batch: 61, Loss: 2.159890651702881, Accuracy: 0.4150390625\n",
      "Batch: 62, Loss: 2.3187265396118164, Accuracy: 0.3876953125\n",
      "Batch: 63, Loss: 2.1744627952575684, Accuracy: 0.3916015625\n",
      "Batch: 64, Loss: 2.1871962547302246, Accuracy: 0.408203125\n",
      "Batch: 65, Loss: 2.2603201866149902, Accuracy: 0.384765625\n",
      "Batch: 66, Loss: 2.167088270187378, Accuracy: 0.412109375\n",
      "Batch: 67, Loss: 2.1536126136779785, Accuracy: 0.40625\n",
      "Batch: 68, Loss: 2.2639660835266113, Accuracy: 0.41015625\n",
      "Batch: 69, Loss: 2.2893166542053223, Accuracy: 0.408203125\n",
      "Batch: 70, Loss: 2.324514865875244, Accuracy: 0.3828125\n",
      "Batch: 71, Loss: 2.2052433490753174, Accuracy: 0.3955078125\n",
      "Batch: 72, Loss: 2.1579179763793945, Accuracy: 0.4169921875\n",
      "Batch: 73, Loss: 2.2983179092407227, Accuracy: 0.380859375\n",
      "Batch: 74, Loss: 2.209085464477539, Accuracy: 0.404296875\n",
      "Batch: 75, Loss: 2.118826389312744, Accuracy: 0.4150390625\n",
      "Batch: 76, Loss: 2.1048970222473145, Accuracy: 0.3994140625\n",
      "Batch: 77, Loss: 2.1785318851470947, Accuracy: 0.4091796875\n",
      "Batch: 78, Loss: 2.3164401054382324, Accuracy: 0.3955078125\n",
      "Batch: 79, Loss: 2.2244529724121094, Accuracy: 0.4296875\n",
      "Batch: 80, Loss: 2.0195717811584473, Accuracy: 0.4345703125\n",
      "Batch: 81, Loss: 2.0289201736450195, Accuracy: 0.4228515625\n",
      "Batch: 82, Loss: 2.049755573272705, Accuracy: 0.4228515625\n",
      "Batch: 83, Loss: 2.1301865577697754, Accuracy: 0.41796875\n",
      "Batch: 84, Loss: 2.1758337020874023, Accuracy: 0.423828125\n",
      "Batch: 85, Loss: 2.1037163734436035, Accuracy: 0.4423828125\n",
      "Batch: 86, Loss: 2.1484479904174805, Accuracy: 0.4140625\n",
      "Batch: 87, Loss: 2.132040023803711, Accuracy: 0.4384765625\n",
      "Batch: 88, Loss: 2.1974897384643555, Accuracy: 0.408203125\n",
      "Batch: 89, Loss: 2.173029899597168, Accuracy: 0.41015625\n",
      "Batch: 90, Loss: 2.105435609817505, Accuracy: 0.439453125\n",
      "Batch: 91, Loss: 2.0825982093811035, Accuracy: 0.4228515625\n",
      "Batch: 92, Loss: 2.107478618621826, Accuracy: 0.4296875\n",
      "Batch: 93, Loss: 2.1023690700531006, Accuracy: 0.4228515625\n",
      "Batch: 94, Loss: 2.0590157508850098, Accuracy: 0.4345703125\n",
      "Batch: 95, Loss: 1.9521074295043945, Accuracy: 0.4541015625\n",
      "Batch: 96, Loss: 2.138758897781372, Accuracy: 0.4375\n",
      "Batch: 97, Loss: 2.03304386138916, Accuracy: 0.46484375\n",
      "Batch: 98, Loss: 2.0507349967956543, Accuracy: 0.4716796875\n",
      "Batch: 99, Loss: 1.9657361507415771, Accuracy: 0.451171875\n",
      "Batch: 100, Loss: 1.903275489807129, Accuracy: 0.46484375\n",
      "Batch: 101, Loss: 1.9986332654953003, Accuracy: 0.4423828125\n",
      "Batch: 102, Loss: 1.9451355934143066, Accuracy: 0.44921875\n",
      "Batch: 103, Loss: 2.192152500152588, Accuracy: 0.4189453125\n",
      "Batch: 104, Loss: 1.9697787761688232, Accuracy: 0.4658203125\n",
      "Batch: 105, Loss: 2.027723789215088, Accuracy: 0.4462890625\n",
      "Batch: 106, Loss: 2.066761016845703, Accuracy: 0.4345703125\n",
      "Batch: 107, Loss: 2.1229135990142822, Accuracy: 0.427734375\n",
      "Batch: 108, Loss: 2.168668746948242, Accuracy: 0.4208984375\n",
      "Batch: 109, Loss: 2.1102209091186523, Accuracy: 0.4365234375\n",
      "Batch: 110, Loss: 1.906868577003479, Accuracy: 0.4736328125\n",
      "Batch: 111, Loss: 2.0019092559814453, Accuracy: 0.451171875\n",
      "Batch: 112, Loss: 2.086251735687256, Accuracy: 0.462890625\n",
      "Batch: 113, Loss: 2.1355183124542236, Accuracy: 0.439453125\n",
      "Batch: 114, Loss: 2.0724968910217285, Accuracy: 0.4306640625\n",
      "Batch: 115, Loss: 2.1259641647338867, Accuracy: 0.4384765625\n",
      "Batch: 116, Loss: 2.1101455688476562, Accuracy: 0.4130859375\n",
      "Batch: 117, Loss: 2.173492908477783, Accuracy: 0.421875\n",
      "Batch: 118, Loss: 2.0046885013580322, Accuracy: 0.45703125\n",
      "Batch: 119, Loss: 2.005403995513916, Accuracy: 0.4736328125\n",
      "Batch: 120, Loss: 2.029388904571533, Accuracy: 0.443359375\n",
      "Batch: 121, Loss: 2.0212392807006836, Accuracy: 0.4443359375\n",
      "Batch: 122, Loss: 2.1109204292297363, Accuracy: 0.4501953125\n",
      "Batch: 123, Loss: 2.0767269134521484, Accuracy: 0.455078125\n",
      "Batch: 124, Loss: 2.038114547729492, Accuracy: 0.4541015625\n",
      "Batch: 125, Loss: 2.007512092590332, Accuracy: 0.4375\n",
      "Batch: 126, Loss: 2.00559663772583, Accuracy: 0.4287109375\n",
      "Batch: 127, Loss: 2.024787187576294, Accuracy: 0.453125\n",
      "Batch: 128, Loss: 2.204072952270508, Accuracy: 0.41796875\n",
      "Batch: 129, Loss: 2.0136420726776123, Accuracy: 0.4453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 2.180293321609497, Accuracy: 0.427734375\n",
      "Batch: 131, Loss: 2.0374560356140137, Accuracy: 0.4365234375\n",
      "Batch: 132, Loss: 2.1280484199523926, Accuracy: 0.4306640625\n",
      "Batch: 133, Loss: 2.015058755874634, Accuracy: 0.462890625\n",
      "Batch: 134, Loss: 1.9652308225631714, Accuracy: 0.4599609375\n",
      "Batch: 135, Loss: 1.9066145420074463, Accuracy: 0.4833984375\n",
      "Batch: 136, Loss: 1.9156625270843506, Accuracy: 0.4677734375\n",
      "Batch: 137, Loss: 1.8048200607299805, Accuracy: 0.478515625\n",
      "Batch: 138, Loss: 1.7581716775894165, Accuracy: 0.5009765625\n",
      "Batch: 139, Loss: 1.8850350379943848, Accuracy: 0.46484375\n",
      "Batch: 140, Loss: 1.9436075687408447, Accuracy: 0.4580078125\n",
      "Batch: 141, Loss: 1.9501351118087769, Accuracy: 0.4736328125\n",
      "Batch: 142, Loss: 1.914286494255066, Accuracy: 0.4697265625\n",
      "Batch: 143, Loss: 2.024998426437378, Accuracy: 0.427734375\n",
      "Batch: 144, Loss: 1.9655182361602783, Accuracy: 0.4609375\n",
      "Batch: 145, Loss: 1.882387638092041, Accuracy: 0.455078125\n",
      "Batch: 146, Loss: 1.9959136247634888, Accuracy: 0.4501953125\n",
      "Batch: 147, Loss: 1.985405683517456, Accuracy: 0.451171875\n",
      "Batch: 148, Loss: 2.0054264068603516, Accuracy: 0.42578125\n",
      "Batch: 149, Loss: 1.9602808952331543, Accuracy: 0.4404296875\n",
      "Batch: 150, Loss: 1.9171967506408691, Accuracy: 0.47265625\n",
      "Batch: 151, Loss: 1.9324426651000977, Accuracy: 0.4765625\n",
      "Epoch 3/80\n",
      "Batch: 1, Loss: 1.9480679035186768, Accuracy: 0.4443359375\n",
      "Batch: 2, Loss: 1.778833270072937, Accuracy: 0.4765625\n",
      "Batch: 3, Loss: 1.890293836593628, Accuracy: 0.4775390625\n",
      "Batch: 4, Loss: 1.8518521785736084, Accuracy: 0.521484375\n",
      "Batch: 5, Loss: 1.8771820068359375, Accuracy: 0.4833984375\n",
      "Batch: 6, Loss: 1.8487153053283691, Accuracy: 0.4462890625\n",
      "Batch: 7, Loss: 1.825913667678833, Accuracy: 0.470703125\n",
      "Batch: 8, Loss: 1.8063771724700928, Accuracy: 0.490234375\n",
      "Batch: 9, Loss: 1.7841532230377197, Accuracy: 0.498046875\n",
      "Batch: 10, Loss: 1.7851920127868652, Accuracy: 0.4853515625\n",
      "Batch: 11, Loss: 1.738381266593933, Accuracy: 0.46875\n",
      "Batch: 12, Loss: 1.9237737655639648, Accuracy: 0.458984375\n",
      "Batch: 13, Loss: 1.7561143636703491, Accuracy: 0.5244140625\n",
      "Batch: 14, Loss: 1.9276576042175293, Accuracy: 0.470703125\n",
      "Batch: 15, Loss: 1.9470981359481812, Accuracy: 0.470703125\n",
      "Batch: 16, Loss: 1.8111135959625244, Accuracy: 0.486328125\n",
      "Batch: 17, Loss: 1.8478152751922607, Accuracy: 0.458984375\n",
      "Batch: 18, Loss: 1.856882095336914, Accuracy: 0.45703125\n",
      "Batch: 19, Loss: 1.922153115272522, Accuracy: 0.46875\n",
      "Batch: 20, Loss: 1.9350913763046265, Accuracy: 0.47265625\n",
      "Batch: 21, Loss: 1.8307063579559326, Accuracy: 0.4873046875\n",
      "Batch: 22, Loss: 1.8830885887145996, Accuracy: 0.462890625\n",
      "Batch: 23, Loss: 1.7710363864898682, Accuracy: 0.486328125\n",
      "Batch: 24, Loss: 1.888575553894043, Accuracy: 0.486328125\n",
      "Batch: 25, Loss: 1.8201515674591064, Accuracy: 0.4775390625\n",
      "Batch: 26, Loss: 1.7363245487213135, Accuracy: 0.5009765625\n",
      "Batch: 27, Loss: 1.8261915445327759, Accuracy: 0.486328125\n",
      "Batch: 28, Loss: 1.7968642711639404, Accuracy: 0.48046875\n",
      "Batch: 29, Loss: 1.8620924949645996, Accuracy: 0.4765625\n",
      "Batch: 30, Loss: 1.9276907444000244, Accuracy: 0.4755859375\n",
      "Batch: 31, Loss: 1.9526312351226807, Accuracy: 0.4658203125\n",
      "Batch: 32, Loss: 1.7546911239624023, Accuracy: 0.4951171875\n",
      "Batch: 33, Loss: 1.9071564674377441, Accuracy: 0.474609375\n",
      "Batch: 34, Loss: 1.9966440200805664, Accuracy: 0.4462890625\n",
      "Batch: 35, Loss: 1.8612186908721924, Accuracy: 0.478515625\n",
      "Batch: 36, Loss: 1.8994938135147095, Accuracy: 0.4833984375\n",
      "Batch: 37, Loss: 1.9941155910491943, Accuracy: 0.4404296875\n",
      "Batch: 38, Loss: 1.8201448917388916, Accuracy: 0.474609375\n",
      "Batch: 39, Loss: 1.8679146766662598, Accuracy: 0.478515625\n",
      "Batch: 40, Loss: 1.9234495162963867, Accuracy: 0.505859375\n",
      "Batch: 41, Loss: 1.91732656955719, Accuracy: 0.4873046875\n",
      "Batch: 42, Loss: 1.7033058404922485, Accuracy: 0.515625\n",
      "Batch: 43, Loss: 1.7076077461242676, Accuracy: 0.478515625\n",
      "Batch: 44, Loss: 1.6916348934173584, Accuracy: 0.501953125\n",
      "Batch: 45, Loss: 1.6473214626312256, Accuracy: 0.5263671875\n",
      "Batch: 46, Loss: 1.8624975681304932, Accuracy: 0.521484375\n",
      "Batch: 47, Loss: 1.8781466484069824, Accuracy: 0.494140625\n",
      "Batch: 48, Loss: 1.896886944770813, Accuracy: 0.4765625\n",
      "Batch: 49, Loss: 1.8964662551879883, Accuracy: 0.474609375\n",
      "Batch: 50, Loss: 1.9246234893798828, Accuracy: 0.447265625\n",
      "Batch: 51, Loss: 1.9626582860946655, Accuracy: 0.4638671875\n",
      "Batch: 52, Loss: 1.9047863483428955, Accuracy: 0.4853515625\n",
      "Batch: 53, Loss: 1.7467175722122192, Accuracy: 0.5009765625\n",
      "Batch: 54, Loss: 1.7979459762573242, Accuracy: 0.5\n",
      "Batch: 55, Loss: 1.7412457466125488, Accuracy: 0.4990234375\n",
      "Batch: 56, Loss: 1.8717138767242432, Accuracy: 0.490234375\n",
      "Batch: 57, Loss: 1.8257068395614624, Accuracy: 0.48828125\n",
      "Batch: 58, Loss: 1.904144048690796, Accuracy: 0.47265625\n",
      "Batch: 59, Loss: 1.7053018808364868, Accuracy: 0.5517578125\n",
      "Batch: 60, Loss: 1.7045722007751465, Accuracy: 0.5185546875\n",
      "Batch: 61, Loss: 1.7364873886108398, Accuracy: 0.5078125\n",
      "Batch: 62, Loss: 1.8169491291046143, Accuracy: 0.4970703125\n",
      "Batch: 63, Loss: 1.7883886098861694, Accuracy: 0.484375\n",
      "Batch: 64, Loss: 1.7526607513427734, Accuracy: 0.51171875\n",
      "Batch: 65, Loss: 1.8460843563079834, Accuracy: 0.4873046875\n",
      "Batch: 66, Loss: 1.7139067649841309, Accuracy: 0.5126953125\n",
      "Batch: 67, Loss: 1.7755093574523926, Accuracy: 0.5087890625\n",
      "Batch: 68, Loss: 1.8529447317123413, Accuracy: 0.5009765625\n",
      "Batch: 69, Loss: 1.8526166677474976, Accuracy: 0.4873046875\n",
      "Batch: 70, Loss: 1.8926019668579102, Accuracy: 0.470703125\n",
      "Batch: 71, Loss: 1.777022123336792, Accuracy: 0.4921875\n",
      "Batch: 72, Loss: 1.7041549682617188, Accuracy: 0.5009765625\n",
      "Batch: 73, Loss: 1.7801486253738403, Accuracy: 0.4970703125\n",
      "Batch: 74, Loss: 1.7018649578094482, Accuracy: 0.4990234375\n",
      "Batch: 75, Loss: 1.6347339153289795, Accuracy: 0.5361328125\n",
      "Batch: 76, Loss: 1.740933895111084, Accuracy: 0.455078125\n",
      "Batch: 77, Loss: 1.8026416301727295, Accuracy: 0.462890625\n",
      "Batch: 78, Loss: 1.8223059177398682, Accuracy: 0.53125\n",
      "Batch: 79, Loss: 1.6798157691955566, Accuracy: 0.5478515625\n",
      "Batch: 80, Loss: 1.611004114151001, Accuracy: 0.5048828125\n",
      "Batch: 81, Loss: 1.7440309524536133, Accuracy: 0.46484375\n",
      "Batch: 82, Loss: 1.7144536972045898, Accuracy: 0.490234375\n",
      "Batch: 83, Loss: 1.7129995822906494, Accuracy: 0.5244140625\n",
      "Batch: 84, Loss: 1.7036939859390259, Accuracy: 0.529296875\n",
      "Batch: 85, Loss: 1.6629304885864258, Accuracy: 0.541015625\n",
      "Batch: 86, Loss: 1.8352508544921875, Accuracy: 0.4814453125\n",
      "Batch: 87, Loss: 1.7183533906936646, Accuracy: 0.51953125\n",
      "Batch: 88, Loss: 1.8278683423995972, Accuracy: 0.490234375\n",
      "Batch: 89, Loss: 1.8211703300476074, Accuracy: 0.4794921875\n",
      "Batch: 90, Loss: 1.6894073486328125, Accuracy: 0.5146484375\n",
      "Batch: 91, Loss: 1.6696228981018066, Accuracy: 0.515625\n",
      "Batch: 92, Loss: 1.7686188220977783, Accuracy: 0.4931640625\n",
      "Batch: 93, Loss: 1.7365388870239258, Accuracy: 0.513671875\n",
      "Batch: 94, Loss: 1.6776666641235352, Accuracy: 0.505859375\n",
      "Batch: 95, Loss: 1.6605992317199707, Accuracy: 0.501953125\n",
      "Batch: 96, Loss: 1.7287135124206543, Accuracy: 0.5166015625\n",
      "Batch: 97, Loss: 1.612180471420288, Accuracy: 0.5458984375\n",
      "Batch: 98, Loss: 1.6707912683486938, Accuracy: 0.53515625\n",
      "Batch: 99, Loss: 1.605729579925537, Accuracy: 0.5146484375\n",
      "Batch: 100, Loss: 1.6342812776565552, Accuracy: 0.5224609375\n",
      "Batch: 101, Loss: 1.6496936082839966, Accuracy: 0.52734375\n",
      "Batch: 102, Loss: 1.617279291152954, Accuracy: 0.521484375\n",
      "Batch: 103, Loss: 1.8169238567352295, Accuracy: 0.501953125\n",
      "Batch: 104, Loss: 1.6370964050292969, Accuracy: 0.5185546875\n",
      "Batch: 105, Loss: 1.702080488204956, Accuracy: 0.5146484375\n",
      "Batch: 106, Loss: 1.7437639236450195, Accuracy: 0.48828125\n",
      "Batch: 107, Loss: 1.8443619012832642, Accuracy: 0.482421875\n",
      "Batch: 108, Loss: 1.8413901329040527, Accuracy: 0.4794921875\n",
      "Batch: 109, Loss: 1.8252100944519043, Accuracy: 0.4951171875\n",
      "Batch: 110, Loss: 1.535907506942749, Accuracy: 0.548828125\n",
      "Batch: 111, Loss: 1.774031400680542, Accuracy: 0.4716796875\n",
      "Batch: 112, Loss: 1.7394263744354248, Accuracy: 0.513671875\n",
      "Batch: 113, Loss: 1.747633934020996, Accuracy: 0.5302734375\n",
      "Batch: 114, Loss: 1.7897348403930664, Accuracy: 0.486328125\n",
      "Batch: 115, Loss: 1.8070740699768066, Accuracy: 0.51171875\n",
      "Batch: 116, Loss: 1.8224453926086426, Accuracy: 0.46484375\n",
      "Batch: 117, Loss: 1.8141658306121826, Accuracy: 0.50390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 1.5942516326904297, Accuracy: 0.5654296875\n",
      "Batch: 119, Loss: 1.6328966617584229, Accuracy: 0.5517578125\n",
      "Batch: 120, Loss: 1.736340045928955, Accuracy: 0.4912109375\n",
      "Batch: 121, Loss: 1.7629339694976807, Accuracy: 0.4970703125\n",
      "Batch: 122, Loss: 1.738710641860962, Accuracy: 0.5283203125\n",
      "Batch: 123, Loss: 1.711028814315796, Accuracy: 0.5263671875\n",
      "Batch: 124, Loss: 1.688997745513916, Accuracy: 0.5283203125\n",
      "Batch: 125, Loss: 1.7375606298446655, Accuracy: 0.4912109375\n",
      "Batch: 126, Loss: 1.6879808902740479, Accuracy: 0.4951171875\n",
      "Batch: 127, Loss: 1.6707812547683716, Accuracy: 0.533203125\n",
      "Batch: 128, Loss: 1.877935767173767, Accuracy: 0.48828125\n",
      "Batch: 129, Loss: 1.6645252704620361, Accuracy: 0.5224609375\n",
      "Batch: 130, Loss: 1.898031234741211, Accuracy: 0.46875\n",
      "Batch: 131, Loss: 1.744023323059082, Accuracy: 0.4892578125\n",
      "Batch: 132, Loss: 1.8175116777420044, Accuracy: 0.5029296875\n",
      "Batch: 133, Loss: 1.6977132558822632, Accuracy: 0.51953125\n",
      "Batch: 134, Loss: 1.6592848300933838, Accuracy: 0.4990234375\n",
      "Batch: 135, Loss: 1.635419249534607, Accuracy: 0.5380859375\n",
      "Batch: 136, Loss: 1.619492769241333, Accuracy: 0.52734375\n",
      "Batch: 137, Loss: 1.5535081624984741, Accuracy: 0.537109375\n",
      "Batch: 138, Loss: 1.463299036026001, Accuracy: 0.568359375\n",
      "Batch: 139, Loss: 1.5761080980300903, Accuracy: 0.5185546875\n",
      "Batch: 140, Loss: 1.665854811668396, Accuracy: 0.498046875\n",
      "Batch: 141, Loss: 1.6657229661941528, Accuracy: 0.5224609375\n",
      "Batch: 142, Loss: 1.6367664337158203, Accuracy: 0.5146484375\n",
      "Batch: 143, Loss: 1.7091178894042969, Accuracy: 0.49609375\n",
      "Batch: 144, Loss: 1.6561435461044312, Accuracy: 0.52734375\n",
      "Batch: 145, Loss: 1.5790892839431763, Accuracy: 0.521484375\n",
      "Batch: 146, Loss: 1.7248177528381348, Accuracy: 0.4990234375\n",
      "Batch: 147, Loss: 1.70965576171875, Accuracy: 0.501953125\n",
      "Batch: 148, Loss: 1.7840303182601929, Accuracy: 0.4580078125\n",
      "Batch: 149, Loss: 1.727288007736206, Accuracy: 0.4921875\n",
      "Batch: 150, Loss: 1.6296874284744263, Accuracy: 0.5263671875\n",
      "Batch: 151, Loss: 1.624640941619873, Accuracy: 0.5439453125\n",
      "Epoch 4/80\n",
      "Batch: 1, Loss: 1.8182883262634277, Accuracy: 0.4599609375\n",
      "Batch: 2, Loss: 1.5953750610351562, Accuracy: 0.490234375\n",
      "Batch: 3, Loss: 1.608922004699707, Accuracy: 0.5224609375\n",
      "Batch: 4, Loss: 1.5317299365997314, Accuracy: 0.576171875\n",
      "Batch: 5, Loss: 1.5943021774291992, Accuracy: 0.529296875\n",
      "Batch: 6, Loss: 1.6616888046264648, Accuracy: 0.5009765625\n",
      "Batch: 7, Loss: 1.660037875175476, Accuracy: 0.494140625\n",
      "Batch: 8, Loss: 1.5520724058151245, Accuracy: 0.5302734375\n",
      "Batch: 9, Loss: 1.5111870765686035, Accuracy: 0.560546875\n",
      "Batch: 10, Loss: 1.5634725093841553, Accuracy: 0.5087890625\n",
      "Batch: 11, Loss: 1.5924274921417236, Accuracy: 0.494140625\n",
      "Batch: 12, Loss: 1.6918718814849854, Accuracy: 0.5087890625\n",
      "Batch: 13, Loss: 1.4351966381072998, Accuracy: 0.5908203125\n",
      "Batch: 14, Loss: 1.726727843284607, Accuracy: 0.490234375\n",
      "Batch: 15, Loss: 1.6467183828353882, Accuracy: 0.5419921875\n",
      "Batch: 16, Loss: 1.5757492780685425, Accuracy: 0.529296875\n",
      "Batch: 17, Loss: 1.6310558319091797, Accuracy: 0.498046875\n",
      "Batch: 18, Loss: 1.6642259359359741, Accuracy: 0.4912109375\n",
      "Batch: 19, Loss: 1.6705703735351562, Accuracy: 0.5068359375\n",
      "Batch: 20, Loss: 1.638623595237732, Accuracy: 0.552734375\n",
      "Batch: 21, Loss: 1.5943851470947266, Accuracy: 0.537109375\n",
      "Batch: 22, Loss: 1.7130913734436035, Accuracy: 0.4951171875\n",
      "Batch: 23, Loss: 1.5538378953933716, Accuracy: 0.5283203125\n",
      "Batch: 24, Loss: 1.6423702239990234, Accuracy: 0.5302734375\n",
      "Batch: 25, Loss: 1.604438066482544, Accuracy: 0.5166015625\n",
      "Batch: 26, Loss: 1.5369617938995361, Accuracy: 0.552734375\n",
      "Batch: 27, Loss: 1.6008813381195068, Accuracy: 0.533203125\n",
      "Batch: 28, Loss: 1.6115329265594482, Accuracy: 0.505859375\n",
      "Batch: 29, Loss: 1.6748342514038086, Accuracy: 0.501953125\n",
      "Batch: 30, Loss: 1.6440821886062622, Accuracy: 0.54296875\n",
      "Batch: 31, Loss: 1.664723515510559, Accuracy: 0.525390625\n",
      "Batch: 32, Loss: 1.545802354812622, Accuracy: 0.5341796875\n",
      "Batch: 33, Loss: 1.7117326259613037, Accuracy: 0.5009765625\n",
      "Batch: 34, Loss: 1.7990891933441162, Accuracy: 0.4755859375\n",
      "Batch: 35, Loss: 1.642594575881958, Accuracy: 0.51171875\n",
      "Batch: 36, Loss: 1.6303296089172363, Accuracy: 0.51953125\n",
      "Batch: 37, Loss: 1.7198164463043213, Accuracy: 0.50390625\n",
      "Batch: 38, Loss: 1.599970817565918, Accuracy: 0.5107421875\n",
      "Batch: 39, Loss: 1.675011396408081, Accuracy: 0.5029296875\n",
      "Batch: 40, Loss: 1.6704745292663574, Accuracy: 0.556640625\n",
      "Batch: 41, Loss: 1.7271006107330322, Accuracy: 0.5029296875\n",
      "Batch: 42, Loss: 1.5222939252853394, Accuracy: 0.53515625\n",
      "Batch: 43, Loss: 1.5283056497573853, Accuracy: 0.5078125\n",
      "Batch: 44, Loss: 1.5467063188552856, Accuracy: 0.53515625\n",
      "Batch: 45, Loss: 1.437635898590088, Accuracy: 0.5537109375\n",
      "Batch: 46, Loss: 1.6204317808151245, Accuracy: 0.552734375\n",
      "Batch: 47, Loss: 1.6729778051376343, Accuracy: 0.5205078125\n",
      "Batch: 48, Loss: 1.6792235374450684, Accuracy: 0.5107421875\n",
      "Batch: 49, Loss: 1.7196615934371948, Accuracy: 0.4931640625\n",
      "Batch: 50, Loss: 1.6999282836914062, Accuracy: 0.5009765625\n",
      "Batch: 51, Loss: 1.7793450355529785, Accuracy: 0.482421875\n",
      "Batch: 52, Loss: 1.7266249656677246, Accuracy: 0.50390625\n",
      "Batch: 53, Loss: 1.5622220039367676, Accuracy: 0.5263671875\n",
      "Batch: 54, Loss: 1.5803720951080322, Accuracy: 0.556640625\n",
      "Batch: 55, Loss: 1.582959532737732, Accuracy: 0.515625\n",
      "Batch: 56, Loss: 1.6663227081298828, Accuracy: 0.5068359375\n",
      "Batch: 57, Loss: 1.625038504600525, Accuracy: 0.5244140625\n",
      "Batch: 58, Loss: 1.7409446239471436, Accuracy: 0.494140625\n",
      "Batch: 59, Loss: 1.498934268951416, Accuracy: 0.5947265625\n",
      "Batch: 60, Loss: 1.4955720901489258, Accuracy: 0.5615234375\n",
      "Batch: 61, Loss: 1.5827076435089111, Accuracy: 0.5283203125\n",
      "Batch: 62, Loss: 1.6285138130187988, Accuracy: 0.5283203125\n",
      "Batch: 63, Loss: 1.5965771675109863, Accuracy: 0.537109375\n",
      "Batch: 64, Loss: 1.5744941234588623, Accuracy: 0.53515625\n",
      "Batch: 65, Loss: 1.663002371788025, Accuracy: 0.501953125\n",
      "Batch: 66, Loss: 1.5299749374389648, Accuracy: 0.556640625\n",
      "Batch: 67, Loss: 1.6634163856506348, Accuracy: 0.513671875\n",
      "Batch: 68, Loss: 1.7008389234542847, Accuracy: 0.5361328125\n",
      "Batch: 69, Loss: 1.6010249853134155, Accuracy: 0.537109375\n",
      "Batch: 70, Loss: 1.708221435546875, Accuracy: 0.5078125\n",
      "Batch: 71, Loss: 1.6101276874542236, Accuracy: 0.51953125\n",
      "Batch: 72, Loss: 1.5089625120162964, Accuracy: 0.5419921875\n",
      "Batch: 73, Loss: 1.5713791847229004, Accuracy: 0.537109375\n",
      "Batch: 74, Loss: 1.4879542589187622, Accuracy: 0.5556640625\n",
      "Batch: 75, Loss: 1.457122564315796, Accuracy: 0.55078125\n",
      "Batch: 76, Loss: 1.604576826095581, Accuracy: 0.4921875\n",
      "Batch: 77, Loss: 1.6382746696472168, Accuracy: 0.4931640625\n",
      "Batch: 78, Loss: 1.6130746603012085, Accuracy: 0.5673828125\n",
      "Batch: 79, Loss: 1.4444276094436646, Accuracy: 0.59765625\n",
      "Batch: 80, Loss: 1.4356820583343506, Accuracy: 0.5498046875\n",
      "Batch: 81, Loss: 1.6146366596221924, Accuracy: 0.4912109375\n",
      "Batch: 82, Loss: 1.5680947303771973, Accuracy: 0.51953125\n",
      "Batch: 83, Loss: 1.5350854396820068, Accuracy: 0.5546875\n",
      "Batch: 84, Loss: 1.5083658695220947, Accuracy: 0.5791015625\n",
      "Batch: 85, Loss: 1.464849829673767, Accuracy: 0.5615234375\n",
      "Batch: 86, Loss: 1.6957299709320068, Accuracy: 0.4892578125\n",
      "Batch: 87, Loss: 1.5298388004302979, Accuracy: 0.5498046875\n",
      "Batch: 88, Loss: 1.671434998512268, Accuracy: 0.533203125\n",
      "Batch: 89, Loss: 1.6520962715148926, Accuracy: 0.515625\n",
      "Batch: 90, Loss: 1.4923241138458252, Accuracy: 0.55859375\n",
      "Batch: 91, Loss: 1.4762318134307861, Accuracy: 0.5673828125\n",
      "Batch: 92, Loss: 1.6146011352539062, Accuracy: 0.5341796875\n",
      "Batch: 93, Loss: 1.5539603233337402, Accuracy: 0.5341796875\n",
      "Batch: 94, Loss: 1.5347869396209717, Accuracy: 0.521484375\n",
      "Batch: 95, Loss: 1.5105476379394531, Accuracy: 0.521484375\n",
      "Batch: 96, Loss: 1.5420515537261963, Accuracy: 0.546875\n",
      "Batch: 97, Loss: 1.4242393970489502, Accuracy: 0.5712890625\n",
      "Batch: 98, Loss: 1.4907512664794922, Accuracy: 0.576171875\n",
      "Batch: 99, Loss: 1.4550678730010986, Accuracy: 0.5498046875\n",
      "Batch: 100, Loss: 1.5154695510864258, Accuracy: 0.53515625\n",
      "Batch: 101, Loss: 1.5186686515808105, Accuracy: 0.529296875\n",
      "Batch: 102, Loss: 1.4686543941497803, Accuracy: 0.5400390625\n",
      "Batch: 103, Loss: 1.6450695991516113, Accuracy: 0.51953125\n",
      "Batch: 104, Loss: 1.4814746379852295, Accuracy: 0.5595703125\n",
      "Batch: 105, Loss: 1.544651746749878, Accuracy: 0.529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 1.608290672302246, Accuracy: 0.51953125\n",
      "Batch: 107, Loss: 1.690476655960083, Accuracy: 0.517578125\n",
      "Batch: 108, Loss: 1.669311761856079, Accuracy: 0.5185546875\n",
      "Batch: 109, Loss: 1.6752023696899414, Accuracy: 0.505859375\n",
      "Batch: 110, Loss: 1.3810453414916992, Accuracy: 0.5830078125\n",
      "Batch: 111, Loss: 1.620192050933838, Accuracy: 0.4990234375\n",
      "Batch: 112, Loss: 1.5666630268096924, Accuracy: 0.55078125\n",
      "Batch: 113, Loss: 1.5993014574050903, Accuracy: 0.564453125\n",
      "Batch: 114, Loss: 1.6870770454406738, Accuracy: 0.5146484375\n",
      "Batch: 115, Loss: 1.6877293586730957, Accuracy: 0.5068359375\n",
      "Batch: 116, Loss: 1.6721818447113037, Accuracy: 0.4951171875\n",
      "Batch: 117, Loss: 1.6718238592147827, Accuracy: 0.5283203125\n",
      "Batch: 118, Loss: 1.445893406867981, Accuracy: 0.580078125\n",
      "Batch: 119, Loss: 1.473686933517456, Accuracy: 0.5751953125\n",
      "Batch: 120, Loss: 1.6057320833206177, Accuracy: 0.521484375\n",
      "Batch: 121, Loss: 1.6197350025177002, Accuracy: 0.5107421875\n",
      "Batch: 122, Loss: 1.54573392868042, Accuracy: 0.5625\n",
      "Batch: 123, Loss: 1.5567479133605957, Accuracy: 0.5634765625\n",
      "Batch: 124, Loss: 1.546523094177246, Accuracy: 0.5625\n",
      "Batch: 125, Loss: 1.6082326173782349, Accuracy: 0.5244140625\n",
      "Batch: 126, Loss: 1.5889534950256348, Accuracy: 0.4970703125\n",
      "Batch: 127, Loss: 1.4949378967285156, Accuracy: 0.55859375\n",
      "Batch: 128, Loss: 1.7488129138946533, Accuracy: 0.5107421875\n",
      "Batch: 129, Loss: 1.530837059020996, Accuracy: 0.537109375\n",
      "Batch: 130, Loss: 1.7705628871917725, Accuracy: 0.490234375\n",
      "Batch: 131, Loss: 1.5964503288269043, Accuracy: 0.51953125\n",
      "Batch: 132, Loss: 1.6487271785736084, Accuracy: 0.515625\n",
      "Batch: 133, Loss: 1.5530595779418945, Accuracy: 0.5458984375\n",
      "Batch: 134, Loss: 1.5250595808029175, Accuracy: 0.5380859375\n",
      "Batch: 135, Loss: 1.4834342002868652, Accuracy: 0.56640625\n",
      "Batch: 136, Loss: 1.4948526620864868, Accuracy: 0.5458984375\n",
      "Batch: 137, Loss: 1.4494812488555908, Accuracy: 0.52734375\n",
      "Batch: 138, Loss: 1.3499881029129028, Accuracy: 0.5732421875\n",
      "Batch: 139, Loss: 1.4693114757537842, Accuracy: 0.5458984375\n",
      "Batch: 140, Loss: 1.518681526184082, Accuracy: 0.5146484375\n",
      "Batch: 141, Loss: 1.535550594329834, Accuracy: 0.537109375\n",
      "Batch: 142, Loss: 1.5141810178756714, Accuracy: 0.5302734375\n",
      "Batch: 143, Loss: 1.5736393928527832, Accuracy: 0.517578125\n",
      "Batch: 144, Loss: 1.5190393924713135, Accuracy: 0.5439453125\n",
      "Batch: 145, Loss: 1.4420541524887085, Accuracy: 0.5576171875\n",
      "Batch: 146, Loss: 1.6099634170532227, Accuracy: 0.5087890625\n",
      "Batch: 147, Loss: 1.5885382890701294, Accuracy: 0.5126953125\n",
      "Batch: 148, Loss: 1.6665728092193604, Accuracy: 0.4853515625\n",
      "Batch: 149, Loss: 1.5590623617172241, Accuracy: 0.53125\n",
      "Batch: 150, Loss: 1.5002119541168213, Accuracy: 0.5380859375\n",
      "Batch: 151, Loss: 1.4589149951934814, Accuracy: 0.5595703125\n",
      "Epoch 5/80\n",
      "Batch: 1, Loss: 1.6676384210586548, Accuracy: 0.4716796875\n",
      "Batch: 2, Loss: 1.4875797033309937, Accuracy: 0.51953125\n",
      "Batch: 3, Loss: 1.4775598049163818, Accuracy: 0.546875\n",
      "Batch: 4, Loss: 1.3993546962738037, Accuracy: 0.5927734375\n",
      "Batch: 5, Loss: 1.4263100624084473, Accuracy: 0.583984375\n",
      "Batch: 6, Loss: 1.5242829322814941, Accuracy: 0.51171875\n",
      "Batch: 7, Loss: 1.518747091293335, Accuracy: 0.5244140625\n",
      "Batch: 8, Loss: 1.4236663579940796, Accuracy: 0.556640625\n",
      "Batch: 9, Loss: 1.405153751373291, Accuracy: 0.5634765625\n",
      "Batch: 10, Loss: 1.4245612621307373, Accuracy: 0.5419921875\n",
      "Batch: 11, Loss: 1.4935177564620972, Accuracy: 0.525390625\n",
      "Batch: 12, Loss: 1.5966824293136597, Accuracy: 0.509765625\n",
      "Batch: 13, Loss: 1.309014081954956, Accuracy: 0.60546875\n",
      "Batch: 14, Loss: 1.6265884637832642, Accuracy: 0.50390625\n",
      "Batch: 15, Loss: 1.519741177558899, Accuracy: 0.56640625\n",
      "Batch: 16, Loss: 1.452872395515442, Accuracy: 0.541015625\n",
      "Batch: 17, Loss: 1.5512592792510986, Accuracy: 0.49609375\n",
      "Batch: 18, Loss: 1.5377254486083984, Accuracy: 0.525390625\n",
      "Batch: 19, Loss: 1.5624558925628662, Accuracy: 0.525390625\n",
      "Batch: 20, Loss: 1.5012032985687256, Accuracy: 0.5849609375\n",
      "Batch: 21, Loss: 1.488259196281433, Accuracy: 0.53515625\n",
      "Batch: 22, Loss: 1.5904871225357056, Accuracy: 0.513671875\n",
      "Batch: 23, Loss: 1.4380669593811035, Accuracy: 0.5546875\n",
      "Batch: 24, Loss: 1.5482070446014404, Accuracy: 0.5283203125\n",
      "Batch: 25, Loss: 1.4811666011810303, Accuracy: 0.5517578125\n",
      "Batch: 26, Loss: 1.4216077327728271, Accuracy: 0.5634765625\n",
      "Batch: 27, Loss: 1.4706748723983765, Accuracy: 0.533203125\n",
      "Batch: 28, Loss: 1.5305330753326416, Accuracy: 0.5302734375\n",
      "Batch: 29, Loss: 1.5754849910736084, Accuracy: 0.513671875\n",
      "Batch: 30, Loss: 1.5097575187683105, Accuracy: 0.5673828125\n",
      "Batch: 31, Loss: 1.5162928104400635, Accuracy: 0.5625\n",
      "Batch: 32, Loss: 1.4235539436340332, Accuracy: 0.5673828125\n",
      "Batch: 33, Loss: 1.60609769821167, Accuracy: 0.5087890625\n",
      "Batch: 34, Loss: 1.6952457427978516, Accuracy: 0.5068359375\n",
      "Batch: 35, Loss: 1.5286078453063965, Accuracy: 0.5263671875\n",
      "Batch: 36, Loss: 1.52587890625, Accuracy: 0.548828125\n",
      "Batch: 37, Loss: 1.6013329029083252, Accuracy: 0.53515625\n",
      "Batch: 38, Loss: 1.4899760484695435, Accuracy: 0.53125\n",
      "Batch: 39, Loss: 1.5385527610778809, Accuracy: 0.5439453125\n",
      "Batch: 40, Loss: 1.5516403913497925, Accuracy: 0.556640625\n",
      "Batch: 41, Loss: 1.6053786277770996, Accuracy: 0.53125\n",
      "Batch: 42, Loss: 1.3631153106689453, Accuracy: 0.572265625\n",
      "Batch: 43, Loss: 1.451120376586914, Accuracy: 0.5263671875\n",
      "Batch: 44, Loss: 1.4423381090164185, Accuracy: 0.53125\n",
      "Batch: 45, Loss: 1.336766004562378, Accuracy: 0.5537109375\n",
      "Batch: 46, Loss: 1.5371851921081543, Accuracy: 0.556640625\n",
      "Batch: 47, Loss: 1.5279839038848877, Accuracy: 0.548828125\n",
      "Batch: 48, Loss: 1.5452457666397095, Accuracy: 0.5390625\n",
      "Batch: 49, Loss: 1.6050102710723877, Accuracy: 0.501953125\n",
      "Batch: 50, Loss: 1.593945860862732, Accuracy: 0.509765625\n",
      "Batch: 51, Loss: 1.6976268291473389, Accuracy: 0.50390625\n",
      "Batch: 52, Loss: 1.6146290302276611, Accuracy: 0.5380859375\n",
      "Batch: 53, Loss: 1.4217449426651, Accuracy: 0.55078125\n",
      "Batch: 54, Loss: 1.4579057693481445, Accuracy: 0.5859375\n",
      "Batch: 55, Loss: 1.4746936559677124, Accuracy: 0.55078125\n",
      "Batch: 56, Loss: 1.564070701599121, Accuracy: 0.5224609375\n",
      "Batch: 57, Loss: 1.5426881313323975, Accuracy: 0.5517578125\n",
      "Batch: 58, Loss: 1.6563122272491455, Accuracy: 0.5146484375\n",
      "Batch: 59, Loss: 1.3765461444854736, Accuracy: 0.6083984375\n",
      "Batch: 60, Loss: 1.369639277458191, Accuracy: 0.583984375\n",
      "Batch: 61, Loss: 1.5113130807876587, Accuracy: 0.5244140625\n",
      "Batch: 62, Loss: 1.5306649208068848, Accuracy: 0.541015625\n",
      "Batch: 63, Loss: 1.482439398765564, Accuracy: 0.5439453125\n",
      "Batch: 64, Loss: 1.4481439590454102, Accuracy: 0.5615234375\n",
      "Batch: 65, Loss: 1.560449242591858, Accuracy: 0.52734375\n",
      "Batch: 66, Loss: 1.4258935451507568, Accuracy: 0.572265625\n",
      "Batch: 67, Loss: 1.558779239654541, Accuracy: 0.5341796875\n",
      "Batch: 68, Loss: 1.5839208364486694, Accuracy: 0.5576171875\n",
      "Batch: 69, Loss: 1.4871894121170044, Accuracy: 0.5517578125\n",
      "Batch: 70, Loss: 1.5564302206039429, Accuracy: 0.5380859375\n",
      "Batch: 71, Loss: 1.4980264902114868, Accuracy: 0.5458984375\n",
      "Batch: 72, Loss: 1.4169566631317139, Accuracy: 0.5732421875\n",
      "Batch: 73, Loss: 1.4730204343795776, Accuracy: 0.5712890625\n",
      "Batch: 74, Loss: 1.4064559936523438, Accuracy: 0.5771484375\n",
      "Batch: 75, Loss: 1.3593560457229614, Accuracy: 0.5849609375\n",
      "Batch: 76, Loss: 1.5279066562652588, Accuracy: 0.501953125\n",
      "Batch: 77, Loss: 1.547850489616394, Accuracy: 0.5283203125\n",
      "Batch: 78, Loss: 1.5125513076782227, Accuracy: 0.5673828125\n",
      "Batch: 79, Loss: 1.3475455045700073, Accuracy: 0.6171875\n",
      "Batch: 80, Loss: 1.3678109645843506, Accuracy: 0.5810546875\n",
      "Batch: 81, Loss: 1.5242199897766113, Accuracy: 0.50390625\n",
      "Batch: 82, Loss: 1.4769275188446045, Accuracy: 0.5478515625\n",
      "Batch: 83, Loss: 1.4094440937042236, Accuracy: 0.5830078125\n",
      "Batch: 84, Loss: 1.41901695728302, Accuracy: 0.5751953125\n",
      "Batch: 85, Loss: 1.3628458976745605, Accuracy: 0.59765625\n",
      "Batch: 86, Loss: 1.6189427375793457, Accuracy: 0.5068359375\n",
      "Batch: 87, Loss: 1.4184434413909912, Accuracy: 0.578125\n",
      "Batch: 88, Loss: 1.5687036514282227, Accuracy: 0.546875\n",
      "Batch: 89, Loss: 1.558494210243225, Accuracy: 0.5244140625\n",
      "Batch: 90, Loss: 1.408890724182129, Accuracy: 0.5634765625\n",
      "Batch: 91, Loss: 1.3899670839309692, Accuracy: 0.5712890625\n",
      "Batch: 92, Loss: 1.4973914623260498, Accuracy: 0.5419921875\n",
      "Batch: 93, Loss: 1.4584180116653442, Accuracy: 0.5634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 1.4200294017791748, Accuracy: 0.5556640625\n",
      "Batch: 95, Loss: 1.4663161039352417, Accuracy: 0.533203125\n",
      "Batch: 96, Loss: 1.4563930034637451, Accuracy: 0.5703125\n",
      "Batch: 97, Loss: 1.3286020755767822, Accuracy: 0.5947265625\n",
      "Batch: 98, Loss: 1.3879036903381348, Accuracy: 0.5888671875\n",
      "Batch: 99, Loss: 1.3605982065200806, Accuracy: 0.5693359375\n",
      "Batch: 100, Loss: 1.4290564060211182, Accuracy: 0.5556640625\n",
      "Batch: 101, Loss: 1.4605306386947632, Accuracy: 0.5390625\n",
      "Batch: 102, Loss: 1.365293264389038, Accuracy: 0.57421875\n",
      "Batch: 103, Loss: 1.5618431568145752, Accuracy: 0.5419921875\n",
      "Batch: 104, Loss: 1.3860135078430176, Accuracy: 0.5732421875\n",
      "Batch: 105, Loss: 1.4510585069656372, Accuracy: 0.546875\n",
      "Batch: 106, Loss: 1.505379319190979, Accuracy: 0.541015625\n",
      "Batch: 107, Loss: 1.5852452516555786, Accuracy: 0.5302734375\n",
      "Batch: 108, Loss: 1.556603193283081, Accuracy: 0.5361328125\n",
      "Batch: 109, Loss: 1.6031184196472168, Accuracy: 0.5078125\n",
      "Batch: 110, Loss: 1.3062794208526611, Accuracy: 0.580078125\n",
      "Batch: 111, Loss: 1.5563899278640747, Accuracy: 0.5029296875\n",
      "Batch: 112, Loss: 1.458522081375122, Accuracy: 0.578125\n",
      "Batch: 113, Loss: 1.4734513759613037, Accuracy: 0.58203125\n",
      "Batch: 114, Loss: 1.605417251586914, Accuracy: 0.5322265625\n",
      "Batch: 115, Loss: 1.6300990581512451, Accuracy: 0.544921875\n",
      "Batch: 116, Loss: 1.5828421115875244, Accuracy: 0.5205078125\n",
      "Batch: 117, Loss: 1.5558151006698608, Accuracy: 0.5419921875\n",
      "Batch: 118, Loss: 1.3144896030426025, Accuracy: 0.6142578125\n",
      "Batch: 119, Loss: 1.3837648630142212, Accuracy: 0.6025390625\n",
      "Batch: 120, Loss: 1.5047731399536133, Accuracy: 0.5244140625\n",
      "Batch: 121, Loss: 1.5506715774536133, Accuracy: 0.5458984375\n",
      "Batch: 122, Loss: 1.440778374671936, Accuracy: 0.57421875\n",
      "Batch: 123, Loss: 1.4479689598083496, Accuracy: 0.580078125\n",
      "Batch: 124, Loss: 1.4645344018936157, Accuracy: 0.5771484375\n",
      "Batch: 125, Loss: 1.5185229778289795, Accuracy: 0.5517578125\n",
      "Batch: 126, Loss: 1.4782780408859253, Accuracy: 0.5380859375\n",
      "Batch: 127, Loss: 1.4044477939605713, Accuracy: 0.5751953125\n",
      "Batch: 128, Loss: 1.6712502241134644, Accuracy: 0.5185546875\n",
      "Batch: 129, Loss: 1.4628102779388428, Accuracy: 0.5546875\n",
      "Batch: 130, Loss: 1.703191876411438, Accuracy: 0.5107421875\n",
      "Batch: 131, Loss: 1.5238449573516846, Accuracy: 0.5498046875\n",
      "Batch: 132, Loss: 1.552471399307251, Accuracy: 0.53125\n",
      "Batch: 133, Loss: 1.453343391418457, Accuracy: 0.564453125\n",
      "Batch: 134, Loss: 1.411238670349121, Accuracy: 0.560546875\n",
      "Batch: 135, Loss: 1.3730220794677734, Accuracy: 0.5810546875\n",
      "Batch: 136, Loss: 1.4241583347320557, Accuracy: 0.5712890625\n",
      "Batch: 137, Loss: 1.3345954418182373, Accuracy: 0.560546875\n",
      "Batch: 138, Loss: 1.2391124963760376, Accuracy: 0.611328125\n",
      "Batch: 139, Loss: 1.3797098398208618, Accuracy: 0.5537109375\n",
      "Batch: 140, Loss: 1.4313511848449707, Accuracy: 0.5361328125\n",
      "Batch: 141, Loss: 1.4601187705993652, Accuracy: 0.5546875\n",
      "Batch: 142, Loss: 1.459116816520691, Accuracy: 0.5556640625\n",
      "Batch: 143, Loss: 1.4947996139526367, Accuracy: 0.5341796875\n",
      "Batch: 144, Loss: 1.431408405303955, Accuracy: 0.57421875\n",
      "Batch: 145, Loss: 1.352741003036499, Accuracy: 0.5703125\n",
      "Batch: 146, Loss: 1.5276846885681152, Accuracy: 0.529296875\n",
      "Batch: 147, Loss: 1.4984921216964722, Accuracy: 0.541015625\n",
      "Batch: 148, Loss: 1.614713430404663, Accuracy: 0.4833984375\n",
      "Batch: 149, Loss: 1.48153817653656, Accuracy: 0.5224609375\n",
      "Batch: 150, Loss: 1.4089347124099731, Accuracy: 0.5703125\n",
      "Batch: 151, Loss: 1.3694844245910645, Accuracy: 0.580078125\n",
      "Epoch 6/80\n",
      "Batch: 1, Loss: 1.619484543800354, Accuracy: 0.4892578125\n",
      "Batch: 2, Loss: 1.4217480421066284, Accuracy: 0.5390625\n",
      "Batch: 3, Loss: 1.377090573310852, Accuracy: 0.5703125\n",
      "Batch: 4, Loss: 1.3242788314819336, Accuracy: 0.6201171875\n",
      "Batch: 5, Loss: 1.352562427520752, Accuracy: 0.61328125\n",
      "Batch: 6, Loss: 1.4893404245376587, Accuracy: 0.51953125\n",
      "Batch: 7, Loss: 1.4895524978637695, Accuracy: 0.5361328125\n",
      "Batch: 8, Loss: 1.353006362915039, Accuracy: 0.560546875\n",
      "Batch: 9, Loss: 1.3212380409240723, Accuracy: 0.58984375\n",
      "Batch: 10, Loss: 1.3371775150299072, Accuracy: 0.58203125\n",
      "Batch: 11, Loss: 1.4622678756713867, Accuracy: 0.529296875\n",
      "Batch: 12, Loss: 1.5076425075531006, Accuracy: 0.5302734375\n",
      "Batch: 13, Loss: 1.2211041450500488, Accuracy: 0.6396484375\n",
      "Batch: 14, Loss: 1.5324347019195557, Accuracy: 0.5263671875\n",
      "Batch: 15, Loss: 1.4281913042068481, Accuracy: 0.5830078125\n",
      "Batch: 16, Loss: 1.3622140884399414, Accuracy: 0.5732421875\n",
      "Batch: 17, Loss: 1.4694015979766846, Accuracy: 0.5419921875\n",
      "Batch: 18, Loss: 1.4696400165557861, Accuracy: 0.517578125\n",
      "Batch: 19, Loss: 1.471353530883789, Accuracy: 0.548828125\n",
      "Batch: 20, Loss: 1.4093034267425537, Accuracy: 0.599609375\n",
      "Batch: 21, Loss: 1.401353359222412, Accuracy: 0.572265625\n",
      "Batch: 22, Loss: 1.5324671268463135, Accuracy: 0.5361328125\n",
      "Batch: 23, Loss: 1.370851755142212, Accuracy: 0.560546875\n",
      "Batch: 24, Loss: 1.4774229526519775, Accuracy: 0.556640625\n",
      "Batch: 25, Loss: 1.4044482707977295, Accuracy: 0.5703125\n",
      "Batch: 26, Loss: 1.3402533531188965, Accuracy: 0.5830078125\n",
      "Batch: 27, Loss: 1.369163990020752, Accuracy: 0.556640625\n",
      "Batch: 28, Loss: 1.4402536153793335, Accuracy: 0.55078125\n",
      "Batch: 29, Loss: 1.492684006690979, Accuracy: 0.5146484375\n",
      "Batch: 30, Loss: 1.423534870147705, Accuracy: 0.5927734375\n",
      "Batch: 31, Loss: 1.4111096858978271, Accuracy: 0.5869140625\n",
      "Batch: 32, Loss: 1.3533222675323486, Accuracy: 0.5751953125\n",
      "Batch: 33, Loss: 1.5406726598739624, Accuracy: 0.533203125\n",
      "Batch: 34, Loss: 1.6126497983932495, Accuracy: 0.5146484375\n",
      "Batch: 35, Loss: 1.4671649932861328, Accuracy: 0.53515625\n",
      "Batch: 36, Loss: 1.4739305973052979, Accuracy: 0.5537109375\n",
      "Batch: 37, Loss: 1.5168263912200928, Accuracy: 0.552734375\n",
      "Batch: 38, Loss: 1.4098211526870728, Accuracy: 0.5478515625\n",
      "Batch: 39, Loss: 1.4681997299194336, Accuracy: 0.5546875\n",
      "Batch: 40, Loss: 1.4759942293167114, Accuracy: 0.5732421875\n",
      "Batch: 41, Loss: 1.5205107927322388, Accuracy: 0.5556640625\n",
      "Batch: 42, Loss: 1.298064947128296, Accuracy: 0.603515625\n",
      "Batch: 43, Loss: 1.3992083072662354, Accuracy: 0.5361328125\n",
      "Batch: 44, Loss: 1.3770562410354614, Accuracy: 0.55859375\n",
      "Batch: 45, Loss: 1.246315836906433, Accuracy: 0.607421875\n",
      "Batch: 46, Loss: 1.446535587310791, Accuracy: 0.58203125\n",
      "Batch: 47, Loss: 1.4412168264389038, Accuracy: 0.5654296875\n",
      "Batch: 48, Loss: 1.4413073062896729, Accuracy: 0.5673828125\n",
      "Batch: 49, Loss: 1.5525593757629395, Accuracy: 0.52734375\n",
      "Batch: 50, Loss: 1.521303415298462, Accuracy: 0.5234375\n",
      "Batch: 51, Loss: 1.640610933303833, Accuracy: 0.50390625\n",
      "Batch: 52, Loss: 1.5404200553894043, Accuracy: 0.5537109375\n",
      "Batch: 53, Loss: 1.343656301498413, Accuracy: 0.5810546875\n",
      "Batch: 54, Loss: 1.3709124326705933, Accuracy: 0.5927734375\n",
      "Batch: 55, Loss: 1.408582091331482, Accuracy: 0.556640625\n",
      "Batch: 56, Loss: 1.4869122505187988, Accuracy: 0.5458984375\n",
      "Batch: 57, Loss: 1.4401509761810303, Accuracy: 0.5888671875\n",
      "Batch: 58, Loss: 1.5877385139465332, Accuracy: 0.5244140625\n",
      "Batch: 59, Loss: 1.3043022155761719, Accuracy: 0.6171875\n",
      "Batch: 60, Loss: 1.3180763721466064, Accuracy: 0.5908203125\n",
      "Batch: 61, Loss: 1.4037821292877197, Accuracy: 0.5478515625\n",
      "Batch: 62, Loss: 1.4558762311935425, Accuracy: 0.560546875\n",
      "Batch: 63, Loss: 1.4439839124679565, Accuracy: 0.5498046875\n",
      "Batch: 64, Loss: 1.3816018104553223, Accuracy: 0.5712890625\n",
      "Batch: 65, Loss: 1.4611661434173584, Accuracy: 0.5556640625\n",
      "Batch: 66, Loss: 1.333143711090088, Accuracy: 0.5908203125\n",
      "Batch: 67, Loss: 1.4762094020843506, Accuracy: 0.564453125\n",
      "Batch: 68, Loss: 1.5003345012664795, Accuracy: 0.5673828125\n",
      "Batch: 69, Loss: 1.4177258014678955, Accuracy: 0.5595703125\n",
      "Batch: 70, Loss: 1.5049335956573486, Accuracy: 0.5546875\n",
      "Batch: 71, Loss: 1.4390511512756348, Accuracy: 0.568359375\n",
      "Batch: 72, Loss: 1.3199596405029297, Accuracy: 0.5830078125\n",
      "Batch: 73, Loss: 1.3982462882995605, Accuracy: 0.5849609375\n",
      "Batch: 74, Loss: 1.3303513526916504, Accuracy: 0.5966796875\n",
      "Batch: 75, Loss: 1.3018205165863037, Accuracy: 0.6064453125\n",
      "Batch: 76, Loss: 1.4579839706420898, Accuracy: 0.53125\n",
      "Batch: 77, Loss: 1.4735937118530273, Accuracy: 0.5400390625\n",
      "Batch: 78, Loss: 1.397096872329712, Accuracy: 0.6044921875\n",
      "Batch: 79, Loss: 1.2797300815582275, Accuracy: 0.6337890625\n",
      "Batch: 80, Loss: 1.2917704582214355, Accuracy: 0.5966796875\n",
      "Batch: 81, Loss: 1.46797513961792, Accuracy: 0.529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 1.4108070135116577, Accuracy: 0.552734375\n",
      "Batch: 83, Loss: 1.318598985671997, Accuracy: 0.6103515625\n",
      "Batch: 84, Loss: 1.3459817171096802, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.2908856868743896, Accuracy: 0.6103515625\n",
      "Batch: 86, Loss: 1.5307512283325195, Accuracy: 0.53515625\n",
      "Batch: 87, Loss: 1.3376089334487915, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.5071601867675781, Accuracy: 0.552734375\n",
      "Batch: 89, Loss: 1.4623116254806519, Accuracy: 0.54296875\n",
      "Batch: 90, Loss: 1.3433815240859985, Accuracy: 0.591796875\n",
      "Batch: 91, Loss: 1.3428337574005127, Accuracy: 0.5908203125\n",
      "Batch: 92, Loss: 1.4162847995758057, Accuracy: 0.546875\n",
      "Batch: 93, Loss: 1.3694732189178467, Accuracy: 0.5751953125\n",
      "Batch: 94, Loss: 1.3602180480957031, Accuracy: 0.5625\n",
      "Batch: 95, Loss: 1.3758916854858398, Accuracy: 0.5615234375\n",
      "Batch: 96, Loss: 1.3544631004333496, Accuracy: 0.595703125\n",
      "Batch: 97, Loss: 1.212435007095337, Accuracy: 0.6259765625\n",
      "Batch: 98, Loss: 1.3307147026062012, Accuracy: 0.6123046875\n",
      "Batch: 99, Loss: 1.2684193849563599, Accuracy: 0.6142578125\n",
      "Batch: 100, Loss: 1.3638782501220703, Accuracy: 0.5791015625\n",
      "Batch: 101, Loss: 1.4092626571655273, Accuracy: 0.5478515625\n",
      "Batch: 102, Loss: 1.314676284790039, Accuracy: 0.5986328125\n",
      "Batch: 103, Loss: 1.4620009660720825, Accuracy: 0.5693359375\n",
      "Batch: 104, Loss: 1.3062376976013184, Accuracy: 0.5986328125\n",
      "Batch: 105, Loss: 1.4021384716033936, Accuracy: 0.552734375\n",
      "Batch: 106, Loss: 1.422227382659912, Accuracy: 0.552734375\n",
      "Batch: 107, Loss: 1.5260236263275146, Accuracy: 0.53515625\n",
      "Batch: 108, Loss: 1.5016697645187378, Accuracy: 0.533203125\n",
      "Batch: 109, Loss: 1.5129626989364624, Accuracy: 0.5283203125\n",
      "Batch: 110, Loss: 1.2152369022369385, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.4784586429595947, Accuracy: 0.5498046875\n",
      "Batch: 112, Loss: 1.419190526008606, Accuracy: 0.57421875\n",
      "Batch: 113, Loss: 1.4359605312347412, Accuracy: 0.607421875\n",
      "Batch: 114, Loss: 1.5552129745483398, Accuracy: 0.5439453125\n",
      "Batch: 115, Loss: 1.5604171752929688, Accuracy: 0.5546875\n",
      "Batch: 116, Loss: 1.4961636066436768, Accuracy: 0.5400390625\n",
      "Batch: 117, Loss: 1.5057615041732788, Accuracy: 0.564453125\n",
      "Batch: 118, Loss: 1.2533154487609863, Accuracy: 0.625\n",
      "Batch: 119, Loss: 1.3293683528900146, Accuracy: 0.6103515625\n",
      "Batch: 120, Loss: 1.4744564294815063, Accuracy: 0.5419921875\n",
      "Batch: 121, Loss: 1.49448823928833, Accuracy: 0.5400390625\n",
      "Batch: 122, Loss: 1.363492488861084, Accuracy: 0.5966796875\n",
      "Batch: 123, Loss: 1.392670750617981, Accuracy: 0.5859375\n",
      "Batch: 124, Loss: 1.4116743803024292, Accuracy: 0.578125\n",
      "Batch: 125, Loss: 1.4734200239181519, Accuracy: 0.5517578125\n",
      "Batch: 126, Loss: 1.4278554916381836, Accuracy: 0.5625\n",
      "Batch: 127, Loss: 1.3388562202453613, Accuracy: 0.6142578125\n",
      "Batch: 128, Loss: 1.583366870880127, Accuracy: 0.5361328125\n",
      "Batch: 129, Loss: 1.3730952739715576, Accuracy: 0.564453125\n",
      "Batch: 130, Loss: 1.656858205795288, Accuracy: 0.515625\n",
      "Batch: 131, Loss: 1.4603369235992432, Accuracy: 0.564453125\n",
      "Batch: 132, Loss: 1.4906442165374756, Accuracy: 0.5546875\n",
      "Batch: 133, Loss: 1.3712010383605957, Accuracy: 0.587890625\n",
      "Batch: 134, Loss: 1.383716344833374, Accuracy: 0.57421875\n",
      "Batch: 135, Loss: 1.3395822048187256, Accuracy: 0.607421875\n",
      "Batch: 136, Loss: 1.3545317649841309, Accuracy: 0.591796875\n",
      "Batch: 137, Loss: 1.3148396015167236, Accuracy: 0.5732421875\n",
      "Batch: 138, Loss: 1.1891684532165527, Accuracy: 0.6201171875\n",
      "Batch: 139, Loss: 1.3088369369506836, Accuracy: 0.578125\n",
      "Batch: 140, Loss: 1.3560938835144043, Accuracy: 0.568359375\n",
      "Batch: 141, Loss: 1.420804738998413, Accuracy: 0.5712890625\n",
      "Batch: 142, Loss: 1.4134142398834229, Accuracy: 0.57421875\n",
      "Batch: 143, Loss: 1.419944405555725, Accuracy: 0.5546875\n",
      "Batch: 144, Loss: 1.3619786500930786, Accuracy: 0.5869140625\n",
      "Batch: 145, Loss: 1.2793331146240234, Accuracy: 0.5908203125\n",
      "Batch: 146, Loss: 1.4544692039489746, Accuracy: 0.541015625\n",
      "Batch: 147, Loss: 1.421058177947998, Accuracy: 0.5732421875\n",
      "Batch: 148, Loss: 1.531952977180481, Accuracy: 0.5048828125\n",
      "Batch: 149, Loss: 1.4086600542068481, Accuracy: 0.556640625\n",
      "Batch: 150, Loss: 1.3367207050323486, Accuracy: 0.57421875\n",
      "Batch: 151, Loss: 1.2892467975616455, Accuracy: 0.607421875\n",
      "Epoch 7/80\n",
      "Batch: 1, Loss: 1.5950255393981934, Accuracy: 0.48828125\n",
      "Batch: 2, Loss: 1.368929386138916, Accuracy: 0.54296875\n",
      "Batch: 3, Loss: 1.310040831565857, Accuracy: 0.5927734375\n",
      "Batch: 4, Loss: 1.2406178712844849, Accuracy: 0.625\n",
      "Batch: 5, Loss: 1.271744728088379, Accuracy: 0.6123046875\n",
      "Batch: 6, Loss: 1.4070357084274292, Accuracy: 0.5439453125\n",
      "Batch: 7, Loss: 1.4111384153366089, Accuracy: 0.55078125\n",
      "Batch: 8, Loss: 1.2781150341033936, Accuracy: 0.5771484375\n",
      "Batch: 9, Loss: 1.2487900257110596, Accuracy: 0.607421875\n",
      "Batch: 10, Loss: 1.2801965475082397, Accuracy: 0.595703125\n",
      "Batch: 11, Loss: 1.416764259338379, Accuracy: 0.5322265625\n",
      "Batch: 12, Loss: 1.4626245498657227, Accuracy: 0.5361328125\n",
      "Batch: 13, Loss: 1.1677906513214111, Accuracy: 0.646484375\n",
      "Batch: 14, Loss: 1.4646440744400024, Accuracy: 0.5341796875\n",
      "Batch: 15, Loss: 1.3563885688781738, Accuracy: 0.6015625\n",
      "Batch: 16, Loss: 1.3138116598129272, Accuracy: 0.5888671875\n",
      "Batch: 17, Loss: 1.4051891565322876, Accuracy: 0.5576171875\n",
      "Batch: 18, Loss: 1.4090453386306763, Accuracy: 0.55078125\n",
      "Batch: 19, Loss: 1.4240808486938477, Accuracy: 0.5634765625\n",
      "Batch: 20, Loss: 1.32979154586792, Accuracy: 0.609375\n",
      "Batch: 21, Loss: 1.327075719833374, Accuracy: 0.5849609375\n",
      "Batch: 22, Loss: 1.452026128768921, Accuracy: 0.5673828125\n",
      "Batch: 23, Loss: 1.2935460805892944, Accuracy: 0.5771484375\n",
      "Batch: 24, Loss: 1.3690736293792725, Accuracy: 0.5673828125\n",
      "Batch: 25, Loss: 1.343950867652893, Accuracy: 0.5859375\n",
      "Batch: 26, Loss: 1.2654049396514893, Accuracy: 0.6103515625\n",
      "Batch: 27, Loss: 1.2913681268692017, Accuracy: 0.591796875\n",
      "Batch: 28, Loss: 1.3932645320892334, Accuracy: 0.548828125\n",
      "Batch: 29, Loss: 1.420609474182129, Accuracy: 0.5458984375\n",
      "Batch: 30, Loss: 1.3811039924621582, Accuracy: 0.6044921875\n",
      "Batch: 31, Loss: 1.3394744396209717, Accuracy: 0.6083984375\n",
      "Batch: 32, Loss: 1.275294303894043, Accuracy: 0.5927734375\n",
      "Batch: 33, Loss: 1.4816365242004395, Accuracy: 0.546875\n",
      "Batch: 34, Loss: 1.5435082912445068, Accuracy: 0.5341796875\n",
      "Batch: 35, Loss: 1.3872771263122559, Accuracy: 0.560546875\n",
      "Batch: 36, Loss: 1.3971095085144043, Accuracy: 0.5888671875\n",
      "Batch: 37, Loss: 1.4444057941436768, Accuracy: 0.578125\n",
      "Batch: 38, Loss: 1.3551307916641235, Accuracy: 0.5576171875\n",
      "Batch: 39, Loss: 1.4332518577575684, Accuracy: 0.5595703125\n",
      "Batch: 40, Loss: 1.4026703834533691, Accuracy: 0.587890625\n",
      "Batch: 41, Loss: 1.4268192052841187, Accuracy: 0.5693359375\n",
      "Batch: 42, Loss: 1.1995611190795898, Accuracy: 0.6259765625\n",
      "Batch: 43, Loss: 1.3264572620391846, Accuracy: 0.568359375\n",
      "Batch: 44, Loss: 1.3338072299957275, Accuracy: 0.55078125\n",
      "Batch: 45, Loss: 1.1967368125915527, Accuracy: 0.6103515625\n",
      "Batch: 46, Loss: 1.346390962600708, Accuracy: 0.5986328125\n",
      "Batch: 47, Loss: 1.3744266033172607, Accuracy: 0.5830078125\n",
      "Batch: 48, Loss: 1.3573997020721436, Accuracy: 0.58984375\n",
      "Batch: 49, Loss: 1.4617400169372559, Accuracy: 0.5517578125\n",
      "Batch: 50, Loss: 1.4032440185546875, Accuracy: 0.560546875\n",
      "Batch: 51, Loss: 1.5555940866470337, Accuracy: 0.5146484375\n",
      "Batch: 52, Loss: 1.4938799142837524, Accuracy: 0.5517578125\n",
      "Batch: 53, Loss: 1.2751011848449707, Accuracy: 0.609375\n",
      "Batch: 54, Loss: 1.3305020332336426, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.3825628757476807, Accuracy: 0.5615234375\n",
      "Batch: 56, Loss: 1.4079999923706055, Accuracy: 0.572265625\n",
      "Batch: 57, Loss: 1.3803493976593018, Accuracy: 0.5947265625\n",
      "Batch: 58, Loss: 1.4864819049835205, Accuracy: 0.556640625\n",
      "Batch: 59, Loss: 1.2234022617340088, Accuracy: 0.6279296875\n",
      "Batch: 60, Loss: 1.2336626052856445, Accuracy: 0.62109375\n",
      "Batch: 61, Loss: 1.3581725358963013, Accuracy: 0.5595703125\n",
      "Batch: 62, Loss: 1.3662530183792114, Accuracy: 0.572265625\n",
      "Batch: 63, Loss: 1.34136962890625, Accuracy: 0.576171875\n",
      "Batch: 64, Loss: 1.3127611875534058, Accuracy: 0.587890625\n",
      "Batch: 65, Loss: 1.4043433666229248, Accuracy: 0.578125\n",
      "Batch: 66, Loss: 1.2859923839569092, Accuracy: 0.611328125\n",
      "Batch: 67, Loss: 1.445047378540039, Accuracy: 0.5732421875\n",
      "Batch: 68, Loss: 1.4596269130706787, Accuracy: 0.58984375\n",
      "Batch: 69, Loss: 1.3493465185165405, Accuracy: 0.5986328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.3989708423614502, Accuracy: 0.5791015625\n",
      "Batch: 71, Loss: 1.3839071989059448, Accuracy: 0.572265625\n",
      "Batch: 72, Loss: 1.2731423377990723, Accuracy: 0.603515625\n",
      "Batch: 73, Loss: 1.3265376091003418, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.2758862972259521, Accuracy: 0.6005859375\n",
      "Batch: 75, Loss: 1.2114760875701904, Accuracy: 0.615234375\n",
      "Batch: 76, Loss: 1.3910715579986572, Accuracy: 0.5419921875\n",
      "Batch: 77, Loss: 1.3978875875473022, Accuracy: 0.572265625\n",
      "Batch: 78, Loss: 1.3412957191467285, Accuracy: 0.6015625\n",
      "Batch: 79, Loss: 1.218963861465454, Accuracy: 0.6513671875\n",
      "Batch: 80, Loss: 1.2435712814331055, Accuracy: 0.5986328125\n",
      "Batch: 81, Loss: 1.4092975854873657, Accuracy: 0.54296875\n",
      "Batch: 82, Loss: 1.3683292865753174, Accuracy: 0.564453125\n",
      "Batch: 83, Loss: 1.224442958831787, Accuracy: 0.6328125\n",
      "Batch: 84, Loss: 1.2746552228927612, Accuracy: 0.6181640625\n",
      "Batch: 85, Loss: 1.2095915079116821, Accuracy: 0.626953125\n",
      "Batch: 86, Loss: 1.4968771934509277, Accuracy: 0.5361328125\n",
      "Batch: 87, Loss: 1.2752457857131958, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.432037353515625, Accuracy: 0.5908203125\n",
      "Batch: 89, Loss: 1.4093751907348633, Accuracy: 0.5810546875\n",
      "Batch: 90, Loss: 1.2909371852874756, Accuracy: 0.5888671875\n",
      "Batch: 91, Loss: 1.2939159870147705, Accuracy: 0.595703125\n",
      "Batch: 92, Loss: 1.3655868768692017, Accuracy: 0.58203125\n",
      "Batch: 93, Loss: 1.2758653163909912, Accuracy: 0.6005859375\n",
      "Batch: 94, Loss: 1.294069766998291, Accuracy: 0.58984375\n",
      "Batch: 95, Loss: 1.3526813983917236, Accuracy: 0.57421875\n",
      "Batch: 96, Loss: 1.3094857931137085, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.1706362962722778, Accuracy: 0.640625\n",
      "Batch: 98, Loss: 1.2685589790344238, Accuracy: 0.6298828125\n",
      "Batch: 99, Loss: 1.2173566818237305, Accuracy: 0.6220703125\n",
      "Batch: 100, Loss: 1.288958191871643, Accuracy: 0.61328125\n",
      "Batch: 101, Loss: 1.3639781475067139, Accuracy: 0.56640625\n",
      "Batch: 102, Loss: 1.2505894899368286, Accuracy: 0.599609375\n",
      "Batch: 103, Loss: 1.3810901641845703, Accuracy: 0.5927734375\n",
      "Batch: 104, Loss: 1.2470414638519287, Accuracy: 0.609375\n",
      "Batch: 105, Loss: 1.344763994216919, Accuracy: 0.5693359375\n",
      "Batch: 106, Loss: 1.3719074726104736, Accuracy: 0.5732421875\n",
      "Batch: 107, Loss: 1.4619694948196411, Accuracy: 0.552734375\n",
      "Batch: 108, Loss: 1.4258172512054443, Accuracy: 0.5751953125\n",
      "Batch: 109, Loss: 1.4510422945022583, Accuracy: 0.5361328125\n",
      "Batch: 110, Loss: 1.1934573650360107, Accuracy: 0.6181640625\n",
      "Batch: 111, Loss: 1.4196410179138184, Accuracy: 0.556640625\n",
      "Batch: 112, Loss: 1.3275293111801147, Accuracy: 0.603515625\n",
      "Batch: 113, Loss: 1.3761308193206787, Accuracy: 0.6044921875\n",
      "Batch: 114, Loss: 1.4726370573043823, Accuracy: 0.5576171875\n",
      "Batch: 115, Loss: 1.5055651664733887, Accuracy: 0.55078125\n",
      "Batch: 116, Loss: 1.4636478424072266, Accuracy: 0.5546875\n",
      "Batch: 117, Loss: 1.4288969039916992, Accuracy: 0.580078125\n",
      "Batch: 118, Loss: 1.2009572982788086, Accuracy: 0.63671875\n",
      "Batch: 119, Loss: 1.2598797082901, Accuracy: 0.626953125\n",
      "Batch: 120, Loss: 1.4103143215179443, Accuracy: 0.5576171875\n",
      "Batch: 121, Loss: 1.4400311708450317, Accuracy: 0.5615234375\n",
      "Batch: 122, Loss: 1.2939828634262085, Accuracy: 0.6171875\n",
      "Batch: 123, Loss: 1.3245607614517212, Accuracy: 0.6015625\n",
      "Batch: 124, Loss: 1.3457229137420654, Accuracy: 0.6005859375\n",
      "Batch: 125, Loss: 1.411461591720581, Accuracy: 0.5771484375\n",
      "Batch: 126, Loss: 1.370079755783081, Accuracy: 0.5615234375\n",
      "Batch: 127, Loss: 1.2475895881652832, Accuracy: 0.6298828125\n",
      "Batch: 128, Loss: 1.5200201272964478, Accuracy: 0.560546875\n",
      "Batch: 129, Loss: 1.3138344287872314, Accuracy: 0.58984375\n",
      "Batch: 130, Loss: 1.570430874824524, Accuracy: 0.521484375\n",
      "Batch: 131, Loss: 1.378193974494934, Accuracy: 0.5888671875\n",
      "Batch: 132, Loss: 1.4384756088256836, Accuracy: 0.5693359375\n",
      "Batch: 133, Loss: 1.2892048358917236, Accuracy: 0.587890625\n",
      "Batch: 134, Loss: 1.3199368715286255, Accuracy: 0.5732421875\n",
      "Batch: 135, Loss: 1.2516871690750122, Accuracy: 0.6103515625\n",
      "Batch: 136, Loss: 1.3025283813476562, Accuracy: 0.6025390625\n",
      "Batch: 137, Loss: 1.246044635772705, Accuracy: 0.5830078125\n",
      "Batch: 138, Loss: 1.1319668292999268, Accuracy: 0.62890625\n",
      "Batch: 139, Loss: 1.2645329236984253, Accuracy: 0.6025390625\n",
      "Batch: 140, Loss: 1.3230901956558228, Accuracy: 0.580078125\n",
      "Batch: 141, Loss: 1.3363310098648071, Accuracy: 0.5966796875\n",
      "Batch: 142, Loss: 1.3368504047393799, Accuracy: 0.5869140625\n",
      "Batch: 143, Loss: 1.3713732957839966, Accuracy: 0.576171875\n",
      "Batch: 144, Loss: 1.3377487659454346, Accuracy: 0.587890625\n",
      "Batch: 145, Loss: 1.25022292137146, Accuracy: 0.5888671875\n",
      "Batch: 146, Loss: 1.4085299968719482, Accuracy: 0.5654296875\n",
      "Batch: 147, Loss: 1.3805934190750122, Accuracy: 0.5693359375\n",
      "Batch: 148, Loss: 1.4793579578399658, Accuracy: 0.51953125\n",
      "Batch: 149, Loss: 1.3604263067245483, Accuracy: 0.5712890625\n",
      "Batch: 150, Loss: 1.2755341529846191, Accuracy: 0.595703125\n",
      "Batch: 151, Loss: 1.2271294593811035, Accuracy: 0.6259765625\n",
      "Epoch 8/80\n",
      "Batch: 1, Loss: 1.5519675016403198, Accuracy: 0.5185546875\n",
      "Batch: 2, Loss: 1.311812162399292, Accuracy: 0.5595703125\n",
      "Batch: 3, Loss: 1.2735655307769775, Accuracy: 0.6015625\n",
      "Batch: 4, Loss: 1.2101876735687256, Accuracy: 0.63671875\n",
      "Batch: 5, Loss: 1.2346704006195068, Accuracy: 0.6259765625\n",
      "Batch: 6, Loss: 1.3529305458068848, Accuracy: 0.552734375\n",
      "Batch: 7, Loss: 1.3220252990722656, Accuracy: 0.5751953125\n",
      "Batch: 8, Loss: 1.2356586456298828, Accuracy: 0.5927734375\n",
      "Batch: 9, Loss: 1.1937286853790283, Accuracy: 0.6181640625\n",
      "Batch: 10, Loss: 1.2136064767837524, Accuracy: 0.611328125\n",
      "Batch: 11, Loss: 1.3907111883163452, Accuracy: 0.541015625\n",
      "Batch: 12, Loss: 1.3928277492523193, Accuracy: 0.5615234375\n",
      "Batch: 13, Loss: 1.1335092782974243, Accuracy: 0.6474609375\n",
      "Batch: 14, Loss: 1.4186872243881226, Accuracy: 0.548828125\n",
      "Batch: 15, Loss: 1.3050248622894287, Accuracy: 0.609375\n",
      "Batch: 16, Loss: 1.2653088569641113, Accuracy: 0.607421875\n",
      "Batch: 17, Loss: 1.3720265626907349, Accuracy: 0.5634765625\n",
      "Batch: 18, Loss: 1.3337626457214355, Accuracy: 0.5703125\n",
      "Batch: 19, Loss: 1.3800654411315918, Accuracy: 0.587890625\n",
      "Batch: 20, Loss: 1.2825814485549927, Accuracy: 0.6171875\n",
      "Batch: 21, Loss: 1.2878804206848145, Accuracy: 0.60546875\n",
      "Batch: 22, Loss: 1.3917160034179688, Accuracy: 0.5830078125\n",
      "Batch: 23, Loss: 1.2440001964569092, Accuracy: 0.5986328125\n",
      "Batch: 24, Loss: 1.3435909748077393, Accuracy: 0.5830078125\n",
      "Batch: 25, Loss: 1.3055591583251953, Accuracy: 0.599609375\n",
      "Batch: 26, Loss: 1.2003408670425415, Accuracy: 0.619140625\n",
      "Batch: 27, Loss: 1.2415344715118408, Accuracy: 0.6044921875\n",
      "Batch: 28, Loss: 1.3262317180633545, Accuracy: 0.5732421875\n",
      "Batch: 29, Loss: 1.3394737243652344, Accuracy: 0.583984375\n",
      "Batch: 30, Loss: 1.2990527153015137, Accuracy: 0.6279296875\n",
      "Batch: 31, Loss: 1.2765910625457764, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.221574306488037, Accuracy: 0.6123046875\n",
      "Batch: 33, Loss: 1.4217121601104736, Accuracy: 0.5625\n",
      "Batch: 34, Loss: 1.4892635345458984, Accuracy: 0.5576171875\n",
      "Batch: 35, Loss: 1.315057396888733, Accuracy: 0.58203125\n",
      "Batch: 36, Loss: 1.3594707250595093, Accuracy: 0.5888671875\n",
      "Batch: 37, Loss: 1.373622179031372, Accuracy: 0.5908203125\n",
      "Batch: 38, Loss: 1.3272002935409546, Accuracy: 0.5810546875\n",
      "Batch: 39, Loss: 1.3570424318313599, Accuracy: 0.5859375\n",
      "Batch: 40, Loss: 1.3552634716033936, Accuracy: 0.5966796875\n",
      "Batch: 41, Loss: 1.3996037244796753, Accuracy: 0.591796875\n",
      "Batch: 42, Loss: 1.1395306587219238, Accuracy: 0.646484375\n",
      "Batch: 43, Loss: 1.292593240737915, Accuracy: 0.576171875\n",
      "Batch: 44, Loss: 1.2820069789886475, Accuracy: 0.578125\n",
      "Batch: 45, Loss: 1.1428630352020264, Accuracy: 0.6171875\n",
      "Batch: 46, Loss: 1.2990913391113281, Accuracy: 0.607421875\n",
      "Batch: 47, Loss: 1.333991289138794, Accuracy: 0.603515625\n",
      "Batch: 48, Loss: 1.2822048664093018, Accuracy: 0.6005859375\n",
      "Batch: 49, Loss: 1.4349281787872314, Accuracy: 0.5634765625\n",
      "Batch: 50, Loss: 1.3636517524719238, Accuracy: 0.5654296875\n",
      "Batch: 51, Loss: 1.4819775819778442, Accuracy: 0.544921875\n",
      "Batch: 52, Loss: 1.425675630569458, Accuracy: 0.572265625\n",
      "Batch: 53, Loss: 1.1945359706878662, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.2730365991592407, Accuracy: 0.6171875\n",
      "Batch: 55, Loss: 1.311166524887085, Accuracy: 0.5830078125\n",
      "Batch: 56, Loss: 1.358612298965454, Accuracy: 0.57421875\n",
      "Batch: 57, Loss: 1.3676154613494873, Accuracy: 0.5927734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.4460537433624268, Accuracy: 0.5625\n",
      "Batch: 59, Loss: 1.1704623699188232, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.1729551553726196, Accuracy: 0.62890625\n",
      "Batch: 61, Loss: 1.311226487159729, Accuracy: 0.5849609375\n",
      "Batch: 62, Loss: 1.2926928997039795, Accuracy: 0.6142578125\n",
      "Batch: 63, Loss: 1.3075578212738037, Accuracy: 0.5849609375\n",
      "Batch: 64, Loss: 1.2688720226287842, Accuracy: 0.5888671875\n",
      "Batch: 65, Loss: 1.3190802335739136, Accuracy: 0.587890625\n",
      "Batch: 66, Loss: 1.223578929901123, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.3487756252288818, Accuracy: 0.583984375\n",
      "Batch: 68, Loss: 1.3817226886749268, Accuracy: 0.5927734375\n",
      "Batch: 69, Loss: 1.3007519245147705, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.389897108078003, Accuracy: 0.5908203125\n",
      "Batch: 71, Loss: 1.3467179536819458, Accuracy: 0.583984375\n",
      "Batch: 72, Loss: 1.21665620803833, Accuracy: 0.6142578125\n",
      "Batch: 73, Loss: 1.2627640962600708, Accuracy: 0.60546875\n",
      "Batch: 74, Loss: 1.2373268604278564, Accuracy: 0.60546875\n",
      "Batch: 75, Loss: 1.1562832593917847, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.3194093704223633, Accuracy: 0.560546875\n",
      "Batch: 77, Loss: 1.3496744632720947, Accuracy: 0.5927734375\n",
      "Batch: 78, Loss: 1.2938847541809082, Accuracy: 0.615234375\n",
      "Batch: 79, Loss: 1.1721069812774658, Accuracy: 0.65625\n",
      "Batch: 80, Loss: 1.1919488906860352, Accuracy: 0.609375\n",
      "Batch: 81, Loss: 1.3579672574996948, Accuracy: 0.5576171875\n",
      "Batch: 82, Loss: 1.3181524276733398, Accuracy: 0.576171875\n",
      "Batch: 83, Loss: 1.155633568763733, Accuracy: 0.6494140625\n",
      "Batch: 84, Loss: 1.2425984144210815, Accuracy: 0.63671875\n",
      "Batch: 85, Loss: 1.1845958232879639, Accuracy: 0.6279296875\n",
      "Batch: 86, Loss: 1.450974464416504, Accuracy: 0.552734375\n",
      "Batch: 87, Loss: 1.24074387550354, Accuracy: 0.62890625\n",
      "Batch: 88, Loss: 1.366867184638977, Accuracy: 0.5986328125\n",
      "Batch: 89, Loss: 1.3219927549362183, Accuracy: 0.5966796875\n",
      "Batch: 90, Loss: 1.2089749574661255, Accuracy: 0.62109375\n",
      "Batch: 91, Loss: 1.2311210632324219, Accuracy: 0.62109375\n",
      "Batch: 92, Loss: 1.313169002532959, Accuracy: 0.5947265625\n",
      "Batch: 93, Loss: 1.2367959022521973, Accuracy: 0.609375\n",
      "Batch: 94, Loss: 1.2452900409698486, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.2829581499099731, Accuracy: 0.5693359375\n",
      "Batch: 96, Loss: 1.2702062129974365, Accuracy: 0.607421875\n",
      "Batch: 97, Loss: 1.146711826324463, Accuracy: 0.638671875\n",
      "Batch: 98, Loss: 1.1956431865692139, Accuracy: 0.64453125\n",
      "Batch: 99, Loss: 1.1753389835357666, Accuracy: 0.650390625\n",
      "Batch: 100, Loss: 1.2572989463806152, Accuracy: 0.6083984375\n",
      "Batch: 101, Loss: 1.3217012882232666, Accuracy: 0.5810546875\n",
      "Batch: 102, Loss: 1.209348201751709, Accuracy: 0.6162109375\n",
      "Batch: 103, Loss: 1.3344197273254395, Accuracy: 0.607421875\n",
      "Batch: 104, Loss: 1.1951920986175537, Accuracy: 0.62890625\n",
      "Batch: 105, Loss: 1.3047468662261963, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.2970300912857056, Accuracy: 0.6083984375\n",
      "Batch: 107, Loss: 1.4013025760650635, Accuracy: 0.5634765625\n",
      "Batch: 108, Loss: 1.3691215515136719, Accuracy: 0.568359375\n",
      "Batch: 109, Loss: 1.4216649532318115, Accuracy: 0.5498046875\n",
      "Batch: 110, Loss: 1.1154401302337646, Accuracy: 0.642578125\n",
      "Batch: 111, Loss: 1.3799808025360107, Accuracy: 0.5595703125\n",
      "Batch: 112, Loss: 1.327307105064392, Accuracy: 0.6025390625\n",
      "Batch: 113, Loss: 1.3035203218460083, Accuracy: 0.6181640625\n",
      "Batch: 114, Loss: 1.437807321548462, Accuracy: 0.556640625\n",
      "Batch: 115, Loss: 1.4228339195251465, Accuracy: 0.591796875\n",
      "Batch: 116, Loss: 1.3867406845092773, Accuracy: 0.5673828125\n",
      "Batch: 117, Loss: 1.3661686182022095, Accuracy: 0.580078125\n",
      "Batch: 118, Loss: 1.1415077447891235, Accuracy: 0.6494140625\n",
      "Batch: 119, Loss: 1.2108397483825684, Accuracy: 0.6357421875\n",
      "Batch: 120, Loss: 1.352407693862915, Accuracy: 0.564453125\n",
      "Batch: 121, Loss: 1.37691068649292, Accuracy: 0.5732421875\n",
      "Batch: 122, Loss: 1.2512736320495605, Accuracy: 0.6298828125\n",
      "Batch: 123, Loss: 1.2682329416275024, Accuracy: 0.6181640625\n",
      "Batch: 124, Loss: 1.3132069110870361, Accuracy: 0.607421875\n",
      "Batch: 125, Loss: 1.3342041969299316, Accuracy: 0.5810546875\n",
      "Batch: 126, Loss: 1.3191851377487183, Accuracy: 0.564453125\n",
      "Batch: 127, Loss: 1.190382480621338, Accuracy: 0.6494140625\n",
      "Batch: 128, Loss: 1.4448773860931396, Accuracy: 0.5712890625\n",
      "Batch: 129, Loss: 1.276249647140503, Accuracy: 0.5986328125\n",
      "Batch: 130, Loss: 1.542510747909546, Accuracy: 0.5205078125\n",
      "Batch: 131, Loss: 1.341407060623169, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.3871057033538818, Accuracy: 0.578125\n",
      "Batch: 133, Loss: 1.2299696207046509, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.2791752815246582, Accuracy: 0.5966796875\n",
      "Batch: 135, Loss: 1.221685528755188, Accuracy: 0.611328125\n",
      "Batch: 136, Loss: 1.26112961769104, Accuracy: 0.5966796875\n",
      "Batch: 137, Loss: 1.1902101039886475, Accuracy: 0.5888671875\n",
      "Batch: 138, Loss: 1.0820086002349854, Accuracy: 0.640625\n",
      "Batch: 139, Loss: 1.1836378574371338, Accuracy: 0.611328125\n",
      "Batch: 140, Loss: 1.2947304248809814, Accuracy: 0.5859375\n",
      "Batch: 141, Loss: 1.2942557334899902, Accuracy: 0.59375\n",
      "Batch: 142, Loss: 1.3002727031707764, Accuracy: 0.5849609375\n",
      "Batch: 143, Loss: 1.3338923454284668, Accuracy: 0.57421875\n",
      "Batch: 144, Loss: 1.2621943950653076, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.2022240161895752, Accuracy: 0.5986328125\n",
      "Batch: 146, Loss: 1.3707486391067505, Accuracy: 0.572265625\n",
      "Batch: 147, Loss: 1.3119475841522217, Accuracy: 0.59375\n",
      "Batch: 148, Loss: 1.4259912967681885, Accuracy: 0.5390625\n",
      "Batch: 149, Loss: 1.3041362762451172, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.2274606227874756, Accuracy: 0.6181640625\n",
      "Batch: 151, Loss: 1.1778655052185059, Accuracy: 0.6337890625\n",
      "Epoch 9/80\n",
      "Batch: 1, Loss: 1.5076725482940674, Accuracy: 0.529296875\n",
      "Batch: 2, Loss: 1.2974474430084229, Accuracy: 0.5634765625\n",
      "Batch: 3, Loss: 1.2191009521484375, Accuracy: 0.611328125\n",
      "Batch: 4, Loss: 1.1632375717163086, Accuracy: 0.6591796875\n",
      "Batch: 5, Loss: 1.1730115413665771, Accuracy: 0.6396484375\n",
      "Batch: 6, Loss: 1.3230191469192505, Accuracy: 0.58203125\n",
      "Batch: 7, Loss: 1.2964389324188232, Accuracy: 0.587890625\n",
      "Batch: 8, Loss: 1.1987764835357666, Accuracy: 0.6142578125\n",
      "Batch: 9, Loss: 1.1678476333618164, Accuracy: 0.6376953125\n",
      "Batch: 10, Loss: 1.1866146326065063, Accuracy: 0.623046875\n",
      "Batch: 11, Loss: 1.3213708400726318, Accuracy: 0.576171875\n",
      "Batch: 12, Loss: 1.3594675064086914, Accuracy: 0.572265625\n",
      "Batch: 13, Loss: 1.0863145589828491, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 1.3765006065368652, Accuracy: 0.572265625\n",
      "Batch: 15, Loss: 1.2541481256484985, Accuracy: 0.6259765625\n",
      "Batch: 16, Loss: 1.2408051490783691, Accuracy: 0.62109375\n",
      "Batch: 17, Loss: 1.319625973701477, Accuracy: 0.580078125\n",
      "Batch: 18, Loss: 1.326843500137329, Accuracy: 0.5859375\n",
      "Batch: 19, Loss: 1.363034963607788, Accuracy: 0.5791015625\n",
      "Batch: 20, Loss: 1.2560477256774902, Accuracy: 0.6103515625\n",
      "Batch: 21, Loss: 1.2542697191238403, Accuracy: 0.6025390625\n",
      "Batch: 22, Loss: 1.372586965560913, Accuracy: 0.568359375\n",
      "Batch: 23, Loss: 1.1995607614517212, Accuracy: 0.6123046875\n",
      "Batch: 24, Loss: 1.2970702648162842, Accuracy: 0.583984375\n",
      "Batch: 25, Loss: 1.2575680017471313, Accuracy: 0.6142578125\n",
      "Batch: 26, Loss: 1.1685676574707031, Accuracy: 0.6318359375\n",
      "Batch: 27, Loss: 1.2025134563446045, Accuracy: 0.6103515625\n",
      "Batch: 28, Loss: 1.3022937774658203, Accuracy: 0.5849609375\n",
      "Batch: 29, Loss: 1.3099042177200317, Accuracy: 0.576171875\n",
      "Batch: 30, Loss: 1.2414989471435547, Accuracy: 0.626953125\n",
      "Batch: 31, Loss: 1.2276206016540527, Accuracy: 0.6279296875\n",
      "Batch: 32, Loss: 1.1667391061782837, Accuracy: 0.6181640625\n",
      "Batch: 33, Loss: 1.3794951438903809, Accuracy: 0.5673828125\n",
      "Batch: 34, Loss: 1.4215543270111084, Accuracy: 0.572265625\n",
      "Batch: 35, Loss: 1.3266844749450684, Accuracy: 0.5732421875\n",
      "Batch: 36, Loss: 1.3103114366531372, Accuracy: 0.6005859375\n",
      "Batch: 37, Loss: 1.3150842189788818, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.295440673828125, Accuracy: 0.572265625\n",
      "Batch: 39, Loss: 1.3201098442077637, Accuracy: 0.60546875\n",
      "Batch: 40, Loss: 1.3096911907196045, Accuracy: 0.6025390625\n",
      "Batch: 41, Loss: 1.3450167179107666, Accuracy: 0.5849609375\n",
      "Batch: 42, Loss: 1.0813403129577637, Accuracy: 0.6474609375\n",
      "Batch: 43, Loss: 1.237928867340088, Accuracy: 0.5810546875\n",
      "Batch: 44, Loss: 1.2337900400161743, Accuracy: 0.576171875\n",
      "Batch: 45, Loss: 1.0763224363327026, Accuracy: 0.6455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 1.2377386093139648, Accuracy: 0.6240234375\n",
      "Batch: 47, Loss: 1.2678219079971313, Accuracy: 0.611328125\n",
      "Batch: 48, Loss: 1.2252333164215088, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.395904541015625, Accuracy: 0.55859375\n",
      "Batch: 50, Loss: 1.3410630226135254, Accuracy: 0.5810546875\n",
      "Batch: 51, Loss: 1.4426743984222412, Accuracy: 0.5546875\n",
      "Batch: 52, Loss: 1.3824577331542969, Accuracy: 0.591796875\n",
      "Batch: 53, Loss: 1.1321203708648682, Accuracy: 0.63671875\n",
      "Batch: 54, Loss: 1.235826015472412, Accuracy: 0.634765625\n",
      "Batch: 55, Loss: 1.2844510078430176, Accuracy: 0.5791015625\n",
      "Batch: 56, Loss: 1.3291316032409668, Accuracy: 0.5791015625\n",
      "Batch: 57, Loss: 1.2711000442504883, Accuracy: 0.6162109375\n",
      "Batch: 58, Loss: 1.3629348278045654, Accuracy: 0.58203125\n",
      "Batch: 59, Loss: 1.1437677145004272, Accuracy: 0.6552734375\n",
      "Batch: 60, Loss: 1.127145767211914, Accuracy: 0.6328125\n",
      "Batch: 61, Loss: 1.2592508792877197, Accuracy: 0.60546875\n",
      "Batch: 62, Loss: 1.2538659572601318, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.2537049055099487, Accuracy: 0.6142578125\n",
      "Batch: 64, Loss: 1.2132165431976318, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.289811134338379, Accuracy: 0.5927734375\n",
      "Batch: 66, Loss: 1.186941146850586, Accuracy: 0.626953125\n",
      "Batch: 67, Loss: 1.3265197277069092, Accuracy: 0.5966796875\n",
      "Batch: 68, Loss: 1.357046127319336, Accuracy: 0.5986328125\n",
      "Batch: 69, Loss: 1.236647605895996, Accuracy: 0.611328125\n",
      "Batch: 70, Loss: 1.308234691619873, Accuracy: 0.6201171875\n",
      "Batch: 71, Loss: 1.296785593032837, Accuracy: 0.595703125\n",
      "Batch: 72, Loss: 1.174560785293579, Accuracy: 0.634765625\n",
      "Batch: 73, Loss: 1.2192790508270264, Accuracy: 0.6259765625\n",
      "Batch: 74, Loss: 1.2119182348251343, Accuracy: 0.61328125\n",
      "Batch: 75, Loss: 1.1427572965621948, Accuracy: 0.650390625\n",
      "Batch: 76, Loss: 1.305545687675476, Accuracy: 0.5810546875\n",
      "Batch: 77, Loss: 1.288236379623413, Accuracy: 0.5712890625\n",
      "Batch: 78, Loss: 1.2574529647827148, Accuracy: 0.625\n",
      "Batch: 79, Loss: 1.145684003829956, Accuracy: 0.6708984375\n",
      "Batch: 80, Loss: 1.1810741424560547, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.3190975189208984, Accuracy: 0.55859375\n",
      "Batch: 82, Loss: 1.279052972793579, Accuracy: 0.58984375\n",
      "Batch: 83, Loss: 1.1050169467926025, Accuracy: 0.6669921875\n",
      "Batch: 84, Loss: 1.2165879011154175, Accuracy: 0.6337890625\n",
      "Batch: 85, Loss: 1.1377118825912476, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.4057613611221313, Accuracy: 0.548828125\n",
      "Batch: 87, Loss: 1.207064151763916, Accuracy: 0.6337890625\n",
      "Batch: 88, Loss: 1.3493094444274902, Accuracy: 0.59765625\n",
      "Batch: 89, Loss: 1.3036317825317383, Accuracy: 0.5947265625\n",
      "Batch: 90, Loss: 1.1836748123168945, Accuracy: 0.6201171875\n",
      "Batch: 91, Loss: 1.2143000364303589, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.2511402368545532, Accuracy: 0.6240234375\n",
      "Batch: 93, Loss: 1.191563606262207, Accuracy: 0.6318359375\n",
      "Batch: 94, Loss: 1.2056527137756348, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.2627966403961182, Accuracy: 0.5791015625\n",
      "Batch: 96, Loss: 1.218374490737915, Accuracy: 0.623046875\n",
      "Batch: 97, Loss: 1.097005009651184, Accuracy: 0.65234375\n",
      "Batch: 98, Loss: 1.167095422744751, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1330900192260742, Accuracy: 0.6494140625\n",
      "Batch: 100, Loss: 1.242506980895996, Accuracy: 0.6123046875\n",
      "Batch: 101, Loss: 1.2867534160614014, Accuracy: 0.5908203125\n",
      "Batch: 102, Loss: 1.15632963180542, Accuracy: 0.62890625\n",
      "Batch: 103, Loss: 1.2956838607788086, Accuracy: 0.61328125\n",
      "Batch: 104, Loss: 1.1567636728286743, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.2649414539337158, Accuracy: 0.595703125\n",
      "Batch: 106, Loss: 1.272283911705017, Accuracy: 0.5927734375\n",
      "Batch: 107, Loss: 1.3819868564605713, Accuracy: 0.5859375\n",
      "Batch: 108, Loss: 1.3394198417663574, Accuracy: 0.5703125\n",
      "Batch: 109, Loss: 1.3818755149841309, Accuracy: 0.5517578125\n",
      "Batch: 110, Loss: 1.0910229682922363, Accuracy: 0.6474609375\n",
      "Batch: 111, Loss: 1.3176966905593872, Accuracy: 0.58203125\n",
      "Batch: 112, Loss: 1.2563700675964355, Accuracy: 0.611328125\n",
      "Batch: 113, Loss: 1.258187174797058, Accuracy: 0.62890625\n",
      "Batch: 114, Loss: 1.393164873123169, Accuracy: 0.57421875\n",
      "Batch: 115, Loss: 1.3942697048187256, Accuracy: 0.58984375\n",
      "Batch: 116, Loss: 1.3470704555511475, Accuracy: 0.576171875\n",
      "Batch: 117, Loss: 1.3169918060302734, Accuracy: 0.5810546875\n",
      "Batch: 118, Loss: 1.1147181987762451, Accuracy: 0.666015625\n",
      "Batch: 119, Loss: 1.1590863466262817, Accuracy: 0.65234375\n",
      "Batch: 120, Loss: 1.2927074432373047, Accuracy: 0.5947265625\n",
      "Batch: 121, Loss: 1.3485562801361084, Accuracy: 0.5771484375\n",
      "Batch: 122, Loss: 1.1985344886779785, Accuracy: 0.642578125\n",
      "Batch: 123, Loss: 1.2111514806747437, Accuracy: 0.623046875\n",
      "Batch: 124, Loss: 1.2498735189437866, Accuracy: 0.62109375\n",
      "Batch: 125, Loss: 1.2905184030532837, Accuracy: 0.591796875\n",
      "Batch: 126, Loss: 1.2648084163665771, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.1561248302459717, Accuracy: 0.6533203125\n",
      "Batch: 128, Loss: 1.4069948196411133, Accuracy: 0.59375\n",
      "Batch: 129, Loss: 1.2152012586593628, Accuracy: 0.607421875\n",
      "Batch: 130, Loss: 1.4817490577697754, Accuracy: 0.546875\n",
      "Batch: 131, Loss: 1.2979652881622314, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.360992431640625, Accuracy: 0.5908203125\n",
      "Batch: 133, Loss: 1.2059736251831055, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.238703966140747, Accuracy: 0.6064453125\n",
      "Batch: 135, Loss: 1.1651149988174438, Accuracy: 0.642578125\n",
      "Batch: 136, Loss: 1.2419214248657227, Accuracy: 0.6201171875\n",
      "Batch: 137, Loss: 1.18674635887146, Accuracy: 0.6015625\n",
      "Batch: 138, Loss: 1.0613839626312256, Accuracy: 0.6484375\n",
      "Batch: 139, Loss: 1.1491392850875854, Accuracy: 0.60546875\n",
      "Batch: 140, Loss: 1.2330540418624878, Accuracy: 0.5927734375\n",
      "Batch: 141, Loss: 1.2691292762756348, Accuracy: 0.611328125\n",
      "Batch: 142, Loss: 1.2834030389785767, Accuracy: 0.591796875\n",
      "Batch: 143, Loss: 1.2794957160949707, Accuracy: 0.60546875\n",
      "Batch: 144, Loss: 1.232590675354004, Accuracy: 0.6103515625\n",
      "Batch: 145, Loss: 1.1579999923706055, Accuracy: 0.6142578125\n",
      "Batch: 146, Loss: 1.3091728687286377, Accuracy: 0.5693359375\n",
      "Batch: 147, Loss: 1.2559914588928223, Accuracy: 0.5927734375\n",
      "Batch: 148, Loss: 1.3950754404067993, Accuracy: 0.54296875\n",
      "Batch: 149, Loss: 1.2743592262268066, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.1952040195465088, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.123209834098816, Accuracy: 0.6533203125\n",
      "Epoch 10/80\n",
      "Batch: 1, Loss: 1.4887851476669312, Accuracy: 0.529296875\n",
      "Batch: 2, Loss: 1.276179313659668, Accuracy: 0.5595703125\n",
      "Batch: 3, Loss: 1.1988048553466797, Accuracy: 0.611328125\n",
      "Batch: 4, Loss: 1.108076572418213, Accuracy: 0.6669921875\n",
      "Batch: 5, Loss: 1.153185486793518, Accuracy: 0.646484375\n",
      "Batch: 6, Loss: 1.2679450511932373, Accuracy: 0.5771484375\n",
      "Batch: 7, Loss: 1.2273707389831543, Accuracy: 0.591796875\n",
      "Batch: 8, Loss: 1.146459698677063, Accuracy: 0.611328125\n",
      "Batch: 9, Loss: 1.1121693849563599, Accuracy: 0.6455078125\n",
      "Batch: 10, Loss: 1.135054588317871, Accuracy: 0.6376953125\n",
      "Batch: 11, Loss: 1.3115381002426147, Accuracy: 0.5693359375\n",
      "Batch: 12, Loss: 1.3337382078170776, Accuracy: 0.58203125\n",
      "Batch: 13, Loss: 1.0560228824615479, Accuracy: 0.6640625\n",
      "Batch: 14, Loss: 1.336726427078247, Accuracy: 0.5703125\n",
      "Batch: 15, Loss: 1.1817424297332764, Accuracy: 0.6484375\n",
      "Batch: 16, Loss: 1.1700069904327393, Accuracy: 0.623046875\n",
      "Batch: 17, Loss: 1.269818902015686, Accuracy: 0.5947265625\n",
      "Batch: 18, Loss: 1.2539860010147095, Accuracy: 0.5986328125\n",
      "Batch: 19, Loss: 1.2830727100372314, Accuracy: 0.6103515625\n",
      "Batch: 20, Loss: 1.1802470684051514, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1914923191070557, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.3277562856674194, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.1972861289978027, Accuracy: 0.6181640625\n",
      "Batch: 24, Loss: 1.261068344116211, Accuracy: 0.59765625\n",
      "Batch: 25, Loss: 1.2250468730926514, Accuracy: 0.6064453125\n",
      "Batch: 26, Loss: 1.1249799728393555, Accuracy: 0.6376953125\n",
      "Batch: 27, Loss: 1.1739261150360107, Accuracy: 0.6259765625\n",
      "Batch: 28, Loss: 1.2802621126174927, Accuracy: 0.578125\n",
      "Batch: 29, Loss: 1.2503986358642578, Accuracy: 0.60546875\n",
      "Batch: 30, Loss: 1.194002389907837, Accuracy: 0.6416015625\n",
      "Batch: 31, Loss: 1.1827542781829834, Accuracy: 0.6513671875\n",
      "Batch: 32, Loss: 1.139312982559204, Accuracy: 0.6298828125\n",
      "Batch: 33, Loss: 1.3326799869537354, Accuracy: 0.5869140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.3981260061264038, Accuracy: 0.583984375\n",
      "Batch: 35, Loss: 1.2662286758422852, Accuracy: 0.6005859375\n",
      "Batch: 36, Loss: 1.2618236541748047, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.2919912338256836, Accuracy: 0.58984375\n",
      "Batch: 38, Loss: 1.2620961666107178, Accuracy: 0.59765625\n",
      "Batch: 39, Loss: 1.2747493982315063, Accuracy: 0.615234375\n",
      "Batch: 40, Loss: 1.2885676622390747, Accuracy: 0.615234375\n",
      "Batch: 41, Loss: 1.285172939300537, Accuracy: 0.61328125\n",
      "Batch: 42, Loss: 1.0351879596710205, Accuracy: 0.6640625\n",
      "Batch: 43, Loss: 1.2257853746414185, Accuracy: 0.59375\n",
      "Batch: 44, Loss: 1.2133991718292236, Accuracy: 0.5859375\n",
      "Batch: 45, Loss: 1.0644831657409668, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.2076318264007568, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.218923807144165, Accuracy: 0.625\n",
      "Batch: 48, Loss: 1.2036170959472656, Accuracy: 0.62890625\n",
      "Batch: 49, Loss: 1.348479986190796, Accuracy: 0.576171875\n",
      "Batch: 50, Loss: 1.2900906801223755, Accuracy: 0.5947265625\n",
      "Batch: 51, Loss: 1.4036506414413452, Accuracy: 0.5693359375\n",
      "Batch: 52, Loss: 1.3259426355361938, Accuracy: 0.59765625\n",
      "Batch: 53, Loss: 1.1087076663970947, Accuracy: 0.6494140625\n",
      "Batch: 54, Loss: 1.1758623123168945, Accuracy: 0.6396484375\n",
      "Batch: 55, Loss: 1.2428739070892334, Accuracy: 0.6044921875\n",
      "Batch: 56, Loss: 1.302473545074463, Accuracy: 0.5869140625\n",
      "Batch: 57, Loss: 1.2662341594696045, Accuracy: 0.603515625\n",
      "Batch: 58, Loss: 1.3327946662902832, Accuracy: 0.611328125\n",
      "Batch: 59, Loss: 1.1212633848190308, Accuracy: 0.658203125\n",
      "Batch: 60, Loss: 1.1013022661209106, Accuracy: 0.634765625\n",
      "Batch: 61, Loss: 1.2360470294952393, Accuracy: 0.6064453125\n",
      "Batch: 62, Loss: 1.2062737941741943, Accuracy: 0.62109375\n",
      "Batch: 63, Loss: 1.210302472114563, Accuracy: 0.6298828125\n",
      "Batch: 64, Loss: 1.1810181140899658, Accuracy: 0.6240234375\n",
      "Batch: 65, Loss: 1.2296173572540283, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1494344472885132, Accuracy: 0.634765625\n",
      "Batch: 67, Loss: 1.2940189838409424, Accuracy: 0.5986328125\n",
      "Batch: 68, Loss: 1.3130192756652832, Accuracy: 0.611328125\n",
      "Batch: 69, Loss: 1.2284778356552124, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.2642525434494019, Accuracy: 0.615234375\n",
      "Batch: 71, Loss: 1.2260974645614624, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.1331220865249634, Accuracy: 0.6416015625\n",
      "Batch: 73, Loss: 1.189009189605713, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.1635069847106934, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.0788030624389648, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.2396478652954102, Accuracy: 0.5986328125\n",
      "Batch: 77, Loss: 1.2389682531356812, Accuracy: 0.6103515625\n",
      "Batch: 78, Loss: 1.2164816856384277, Accuracy: 0.6259765625\n",
      "Batch: 79, Loss: 1.09791100025177, Accuracy: 0.6826171875\n",
      "Batch: 80, Loss: 1.1212643384933472, Accuracy: 0.6279296875\n",
      "Batch: 81, Loss: 1.2922089099884033, Accuracy: 0.580078125\n",
      "Batch: 82, Loss: 1.232778549194336, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.0867688655853271, Accuracy: 0.6689453125\n",
      "Batch: 84, Loss: 1.1660714149475098, Accuracy: 0.638671875\n",
      "Batch: 85, Loss: 1.1076699495315552, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.3742109537124634, Accuracy: 0.576171875\n",
      "Batch: 87, Loss: 1.1707429885864258, Accuracy: 0.642578125\n",
      "Batch: 88, Loss: 1.3145248889923096, Accuracy: 0.58984375\n",
      "Batch: 89, Loss: 1.2557646036148071, Accuracy: 0.60546875\n",
      "Batch: 90, Loss: 1.1485438346862793, Accuracy: 0.6337890625\n",
      "Batch: 91, Loss: 1.181304931640625, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.2366915941238403, Accuracy: 0.6044921875\n",
      "Batch: 93, Loss: 1.181227207183838, Accuracy: 0.634765625\n",
      "Batch: 94, Loss: 1.1798388957977295, Accuracy: 0.61328125\n",
      "Batch: 95, Loss: 1.2102713584899902, Accuracy: 0.5966796875\n",
      "Batch: 96, Loss: 1.20137357711792, Accuracy: 0.6240234375\n",
      "Batch: 97, Loss: 1.0324633121490479, Accuracy: 0.6630859375\n",
      "Batch: 98, Loss: 1.1225999593734741, Accuracy: 0.671875\n",
      "Batch: 99, Loss: 1.0849565267562866, Accuracy: 0.65625\n",
      "Batch: 100, Loss: 1.1858229637145996, Accuracy: 0.6279296875\n",
      "Batch: 101, Loss: 1.2530517578125, Accuracy: 0.603515625\n",
      "Batch: 102, Loss: 1.1294854879379272, Accuracy: 0.630859375\n",
      "Batch: 103, Loss: 1.2610015869140625, Accuracy: 0.6171875\n",
      "Batch: 104, Loss: 1.1165313720703125, Accuracy: 0.638671875\n",
      "Batch: 105, Loss: 1.2163609266281128, Accuracy: 0.60546875\n",
      "Batch: 106, Loss: 1.234886884689331, Accuracy: 0.607421875\n",
      "Batch: 107, Loss: 1.3198204040527344, Accuracy: 0.583984375\n",
      "Batch: 108, Loss: 1.2813276052474976, Accuracy: 0.595703125\n",
      "Batch: 109, Loss: 1.3495441675186157, Accuracy: 0.560546875\n",
      "Batch: 110, Loss: 1.0341219902038574, Accuracy: 0.66796875\n",
      "Batch: 111, Loss: 1.283226490020752, Accuracy: 0.583984375\n",
      "Batch: 112, Loss: 1.238311529159546, Accuracy: 0.609375\n",
      "Batch: 113, Loss: 1.2437150478363037, Accuracy: 0.6416015625\n",
      "Batch: 114, Loss: 1.3666858673095703, Accuracy: 0.57421875\n",
      "Batch: 115, Loss: 1.3439936637878418, Accuracy: 0.5947265625\n",
      "Batch: 116, Loss: 1.313244342803955, Accuracy: 0.578125\n",
      "Batch: 117, Loss: 1.2857375144958496, Accuracy: 0.5859375\n",
      "Batch: 118, Loss: 1.0549671649932861, Accuracy: 0.65625\n",
      "Batch: 119, Loss: 1.143277883529663, Accuracy: 0.66015625\n",
      "Batch: 120, Loss: 1.2830941677093506, Accuracy: 0.583984375\n",
      "Batch: 121, Loss: 1.3037798404693604, Accuracy: 0.5849609375\n",
      "Batch: 122, Loss: 1.1586291790008545, Accuracy: 0.6416015625\n",
      "Batch: 123, Loss: 1.184901237487793, Accuracy: 0.646484375\n",
      "Batch: 124, Loss: 1.21071457862854, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.2664507627487183, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.248890995979309, Accuracy: 0.59375\n",
      "Batch: 127, Loss: 1.1168324947357178, Accuracy: 0.6630859375\n",
      "Batch: 128, Loss: 1.3723464012145996, Accuracy: 0.5908203125\n",
      "Batch: 129, Loss: 1.1990302801132202, Accuracy: 0.6259765625\n",
      "Batch: 130, Loss: 1.4310880899429321, Accuracy: 0.5732421875\n",
      "Batch: 131, Loss: 1.2621994018554688, Accuracy: 0.6240234375\n",
      "Batch: 132, Loss: 1.3148218393325806, Accuracy: 0.591796875\n",
      "Batch: 133, Loss: 1.1558642387390137, Accuracy: 0.6337890625\n",
      "Batch: 134, Loss: 1.183821201324463, Accuracy: 0.615234375\n",
      "Batch: 135, Loss: 1.1322689056396484, Accuracy: 0.646484375\n",
      "Batch: 136, Loss: 1.1698722839355469, Accuracy: 0.6220703125\n",
      "Batch: 137, Loss: 1.1650251150131226, Accuracy: 0.59765625\n",
      "Batch: 138, Loss: 1.0077588558197021, Accuracy: 0.67578125\n",
      "Batch: 139, Loss: 1.135132074356079, Accuracy: 0.623046875\n",
      "Batch: 140, Loss: 1.2092342376708984, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.241303563117981, Accuracy: 0.6123046875\n",
      "Batch: 142, Loss: 1.2639446258544922, Accuracy: 0.595703125\n",
      "Batch: 143, Loss: 1.2322516441345215, Accuracy: 0.6171875\n",
      "Batch: 144, Loss: 1.2141213417053223, Accuracy: 0.626953125\n",
      "Batch: 145, Loss: 1.1292357444763184, Accuracy: 0.6171875\n",
      "Batch: 146, Loss: 1.287312626838684, Accuracy: 0.5908203125\n",
      "Batch: 147, Loss: 1.2650082111358643, Accuracy: 0.59765625\n",
      "Batch: 148, Loss: 1.3623294830322266, Accuracy: 0.5400390625\n",
      "Batch: 149, Loss: 1.2299728393554688, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.1719679832458496, Accuracy: 0.6337890625\n",
      "Batch: 151, Loss: 1.08469820022583, Accuracy: 0.6630859375\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/80\n",
      "Batch: 1, Loss: 1.4345555305480957, Accuracy: 0.5458984375\n",
      "Batch: 2, Loss: 1.251112937927246, Accuracy: 0.560546875\n",
      "Batch: 3, Loss: 1.1483148336410522, Accuracy: 0.619140625\n",
      "Batch: 4, Loss: 1.0858588218688965, Accuracy: 0.6669921875\n",
      "Batch: 5, Loss: 1.1113255023956299, Accuracy: 0.66015625\n",
      "Batch: 6, Loss: 1.2320621013641357, Accuracy: 0.609375\n",
      "Batch: 7, Loss: 1.1926989555358887, Accuracy: 0.61328125\n",
      "Batch: 8, Loss: 1.1206551790237427, Accuracy: 0.623046875\n",
      "Batch: 9, Loss: 1.093908667564392, Accuracy: 0.6513671875\n",
      "Batch: 10, Loss: 1.1088811159133911, Accuracy: 0.6455078125\n",
      "Batch: 11, Loss: 1.2640929222106934, Accuracy: 0.58984375\n",
      "Batch: 12, Loss: 1.2807989120483398, Accuracy: 0.6142578125\n",
      "Batch: 13, Loss: 1.021862506866455, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 1.3043113946914673, Accuracy: 0.583984375\n",
      "Batch: 15, Loss: 1.1641901731491089, Accuracy: 0.6494140625\n",
      "Batch: 16, Loss: 1.1458947658538818, Accuracy: 0.642578125\n",
      "Batch: 17, Loss: 1.2283051013946533, Accuracy: 0.607421875\n",
      "Batch: 18, Loss: 1.2115600109100342, Accuracy: 0.6064453125\n",
      "Batch: 19, Loss: 1.2517081499099731, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.175206184387207, Accuracy: 0.640625\n",
      "Batch: 21, Loss: 1.1348896026611328, Accuracy: 0.63671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 1.2828036546707153, Accuracy: 0.6044921875\n",
      "Batch: 23, Loss: 1.1545052528381348, Accuracy: 0.6337890625\n",
      "Batch: 24, Loss: 1.232348918914795, Accuracy: 0.59765625\n",
      "Batch: 25, Loss: 1.1636450290679932, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.088437557220459, Accuracy: 0.6552734375\n",
      "Batch: 27, Loss: 1.1151666641235352, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.2331101894378662, Accuracy: 0.599609375\n",
      "Batch: 29, Loss: 1.2330796718597412, Accuracy: 0.6015625\n",
      "Batch: 30, Loss: 1.1840465068817139, Accuracy: 0.650390625\n",
      "Batch: 31, Loss: 1.1652493476867676, Accuracy: 0.6376953125\n",
      "Batch: 32, Loss: 1.0917235612869263, Accuracy: 0.650390625\n",
      "Batch: 33, Loss: 1.2949929237365723, Accuracy: 0.59765625\n",
      "Batch: 34, Loss: 1.3527748584747314, Accuracy: 0.58203125\n",
      "Batch: 35, Loss: 1.2203149795532227, Accuracy: 0.587890625\n",
      "Batch: 36, Loss: 1.245265007019043, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.2427330017089844, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.2226755619049072, Accuracy: 0.6015625\n",
      "Batch: 39, Loss: 1.2300746440887451, Accuracy: 0.619140625\n",
      "Batch: 40, Loss: 1.2485578060150146, Accuracy: 0.6025390625\n",
      "Batch: 41, Loss: 1.2282984256744385, Accuracy: 0.615234375\n",
      "Batch: 42, Loss: 1.0072989463806152, Accuracy: 0.673828125\n",
      "Batch: 43, Loss: 1.198094129562378, Accuracy: 0.6005859375\n",
      "Batch: 44, Loss: 1.1805763244628906, Accuracy: 0.5947265625\n",
      "Batch: 45, Loss: 1.0396770238876343, Accuracy: 0.6572265625\n",
      "Batch: 46, Loss: 1.1658029556274414, Accuracy: 0.6474609375\n",
      "Batch: 47, Loss: 1.1844580173492432, Accuracy: 0.6455078125\n",
      "Batch: 48, Loss: 1.1560932397842407, Accuracy: 0.6435546875\n",
      "Batch: 49, Loss: 1.3253812789916992, Accuracy: 0.5791015625\n",
      "Batch: 50, Loss: 1.2461562156677246, Accuracy: 0.603515625\n",
      "Batch: 51, Loss: 1.3561010360717773, Accuracy: 0.57421875\n",
      "Batch: 52, Loss: 1.308058261871338, Accuracy: 0.6025390625\n",
      "Batch: 53, Loss: 1.074418067932129, Accuracy: 0.6513671875\n",
      "Batch: 54, Loss: 1.165619969367981, Accuracy: 0.650390625\n",
      "Batch: 55, Loss: 1.2057678699493408, Accuracy: 0.6181640625\n",
      "Batch: 56, Loss: 1.2572453022003174, Accuracy: 0.6142578125\n",
      "Batch: 57, Loss: 1.211416482925415, Accuracy: 0.626953125\n",
      "Batch: 58, Loss: 1.2700072526931763, Accuracy: 0.6103515625\n",
      "Batch: 59, Loss: 1.0847258567810059, Accuracy: 0.6787109375\n",
      "Batch: 60, Loss: 1.0776569843292236, Accuracy: 0.6513671875\n",
      "Batch: 61, Loss: 1.2050058841705322, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.1421608924865723, Accuracy: 0.646484375\n",
      "Batch: 63, Loss: 1.1894385814666748, Accuracy: 0.607421875\n",
      "Batch: 64, Loss: 1.1494431495666504, Accuracy: 0.630859375\n",
      "Batch: 65, Loss: 1.2111222743988037, Accuracy: 0.630859375\n",
      "Batch: 66, Loss: 1.1264002323150635, Accuracy: 0.642578125\n",
      "Batch: 67, Loss: 1.2554490566253662, Accuracy: 0.6181640625\n",
      "Batch: 68, Loss: 1.268707513809204, Accuracy: 0.60546875\n",
      "Batch: 69, Loss: 1.189767599105835, Accuracy: 0.6162109375\n",
      "Batch: 70, Loss: 1.2263457775115967, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.2089598178863525, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.0805867910385132, Accuracy: 0.64453125\n",
      "Batch: 73, Loss: 1.1747968196868896, Accuracy: 0.6201171875\n",
      "Batch: 74, Loss: 1.1252357959747314, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.0450503826141357, Accuracy: 0.6748046875\n",
      "Batch: 76, Loss: 1.2064208984375, Accuracy: 0.603515625\n",
      "Batch: 77, Loss: 1.202718734741211, Accuracy: 0.6171875\n",
      "Batch: 78, Loss: 1.1728795766830444, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.069572925567627, Accuracy: 0.6796875\n",
      "Batch: 80, Loss: 1.083475947380066, Accuracy: 0.6435546875\n",
      "Batch: 81, Loss: 1.2317960262298584, Accuracy: 0.5859375\n",
      "Batch: 82, Loss: 1.2114393711090088, Accuracy: 0.6083984375\n",
      "Batch: 83, Loss: 1.0587810277938843, Accuracy: 0.67578125\n",
      "Batch: 84, Loss: 1.1482183933258057, Accuracy: 0.6494140625\n",
      "Batch: 85, Loss: 1.0850166082382202, Accuracy: 0.6416015625\n",
      "Batch: 86, Loss: 1.3385149240493774, Accuracy: 0.5869140625\n",
      "Batch: 87, Loss: 1.1247743368148804, Accuracy: 0.638671875\n",
      "Batch: 88, Loss: 1.2566293478012085, Accuracy: 0.6240234375\n",
      "Batch: 89, Loss: 1.2131884098052979, Accuracy: 0.625\n",
      "Batch: 90, Loss: 1.11776602268219, Accuracy: 0.6591796875\n",
      "Batch: 91, Loss: 1.1600234508514404, Accuracy: 0.6337890625\n",
      "Batch: 92, Loss: 1.1929913759231567, Accuracy: 0.6171875\n",
      "Batch: 93, Loss: 1.127084493637085, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.1471068859100342, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1901166439056396, Accuracy: 0.6025390625\n",
      "Batch: 96, Loss: 1.148216962814331, Accuracy: 0.6416015625\n",
      "Batch: 97, Loss: 1.0269780158996582, Accuracy: 0.6640625\n",
      "Batch: 98, Loss: 1.0847282409667969, Accuracy: 0.658203125\n",
      "Batch: 99, Loss: 1.0565497875213623, Accuracy: 0.6650390625\n",
      "Batch: 100, Loss: 1.1352503299713135, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.240820288658142, Accuracy: 0.611328125\n",
      "Batch: 102, Loss: 1.1246556043624878, Accuracy: 0.6396484375\n",
      "Batch: 103, Loss: 1.2072620391845703, Accuracy: 0.6337890625\n",
      "Batch: 104, Loss: 1.091996192932129, Accuracy: 0.6455078125\n",
      "Batch: 105, Loss: 1.2237858772277832, Accuracy: 0.59765625\n",
      "Batch: 106, Loss: 1.1993592977523804, Accuracy: 0.6259765625\n",
      "Batch: 107, Loss: 1.2896766662597656, Accuracy: 0.59765625\n",
      "Batch: 108, Loss: 1.2608354091644287, Accuracy: 0.5869140625\n",
      "Batch: 109, Loss: 1.3345675468444824, Accuracy: 0.5712890625\n",
      "Batch: 110, Loss: 1.0189054012298584, Accuracy: 0.6826171875\n",
      "Batch: 111, Loss: 1.2397291660308838, Accuracy: 0.5986328125\n",
      "Batch: 112, Loss: 1.198906421661377, Accuracy: 0.6328125\n",
      "Batch: 113, Loss: 1.195512056350708, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.3146941661834717, Accuracy: 0.59375\n",
      "Batch: 115, Loss: 1.3182153701782227, Accuracy: 0.6103515625\n",
      "Batch: 116, Loss: 1.2463817596435547, Accuracy: 0.595703125\n",
      "Batch: 117, Loss: 1.2745490074157715, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.0303640365600586, Accuracy: 0.6708984375\n",
      "Batch: 119, Loss: 1.0899417400360107, Accuracy: 0.658203125\n",
      "Batch: 120, Loss: 1.225517988204956, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.274169921875, Accuracy: 0.609375\n",
      "Batch: 122, Loss: 1.1351908445358276, Accuracy: 0.6513671875\n",
      "Batch: 123, Loss: 1.1356903314590454, Accuracy: 0.64453125\n",
      "Batch: 124, Loss: 1.1691133975982666, Accuracy: 0.630859375\n",
      "Batch: 125, Loss: 1.2174099683761597, Accuracy: 0.6142578125\n",
      "Batch: 126, Loss: 1.1976312398910522, Accuracy: 0.59375\n",
      "Batch: 127, Loss: 1.0620144605636597, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.3183822631835938, Accuracy: 0.5927734375\n",
      "Batch: 129, Loss: 1.150425910949707, Accuracy: 0.630859375\n",
      "Batch: 130, Loss: 1.4109036922454834, Accuracy: 0.5625\n",
      "Batch: 131, Loss: 1.2467219829559326, Accuracy: 0.6142578125\n",
      "Batch: 132, Loss: 1.2952723503112793, Accuracy: 0.6103515625\n",
      "Batch: 133, Loss: 1.1235555410385132, Accuracy: 0.646484375\n",
      "Batch: 134, Loss: 1.1580910682678223, Accuracy: 0.626953125\n",
      "Batch: 135, Loss: 1.0861815214157104, Accuracy: 0.6689453125\n",
      "Batch: 136, Loss: 1.1710691452026367, Accuracy: 0.6298828125\n",
      "Batch: 137, Loss: 1.1372919082641602, Accuracy: 0.6162109375\n",
      "Batch: 138, Loss: 0.9823817014694214, Accuracy: 0.6708984375\n",
      "Batch: 139, Loss: 1.0963783264160156, Accuracy: 0.638671875\n",
      "Batch: 140, Loss: 1.155855417251587, Accuracy: 0.6298828125\n",
      "Batch: 141, Loss: 1.181217908859253, Accuracy: 0.646484375\n",
      "Batch: 142, Loss: 1.2188329696655273, Accuracy: 0.619140625\n",
      "Batch: 143, Loss: 1.2183513641357422, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.2043890953063965, Accuracy: 0.6142578125\n",
      "Batch: 145, Loss: 1.109329342842102, Accuracy: 0.6259765625\n",
      "Batch: 146, Loss: 1.2398483753204346, Accuracy: 0.6015625\n",
      "Batch: 147, Loss: 1.1903371810913086, Accuracy: 0.630859375\n",
      "Batch: 148, Loss: 1.3243988752365112, Accuracy: 0.5576171875\n",
      "Batch: 149, Loss: 1.1994826793670654, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.1156927347183228, Accuracy: 0.6357421875\n",
      "Batch: 151, Loss: 1.0612126588821411, Accuracy: 0.6640625\n",
      "Epoch 12/80\n",
      "Batch: 1, Loss: 1.404000997543335, Accuracy: 0.5595703125\n",
      "Batch: 2, Loss: 1.2265143394470215, Accuracy: 0.5908203125\n",
      "Batch: 3, Loss: 1.1508605480194092, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.0508242845535278, Accuracy: 0.6787109375\n",
      "Batch: 5, Loss: 1.0837594270706177, Accuracy: 0.6689453125\n",
      "Batch: 6, Loss: 1.191077470779419, Accuracy: 0.607421875\n",
      "Batch: 7, Loss: 1.1509058475494385, Accuracy: 0.6220703125\n",
      "Batch: 8, Loss: 1.082878589630127, Accuracy: 0.63671875\n",
      "Batch: 9, Loss: 1.0685609579086304, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 1.0714061260223389, Accuracy: 0.6591796875\n",
      "Batch: 11, Loss: 1.2388873100280762, Accuracy: 0.5810546875\n",
      "Batch: 12, Loss: 1.235445261001587, Accuracy: 0.6142578125\n",
      "Batch: 13, Loss: 1.012235164642334, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 1.2679688930511475, Accuracy: 0.5849609375\n",
      "Batch: 15, Loss: 1.1196348667144775, Accuracy: 0.65625\n",
      "Batch: 16, Loss: 1.0954504013061523, Accuracy: 0.650390625\n",
      "Batch: 17, Loss: 1.2015299797058105, Accuracy: 0.6005859375\n",
      "Batch: 18, Loss: 1.2006056308746338, Accuracy: 0.6123046875\n",
      "Batch: 19, Loss: 1.2303192615509033, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.1152805089950562, Accuracy: 0.658203125\n",
      "Batch: 21, Loss: 1.1059181690216064, Accuracy: 0.65234375\n",
      "Batch: 22, Loss: 1.2371635437011719, Accuracy: 0.625\n",
      "Batch: 23, Loss: 1.1249561309814453, Accuracy: 0.6337890625\n",
      "Batch: 24, Loss: 1.1873713731765747, Accuracy: 0.62109375\n",
      "Batch: 25, Loss: 1.1697691679000854, Accuracy: 0.6357421875\n",
      "Batch: 26, Loss: 1.0723085403442383, Accuracy: 0.6494140625\n",
      "Batch: 27, Loss: 1.0848596096038818, Accuracy: 0.6416015625\n",
      "Batch: 28, Loss: 1.2130141258239746, Accuracy: 0.60546875\n",
      "Batch: 29, Loss: 1.1970512866973877, Accuracy: 0.60546875\n",
      "Batch: 30, Loss: 1.1279774904251099, Accuracy: 0.6630859375\n",
      "Batch: 31, Loss: 1.1039903163909912, Accuracy: 0.6513671875\n",
      "Batch: 32, Loss: 1.0735598802566528, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.283432960510254, Accuracy: 0.5810546875\n",
      "Batch: 34, Loss: 1.3411338329315186, Accuracy: 0.5810546875\n",
      "Batch: 35, Loss: 1.188035249710083, Accuracy: 0.6044921875\n",
      "Batch: 36, Loss: 1.2015334367752075, Accuracy: 0.619140625\n",
      "Batch: 37, Loss: 1.198357105255127, Accuracy: 0.6279296875\n",
      "Batch: 38, Loss: 1.1961088180541992, Accuracy: 0.6123046875\n",
      "Batch: 39, Loss: 1.2133082151412964, Accuracy: 0.630859375\n",
      "Batch: 40, Loss: 1.1814675331115723, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.197577714920044, Accuracy: 0.6240234375\n",
      "Batch: 42, Loss: 0.9608513116836548, Accuracy: 0.68359375\n",
      "Batch: 43, Loss: 1.1690781116485596, Accuracy: 0.611328125\n",
      "Batch: 44, Loss: 1.1350252628326416, Accuracy: 0.625\n",
      "Batch: 45, Loss: 0.9993019104003906, Accuracy: 0.6796875\n",
      "Batch: 46, Loss: 1.1480178833007812, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.1413887739181519, Accuracy: 0.650390625\n",
      "Batch: 48, Loss: 1.1174135208129883, Accuracy: 0.658203125\n",
      "Batch: 49, Loss: 1.3202093839645386, Accuracy: 0.5810546875\n",
      "Batch: 50, Loss: 1.2440109252929688, Accuracy: 0.6025390625\n",
      "Batch: 51, Loss: 1.3446705341339111, Accuracy: 0.576171875\n",
      "Batch: 52, Loss: 1.3044482469558716, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.040636420249939, Accuracy: 0.6572265625\n",
      "Batch: 54, Loss: 1.1424442529678345, Accuracy: 0.6494140625\n",
      "Batch: 55, Loss: 1.1897895336151123, Accuracy: 0.6171875\n",
      "Batch: 56, Loss: 1.2315843105316162, Accuracy: 0.615234375\n",
      "Batch: 57, Loss: 1.181105375289917, Accuracy: 0.6298828125\n",
      "Batch: 58, Loss: 1.2393722534179688, Accuracy: 0.6259765625\n",
      "Batch: 59, Loss: 1.04166841506958, Accuracy: 0.69140625\n",
      "Batch: 60, Loss: 1.046776294708252, Accuracy: 0.6689453125\n",
      "Batch: 61, Loss: 1.1659488677978516, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.1477766036987305, Accuracy: 0.630859375\n",
      "Batch: 63, Loss: 1.1195242404937744, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.1143465042114258, Accuracy: 0.63671875\n",
      "Batch: 65, Loss: 1.1633284091949463, Accuracy: 0.6474609375\n",
      "Batch: 66, Loss: 1.1037590503692627, Accuracy: 0.658203125\n",
      "Batch: 67, Loss: 1.211042881011963, Accuracy: 0.640625\n",
      "Batch: 68, Loss: 1.2324495315551758, Accuracy: 0.61328125\n",
      "Batch: 69, Loss: 1.1484425067901611, Accuracy: 0.6416015625\n",
      "Batch: 70, Loss: 1.1844632625579834, Accuracy: 0.6298828125\n",
      "Batch: 71, Loss: 1.1933391094207764, Accuracy: 0.6123046875\n",
      "Batch: 72, Loss: 1.0710463523864746, Accuracy: 0.6572265625\n",
      "Batch: 73, Loss: 1.1402279138565063, Accuracy: 0.640625\n",
      "Batch: 74, Loss: 1.102561354637146, Accuracy: 0.6474609375\n",
      "Batch: 75, Loss: 1.0191298723220825, Accuracy: 0.6904296875\n",
      "Batch: 76, Loss: 1.1756900548934937, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.1396771669387817, Accuracy: 0.6357421875\n",
      "Batch: 78, Loss: 1.1550904512405396, Accuracy: 0.642578125\n",
      "Batch: 79, Loss: 1.0743328332901, Accuracy: 0.673828125\n",
      "Batch: 80, Loss: 1.0540211200714111, Accuracy: 0.66015625\n",
      "Batch: 81, Loss: 1.184713363647461, Accuracy: 0.609375\n",
      "Batch: 82, Loss: 1.146891713142395, Accuracy: 0.6376953125\n",
      "Batch: 83, Loss: 1.020658016204834, Accuracy: 0.6904296875\n",
      "Batch: 84, Loss: 1.1211130619049072, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.0551989078521729, Accuracy: 0.671875\n",
      "Batch: 86, Loss: 1.3070957660675049, Accuracy: 0.5908203125\n",
      "Batch: 87, Loss: 1.1008846759796143, Accuracy: 0.66015625\n",
      "Batch: 88, Loss: 1.22391939163208, Accuracy: 0.6279296875\n",
      "Batch: 89, Loss: 1.188464641571045, Accuracy: 0.63671875\n",
      "Batch: 90, Loss: 1.0889670848846436, Accuracy: 0.66015625\n",
      "Batch: 91, Loss: 1.115701675415039, Accuracy: 0.6435546875\n",
      "Batch: 92, Loss: 1.173006296157837, Accuracy: 0.634765625\n",
      "Batch: 93, Loss: 1.1065130233764648, Accuracy: 0.6416015625\n",
      "Batch: 94, Loss: 1.1132891178131104, Accuracy: 0.6416015625\n",
      "Batch: 95, Loss: 1.14306640625, Accuracy: 0.62890625\n",
      "Batch: 96, Loss: 1.1451759338378906, Accuracy: 0.6435546875\n",
      "Batch: 97, Loss: 1.0053203105926514, Accuracy: 0.6748046875\n",
      "Batch: 98, Loss: 1.0555124282836914, Accuracy: 0.6796875\n",
      "Batch: 99, Loss: 1.0369985103607178, Accuracy: 0.6640625\n",
      "Batch: 100, Loss: 1.1092448234558105, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.2020063400268555, Accuracy: 0.6181640625\n",
      "Batch: 102, Loss: 1.0938141345977783, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.185086727142334, Accuracy: 0.640625\n",
      "Batch: 104, Loss: 1.0736920833587646, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.1773793697357178, Accuracy: 0.6171875\n",
      "Batch: 106, Loss: 1.1447217464447021, Accuracy: 0.6416015625\n",
      "Batch: 107, Loss: 1.2373136281967163, Accuracy: 0.61328125\n",
      "Batch: 108, Loss: 1.2295749187469482, Accuracy: 0.583984375\n",
      "Batch: 109, Loss: 1.282840371131897, Accuracy: 0.5703125\n",
      "Batch: 110, Loss: 1.0203430652618408, Accuracy: 0.6630859375\n",
      "Batch: 111, Loss: 1.2186377048492432, Accuracy: 0.6044921875\n",
      "Batch: 112, Loss: 1.1762254238128662, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.168751835823059, Accuracy: 0.65234375\n",
      "Batch: 114, Loss: 1.2720584869384766, Accuracy: 0.6025390625\n",
      "Batch: 115, Loss: 1.2841976881027222, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.2458624839782715, Accuracy: 0.603515625\n",
      "Batch: 117, Loss: 1.214542269706726, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.0031672716140747, Accuracy: 0.6904296875\n",
      "Batch: 119, Loss: 1.0562950372695923, Accuracy: 0.6708984375\n",
      "Batch: 120, Loss: 1.1954997777938843, Accuracy: 0.6103515625\n",
      "Batch: 121, Loss: 1.21408212184906, Accuracy: 0.6142578125\n",
      "Batch: 122, Loss: 1.1170700788497925, Accuracy: 0.658203125\n",
      "Batch: 123, Loss: 1.1217334270477295, Accuracy: 0.654296875\n",
      "Batch: 124, Loss: 1.1568877696990967, Accuracy: 0.6279296875\n",
      "Batch: 125, Loss: 1.1913182735443115, Accuracy: 0.611328125\n",
      "Batch: 126, Loss: 1.1679240465164185, Accuracy: 0.6181640625\n",
      "Batch: 127, Loss: 1.0491482019424438, Accuracy: 0.6826171875\n",
      "Batch: 128, Loss: 1.2912156581878662, Accuracy: 0.615234375\n",
      "Batch: 129, Loss: 1.1157798767089844, Accuracy: 0.6533203125\n",
      "Batch: 130, Loss: 1.3712053298950195, Accuracy: 0.578125\n",
      "Batch: 131, Loss: 1.1975289583206177, Accuracy: 0.634765625\n",
      "Batch: 132, Loss: 1.2272531986236572, Accuracy: 0.60546875\n",
      "Batch: 133, Loss: 1.0893023014068604, Accuracy: 0.638671875\n",
      "Batch: 134, Loss: 1.1364058256149292, Accuracy: 0.623046875\n",
      "Batch: 135, Loss: 1.0464799404144287, Accuracy: 0.666015625\n",
      "Batch: 136, Loss: 1.15791654586792, Accuracy: 0.630859375\n",
      "Batch: 137, Loss: 1.088773488998413, Accuracy: 0.6259765625\n",
      "Batch: 138, Loss: 0.9622812271118164, Accuracy: 0.673828125\n",
      "Batch: 139, Loss: 1.072124719619751, Accuracy: 0.646484375\n",
      "Batch: 140, Loss: 1.1382830142974854, Accuracy: 0.62890625\n",
      "Batch: 141, Loss: 1.1671195030212402, Accuracy: 0.623046875\n",
      "Batch: 142, Loss: 1.1865296363830566, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.1798597574234009, Accuracy: 0.630859375\n",
      "Batch: 144, Loss: 1.1403056383132935, Accuracy: 0.6396484375\n",
      "Batch: 145, Loss: 1.089741587638855, Accuracy: 0.6328125\n",
      "Batch: 146, Loss: 1.2139055728912354, Accuracy: 0.5927734375\n",
      "Batch: 147, Loss: 1.1532211303710938, Accuracy: 0.6337890625\n",
      "Batch: 148, Loss: 1.3064266443252563, Accuracy: 0.5751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 1.161123514175415, Accuracy: 0.6328125\n",
      "Batch: 150, Loss: 1.0879571437835693, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.039638876914978, Accuracy: 0.681640625\n",
      "Epoch 13/80\n",
      "Batch: 1, Loss: 1.3668341636657715, Accuracy: 0.5615234375\n",
      "Batch: 2, Loss: 1.2196592092514038, Accuracy: 0.587890625\n",
      "Batch: 3, Loss: 1.1189765930175781, Accuracy: 0.63671875\n",
      "Batch: 4, Loss: 1.03501558303833, Accuracy: 0.6708984375\n",
      "Batch: 5, Loss: 1.0725839138031006, Accuracy: 0.6787109375\n",
      "Batch: 6, Loss: 1.138562798500061, Accuracy: 0.6123046875\n",
      "Batch: 7, Loss: 1.1380811929702759, Accuracy: 0.6259765625\n",
      "Batch: 8, Loss: 1.0526645183563232, Accuracy: 0.658203125\n",
      "Batch: 9, Loss: 1.0301421880722046, Accuracy: 0.66796875\n",
      "Batch: 10, Loss: 1.0295875072479248, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 1.2091469764709473, Accuracy: 0.6103515625\n",
      "Batch: 12, Loss: 1.1919970512390137, Accuracy: 0.611328125\n",
      "Batch: 13, Loss: 1.0000579357147217, Accuracy: 0.685546875\n",
      "Batch: 14, Loss: 1.226117730140686, Accuracy: 0.607421875\n",
      "Batch: 15, Loss: 1.068138837814331, Accuracy: 0.6689453125\n",
      "Batch: 16, Loss: 1.060915231704712, Accuracy: 0.6748046875\n",
      "Batch: 17, Loss: 1.1750999689102173, Accuracy: 0.642578125\n",
      "Batch: 18, Loss: 1.1576366424560547, Accuracy: 0.6357421875\n",
      "Batch: 19, Loss: 1.187882900238037, Accuracy: 0.638671875\n",
      "Batch: 20, Loss: 1.0831366777420044, Accuracy: 0.67578125\n",
      "Batch: 21, Loss: 1.0966825485229492, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.1937358379364014, Accuracy: 0.6142578125\n",
      "Batch: 23, Loss: 1.0804908275604248, Accuracy: 0.6396484375\n",
      "Batch: 24, Loss: 1.1456072330474854, Accuracy: 0.6416015625\n",
      "Batch: 25, Loss: 1.1157500743865967, Accuracy: 0.6455078125\n",
      "Batch: 26, Loss: 1.008911371231079, Accuracy: 0.6875\n",
      "Batch: 27, Loss: 1.0555686950683594, Accuracy: 0.6650390625\n",
      "Batch: 28, Loss: 1.162576675415039, Accuracy: 0.6220703125\n",
      "Batch: 29, Loss: 1.1427640914916992, Accuracy: 0.6357421875\n",
      "Batch: 30, Loss: 1.0787569284439087, Accuracy: 0.662109375\n",
      "Batch: 31, Loss: 1.0665725469589233, Accuracy: 0.662109375\n",
      "Batch: 32, Loss: 1.0447880029678345, Accuracy: 0.6640625\n",
      "Batch: 33, Loss: 1.2239760160446167, Accuracy: 0.607421875\n",
      "Batch: 34, Loss: 1.2816358804702759, Accuracy: 0.58984375\n",
      "Batch: 35, Loss: 1.1510541439056396, Accuracy: 0.626953125\n",
      "Batch: 36, Loss: 1.1824084520339966, Accuracy: 0.6357421875\n",
      "Batch: 37, Loss: 1.194366455078125, Accuracy: 0.6298828125\n",
      "Batch: 38, Loss: 1.148787260055542, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.1657764911651611, Accuracy: 0.650390625\n",
      "Batch: 40, Loss: 1.1854562759399414, Accuracy: 0.634765625\n",
      "Batch: 41, Loss: 1.176588535308838, Accuracy: 0.6162109375\n",
      "Batch: 42, Loss: 0.9306463003158569, Accuracy: 0.7080078125\n",
      "Batch: 43, Loss: 1.1118812561035156, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.1449655294418335, Accuracy: 0.6201171875\n",
      "Batch: 45, Loss: 0.9718043208122253, Accuracy: 0.6708984375\n",
      "Batch: 46, Loss: 1.102081537246704, Accuracy: 0.66015625\n",
      "Batch: 47, Loss: 1.1098700761795044, Accuracy: 0.6650390625\n",
      "Batch: 48, Loss: 1.0866727828979492, Accuracy: 0.65234375\n",
      "Batch: 49, Loss: 1.276710033416748, Accuracy: 0.5947265625\n",
      "Batch: 50, Loss: 1.1951546669006348, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.294198751449585, Accuracy: 0.59765625\n",
      "Batch: 52, Loss: 1.2278696298599243, Accuracy: 0.6181640625\n",
      "Batch: 53, Loss: 1.0341719388961792, Accuracy: 0.6572265625\n",
      "Batch: 54, Loss: 1.1195461750030518, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.1813898086547852, Accuracy: 0.615234375\n",
      "Batch: 56, Loss: 1.170143723487854, Accuracy: 0.630859375\n",
      "Batch: 57, Loss: 1.1446428298950195, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.2147797346115112, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.0151476860046387, Accuracy: 0.689453125\n",
      "Batch: 60, Loss: 1.010182499885559, Accuracy: 0.6787109375\n",
      "Batch: 61, Loss: 1.1431238651275635, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.0858497619628906, Accuracy: 0.6572265625\n",
      "Batch: 63, Loss: 1.1075825691223145, Accuracy: 0.6435546875\n",
      "Batch: 64, Loss: 1.1087894439697266, Accuracy: 0.6533203125\n",
      "Batch: 65, Loss: 1.1211395263671875, Accuracy: 0.6630859375\n",
      "Batch: 66, Loss: 1.0729374885559082, Accuracy: 0.66796875\n",
      "Batch: 67, Loss: 1.1729326248168945, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.1912624835968018, Accuracy: 0.6279296875\n",
      "Batch: 69, Loss: 1.1099706888198853, Accuracy: 0.6435546875\n",
      "Batch: 70, Loss: 1.1535584926605225, Accuracy: 0.642578125\n",
      "Batch: 71, Loss: 1.1594696044921875, Accuracy: 0.6279296875\n",
      "Batch: 72, Loss: 1.0470681190490723, Accuracy: 0.66796875\n",
      "Batch: 73, Loss: 1.1080386638641357, Accuracy: 0.666015625\n",
      "Batch: 74, Loss: 1.0868982076644897, Accuracy: 0.666015625\n",
      "Batch: 75, Loss: 1.0061827898025513, Accuracy: 0.669921875\n",
      "Batch: 76, Loss: 1.1421163082122803, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.1118128299713135, Accuracy: 0.646484375\n",
      "Batch: 78, Loss: 1.1192843914031982, Accuracy: 0.66015625\n",
      "Batch: 79, Loss: 1.0330519676208496, Accuracy: 0.697265625\n",
      "Batch: 80, Loss: 1.0377724170684814, Accuracy: 0.66796875\n",
      "Batch: 81, Loss: 1.179090142250061, Accuracy: 0.607421875\n",
      "Batch: 82, Loss: 1.144019603729248, Accuracy: 0.6357421875\n",
      "Batch: 83, Loss: 1.0048846006393433, Accuracy: 0.7041015625\n",
      "Batch: 84, Loss: 1.093735933303833, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.013331413269043, Accuracy: 0.6826171875\n",
      "Batch: 86, Loss: 1.271560788154602, Accuracy: 0.6162109375\n",
      "Batch: 87, Loss: 1.0750160217285156, Accuracy: 0.673828125\n",
      "Batch: 88, Loss: 1.1899986267089844, Accuracy: 0.63671875\n",
      "Batch: 89, Loss: 1.1573433876037598, Accuracy: 0.638671875\n",
      "Batch: 90, Loss: 1.058020830154419, Accuracy: 0.666015625\n",
      "Batch: 91, Loss: 1.1104671955108643, Accuracy: 0.646484375\n",
      "Batch: 92, Loss: 1.1173982620239258, Accuracy: 0.6455078125\n",
      "Batch: 93, Loss: 1.0651025772094727, Accuracy: 0.677734375\n",
      "Batch: 94, Loss: 1.0796297788619995, Accuracy: 0.646484375\n",
      "Batch: 95, Loss: 1.142730474472046, Accuracy: 0.6298828125\n",
      "Batch: 96, Loss: 1.102376937866211, Accuracy: 0.6552734375\n",
      "Batch: 97, Loss: 0.9670304656028748, Accuracy: 0.6865234375\n",
      "Batch: 98, Loss: 1.0262216329574585, Accuracy: 0.6884765625\n",
      "Batch: 99, Loss: 1.015681505203247, Accuracy: 0.671875\n",
      "Batch: 100, Loss: 1.0714688301086426, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.1584763526916504, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.0614113807678223, Accuracy: 0.6552734375\n",
      "Batch: 103, Loss: 1.1467055082321167, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.0527167320251465, Accuracy: 0.650390625\n",
      "Batch: 105, Loss: 1.1596355438232422, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.1056571006774902, Accuracy: 0.654296875\n",
      "Batch: 107, Loss: 1.2129004001617432, Accuracy: 0.6318359375\n",
      "Batch: 108, Loss: 1.2087833881378174, Accuracy: 0.6025390625\n",
      "Batch: 109, Loss: 1.2833343744277954, Accuracy: 0.580078125\n",
      "Batch: 110, Loss: 0.9712789058685303, Accuracy: 0.69921875\n",
      "Batch: 111, Loss: 1.186582326889038, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.1495518684387207, Accuracy: 0.646484375\n",
      "Batch: 113, Loss: 1.1336183547973633, Accuracy: 0.65625\n",
      "Batch: 114, Loss: 1.2414839267730713, Accuracy: 0.59765625\n",
      "Batch: 115, Loss: 1.2604515552520752, Accuracy: 0.6201171875\n",
      "Batch: 116, Loss: 1.193030595779419, Accuracy: 0.6259765625\n",
      "Batch: 117, Loss: 1.1768927574157715, Accuracy: 0.6396484375\n",
      "Batch: 118, Loss: 1.0003188848495483, Accuracy: 0.68359375\n",
      "Batch: 119, Loss: 1.0386145114898682, Accuracy: 0.681640625\n",
      "Batch: 120, Loss: 1.182848572731018, Accuracy: 0.619140625\n",
      "Batch: 121, Loss: 1.2032113075256348, Accuracy: 0.6298828125\n",
      "Batch: 122, Loss: 1.0802994966506958, Accuracy: 0.669921875\n",
      "Batch: 123, Loss: 1.1076563596725464, Accuracy: 0.6494140625\n",
      "Batch: 124, Loss: 1.1312413215637207, Accuracy: 0.6435546875\n",
      "Batch: 125, Loss: 1.1834228038787842, Accuracy: 0.6220703125\n",
      "Batch: 126, Loss: 1.1414422988891602, Accuracy: 0.6298828125\n",
      "Batch: 127, Loss: 1.025501012802124, Accuracy: 0.69140625\n",
      "Batch: 128, Loss: 1.2502226829528809, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.0816177129745483, Accuracy: 0.64453125\n",
      "Batch: 130, Loss: 1.3220348358154297, Accuracy: 0.5966796875\n",
      "Batch: 131, Loss: 1.185393214225769, Accuracy: 0.6279296875\n",
      "Batch: 132, Loss: 1.2124912738800049, Accuracy: 0.6259765625\n",
      "Batch: 133, Loss: 1.0610260963439941, Accuracy: 0.666015625\n",
      "Batch: 134, Loss: 1.1137878894805908, Accuracy: 0.6435546875\n",
      "Batch: 135, Loss: 1.0580085515975952, Accuracy: 0.6875\n",
      "Batch: 136, Loss: 1.1133450269699097, Accuracy: 0.6650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 1.07059645652771, Accuracy: 0.6435546875\n",
      "Batch: 138, Loss: 0.9438832998275757, Accuracy: 0.6826171875\n",
      "Batch: 139, Loss: 1.0226576328277588, Accuracy: 0.66015625\n",
      "Batch: 140, Loss: 1.1271841526031494, Accuracy: 0.6220703125\n",
      "Batch: 141, Loss: 1.1127455234527588, Accuracy: 0.642578125\n",
      "Batch: 142, Loss: 1.17866849899292, Accuracy: 0.6474609375\n",
      "Batch: 143, Loss: 1.1275771856307983, Accuracy: 0.6435546875\n",
      "Batch: 144, Loss: 1.1341631412506104, Accuracy: 0.6416015625\n",
      "Batch: 145, Loss: 1.0499086380004883, Accuracy: 0.6416015625\n",
      "Batch: 146, Loss: 1.187490463256836, Accuracy: 0.6123046875\n",
      "Batch: 147, Loss: 1.149134635925293, Accuracy: 0.6318359375\n",
      "Batch: 148, Loss: 1.2731573581695557, Accuracy: 0.59375\n",
      "Batch: 149, Loss: 1.1413218975067139, Accuracy: 0.6376953125\n",
      "Batch: 150, Loss: 1.0684844255447388, Accuracy: 0.638671875\n",
      "Batch: 151, Loss: 0.9880421161651611, Accuracy: 0.6787109375\n",
      "Epoch 14/80\n",
      "Batch: 1, Loss: 1.3470420837402344, Accuracy: 0.5654296875\n",
      "Batch: 2, Loss: 1.1986415386199951, Accuracy: 0.5830078125\n",
      "Batch: 3, Loss: 1.0712307691574097, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 1.0148704051971436, Accuracy: 0.693359375\n",
      "Batch: 5, Loss: 1.0345427989959717, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.1393396854400635, Accuracy: 0.62890625\n",
      "Batch: 7, Loss: 1.0991148948669434, Accuracy: 0.62890625\n",
      "Batch: 8, Loss: 1.0168962478637695, Accuracy: 0.6552734375\n",
      "Batch: 9, Loss: 1.0065646171569824, Accuracy: 0.6923828125\n",
      "Batch: 10, Loss: 1.0075874328613281, Accuracy: 0.6806640625\n",
      "Batch: 11, Loss: 1.1636149883270264, Accuracy: 0.6181640625\n",
      "Batch: 12, Loss: 1.185197353363037, Accuracy: 0.611328125\n",
      "Batch: 13, Loss: 0.9355647563934326, Accuracy: 0.7041015625\n",
      "Batch: 14, Loss: 1.1806232929229736, Accuracy: 0.6162109375\n",
      "Batch: 15, Loss: 1.0318231582641602, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 1.043830156326294, Accuracy: 0.6796875\n",
      "Batch: 17, Loss: 1.1441538333892822, Accuracy: 0.6474609375\n",
      "Batch: 18, Loss: 1.1331160068511963, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1576675176620483, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.0497068166732788, Accuracy: 0.677734375\n",
      "Batch: 21, Loss: 1.0478947162628174, Accuracy: 0.6640625\n",
      "Batch: 22, Loss: 1.1747088432312012, Accuracy: 0.6328125\n",
      "Batch: 23, Loss: 1.0623687505722046, Accuracy: 0.6494140625\n",
      "Batch: 24, Loss: 1.1213014125823975, Accuracy: 0.638671875\n",
      "Batch: 25, Loss: 1.0803537368774414, Accuracy: 0.646484375\n",
      "Batch: 26, Loss: 0.9885299801826477, Accuracy: 0.68359375\n",
      "Batch: 27, Loss: 1.035780429840088, Accuracy: 0.6640625\n",
      "Batch: 28, Loss: 1.1182050704956055, Accuracy: 0.638671875\n",
      "Batch: 29, Loss: 1.1128791570663452, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.0750010013580322, Accuracy: 0.6728515625\n",
      "Batch: 31, Loss: 1.0394713878631592, Accuracy: 0.6787109375\n",
      "Batch: 32, Loss: 1.025327444076538, Accuracy: 0.6689453125\n",
      "Batch: 33, Loss: 1.1700458526611328, Accuracy: 0.6279296875\n",
      "Batch: 34, Loss: 1.2641514539718628, Accuracy: 0.6064453125\n",
      "Batch: 35, Loss: 1.1143739223480225, Accuracy: 0.630859375\n",
      "Batch: 36, Loss: 1.1617906093597412, Accuracy: 0.6455078125\n",
      "Batch: 37, Loss: 1.1597034931182861, Accuracy: 0.640625\n",
      "Batch: 38, Loss: 1.1326425075531006, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.1614277362823486, Accuracy: 0.6298828125\n",
      "Batch: 40, Loss: 1.129630446434021, Accuracy: 0.65234375\n",
      "Batch: 41, Loss: 1.1464145183563232, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 0.895075798034668, Accuracy: 0.7001953125\n",
      "Batch: 43, Loss: 1.1022392511367798, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.084139108657837, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 0.9465586543083191, Accuracy: 0.68359375\n",
      "Batch: 46, Loss: 1.063597321510315, Accuracy: 0.6650390625\n",
      "Batch: 47, Loss: 1.0746713876724243, Accuracy: 0.6669921875\n",
      "Batch: 48, Loss: 1.0429960489273071, Accuracy: 0.662109375\n",
      "Batch: 49, Loss: 1.2137051820755005, Accuracy: 0.6015625\n",
      "Batch: 50, Loss: 1.1609854698181152, Accuracy: 0.623046875\n",
      "Batch: 51, Loss: 1.2604928016662598, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.201741099357605, Accuracy: 0.6220703125\n",
      "Batch: 53, Loss: 1.0138781070709229, Accuracy: 0.662109375\n",
      "Batch: 54, Loss: 1.0893328189849854, Accuracy: 0.650390625\n",
      "Batch: 55, Loss: 1.1500571966171265, Accuracy: 0.623046875\n",
      "Batch: 56, Loss: 1.1397781372070312, Accuracy: 0.6357421875\n",
      "Batch: 57, Loss: 1.0845160484313965, Accuracy: 0.6728515625\n",
      "Batch: 58, Loss: 1.1934261322021484, Accuracy: 0.6474609375\n",
      "Batch: 59, Loss: 0.9842672944068909, Accuracy: 0.689453125\n",
      "Batch: 60, Loss: 0.9881118535995483, Accuracy: 0.685546875\n",
      "Batch: 61, Loss: 1.1392476558685303, Accuracy: 0.6416015625\n",
      "Batch: 62, Loss: 1.0557301044464111, Accuracy: 0.6708984375\n",
      "Batch: 63, Loss: 1.081681489944458, Accuracy: 0.66796875\n",
      "Batch: 64, Loss: 1.0708551406860352, Accuracy: 0.65625\n",
      "Batch: 65, Loss: 1.0907708406448364, Accuracy: 0.6748046875\n",
      "Batch: 66, Loss: 1.0282063484191895, Accuracy: 0.6845703125\n",
      "Batch: 67, Loss: 1.1496104001998901, Accuracy: 0.6572265625\n",
      "Batch: 68, Loss: 1.1623753309249878, Accuracy: 0.6416015625\n",
      "Batch: 69, Loss: 1.0946986675262451, Accuracy: 0.6416015625\n",
      "Batch: 70, Loss: 1.1010849475860596, Accuracy: 0.6552734375\n",
      "Batch: 71, Loss: 1.1465420722961426, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 1.0102194547653198, Accuracy: 0.673828125\n",
      "Batch: 73, Loss: 1.0642906427383423, Accuracy: 0.65625\n",
      "Batch: 74, Loss: 1.0221654176712036, Accuracy: 0.673828125\n",
      "Batch: 75, Loss: 0.9651327133178711, Accuracy: 0.6962890625\n",
      "Batch: 76, Loss: 1.0841156244277954, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.077012300491333, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.0758683681488037, Accuracy: 0.669921875\n",
      "Batch: 79, Loss: 0.9977171421051025, Accuracy: 0.70703125\n",
      "Batch: 80, Loss: 0.992786169052124, Accuracy: 0.6689453125\n",
      "Batch: 81, Loss: 1.1589206457138062, Accuracy: 0.5986328125\n",
      "Batch: 82, Loss: 1.1048845052719116, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 0.9591742157936096, Accuracy: 0.7109375\n",
      "Batch: 84, Loss: 1.0469810962677002, Accuracy: 0.66796875\n",
      "Batch: 85, Loss: 0.9795483946800232, Accuracy: 0.6884765625\n",
      "Batch: 86, Loss: 1.2285181283950806, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.047425389289856, Accuracy: 0.6767578125\n",
      "Batch: 88, Loss: 1.1454882621765137, Accuracy: 0.6591796875\n",
      "Batch: 89, Loss: 1.1383183002471924, Accuracy: 0.6552734375\n",
      "Batch: 90, Loss: 1.046109676361084, Accuracy: 0.671875\n",
      "Batch: 91, Loss: 1.057436466217041, Accuracy: 0.6650390625\n",
      "Batch: 92, Loss: 1.1061487197875977, Accuracy: 0.6484375\n",
      "Batch: 93, Loss: 1.0559602975845337, Accuracy: 0.6650390625\n",
      "Batch: 94, Loss: 1.052964687347412, Accuracy: 0.662109375\n",
      "Batch: 95, Loss: 1.1206328868865967, Accuracy: 0.6298828125\n",
      "Batch: 96, Loss: 1.0573104619979858, Accuracy: 0.6591796875\n",
      "Batch: 97, Loss: 0.9624289274215698, Accuracy: 0.6943359375\n",
      "Batch: 98, Loss: 1.0156221389770508, Accuracy: 0.68359375\n",
      "Batch: 99, Loss: 1.0010056495666504, Accuracy: 0.681640625\n",
      "Batch: 100, Loss: 1.0474379062652588, Accuracy: 0.6689453125\n",
      "Batch: 101, Loss: 1.1489388942718506, Accuracy: 0.6416015625\n",
      "Batch: 102, Loss: 1.0482033491134644, Accuracy: 0.669921875\n",
      "Batch: 103, Loss: 1.1468145847320557, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.0189852714538574, Accuracy: 0.6630859375\n",
      "Batch: 105, Loss: 1.1260911226272583, Accuracy: 0.6318359375\n",
      "Batch: 106, Loss: 1.0959224700927734, Accuracy: 0.662109375\n",
      "Batch: 107, Loss: 1.1688387393951416, Accuracy: 0.64453125\n",
      "Batch: 108, Loss: 1.151690125465393, Accuracy: 0.62109375\n",
      "Batch: 109, Loss: 1.240347146987915, Accuracy: 0.599609375\n",
      "Batch: 110, Loss: 0.9595872759819031, Accuracy: 0.6982421875\n",
      "Batch: 111, Loss: 1.154358983039856, Accuracy: 0.6240234375\n",
      "Batch: 112, Loss: 1.1468231678009033, Accuracy: 0.6337890625\n",
      "Batch: 113, Loss: 1.1226404905319214, Accuracy: 0.6552734375\n",
      "Batch: 114, Loss: 1.2204797267913818, Accuracy: 0.6240234375\n",
      "Batch: 115, Loss: 1.226032018661499, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.187963843345642, Accuracy: 0.626953125\n",
      "Batch: 117, Loss: 1.1644649505615234, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 0.9586373567581177, Accuracy: 0.705078125\n",
      "Batch: 119, Loss: 1.0092196464538574, Accuracy: 0.6875\n",
      "Batch: 120, Loss: 1.1408185958862305, Accuracy: 0.626953125\n",
      "Batch: 121, Loss: 1.1616203784942627, Accuracy: 0.6220703125\n",
      "Batch: 122, Loss: 1.046351671218872, Accuracy: 0.67578125\n",
      "Batch: 123, Loss: 1.0843305587768555, Accuracy: 0.669921875\n",
      "Batch: 124, Loss: 1.1203718185424805, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 125, Loss: 1.1365773677825928, Accuracy: 0.634765625\n",
      "Batch: 126, Loss: 1.106960654258728, Accuracy: 0.658203125\n",
      "Batch: 127, Loss: 1.0019956827163696, Accuracy: 0.68359375\n",
      "Batch: 128, Loss: 1.2180222272872925, Accuracy: 0.6376953125\n",
      "Batch: 129, Loss: 1.0651620626449585, Accuracy: 0.6630859375\n",
      "Batch: 130, Loss: 1.3040424585342407, Accuracy: 0.5888671875\n",
      "Batch: 131, Loss: 1.1970099210739136, Accuracy: 0.62890625\n",
      "Batch: 132, Loss: 1.1704201698303223, Accuracy: 0.64453125\n",
      "Batch: 133, Loss: 1.0241992473602295, Accuracy: 0.6650390625\n",
      "Batch: 134, Loss: 1.1048216819763184, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.0167057514190674, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.1011391878128052, Accuracy: 0.6572265625\n",
      "Batch: 137, Loss: 1.081127643585205, Accuracy: 0.6240234375\n",
      "Batch: 138, Loss: 0.925516664981842, Accuracy: 0.6826171875\n",
      "Batch: 139, Loss: 1.0069780349731445, Accuracy: 0.66015625\n",
      "Batch: 140, Loss: 1.0855642557144165, Accuracy: 0.6376953125\n",
      "Batch: 141, Loss: 1.095578908920288, Accuracy: 0.6552734375\n",
      "Batch: 142, Loss: 1.136159896850586, Accuracy: 0.634765625\n",
      "Batch: 143, Loss: 1.0882831811904907, Accuracy: 0.646484375\n",
      "Batch: 144, Loss: 1.10225510597229, Accuracy: 0.654296875\n",
      "Batch: 145, Loss: 1.029009461402893, Accuracy: 0.6455078125\n",
      "Batch: 146, Loss: 1.1692571640014648, Accuracy: 0.630859375\n",
      "Batch: 147, Loss: 1.1052151918411255, Accuracy: 0.65234375\n",
      "Batch: 148, Loss: 1.2324414253234863, Accuracy: 0.5859375\n",
      "Batch: 149, Loss: 1.110243558883667, Accuracy: 0.6455078125\n",
      "Batch: 150, Loss: 1.0342817306518555, Accuracy: 0.662109375\n",
      "Batch: 151, Loss: 0.964766263961792, Accuracy: 0.6865234375\n",
      "Epoch 15/80\n",
      "Batch: 1, Loss: 1.3199387788772583, Accuracy: 0.5830078125\n",
      "Batch: 2, Loss: 1.1659049987792969, Accuracy: 0.611328125\n",
      "Batch: 3, Loss: 1.0514237880706787, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 0.9822826981544495, Accuracy: 0.70703125\n",
      "Batch: 5, Loss: 1.0222455263137817, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.106950283050537, Accuracy: 0.625\n",
      "Batch: 7, Loss: 1.0786194801330566, Accuracy: 0.63671875\n",
      "Batch: 8, Loss: 0.996618390083313, Accuracy: 0.673828125\n",
      "Batch: 9, Loss: 0.9760164618492126, Accuracy: 0.6962890625\n",
      "Batch: 10, Loss: 0.9560463428497314, Accuracy: 0.6884765625\n",
      "Batch: 11, Loss: 1.142686128616333, Accuracy: 0.640625\n",
      "Batch: 12, Loss: 1.1250810623168945, Accuracy: 0.6318359375\n",
      "Batch: 13, Loss: 0.9229019284248352, Accuracy: 0.7041015625\n",
      "Batch: 14, Loss: 1.187037467956543, Accuracy: 0.6171875\n",
      "Batch: 15, Loss: 1.033764362335205, Accuracy: 0.6865234375\n",
      "Batch: 16, Loss: 1.0461390018463135, Accuracy: 0.6689453125\n",
      "Batch: 17, Loss: 1.1628133058547974, Accuracy: 0.6259765625\n",
      "Batch: 18, Loss: 1.1134690046310425, Accuracy: 0.654296875\n",
      "Batch: 19, Loss: 1.1613423824310303, Accuracy: 0.6513671875\n",
      "Batch: 20, Loss: 1.0331672430038452, Accuracy: 0.67578125\n",
      "Batch: 21, Loss: 1.0186407566070557, Accuracy: 0.658203125\n",
      "Batch: 22, Loss: 1.1662237644195557, Accuracy: 0.640625\n",
      "Batch: 23, Loss: 1.068586826324463, Accuracy: 0.650390625\n",
      "Batch: 24, Loss: 1.1468998193740845, Accuracy: 0.6376953125\n",
      "Batch: 25, Loss: 1.1141676902770996, Accuracy: 0.6533203125\n",
      "Batch: 26, Loss: 0.9880934953689575, Accuracy: 0.6953125\n",
      "Batch: 27, Loss: 1.0288445949554443, Accuracy: 0.66015625\n",
      "Batch: 28, Loss: 1.0898387432098389, Accuracy: 0.6337890625\n",
      "Batch: 29, Loss: 1.0905252695083618, Accuracy: 0.6513671875\n",
      "Batch: 30, Loss: 1.0305968523025513, Accuracy: 0.68359375\n",
      "Batch: 31, Loss: 1.029891014099121, Accuracy: 0.6728515625\n",
      "Batch: 32, Loss: 1.001941442489624, Accuracy: 0.67578125\n",
      "Batch: 33, Loss: 1.1803762912750244, Accuracy: 0.6103515625\n",
      "Batch: 34, Loss: 1.220569372177124, Accuracy: 0.6044921875\n",
      "Batch: 35, Loss: 1.1266288757324219, Accuracy: 0.6162109375\n",
      "Batch: 36, Loss: 1.1206550598144531, Accuracy: 0.6513671875\n",
      "Batch: 37, Loss: 1.0913934707641602, Accuracy: 0.662109375\n",
      "Batch: 38, Loss: 1.128686785697937, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.12876296043396, Accuracy: 0.6572265625\n",
      "Batch: 40, Loss: 1.1283535957336426, Accuracy: 0.646484375\n",
      "Batch: 41, Loss: 1.1107544898986816, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 0.921001672744751, Accuracy: 0.693359375\n",
      "Batch: 43, Loss: 1.0895211696624756, Accuracy: 0.6298828125\n",
      "Batch: 44, Loss: 1.0906864404678345, Accuracy: 0.6416015625\n",
      "Batch: 45, Loss: 0.9340614676475525, Accuracy: 0.6904296875\n",
      "Batch: 46, Loss: 1.044440746307373, Accuracy: 0.6748046875\n",
      "Batch: 47, Loss: 1.0509648323059082, Accuracy: 0.6748046875\n",
      "Batch: 48, Loss: 1.007521390914917, Accuracy: 0.6787109375\n",
      "Batch: 49, Loss: 1.2044765949249268, Accuracy: 0.6123046875\n",
      "Batch: 50, Loss: 1.1397547721862793, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.2380192279815674, Accuracy: 0.615234375\n",
      "Batch: 52, Loss: 1.1795583963394165, Accuracy: 0.6337890625\n",
      "Batch: 53, Loss: 0.9971333742141724, Accuracy: 0.6630859375\n",
      "Batch: 54, Loss: 1.0900685787200928, Accuracy: 0.6552734375\n",
      "Batch: 55, Loss: 1.1297491788864136, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.1536991596221924, Accuracy: 0.6396484375\n",
      "Batch: 57, Loss: 1.085597038269043, Accuracy: 0.6533203125\n",
      "Batch: 58, Loss: 1.1750259399414062, Accuracy: 0.642578125\n",
      "Batch: 59, Loss: 0.999545693397522, Accuracy: 0.69921875\n",
      "Batch: 60, Loss: 0.966634213924408, Accuracy: 0.677734375\n",
      "Batch: 61, Loss: 1.1234710216522217, Accuracy: 0.6396484375\n",
      "Batch: 62, Loss: 1.0291485786437988, Accuracy: 0.6767578125\n",
      "Batch: 63, Loss: 1.0670733451843262, Accuracy: 0.658203125\n",
      "Batch: 64, Loss: 1.0327911376953125, Accuracy: 0.6689453125\n",
      "Batch: 65, Loss: 1.0790249109268188, Accuracy: 0.6796875\n",
      "Batch: 66, Loss: 1.0084259510040283, Accuracy: 0.689453125\n",
      "Batch: 67, Loss: 1.1237287521362305, Accuracy: 0.6611328125\n",
      "Batch: 68, Loss: 1.1487962007522583, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.0898158550262451, Accuracy: 0.6484375\n",
      "Batch: 70, Loss: 1.0859838724136353, Accuracy: 0.6513671875\n",
      "Batch: 71, Loss: 1.1012327671051025, Accuracy: 0.6416015625\n",
      "Batch: 72, Loss: 0.9630348682403564, Accuracy: 0.6904296875\n",
      "Batch: 73, Loss: 1.0263466835021973, Accuracy: 0.6708984375\n",
      "Batch: 74, Loss: 0.9940087795257568, Accuracy: 0.701171875\n",
      "Batch: 75, Loss: 0.9572716355323792, Accuracy: 0.6982421875\n",
      "Batch: 76, Loss: 1.075812816619873, Accuracy: 0.6357421875\n",
      "Batch: 77, Loss: 1.037125587463379, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.0496140718460083, Accuracy: 0.677734375\n",
      "Batch: 79, Loss: 0.9956951141357422, Accuracy: 0.7041015625\n",
      "Batch: 80, Loss: 0.9864105582237244, Accuracy: 0.6669921875\n",
      "Batch: 81, Loss: 1.1294420957565308, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.1072701215744019, Accuracy: 0.6337890625\n",
      "Batch: 83, Loss: 0.9332945346832275, Accuracy: 0.724609375\n",
      "Batch: 84, Loss: 1.040390968322754, Accuracy: 0.671875\n",
      "Batch: 85, Loss: 0.9635387659072876, Accuracy: 0.7060546875\n",
      "Batch: 86, Loss: 1.2305426597595215, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.0175082683563232, Accuracy: 0.6845703125\n",
      "Batch: 88, Loss: 1.1420528888702393, Accuracy: 0.654296875\n",
      "Batch: 89, Loss: 1.0974526405334473, Accuracy: 0.6630859375\n",
      "Batch: 90, Loss: 1.0018712282180786, Accuracy: 0.677734375\n",
      "Batch: 91, Loss: 1.0394673347473145, Accuracy: 0.6708984375\n",
      "Batch: 92, Loss: 1.0826671123504639, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.0139827728271484, Accuracy: 0.6845703125\n",
      "Batch: 94, Loss: 1.0076014995574951, Accuracy: 0.6689453125\n",
      "Batch: 95, Loss: 1.084380865097046, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.0544333457946777, Accuracy: 0.6796875\n",
      "Batch: 97, Loss: 0.9264365434646606, Accuracy: 0.7041015625\n",
      "Batch: 98, Loss: 0.9835858345031738, Accuracy: 0.6953125\n",
      "Batch: 99, Loss: 0.9709898829460144, Accuracy: 0.6865234375\n",
      "Batch: 100, Loss: 1.0402804613113403, Accuracy: 0.6865234375\n",
      "Batch: 101, Loss: 1.1153432130813599, Accuracy: 0.658203125\n",
      "Batch: 102, Loss: 1.040062665939331, Accuracy: 0.6787109375\n",
      "Batch: 103, Loss: 1.0945477485656738, Accuracy: 0.6611328125\n",
      "Batch: 104, Loss: 1.0040849447250366, Accuracy: 0.6728515625\n",
      "Batch: 105, Loss: 1.0994261503219604, Accuracy: 0.646484375\n",
      "Batch: 106, Loss: 1.0605183839797974, Accuracy: 0.6689453125\n",
      "Batch: 107, Loss: 1.1268894672393799, Accuracy: 0.6337890625\n",
      "Batch: 108, Loss: 1.1024872064590454, Accuracy: 0.6298828125\n",
      "Batch: 109, Loss: 1.2298691272735596, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 0.9404579401016235, Accuracy: 0.7021484375\n",
      "Batch: 111, Loss: 1.1230237483978271, Accuracy: 0.6396484375\n",
      "Batch: 112, Loss: 1.0784540176391602, Accuracy: 0.66796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 113, Loss: 1.0942960977554321, Accuracy: 0.65625\n",
      "Batch: 114, Loss: 1.1769657135009766, Accuracy: 0.619140625\n",
      "Batch: 115, Loss: 1.1722080707550049, Accuracy: 0.640625\n",
      "Batch: 116, Loss: 1.1207160949707031, Accuracy: 0.64453125\n",
      "Batch: 117, Loss: 1.1262269020080566, Accuracy: 0.65234375\n",
      "Batch: 118, Loss: 0.936225414276123, Accuracy: 0.7119140625\n",
      "Batch: 119, Loss: 0.9737510681152344, Accuracy: 0.697265625\n",
      "Batch: 120, Loss: 1.10930597782135, Accuracy: 0.6416015625\n",
      "Batch: 121, Loss: 1.110269546508789, Accuracy: 0.6474609375\n",
      "Batch: 122, Loss: 1.0300772190093994, Accuracy: 0.685546875\n",
      "Batch: 123, Loss: 1.0098496675491333, Accuracy: 0.6845703125\n",
      "Batch: 124, Loss: 1.0729402303695679, Accuracy: 0.65625\n",
      "Batch: 125, Loss: 1.112167477607727, Accuracy: 0.6494140625\n",
      "Batch: 126, Loss: 1.0877315998077393, Accuracy: 0.642578125\n",
      "Batch: 127, Loss: 0.9888567924499512, Accuracy: 0.69921875\n",
      "Batch: 128, Loss: 1.2053513526916504, Accuracy: 0.62890625\n",
      "Batch: 129, Loss: 1.0396525859832764, Accuracy: 0.6767578125\n",
      "Batch: 130, Loss: 1.2625489234924316, Accuracy: 0.61328125\n",
      "Batch: 131, Loss: 1.129619836807251, Accuracy: 0.6455078125\n",
      "Batch: 132, Loss: 1.1310534477233887, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 1.0209373235702515, Accuracy: 0.666015625\n",
      "Batch: 134, Loss: 1.0720961093902588, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 0.9867442846298218, Accuracy: 0.7021484375\n",
      "Batch: 136, Loss: 1.0751068592071533, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 1.0227490663528442, Accuracy: 0.650390625\n",
      "Batch: 138, Loss: 0.909294605255127, Accuracy: 0.6865234375\n",
      "Batch: 139, Loss: 1.0024782419204712, Accuracy: 0.666015625\n",
      "Batch: 140, Loss: 1.0537159442901611, Accuracy: 0.654296875\n",
      "Batch: 141, Loss: 1.0933533906936646, Accuracy: 0.658203125\n",
      "Batch: 142, Loss: 1.1198183298110962, Accuracy: 0.640625\n",
      "Batch: 143, Loss: 1.1085195541381836, Accuracy: 0.6533203125\n",
      "Batch: 144, Loss: 1.0829906463623047, Accuracy: 0.662109375\n",
      "Batch: 145, Loss: 0.998957633972168, Accuracy: 0.6572265625\n",
      "Batch: 146, Loss: 1.1152770519256592, Accuracy: 0.6416015625\n",
      "Batch: 147, Loss: 1.1112180948257446, Accuracy: 0.646484375\n",
      "Batch: 148, Loss: 1.2385908365249634, Accuracy: 0.5966796875\n",
      "Batch: 149, Loss: 1.0917078256607056, Accuracy: 0.6416015625\n",
      "Batch: 150, Loss: 1.0158060789108276, Accuracy: 0.68359375\n",
      "Batch: 151, Loss: 0.9665930271148682, Accuracy: 0.6923828125\n",
      "Epoch 16/80\n",
      "Batch: 1, Loss: 1.2938687801361084, Accuracy: 0.59375\n",
      "Batch: 2, Loss: 1.1304423809051514, Accuracy: 0.6220703125\n",
      "Batch: 3, Loss: 1.026934027671814, Accuracy: 0.6611328125\n",
      "Batch: 4, Loss: 0.9623420238494873, Accuracy: 0.693359375\n",
      "Batch: 5, Loss: 0.9766235947608948, Accuracy: 0.701171875\n",
      "Batch: 6, Loss: 1.0706746578216553, Accuracy: 0.6396484375\n",
      "Batch: 7, Loss: 1.035650610923767, Accuracy: 0.65625\n",
      "Batch: 8, Loss: 0.9554898738861084, Accuracy: 0.6884765625\n",
      "Batch: 9, Loss: 0.961007833480835, Accuracy: 0.697265625\n",
      "Batch: 10, Loss: 0.9753032922744751, Accuracy: 0.6787109375\n",
      "Batch: 11, Loss: 1.1148688793182373, Accuracy: 0.6435546875\n",
      "Batch: 12, Loss: 1.119704008102417, Accuracy: 0.642578125\n",
      "Batch: 13, Loss: 0.9101800322532654, Accuracy: 0.705078125\n",
      "Batch: 14, Loss: 1.140838623046875, Accuracy: 0.6396484375\n",
      "Batch: 15, Loss: 1.002900242805481, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 0.9933479428291321, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.066168189048767, Accuracy: 0.66015625\n",
      "Batch: 18, Loss: 1.0850591659545898, Accuracy: 0.6572265625\n",
      "Batch: 19, Loss: 1.123178243637085, Accuracy: 0.6640625\n",
      "Batch: 20, Loss: 0.9927147626876831, Accuracy: 0.6904296875\n",
      "Batch: 21, Loss: 0.9980374574661255, Accuracy: 0.673828125\n",
      "Batch: 22, Loss: 1.120753526687622, Accuracy: 0.6484375\n",
      "Batch: 23, Loss: 1.0322771072387695, Accuracy: 0.6708984375\n",
      "Batch: 24, Loss: 1.0743266344070435, Accuracy: 0.6474609375\n",
      "Batch: 25, Loss: 1.0259003639221191, Accuracy: 0.6630859375\n",
      "Batch: 26, Loss: 0.9329454898834229, Accuracy: 0.7001953125\n",
      "Batch: 27, Loss: 0.985396146774292, Accuracy: 0.677734375\n",
      "Batch: 28, Loss: 1.105120301246643, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.0686997175216675, Accuracy: 0.650390625\n",
      "Batch: 30, Loss: 1.0058209896087646, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 0.983599066734314, Accuracy: 0.67578125\n",
      "Batch: 32, Loss: 0.9705173373222351, Accuracy: 0.671875\n",
      "Batch: 33, Loss: 1.1456413269042969, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.2025878429412842, Accuracy: 0.62109375\n",
      "Batch: 35, Loss: 1.0838600397109985, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.0977874994277954, Accuracy: 0.66796875\n",
      "Batch: 37, Loss: 1.0743417739868164, Accuracy: 0.6708984375\n",
      "Batch: 38, Loss: 1.0679819583892822, Accuracy: 0.6513671875\n",
      "Batch: 39, Loss: 1.0841724872589111, Accuracy: 0.6572265625\n",
      "Batch: 40, Loss: 1.105963945388794, Accuracy: 0.65234375\n",
      "Batch: 41, Loss: 1.066065788269043, Accuracy: 0.6591796875\n",
      "Batch: 42, Loss: 0.8423296213150024, Accuracy: 0.728515625\n",
      "Batch: 43, Loss: 1.039050579071045, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.0629963874816895, Accuracy: 0.6376953125\n",
      "Batch: 45, Loss: 0.9018374681472778, Accuracy: 0.6904296875\n",
      "Batch: 46, Loss: 1.0182898044586182, Accuracy: 0.6806640625\n",
      "Batch: 47, Loss: 1.0406091213226318, Accuracy: 0.6943359375\n",
      "Batch: 48, Loss: 0.9751176834106445, Accuracy: 0.6982421875\n",
      "Batch: 49, Loss: 1.1540336608886719, Accuracy: 0.6318359375\n",
      "Batch: 50, Loss: 1.1179594993591309, Accuracy: 0.634765625\n",
      "Batch: 51, Loss: 1.188391089439392, Accuracy: 0.634765625\n",
      "Batch: 52, Loss: 1.1124321222305298, Accuracy: 0.6376953125\n",
      "Batch: 53, Loss: 0.9699634313583374, Accuracy: 0.68359375\n",
      "Batch: 54, Loss: 1.0514642000198364, Accuracy: 0.658203125\n",
      "Batch: 55, Loss: 1.0857210159301758, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.1129777431488037, Accuracy: 0.6591796875\n",
      "Batch: 57, Loss: 1.051687479019165, Accuracy: 0.662109375\n",
      "Batch: 58, Loss: 1.14205002784729, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 0.938239336013794, Accuracy: 0.7138671875\n",
      "Batch: 60, Loss: 0.9407252669334412, Accuracy: 0.6904296875\n",
      "Batch: 61, Loss: 1.0905914306640625, Accuracy: 0.64453125\n",
      "Batch: 62, Loss: 1.013364553451538, Accuracy: 0.6806640625\n",
      "Batch: 63, Loss: 1.0411739349365234, Accuracy: 0.6708984375\n",
      "Batch: 64, Loss: 1.0065419673919678, Accuracy: 0.693359375\n",
      "Batch: 65, Loss: 1.0345313549041748, Accuracy: 0.681640625\n",
      "Batch: 66, Loss: 1.0044910907745361, Accuracy: 0.6904296875\n",
      "Batch: 67, Loss: 1.0885610580444336, Accuracy: 0.671875\n",
      "Batch: 68, Loss: 1.1259520053863525, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.07077956199646, Accuracy: 0.654296875\n",
      "Batch: 70, Loss: 1.0501742362976074, Accuracy: 0.6796875\n",
      "Batch: 71, Loss: 1.0782191753387451, Accuracy: 0.6484375\n",
      "Batch: 72, Loss: 0.9330679774284363, Accuracy: 0.69140625\n",
      "Batch: 73, Loss: 1.0095717906951904, Accuracy: 0.6689453125\n",
      "Batch: 74, Loss: 0.9902005195617676, Accuracy: 0.7080078125\n",
      "Batch: 75, Loss: 0.9200076460838318, Accuracy: 0.7021484375\n",
      "Batch: 76, Loss: 1.0277811288833618, Accuracy: 0.6689453125\n",
      "Batch: 77, Loss: 1.0339205265045166, Accuracy: 0.6640625\n",
      "Batch: 78, Loss: 1.0290822982788086, Accuracy: 0.6767578125\n",
      "Batch: 79, Loss: 0.9526317715644836, Accuracy: 0.7080078125\n",
      "Batch: 80, Loss: 0.9982721209526062, Accuracy: 0.6669921875\n",
      "Batch: 81, Loss: 1.1036880016326904, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 1.0523213148117065, Accuracy: 0.65625\n",
      "Batch: 83, Loss: 0.9255633354187012, Accuracy: 0.71875\n",
      "Batch: 84, Loss: 1.0256075859069824, Accuracy: 0.671875\n",
      "Batch: 85, Loss: 0.9447293281555176, Accuracy: 0.6982421875\n",
      "Batch: 86, Loss: 1.2110732793807983, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 0.972220778465271, Accuracy: 0.701171875\n",
      "Batch: 88, Loss: 1.103786587715149, Accuracy: 0.677734375\n",
      "Batch: 89, Loss: 1.0712308883666992, Accuracy: 0.6708984375\n",
      "Batch: 90, Loss: 0.9977210164070129, Accuracy: 0.6884765625\n",
      "Batch: 91, Loss: 1.0142643451690674, Accuracy: 0.6669921875\n",
      "Batch: 92, Loss: 1.039624810218811, Accuracy: 0.6767578125\n",
      "Batch: 93, Loss: 0.9834722280502319, Accuracy: 0.6787109375\n",
      "Batch: 94, Loss: 1.0389065742492676, Accuracy: 0.658203125\n",
      "Batch: 95, Loss: 1.0751512050628662, Accuracy: 0.6474609375\n",
      "Batch: 96, Loss: 1.0283712148666382, Accuracy: 0.66796875\n",
      "Batch: 97, Loss: 0.9099098443984985, Accuracy: 0.7001953125\n",
      "Batch: 98, Loss: 0.9506893754005432, Accuracy: 0.701171875\n",
      "Batch: 99, Loss: 0.9365782141685486, Accuracy: 0.6943359375\n",
      "Batch: 100, Loss: 1.0068626403808594, Accuracy: 0.6845703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 101, Loss: 1.0734937191009521, Accuracy: 0.658203125\n",
      "Batch: 102, Loss: 1.0116112232208252, Accuracy: 0.673828125\n",
      "Batch: 103, Loss: 1.0853593349456787, Accuracy: 0.669921875\n",
      "Batch: 104, Loss: 0.9858101606369019, Accuracy: 0.673828125\n",
      "Batch: 105, Loss: 1.0874671936035156, Accuracy: 0.65625\n",
      "Batch: 106, Loss: 1.028127908706665, Accuracy: 0.662109375\n",
      "Batch: 107, Loss: 1.1257350444793701, Accuracy: 0.6650390625\n",
      "Batch: 108, Loss: 1.0812866687774658, Accuracy: 0.64453125\n",
      "Batch: 109, Loss: 1.207540512084961, Accuracy: 0.626953125\n",
      "Batch: 110, Loss: 0.9162566661834717, Accuracy: 0.7080078125\n",
      "Batch: 111, Loss: 1.091360092163086, Accuracy: 0.6474609375\n",
      "Batch: 112, Loss: 1.0558266639709473, Accuracy: 0.669921875\n",
      "Batch: 113, Loss: 1.061357021331787, Accuracy: 0.6748046875\n",
      "Batch: 114, Loss: 1.1461164951324463, Accuracy: 0.6298828125\n",
      "Batch: 115, Loss: 1.1963980197906494, Accuracy: 0.638671875\n",
      "Batch: 116, Loss: 1.1016175746917725, Accuracy: 0.6435546875\n",
      "Batch: 117, Loss: 1.1041582822799683, Accuracy: 0.6484375\n",
      "Batch: 118, Loss: 0.9413968324661255, Accuracy: 0.7041015625\n",
      "Batch: 119, Loss: 0.9591798782348633, Accuracy: 0.69921875\n",
      "Batch: 120, Loss: 1.0869152545928955, Accuracy: 0.64453125\n",
      "Batch: 121, Loss: 1.1125706434249878, Accuracy: 0.6416015625\n",
      "Batch: 122, Loss: 0.9785754680633545, Accuracy: 0.69921875\n",
      "Batch: 123, Loss: 1.0209648609161377, Accuracy: 0.6826171875\n",
      "Batch: 124, Loss: 1.0775232315063477, Accuracy: 0.6552734375\n",
      "Batch: 125, Loss: 1.0744547843933105, Accuracy: 0.658203125\n",
      "Batch: 126, Loss: 1.0849645137786865, Accuracy: 0.6533203125\n",
      "Batch: 127, Loss: 0.9520816802978516, Accuracy: 0.7158203125\n",
      "Batch: 128, Loss: 1.1512030363082886, Accuracy: 0.65625\n",
      "Batch: 129, Loss: 0.9925458431243896, Accuracy: 0.685546875\n",
      "Batch: 130, Loss: 1.2499887943267822, Accuracy: 0.6044921875\n",
      "Batch: 131, Loss: 1.1035523414611816, Accuracy: 0.6630859375\n",
      "Batch: 132, Loss: 1.0930228233337402, Accuracy: 0.66015625\n",
      "Batch: 133, Loss: 0.9650745987892151, Accuracy: 0.68359375\n",
      "Batch: 134, Loss: 1.0497021675109863, Accuracy: 0.669921875\n",
      "Batch: 135, Loss: 0.9815605282783508, Accuracy: 0.701171875\n",
      "Batch: 136, Loss: 1.0403220653533936, Accuracy: 0.6689453125\n",
      "Batch: 137, Loss: 1.0069180727005005, Accuracy: 0.650390625\n",
      "Batch: 138, Loss: 0.8726507425308228, Accuracy: 0.6982421875\n",
      "Batch: 139, Loss: 0.9814713001251221, Accuracy: 0.67578125\n",
      "Batch: 140, Loss: 1.0291752815246582, Accuracy: 0.66796875\n",
      "Batch: 141, Loss: 1.070050597190857, Accuracy: 0.6669921875\n",
      "Batch: 142, Loss: 1.1023635864257812, Accuracy: 0.6513671875\n",
      "Batch: 143, Loss: 1.0672343969345093, Accuracy: 0.6494140625\n",
      "Batch: 144, Loss: 1.052855372428894, Accuracy: 0.6689453125\n",
      "Batch: 145, Loss: 0.9831673502922058, Accuracy: 0.6591796875\n",
      "Batch: 146, Loss: 1.0912528038024902, Accuracy: 0.6474609375\n",
      "Batch: 147, Loss: 1.0761137008666992, Accuracy: 0.6572265625\n",
      "Batch: 148, Loss: 1.1842501163482666, Accuracy: 0.6240234375\n",
      "Batch: 149, Loss: 1.0704519748687744, Accuracy: 0.6552734375\n",
      "Batch: 150, Loss: 0.9941098690032959, Accuracy: 0.6787109375\n",
      "Batch: 151, Loss: 0.9333114624023438, Accuracy: 0.6962890625\n",
      "Epoch 17/80\n",
      "Batch: 1, Loss: 1.2782024145126343, Accuracy: 0.599609375\n",
      "Batch: 2, Loss: 1.1042239665985107, Accuracy: 0.62890625\n",
      "Batch: 3, Loss: 1.0220766067504883, Accuracy: 0.6689453125\n",
      "Batch: 4, Loss: 0.9566676616668701, Accuracy: 0.697265625\n",
      "Batch: 5, Loss: 0.9547824859619141, Accuracy: 0.7060546875\n",
      "Batch: 6, Loss: 1.0426995754241943, Accuracy: 0.6552734375\n",
      "Batch: 7, Loss: 1.0195660591125488, Accuracy: 0.662109375\n",
      "Batch: 8, Loss: 0.9549151659011841, Accuracy: 0.6943359375\n",
      "Batch: 9, Loss: 0.9367282390594482, Accuracy: 0.7099609375\n",
      "Batch: 10, Loss: 0.9270193576812744, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 1.1178537607192993, Accuracy: 0.642578125\n",
      "Batch: 12, Loss: 1.0955781936645508, Accuracy: 0.6435546875\n",
      "Batch: 13, Loss: 0.8892528414726257, Accuracy: 0.6982421875\n",
      "Batch: 14, Loss: 1.1304713487625122, Accuracy: 0.6455078125\n",
      "Batch: 15, Loss: 0.9775426387786865, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.9767873287200928, Accuracy: 0.7060546875\n",
      "Batch: 17, Loss: 1.0673928260803223, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.0557547807693481, Accuracy: 0.666015625\n",
      "Batch: 19, Loss: 1.0862507820129395, Accuracy: 0.6572265625\n",
      "Batch: 20, Loss: 0.9924557209014893, Accuracy: 0.693359375\n",
      "Batch: 21, Loss: 1.001476526260376, Accuracy: 0.6748046875\n",
      "Batch: 22, Loss: 1.123576045036316, Accuracy: 0.6484375\n",
      "Batch: 23, Loss: 1.0296651124954224, Accuracy: 0.66796875\n",
      "Batch: 24, Loss: 1.0552139282226562, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.0108085870742798, Accuracy: 0.671875\n",
      "Batch: 26, Loss: 0.9337787628173828, Accuracy: 0.7109375\n",
      "Batch: 27, Loss: 0.9556787014007568, Accuracy: 0.681640625\n",
      "Batch: 28, Loss: 1.0631461143493652, Accuracy: 0.64453125\n",
      "Batch: 29, Loss: 1.033294677734375, Accuracy: 0.666015625\n",
      "Batch: 30, Loss: 1.0033998489379883, Accuracy: 0.7001953125\n",
      "Batch: 31, Loss: 0.9813246726989746, Accuracy: 0.6962890625\n",
      "Batch: 32, Loss: 0.9326720833778381, Accuracy: 0.701171875\n",
      "Batch: 33, Loss: 1.1345016956329346, Accuracy: 0.6396484375\n",
      "Batch: 34, Loss: 1.1731886863708496, Accuracy: 0.615234375\n",
      "Batch: 35, Loss: 1.07810640335083, Accuracy: 0.6337890625\n",
      "Batch: 36, Loss: 1.081512212753296, Accuracy: 0.6640625\n",
      "Batch: 37, Loss: 1.0386420488357544, Accuracy: 0.677734375\n",
      "Batch: 38, Loss: 1.0587997436523438, Accuracy: 0.654296875\n",
      "Batch: 39, Loss: 1.06850266456604, Accuracy: 0.658203125\n",
      "Batch: 40, Loss: 1.0435593128204346, Accuracy: 0.6806640625\n",
      "Batch: 41, Loss: 1.0607938766479492, Accuracy: 0.6630859375\n",
      "Batch: 42, Loss: 0.8316038846969604, Accuracy: 0.7333984375\n",
      "Batch: 43, Loss: 1.0175846815109253, Accuracy: 0.6611328125\n",
      "Batch: 44, Loss: 0.9953818917274475, Accuracy: 0.673828125\n",
      "Batch: 45, Loss: 0.927584171295166, Accuracy: 0.6865234375\n",
      "Batch: 46, Loss: 0.9844356775283813, Accuracy: 0.68359375\n",
      "Batch: 47, Loss: 0.9952210187911987, Accuracy: 0.705078125\n",
      "Batch: 48, Loss: 0.943069338798523, Accuracy: 0.705078125\n",
      "Batch: 49, Loss: 1.12302565574646, Accuracy: 0.630859375\n",
      "Batch: 50, Loss: 1.081857442855835, Accuracy: 0.6455078125\n",
      "Batch: 51, Loss: 1.1359238624572754, Accuracy: 0.6474609375\n",
      "Batch: 52, Loss: 1.115094780921936, Accuracy: 0.6328125\n",
      "Batch: 53, Loss: 0.9475881457328796, Accuracy: 0.6875\n",
      "Batch: 54, Loss: 1.0059765577316284, Accuracy: 0.6689453125\n",
      "Batch: 55, Loss: 1.0898919105529785, Accuracy: 0.626953125\n",
      "Batch: 56, Loss: 1.0899088382720947, Accuracy: 0.673828125\n",
      "Batch: 57, Loss: 1.0221984386444092, Accuracy: 0.6806640625\n",
      "Batch: 58, Loss: 1.1359367370605469, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 0.9255171418190002, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.9023069739341736, Accuracy: 0.7099609375\n",
      "Batch: 61, Loss: 1.08303701877594, Accuracy: 0.6572265625\n",
      "Batch: 62, Loss: 0.9832471609115601, Accuracy: 0.68359375\n",
      "Batch: 63, Loss: 1.0230669975280762, Accuracy: 0.6640625\n",
      "Batch: 64, Loss: 0.9966694116592407, Accuracy: 0.6943359375\n",
      "Batch: 65, Loss: 1.0261223316192627, Accuracy: 0.6923828125\n",
      "Batch: 66, Loss: 0.9907459020614624, Accuracy: 0.69140625\n",
      "Batch: 67, Loss: 1.0610437393188477, Accuracy: 0.66015625\n",
      "Batch: 68, Loss: 1.0852727890014648, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 1.043196678161621, Accuracy: 0.6572265625\n",
      "Batch: 70, Loss: 1.0407283306121826, Accuracy: 0.6826171875\n",
      "Batch: 71, Loss: 1.029889702796936, Accuracy: 0.6787109375\n",
      "Batch: 72, Loss: 0.9116075038909912, Accuracy: 0.7060546875\n",
      "Batch: 73, Loss: 0.9458689093589783, Accuracy: 0.697265625\n",
      "Batch: 74, Loss: 0.939853310585022, Accuracy: 0.7001953125\n",
      "Batch: 75, Loss: 0.9026282429695129, Accuracy: 0.7158203125\n",
      "Batch: 76, Loss: 1.0135602951049805, Accuracy: 0.6640625\n",
      "Batch: 77, Loss: 0.9972007274627686, Accuracy: 0.677734375\n",
      "Batch: 78, Loss: 0.989923357963562, Accuracy: 0.689453125\n",
      "Batch: 79, Loss: 0.9326614141464233, Accuracy: 0.7158203125\n",
      "Batch: 80, Loss: 0.9667356014251709, Accuracy: 0.673828125\n",
      "Batch: 81, Loss: 1.0737719535827637, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 1.0408376455307007, Accuracy: 0.6611328125\n",
      "Batch: 83, Loss: 0.8971878290176392, Accuracy: 0.7099609375\n",
      "Batch: 84, Loss: 1.0140306949615479, Accuracy: 0.6728515625\n",
      "Batch: 85, Loss: 0.9307337999343872, Accuracy: 0.7109375\n",
      "Batch: 86, Loss: 1.1586856842041016, Accuracy: 0.642578125\n",
      "Batch: 87, Loss: 0.9661544561386108, Accuracy: 0.7080078125\n",
      "Batch: 88, Loss: 1.0914496183395386, Accuracy: 0.6748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 1.0261905193328857, Accuracy: 0.6884765625\n",
      "Batch: 90, Loss: 0.9707238078117371, Accuracy: 0.6865234375\n",
      "Batch: 91, Loss: 1.0024690628051758, Accuracy: 0.6669921875\n",
      "Batch: 92, Loss: 1.0187309980392456, Accuracy: 0.6689453125\n",
      "Batch: 93, Loss: 0.9873080849647522, Accuracy: 0.6787109375\n",
      "Batch: 94, Loss: 0.9754394292831421, Accuracy: 0.701171875\n",
      "Batch: 95, Loss: 1.0525245666503906, Accuracy: 0.654296875\n",
      "Batch: 96, Loss: 0.9974613189697266, Accuracy: 0.6884765625\n",
      "Batch: 97, Loss: 0.9112630486488342, Accuracy: 0.7138671875\n",
      "Batch: 98, Loss: 0.9501101970672607, Accuracy: 0.697265625\n",
      "Batch: 99, Loss: 0.9339743256568909, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 1.0087991952896118, Accuracy: 0.6796875\n",
      "Batch: 101, Loss: 1.061720848083496, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 0.9895679950714111, Accuracy: 0.6689453125\n",
      "Batch: 103, Loss: 1.0745353698730469, Accuracy: 0.6748046875\n",
      "Batch: 104, Loss: 0.955093502998352, Accuracy: 0.693359375\n",
      "Batch: 105, Loss: 1.0648514032363892, Accuracy: 0.6533203125\n",
      "Batch: 106, Loss: 0.9866119623184204, Accuracy: 0.685546875\n",
      "Batch: 107, Loss: 1.0786278247833252, Accuracy: 0.6728515625\n",
      "Batch: 108, Loss: 1.0479297637939453, Accuracy: 0.66015625\n",
      "Batch: 109, Loss: 1.1620697975158691, Accuracy: 0.609375\n",
      "Batch: 110, Loss: 0.8861373662948608, Accuracy: 0.7236328125\n",
      "Batch: 111, Loss: 1.1027123928070068, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.0409140586853027, Accuracy: 0.67578125\n",
      "Batch: 113, Loss: 1.0613983869552612, Accuracy: 0.67578125\n",
      "Batch: 114, Loss: 1.1345772743225098, Accuracy: 0.62890625\n",
      "Batch: 115, Loss: 1.1469511985778809, Accuracy: 0.6572265625\n",
      "Batch: 116, Loss: 1.0848349332809448, Accuracy: 0.6494140625\n",
      "Batch: 117, Loss: 1.06826651096344, Accuracy: 0.666015625\n",
      "Batch: 118, Loss: 0.9099132418632507, Accuracy: 0.7099609375\n",
      "Batch: 119, Loss: 0.927137017250061, Accuracy: 0.703125\n",
      "Batch: 120, Loss: 1.0373637676239014, Accuracy: 0.6748046875\n",
      "Batch: 121, Loss: 1.0904039144515991, Accuracy: 0.6494140625\n",
      "Batch: 122, Loss: 0.976489782333374, Accuracy: 0.6982421875\n",
      "Batch: 123, Loss: 0.9741693139076233, Accuracy: 0.6953125\n",
      "Batch: 124, Loss: 1.045166015625, Accuracy: 0.65234375\n",
      "Batch: 125, Loss: 1.072846531867981, Accuracy: 0.66015625\n",
      "Batch: 126, Loss: 1.014718770980835, Accuracy: 0.6767578125\n",
      "Batch: 127, Loss: 0.9313734173774719, Accuracy: 0.703125\n",
      "Batch: 128, Loss: 1.1195564270019531, Accuracy: 0.6640625\n",
      "Batch: 129, Loss: 0.9975360631942749, Accuracy: 0.681640625\n",
      "Batch: 130, Loss: 1.2160805463790894, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.0790235996246338, Accuracy: 0.6455078125\n",
      "Batch: 132, Loss: 1.077179193496704, Accuracy: 0.662109375\n",
      "Batch: 133, Loss: 0.983299732208252, Accuracy: 0.673828125\n",
      "Batch: 134, Loss: 1.0318834781646729, Accuracy: 0.66796875\n",
      "Batch: 135, Loss: 0.9525907635688782, Accuracy: 0.712890625\n",
      "Batch: 136, Loss: 1.018776535987854, Accuracy: 0.681640625\n",
      "Batch: 137, Loss: 0.9416922330856323, Accuracy: 0.6875\n",
      "Batch: 138, Loss: 0.8770437836647034, Accuracy: 0.7138671875\n",
      "Batch: 139, Loss: 0.9473567008972168, Accuracy: 0.6767578125\n",
      "Batch: 140, Loss: 1.0075812339782715, Accuracy: 0.666015625\n",
      "Batch: 141, Loss: 1.0470232963562012, Accuracy: 0.6630859375\n",
      "Batch: 142, Loss: 1.079829454421997, Accuracy: 0.65625\n",
      "Batch: 143, Loss: 1.0460659265518188, Accuracy: 0.66796875\n",
      "Batch: 144, Loss: 1.0426585674285889, Accuracy: 0.6669921875\n",
      "Batch: 145, Loss: 0.9649766683578491, Accuracy: 0.662109375\n",
      "Batch: 146, Loss: 1.0633236169815063, Accuracy: 0.669921875\n",
      "Batch: 147, Loss: 1.0671799182891846, Accuracy: 0.6650390625\n",
      "Batch: 148, Loss: 1.1914350986480713, Accuracy: 0.6201171875\n",
      "Batch: 149, Loss: 1.0296525955200195, Accuracy: 0.66015625\n",
      "Batch: 150, Loss: 0.9948927164077759, Accuracy: 0.7001953125\n",
      "Batch: 151, Loss: 0.9223182201385498, Accuracy: 0.7119140625\n",
      "Epoch 18/80\n",
      "Batch: 1, Loss: 1.250694751739502, Accuracy: 0.607421875\n",
      "Batch: 2, Loss: 1.0718364715576172, Accuracy: 0.626953125\n",
      "Batch: 3, Loss: 0.9922620058059692, Accuracy: 0.6640625\n",
      "Batch: 4, Loss: 0.9330300092697144, Accuracy: 0.7099609375\n",
      "Batch: 5, Loss: 0.9488781690597534, Accuracy: 0.705078125\n",
      "Batch: 6, Loss: 1.0225242376327515, Accuracy: 0.6787109375\n",
      "Batch: 7, Loss: 1.0074143409729004, Accuracy: 0.66796875\n",
      "Batch: 8, Loss: 0.8988652229309082, Accuracy: 0.6962890625\n",
      "Batch: 9, Loss: 0.9164745807647705, Accuracy: 0.7197265625\n",
      "Batch: 10, Loss: 0.922248125076294, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 1.0846366882324219, Accuracy: 0.6474609375\n",
      "Batch: 12, Loss: 1.0379343032836914, Accuracy: 0.654296875\n",
      "Batch: 13, Loss: 0.8573499917984009, Accuracy: 0.724609375\n",
      "Batch: 14, Loss: 1.1159253120422363, Accuracy: 0.6484375\n",
      "Batch: 15, Loss: 0.9269872903823853, Accuracy: 0.7197265625\n",
      "Batch: 16, Loss: 0.9300554990768433, Accuracy: 0.7158203125\n",
      "Batch: 17, Loss: 1.0151759386062622, Accuracy: 0.6806640625\n",
      "Batch: 18, Loss: 1.025310754776001, Accuracy: 0.6669921875\n",
      "Batch: 19, Loss: 1.0618274211883545, Accuracy: 0.662109375\n",
      "Batch: 20, Loss: 0.9520007371902466, Accuracy: 0.6875\n",
      "Batch: 21, Loss: 0.9710928797721863, Accuracy: 0.6865234375\n",
      "Batch: 22, Loss: 1.1043729782104492, Accuracy: 0.6513671875\n",
      "Batch: 23, Loss: 1.0060410499572754, Accuracy: 0.6640625\n",
      "Batch: 24, Loss: 1.0414525270462036, Accuracy: 0.66015625\n",
      "Batch: 25, Loss: 0.9942232370376587, Accuracy: 0.6796875\n",
      "Batch: 26, Loss: 0.8964537978172302, Accuracy: 0.6982421875\n",
      "Batch: 27, Loss: 0.9457393884658813, Accuracy: 0.6875\n",
      "Batch: 28, Loss: 1.0309969186782837, Accuracy: 0.6474609375\n",
      "Batch: 29, Loss: 1.017038106918335, Accuracy: 0.6591796875\n",
      "Batch: 30, Loss: 0.9682813882827759, Accuracy: 0.7060546875\n",
      "Batch: 31, Loss: 0.956260621547699, Accuracy: 0.6982421875\n",
      "Batch: 32, Loss: 0.9348301291465759, Accuracy: 0.69140625\n",
      "Batch: 33, Loss: 1.0957920551300049, Accuracy: 0.654296875\n",
      "Batch: 34, Loss: 1.1626243591308594, Accuracy: 0.6240234375\n",
      "Batch: 35, Loss: 1.0624759197235107, Accuracy: 0.6533203125\n",
      "Batch: 36, Loss: 1.0761206150054932, Accuracy: 0.658203125\n",
      "Batch: 37, Loss: 1.0296788215637207, Accuracy: 0.6787109375\n",
      "Batch: 38, Loss: 1.0498344898223877, Accuracy: 0.65625\n",
      "Batch: 39, Loss: 1.0377376079559326, Accuracy: 0.6669921875\n",
      "Batch: 40, Loss: 1.0570638179779053, Accuracy: 0.662109375\n",
      "Batch: 41, Loss: 1.0301365852355957, Accuracy: 0.681640625\n",
      "Batch: 42, Loss: 0.8115919232368469, Accuracy: 0.732421875\n",
      "Batch: 43, Loss: 0.9928990006446838, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 1.0168092250823975, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 0.8713478446006775, Accuracy: 0.716796875\n",
      "Batch: 46, Loss: 0.9688185453414917, Accuracy: 0.6982421875\n",
      "Batch: 47, Loss: 0.9832828044891357, Accuracy: 0.6962890625\n",
      "Batch: 48, Loss: 0.9150053262710571, Accuracy: 0.6982421875\n",
      "Batch: 49, Loss: 1.0815374851226807, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.065121054649353, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.1461646556854248, Accuracy: 0.6484375\n",
      "Batch: 52, Loss: 1.0883548259735107, Accuracy: 0.650390625\n",
      "Batch: 53, Loss: 0.9186999201774597, Accuracy: 0.6943359375\n",
      "Batch: 54, Loss: 0.997008740901947, Accuracy: 0.677734375\n",
      "Batch: 55, Loss: 1.0872743129730225, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.077951192855835, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 1.0136446952819824, Accuracy: 0.677734375\n",
      "Batch: 58, Loss: 1.1185604333877563, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 0.9117544293403625, Accuracy: 0.71484375\n",
      "Batch: 60, Loss: 0.8942897915840149, Accuracy: 0.7021484375\n",
      "Batch: 61, Loss: 1.0349557399749756, Accuracy: 0.6728515625\n",
      "Batch: 62, Loss: 0.9748678207397461, Accuracy: 0.6865234375\n",
      "Batch: 63, Loss: 1.0317583084106445, Accuracy: 0.669921875\n",
      "Batch: 64, Loss: 0.9826844930648804, Accuracy: 0.6875\n",
      "Batch: 65, Loss: 0.989171028137207, Accuracy: 0.6806640625\n",
      "Batch: 66, Loss: 0.961389422416687, Accuracy: 0.697265625\n",
      "Batch: 67, Loss: 1.0650862455368042, Accuracy: 0.6728515625\n",
      "Batch: 68, Loss: 1.0665562152862549, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.0116450786590576, Accuracy: 0.6884765625\n",
      "Batch: 70, Loss: 1.0036031007766724, Accuracy: 0.6865234375\n",
      "Batch: 71, Loss: 1.0509687662124634, Accuracy: 0.65234375\n",
      "Batch: 72, Loss: 0.9007729291915894, Accuracy: 0.712890625\n",
      "Batch: 73, Loss: 0.9715757966041565, Accuracy: 0.69921875\n",
      "Batch: 74, Loss: 0.9141305088996887, Accuracy: 0.71484375\n",
      "Batch: 75, Loss: 0.8951048851013184, Accuracy: 0.7060546875\n",
      "Batch: 76, Loss: 0.986195981502533, Accuracy: 0.6806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 0.9674663543701172, Accuracy: 0.689453125\n",
      "Batch: 78, Loss: 0.974366307258606, Accuracy: 0.708984375\n",
      "Batch: 79, Loss: 0.9125723242759705, Accuracy: 0.7294921875\n",
      "Batch: 80, Loss: 0.9386187195777893, Accuracy: 0.6962890625\n",
      "Batch: 81, Loss: 1.041538119316101, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 1.0354448556900024, Accuracy: 0.6513671875\n",
      "Batch: 83, Loss: 0.8900145292282104, Accuracy: 0.734375\n",
      "Batch: 84, Loss: 0.9937213659286499, Accuracy: 0.7021484375\n",
      "Batch: 85, Loss: 0.9163494110107422, Accuracy: 0.71484375\n",
      "Batch: 86, Loss: 1.1574829816818237, Accuracy: 0.646484375\n",
      "Batch: 87, Loss: 0.9422919750213623, Accuracy: 0.703125\n",
      "Batch: 88, Loss: 1.0779396295547485, Accuracy: 0.6689453125\n",
      "Batch: 89, Loss: 1.043249249458313, Accuracy: 0.6689453125\n",
      "Batch: 90, Loss: 0.9485478401184082, Accuracy: 0.705078125\n",
      "Batch: 91, Loss: 0.980477511882782, Accuracy: 0.685546875\n",
      "Batch: 92, Loss: 1.009087085723877, Accuracy: 0.6806640625\n",
      "Batch: 93, Loss: 0.9625875949859619, Accuracy: 0.70703125\n",
      "Batch: 94, Loss: 0.9587934017181396, Accuracy: 0.6962890625\n",
      "Batch: 95, Loss: 1.0397323369979858, Accuracy: 0.6689453125\n",
      "Batch: 96, Loss: 0.9884300231933594, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.9001269340515137, Accuracy: 0.705078125\n",
      "Batch: 98, Loss: 0.913756251335144, Accuracy: 0.7041015625\n",
      "Batch: 99, Loss: 0.9306691288948059, Accuracy: 0.7080078125\n",
      "Batch: 100, Loss: 0.9736206531524658, Accuracy: 0.6962890625\n",
      "Batch: 101, Loss: 1.0501534938812256, Accuracy: 0.6494140625\n",
      "Batch: 102, Loss: 0.9653804302215576, Accuracy: 0.677734375\n",
      "Batch: 103, Loss: 1.0433839559555054, Accuracy: 0.67578125\n",
      "Batch: 104, Loss: 0.912867546081543, Accuracy: 0.7119140625\n",
      "Batch: 105, Loss: 1.0401039123535156, Accuracy: 0.6669921875\n",
      "Batch: 106, Loss: 0.9693059921264648, Accuracy: 0.6923828125\n",
      "Batch: 107, Loss: 1.024519681930542, Accuracy: 0.671875\n",
      "Batch: 108, Loss: 1.0437206029891968, Accuracy: 0.6455078125\n",
      "Batch: 109, Loss: 1.1343185901641846, Accuracy: 0.6318359375\n",
      "Batch: 110, Loss: 0.8586609363555908, Accuracy: 0.7275390625\n",
      "Batch: 111, Loss: 1.0505956411361694, Accuracy: 0.6669921875\n",
      "Batch: 112, Loss: 1.0141141414642334, Accuracy: 0.6865234375\n",
      "Batch: 113, Loss: 1.0348527431488037, Accuracy: 0.689453125\n",
      "Batch: 114, Loss: 1.1218688488006592, Accuracy: 0.64453125\n",
      "Batch: 115, Loss: 1.1279804706573486, Accuracy: 0.6533203125\n",
      "Batch: 116, Loss: 1.0653810501098633, Accuracy: 0.6513671875\n",
      "Batch: 117, Loss: 1.0582916736602783, Accuracy: 0.6669921875\n",
      "Batch: 118, Loss: 0.8965999484062195, Accuracy: 0.7197265625\n",
      "Batch: 119, Loss: 0.9319455027580261, Accuracy: 0.71875\n",
      "Batch: 120, Loss: 1.0427796840667725, Accuracy: 0.669921875\n",
      "Batch: 121, Loss: 1.063931941986084, Accuracy: 0.666015625\n",
      "Batch: 122, Loss: 0.9542721509933472, Accuracy: 0.7158203125\n",
      "Batch: 123, Loss: 0.9791345596313477, Accuracy: 0.7041015625\n",
      "Batch: 124, Loss: 1.013051986694336, Accuracy: 0.673828125\n",
      "Batch: 125, Loss: 1.0443072319030762, Accuracy: 0.6572265625\n",
      "Batch: 126, Loss: 1.0158412456512451, Accuracy: 0.673828125\n",
      "Batch: 127, Loss: 0.9317828416824341, Accuracy: 0.7197265625\n",
      "Batch: 128, Loss: 1.1295140981674194, Accuracy: 0.658203125\n",
      "Batch: 129, Loss: 0.9555392265319824, Accuracy: 0.689453125\n",
      "Batch: 130, Loss: 1.1863080263137817, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.080181360244751, Accuracy: 0.6533203125\n",
      "Batch: 132, Loss: 1.0788084268569946, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 0.9392231702804565, Accuracy: 0.6953125\n",
      "Batch: 134, Loss: 0.9979456067085266, Accuracy: 0.6728515625\n",
      "Batch: 135, Loss: 0.9050137996673584, Accuracy: 0.7265625\n",
      "Batch: 136, Loss: 1.026046872138977, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 0.9756243824958801, Accuracy: 0.658203125\n",
      "Batch: 138, Loss: 0.8561530113220215, Accuracy: 0.7158203125\n",
      "Batch: 139, Loss: 0.94511878490448, Accuracy: 0.6845703125\n",
      "Batch: 140, Loss: 0.9919945597648621, Accuracy: 0.6689453125\n",
      "Batch: 141, Loss: 1.029284954071045, Accuracy: 0.6728515625\n",
      "Batch: 142, Loss: 1.041954517364502, Accuracy: 0.66796875\n",
      "Batch: 143, Loss: 0.9897091388702393, Accuracy: 0.689453125\n",
      "Batch: 144, Loss: 1.0135762691497803, Accuracy: 0.6806640625\n",
      "Batch: 145, Loss: 0.9509536027908325, Accuracy: 0.6669921875\n",
      "Batch: 146, Loss: 1.053354263305664, Accuracy: 0.6611328125\n",
      "Batch: 147, Loss: 1.0433045625686646, Accuracy: 0.658203125\n",
      "Batch: 148, Loss: 1.1623260974884033, Accuracy: 0.6240234375\n",
      "Batch: 149, Loss: 1.0357073545455933, Accuracy: 0.65234375\n",
      "Batch: 150, Loss: 0.9657809734344482, Accuracy: 0.6826171875\n",
      "Batch: 151, Loss: 0.8672176599502563, Accuracy: 0.70703125\n",
      "Epoch 19/80\n",
      "Batch: 1, Loss: 1.2397783994674683, Accuracy: 0.6240234375\n",
      "Batch: 2, Loss: 1.102536916732788, Accuracy: 0.6328125\n",
      "Batch: 3, Loss: 0.9707596302032471, Accuracy: 0.669921875\n",
      "Batch: 4, Loss: 0.927909255027771, Accuracy: 0.705078125\n",
      "Batch: 5, Loss: 0.939450740814209, Accuracy: 0.7060546875\n",
      "Batch: 6, Loss: 1.0322200059890747, Accuracy: 0.677734375\n",
      "Batch: 7, Loss: 0.9654746055603027, Accuracy: 0.6806640625\n",
      "Batch: 8, Loss: 0.9072083234786987, Accuracy: 0.6953125\n",
      "Batch: 9, Loss: 0.8950777053833008, Accuracy: 0.7294921875\n",
      "Batch: 10, Loss: 0.9135745763778687, Accuracy: 0.6982421875\n",
      "Batch: 11, Loss: 1.056309461593628, Accuracy: 0.6357421875\n",
      "Batch: 12, Loss: 1.0558812618255615, Accuracy: 0.666015625\n",
      "Batch: 13, Loss: 0.8466377854347229, Accuracy: 0.72265625\n",
      "Batch: 14, Loss: 1.0944758653640747, Accuracy: 0.6474609375\n",
      "Batch: 15, Loss: 0.9329367876052856, Accuracy: 0.712890625\n",
      "Batch: 16, Loss: 0.942115068435669, Accuracy: 0.71484375\n",
      "Batch: 17, Loss: 1.0141456127166748, Accuracy: 0.669921875\n",
      "Batch: 18, Loss: 1.0137159824371338, Accuracy: 0.677734375\n",
      "Batch: 19, Loss: 1.002205491065979, Accuracy: 0.67578125\n",
      "Batch: 20, Loss: 0.9320250153541565, Accuracy: 0.708984375\n",
      "Batch: 21, Loss: 0.9395995140075684, Accuracy: 0.6943359375\n",
      "Batch: 22, Loss: 1.0797990560531616, Accuracy: 0.662109375\n",
      "Batch: 23, Loss: 0.9876609444618225, Accuracy: 0.685546875\n",
      "Batch: 24, Loss: 1.0085701942443848, Accuracy: 0.66796875\n",
      "Batch: 25, Loss: 0.9619624614715576, Accuracy: 0.7119140625\n",
      "Batch: 26, Loss: 0.8859607577323914, Accuracy: 0.720703125\n",
      "Batch: 27, Loss: 0.9225946664810181, Accuracy: 0.67578125\n",
      "Batch: 28, Loss: 1.0334497690200806, Accuracy: 0.65625\n",
      "Batch: 29, Loss: 0.9939583539962769, Accuracy: 0.6904296875\n",
      "Batch: 30, Loss: 0.9149086475372314, Accuracy: 0.712890625\n",
      "Batch: 31, Loss: 0.9255635738372803, Accuracy: 0.7109375\n",
      "Batch: 32, Loss: 0.9277685880661011, Accuracy: 0.697265625\n",
      "Batch: 33, Loss: 1.076899766921997, Accuracy: 0.6484375\n",
      "Batch: 34, Loss: 1.1339061260223389, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.0126636028289795, Accuracy: 0.6513671875\n",
      "Batch: 36, Loss: 1.0432982444763184, Accuracy: 0.681640625\n",
      "Batch: 37, Loss: 1.006941795349121, Accuracy: 0.671875\n",
      "Batch: 38, Loss: 1.0265867710113525, Accuracy: 0.671875\n",
      "Batch: 39, Loss: 1.0346341133117676, Accuracy: 0.671875\n",
      "Batch: 40, Loss: 1.0184983015060425, Accuracy: 0.6767578125\n",
      "Batch: 41, Loss: 0.9960448741912842, Accuracy: 0.673828125\n",
      "Batch: 42, Loss: 0.7842469215393066, Accuracy: 0.734375\n",
      "Batch: 43, Loss: 0.9816257953643799, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.9980367422103882, Accuracy: 0.669921875\n",
      "Batch: 45, Loss: 0.8706230521202087, Accuracy: 0.7109375\n",
      "Batch: 46, Loss: 0.9351116418838501, Accuracy: 0.716796875\n",
      "Batch: 47, Loss: 0.9647696018218994, Accuracy: 0.7080078125\n",
      "Batch: 48, Loss: 0.9176737070083618, Accuracy: 0.708984375\n",
      "Batch: 49, Loss: 1.073603630065918, Accuracy: 0.6572265625\n",
      "Batch: 50, Loss: 1.0440845489501953, Accuracy: 0.6533203125\n",
      "Batch: 51, Loss: 1.1065418720245361, Accuracy: 0.640625\n",
      "Batch: 52, Loss: 1.0336356163024902, Accuracy: 0.6611328125\n",
      "Batch: 53, Loss: 0.915583610534668, Accuracy: 0.71484375\n",
      "Batch: 54, Loss: 0.9704702496528625, Accuracy: 0.6826171875\n",
      "Batch: 55, Loss: 1.0631108283996582, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.058732509613037, Accuracy: 0.66796875\n",
      "Batch: 57, Loss: 0.9938001036643982, Accuracy: 0.6923828125\n",
      "Batch: 58, Loss: 1.0730550289154053, Accuracy: 0.681640625\n",
      "Batch: 59, Loss: 0.8972335457801819, Accuracy: 0.7255859375\n",
      "Batch: 60, Loss: 0.8714168667793274, Accuracy: 0.7197265625\n",
      "Batch: 61, Loss: 1.0061132907867432, Accuracy: 0.6669921875\n",
      "Batch: 62, Loss: 0.9238110780715942, Accuracy: 0.7119140625\n",
      "Batch: 63, Loss: 0.9811311364173889, Accuracy: 0.6962890625\n",
      "Batch: 64, Loss: 0.962949812412262, Accuracy: 0.7021484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 65, Loss: 0.9786232709884644, Accuracy: 0.689453125\n",
      "Batch: 66, Loss: 0.9544556140899658, Accuracy: 0.7021484375\n",
      "Batch: 67, Loss: 1.041632890701294, Accuracy: 0.6787109375\n",
      "Batch: 68, Loss: 1.0562312602996826, Accuracy: 0.66015625\n",
      "Batch: 69, Loss: 1.0177342891693115, Accuracy: 0.6787109375\n",
      "Batch: 70, Loss: 0.9951894879341125, Accuracy: 0.697265625\n",
      "Batch: 71, Loss: 1.0271108150482178, Accuracy: 0.666015625\n",
      "Batch: 72, Loss: 0.9058098793029785, Accuracy: 0.7109375\n",
      "Batch: 73, Loss: 0.9352496862411499, Accuracy: 0.7001953125\n",
      "Batch: 74, Loss: 0.8857980966567993, Accuracy: 0.736328125\n",
      "Batch: 75, Loss: 0.8611133694648743, Accuracy: 0.73046875\n",
      "Batch: 76, Loss: 0.973483681678772, Accuracy: 0.66796875\n",
      "Batch: 77, Loss: 0.9333409070968628, Accuracy: 0.69140625\n",
      "Batch: 78, Loss: 0.97568678855896, Accuracy: 0.701171875\n",
      "Batch: 79, Loss: 0.8799009323120117, Accuracy: 0.7392578125\n",
      "Batch: 80, Loss: 0.913804292678833, Accuracy: 0.708984375\n",
      "Batch: 81, Loss: 1.0692098140716553, Accuracy: 0.6337890625\n",
      "Batch: 82, Loss: 1.0312894582748413, Accuracy: 0.6474609375\n",
      "Batch: 83, Loss: 0.8711336851119995, Accuracy: 0.7294921875\n",
      "Batch: 84, Loss: 0.9638800024986267, Accuracy: 0.6943359375\n",
      "Batch: 85, Loss: 0.9057374000549316, Accuracy: 0.7333984375\n",
      "Batch: 86, Loss: 1.1213929653167725, Accuracy: 0.65234375\n",
      "Batch: 87, Loss: 0.9137641191482544, Accuracy: 0.716796875\n",
      "Batch: 88, Loss: 1.0618822574615479, Accuracy: 0.6943359375\n",
      "Batch: 89, Loss: 1.0071394443511963, Accuracy: 0.6904296875\n",
      "Batch: 90, Loss: 0.9336099624633789, Accuracy: 0.7109375\n",
      "Batch: 91, Loss: 0.9718655943870544, Accuracy: 0.677734375\n",
      "Batch: 92, Loss: 0.983100414276123, Accuracy: 0.689453125\n",
      "Batch: 93, Loss: 0.94112229347229, Accuracy: 0.69921875\n",
      "Batch: 94, Loss: 0.9580321311950684, Accuracy: 0.6767578125\n",
      "Batch: 95, Loss: 1.003475308418274, Accuracy: 0.6650390625\n",
      "Batch: 96, Loss: 0.9877718687057495, Accuracy: 0.689453125\n",
      "Batch: 97, Loss: 0.8390485644340515, Accuracy: 0.716796875\n",
      "Batch: 98, Loss: 0.9017016887664795, Accuracy: 0.7138671875\n",
      "Batch: 99, Loss: 0.9144436120986938, Accuracy: 0.69921875\n",
      "Batch: 100, Loss: 0.9719408750534058, Accuracy: 0.6875\n",
      "Batch: 101, Loss: 1.0234719514846802, Accuracy: 0.671875\n",
      "Batch: 102, Loss: 0.9660136699676514, Accuracy: 0.6875\n",
      "Batch: 103, Loss: 1.0083415508270264, Accuracy: 0.6875\n",
      "Batch: 104, Loss: 0.9219280481338501, Accuracy: 0.6953125\n",
      "Batch: 105, Loss: 0.9966689348220825, Accuracy: 0.673828125\n",
      "Batch: 106, Loss: 0.9677829742431641, Accuracy: 0.7001953125\n",
      "Batch: 107, Loss: 1.0164434909820557, Accuracy: 0.677734375\n",
      "Batch: 108, Loss: 1.0146516561508179, Accuracy: 0.654296875\n",
      "Batch: 109, Loss: 1.1003072261810303, Accuracy: 0.6416015625\n",
      "Batch: 110, Loss: 0.859296441078186, Accuracy: 0.72265625\n",
      "Batch: 111, Loss: 1.0547044277191162, Accuracy: 0.6484375\n",
      "Batch: 112, Loss: 1.0038807392120361, Accuracy: 0.6875\n",
      "Batch: 113, Loss: 1.011228084564209, Accuracy: 0.67578125\n",
      "Batch: 114, Loss: 1.0859928131103516, Accuracy: 0.646484375\n",
      "Batch: 115, Loss: 1.1054407358169556, Accuracy: 0.6572265625\n",
      "Batch: 116, Loss: 1.0409350395202637, Accuracy: 0.666015625\n",
      "Batch: 117, Loss: 1.0373103618621826, Accuracy: 0.6640625\n",
      "Batch: 118, Loss: 0.8787671327590942, Accuracy: 0.7255859375\n",
      "Batch: 119, Loss: 0.9077415466308594, Accuracy: 0.7138671875\n",
      "Batch: 120, Loss: 1.0094714164733887, Accuracy: 0.6650390625\n",
      "Batch: 121, Loss: 1.056701898574829, Accuracy: 0.66796875\n",
      "Batch: 122, Loss: 0.9561343789100647, Accuracy: 0.7041015625\n",
      "Batch: 123, Loss: 0.9432429075241089, Accuracy: 0.7080078125\n",
      "Batch: 124, Loss: 0.9930577278137207, Accuracy: 0.671875\n",
      "Batch: 125, Loss: 1.0352469682693481, Accuracy: 0.662109375\n",
      "Batch: 126, Loss: 0.9928998351097107, Accuracy: 0.673828125\n",
      "Batch: 127, Loss: 0.9120889902114868, Accuracy: 0.7197265625\n",
      "Batch: 128, Loss: 1.1103157997131348, Accuracy: 0.6611328125\n",
      "Batch: 129, Loss: 0.9496688842773438, Accuracy: 0.6884765625\n",
      "Batch: 130, Loss: 1.1839195489883423, Accuracy: 0.6337890625\n",
      "Batch: 131, Loss: 1.0543205738067627, Accuracy: 0.6650390625\n",
      "Batch: 132, Loss: 1.065239429473877, Accuracy: 0.671875\n",
      "Batch: 133, Loss: 0.9312858581542969, Accuracy: 0.697265625\n",
      "Batch: 134, Loss: 1.0129410028457642, Accuracy: 0.673828125\n",
      "Batch: 135, Loss: 0.9129133224487305, Accuracy: 0.71484375\n",
      "Batch: 136, Loss: 1.033498764038086, Accuracy: 0.6875\n",
      "Batch: 137, Loss: 0.9517471194267273, Accuracy: 0.681640625\n",
      "Batch: 138, Loss: 0.8280081152915955, Accuracy: 0.736328125\n",
      "Batch: 139, Loss: 0.9193930625915527, Accuracy: 0.6796875\n",
      "Batch: 140, Loss: 0.9571456909179688, Accuracy: 0.6875\n",
      "Batch: 141, Loss: 1.0125184059143066, Accuracy: 0.6689453125\n",
      "Batch: 142, Loss: 1.0442372560501099, Accuracy: 0.6640625\n",
      "Batch: 143, Loss: 0.9970959424972534, Accuracy: 0.67578125\n",
      "Batch: 144, Loss: 0.9932848811149597, Accuracy: 0.693359375\n",
      "Batch: 145, Loss: 0.9511328935623169, Accuracy: 0.673828125\n",
      "Batch: 146, Loss: 1.031860113143921, Accuracy: 0.6640625\n",
      "Batch: 147, Loss: 1.0021495819091797, Accuracy: 0.6748046875\n",
      "Batch: 148, Loss: 1.1431337594985962, Accuracy: 0.62109375\n",
      "Batch: 149, Loss: 1.0046743154525757, Accuracy: 0.6748046875\n",
      "Batch: 150, Loss: 0.9553053379058838, Accuracy: 0.69921875\n",
      "Batch: 151, Loss: 0.8657336235046387, Accuracy: 0.724609375\n",
      "Epoch 20/80\n",
      "Batch: 1, Loss: 1.255935788154602, Accuracy: 0.59765625\n",
      "Batch: 2, Loss: 1.055997610092163, Accuracy: 0.65234375\n",
      "Batch: 3, Loss: 0.9328272342681885, Accuracy: 0.6884765625\n",
      "Batch: 4, Loss: 0.8904595375061035, Accuracy: 0.7216796875\n",
      "Batch: 5, Loss: 0.9157649874687195, Accuracy: 0.7119140625\n",
      "Batch: 6, Loss: 1.008131742477417, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 0.9647419452667236, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.896256685256958, Accuracy: 0.7109375\n",
      "Batch: 9, Loss: 0.8970906138420105, Accuracy: 0.736328125\n",
      "Batch: 10, Loss: 0.9110223054885864, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 1.044305443763733, Accuracy: 0.65234375\n",
      "Batch: 12, Loss: 1.0260844230651855, Accuracy: 0.6767578125\n",
      "Batch: 13, Loss: 0.7943241596221924, Accuracy: 0.7470703125\n",
      "Batch: 14, Loss: 1.0599586963653564, Accuracy: 0.6591796875\n",
      "Batch: 15, Loss: 0.917273223400116, Accuracy: 0.7294921875\n",
      "Batch: 16, Loss: 0.9304298162460327, Accuracy: 0.716796875\n",
      "Batch: 17, Loss: 1.0048351287841797, Accuracy: 0.6669921875\n",
      "Batch: 18, Loss: 1.0293123722076416, Accuracy: 0.6728515625\n",
      "Batch: 19, Loss: 1.0216827392578125, Accuracy: 0.6845703125\n",
      "Batch: 20, Loss: 0.8998335003852844, Accuracy: 0.7119140625\n",
      "Batch: 21, Loss: 0.9364229440689087, Accuracy: 0.6875\n",
      "Batch: 22, Loss: 1.0558998584747314, Accuracy: 0.6708984375\n",
      "Batch: 23, Loss: 0.9670647382736206, Accuracy: 0.6806640625\n",
      "Batch: 24, Loss: 0.9930092096328735, Accuracy: 0.6982421875\n",
      "Batch: 25, Loss: 0.9554986953735352, Accuracy: 0.69140625\n",
      "Batch: 26, Loss: 0.8702470660209656, Accuracy: 0.7197265625\n",
      "Batch: 27, Loss: 0.908571720123291, Accuracy: 0.69140625\n",
      "Batch: 28, Loss: 0.9962180852890015, Accuracy: 0.671875\n",
      "Batch: 29, Loss: 0.9860761165618896, Accuracy: 0.677734375\n",
      "Batch: 30, Loss: 0.9161023497581482, Accuracy: 0.70703125\n",
      "Batch: 31, Loss: 0.9025152325630188, Accuracy: 0.7197265625\n",
      "Batch: 32, Loss: 0.9052292108535767, Accuracy: 0.6923828125\n",
      "Batch: 33, Loss: 1.0532193183898926, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.1071791648864746, Accuracy: 0.6513671875\n",
      "Batch: 35, Loss: 0.9924564957618713, Accuracy: 0.6591796875\n",
      "Batch: 36, Loss: 1.0241405963897705, Accuracy: 0.6767578125\n",
      "Batch: 37, Loss: 0.9782850742340088, Accuracy: 0.6796875\n",
      "Batch: 38, Loss: 0.9732822179794312, Accuracy: 0.6962890625\n",
      "Batch: 39, Loss: 1.0077002048492432, Accuracy: 0.6728515625\n",
      "Batch: 40, Loss: 1.000866174697876, Accuracy: 0.6728515625\n",
      "Batch: 41, Loss: 0.9692386984825134, Accuracy: 0.6884765625\n",
      "Batch: 42, Loss: 0.7976571321487427, Accuracy: 0.7294921875\n",
      "Batch: 43, Loss: 0.9896720051765442, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 0.9811183214187622, Accuracy: 0.6826171875\n",
      "Batch: 45, Loss: 0.8543441295623779, Accuracy: 0.73828125\n",
      "Batch: 46, Loss: 0.914848804473877, Accuracy: 0.7158203125\n",
      "Batch: 47, Loss: 0.9377509355545044, Accuracy: 0.716796875\n",
      "Batch: 48, Loss: 0.8887437582015991, Accuracy: 0.720703125\n",
      "Batch: 49, Loss: 1.0373191833496094, Accuracy: 0.66015625\n",
      "Batch: 50, Loss: 0.991762638092041, Accuracy: 0.6728515625\n",
      "Batch: 51, Loss: 1.0903433561325073, Accuracy: 0.650390625\n",
      "Batch: 52, Loss: 1.0419244766235352, Accuracy: 0.6708984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 53, Loss: 0.9063314199447632, Accuracy: 0.7080078125\n",
      "Batch: 54, Loss: 0.9618021249771118, Accuracy: 0.685546875\n",
      "Batch: 55, Loss: 1.0175153017044067, Accuracy: 0.6650390625\n",
      "Batch: 56, Loss: 1.0417624711990356, Accuracy: 0.6787109375\n",
      "Batch: 57, Loss: 0.9660380482673645, Accuracy: 0.6943359375\n",
      "Batch: 58, Loss: 1.050060749053955, Accuracy: 0.6904296875\n",
      "Batch: 59, Loss: 0.880776047706604, Accuracy: 0.716796875\n",
      "Batch: 60, Loss: 0.8763653635978699, Accuracy: 0.708984375\n",
      "Batch: 61, Loss: 0.9915213584899902, Accuracy: 0.671875\n",
      "Batch: 62, Loss: 0.8970449566841125, Accuracy: 0.7119140625\n",
      "Batch: 63, Loss: 0.9714535474777222, Accuracy: 0.689453125\n",
      "Batch: 64, Loss: 0.9319584369659424, Accuracy: 0.701171875\n",
      "Batch: 65, Loss: 0.9689778089523315, Accuracy: 0.7001953125\n",
      "Batch: 66, Loss: 0.9377133846282959, Accuracy: 0.7177734375\n",
      "Batch: 67, Loss: 1.0204557180404663, Accuracy: 0.671875\n",
      "Batch: 68, Loss: 1.0308701992034912, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 0.9675947427749634, Accuracy: 0.6923828125\n",
      "Batch: 70, Loss: 0.9774736166000366, Accuracy: 0.7041015625\n",
      "Batch: 71, Loss: 1.004368543624878, Accuracy: 0.673828125\n",
      "Batch: 72, Loss: 0.881263256072998, Accuracy: 0.7041015625\n",
      "Batch: 73, Loss: 0.8948094248771667, Accuracy: 0.71875\n",
      "Batch: 74, Loss: 0.8934913873672485, Accuracy: 0.73046875\n",
      "Batch: 75, Loss: 0.8389907479286194, Accuracy: 0.724609375\n",
      "Batch: 76, Loss: 0.95474773645401, Accuracy: 0.693359375\n",
      "Batch: 77, Loss: 0.938022792339325, Accuracy: 0.6904296875\n",
      "Batch: 78, Loss: 0.921072244644165, Accuracy: 0.7060546875\n",
      "Batch: 79, Loss: 0.881520688533783, Accuracy: 0.7373046875\n",
      "Batch: 80, Loss: 0.8874767422676086, Accuracy: 0.7138671875\n",
      "Batch: 81, Loss: 1.0148853063583374, Accuracy: 0.666015625\n",
      "Batch: 82, Loss: 0.9902995228767395, Accuracy: 0.6884765625\n",
      "Batch: 83, Loss: 0.8301589488983154, Accuracy: 0.7431640625\n",
      "Batch: 84, Loss: 0.9630802869796753, Accuracy: 0.6884765625\n",
      "Batch: 85, Loss: 0.8824604749679565, Accuracy: 0.7197265625\n",
      "Batch: 86, Loss: 1.1284946203231812, Accuracy: 0.6484375\n",
      "Batch: 87, Loss: 0.8984571695327759, Accuracy: 0.7158203125\n",
      "Batch: 88, Loss: 1.0347901582717896, Accuracy: 0.6875\n",
      "Batch: 89, Loss: 0.9766841530799866, Accuracy: 0.708984375\n",
      "Batch: 90, Loss: 0.9051252603530884, Accuracy: 0.7255859375\n",
      "Batch: 91, Loss: 0.9658910036087036, Accuracy: 0.6953125\n",
      "Batch: 92, Loss: 0.9634270668029785, Accuracy: 0.6875\n",
      "Batch: 93, Loss: 0.9255307912826538, Accuracy: 0.69140625\n",
      "Batch: 94, Loss: 0.9287943840026855, Accuracy: 0.69140625\n",
      "Batch: 95, Loss: 0.9879546165466309, Accuracy: 0.6728515625\n",
      "Batch: 96, Loss: 0.9434212446212769, Accuracy: 0.69921875\n",
      "Batch: 97, Loss: 0.8536942005157471, Accuracy: 0.7294921875\n",
      "Batch: 98, Loss: 0.9152234792709351, Accuracy: 0.7099609375\n",
      "Batch: 99, Loss: 0.9000357389450073, Accuracy: 0.7109375\n",
      "Batch: 100, Loss: 0.9440051317214966, Accuracy: 0.6923828125\n",
      "Batch: 101, Loss: 1.0003585815429688, Accuracy: 0.6796875\n",
      "Batch: 102, Loss: 0.9427937865257263, Accuracy: 0.69921875\n",
      "Batch: 103, Loss: 1.0019145011901855, Accuracy: 0.70703125\n",
      "Batch: 104, Loss: 0.9063972234725952, Accuracy: 0.7021484375\n",
      "Batch: 105, Loss: 0.9878856539726257, Accuracy: 0.6826171875\n",
      "Batch: 106, Loss: 0.9370768070220947, Accuracy: 0.712890625\n",
      "Batch: 107, Loss: 1.005916714668274, Accuracy: 0.669921875\n",
      "Batch: 108, Loss: 0.9636678695678711, Accuracy: 0.6689453125\n",
      "Batch: 109, Loss: 1.0900683403015137, Accuracy: 0.634765625\n",
      "Batch: 110, Loss: 0.819105863571167, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 1.018638014793396, Accuracy: 0.6630859375\n",
      "Batch: 112, Loss: 0.9693641662597656, Accuracy: 0.705078125\n",
      "Batch: 113, Loss: 0.9923368692398071, Accuracy: 0.6884765625\n",
      "Batch: 114, Loss: 1.0516629219055176, Accuracy: 0.6494140625\n",
      "Batch: 115, Loss: 1.1078797578811646, Accuracy: 0.6513671875\n",
      "Batch: 116, Loss: 1.0096688270568848, Accuracy: 0.677734375\n",
      "Batch: 117, Loss: 1.0051376819610596, Accuracy: 0.677734375\n",
      "Batch: 118, Loss: 0.8546651005744934, Accuracy: 0.7255859375\n",
      "Batch: 119, Loss: 0.8876693844795227, Accuracy: 0.7197265625\n",
      "Batch: 120, Loss: 1.0063163042068481, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 1.0311933755874634, Accuracy: 0.671875\n",
      "Batch: 122, Loss: 0.9227344989776611, Accuracy: 0.7109375\n",
      "Batch: 123, Loss: 0.9201632738113403, Accuracy: 0.7236328125\n",
      "Batch: 124, Loss: 0.9868099689483643, Accuracy: 0.6806640625\n",
      "Batch: 125, Loss: 1.0075852870941162, Accuracy: 0.662109375\n",
      "Batch: 126, Loss: 0.9715173840522766, Accuracy: 0.6806640625\n",
      "Batch: 127, Loss: 0.8837907314300537, Accuracy: 0.7314453125\n",
      "Batch: 128, Loss: 1.087111234664917, Accuracy: 0.6591796875\n",
      "Batch: 129, Loss: 0.9279869794845581, Accuracy: 0.7080078125\n",
      "Batch: 130, Loss: 1.168035626411438, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.0353093147277832, Accuracy: 0.6728515625\n",
      "Batch: 132, Loss: 1.027601957321167, Accuracy: 0.6884765625\n",
      "Batch: 133, Loss: 0.9436452388763428, Accuracy: 0.69140625\n",
      "Batch: 134, Loss: 1.0031923055648804, Accuracy: 0.6650390625\n",
      "Batch: 135, Loss: 0.8821240663528442, Accuracy: 0.73046875\n",
      "Batch: 136, Loss: 0.983296275138855, Accuracy: 0.701171875\n",
      "Batch: 137, Loss: 0.9373000860214233, Accuracy: 0.68359375\n",
      "Batch: 138, Loss: 0.8095426559448242, Accuracy: 0.732421875\n",
      "Batch: 139, Loss: 0.9184887409210205, Accuracy: 0.70703125\n",
      "Batch: 140, Loss: 0.9445376992225647, Accuracy: 0.6904296875\n",
      "Batch: 141, Loss: 1.0096369981765747, Accuracy: 0.6630859375\n",
      "Batch: 142, Loss: 0.9867451190948486, Accuracy: 0.681640625\n",
      "Batch: 143, Loss: 0.9695252180099487, Accuracy: 0.697265625\n",
      "Batch: 144, Loss: 1.0073158740997314, Accuracy: 0.6845703125\n",
      "Batch: 145, Loss: 0.9068138599395752, Accuracy: 0.6884765625\n",
      "Batch: 146, Loss: 1.0204973220825195, Accuracy: 0.6591796875\n",
      "Batch: 147, Loss: 1.001377820968628, Accuracy: 0.6708984375\n",
      "Batch: 148, Loss: 1.1043195724487305, Accuracy: 0.6435546875\n",
      "Batch: 149, Loss: 0.976940929889679, Accuracy: 0.6728515625\n",
      "Batch: 150, Loss: 0.9311004281044006, Accuracy: 0.6875\n",
      "Batch: 151, Loss: 0.8407430648803711, Accuracy: 0.7373046875\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/80\n",
      "Batch: 1, Loss: 1.2147024869918823, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.0404822826385498, Accuracy: 0.64453125\n",
      "Batch: 3, Loss: 0.9326679706573486, Accuracy: 0.685546875\n",
      "Batch: 4, Loss: 0.8804631233215332, Accuracy: 0.7373046875\n",
      "Batch: 5, Loss: 0.8988686800003052, Accuracy: 0.71875\n",
      "Batch: 6, Loss: 0.977656900882721, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.9534248113632202, Accuracy: 0.6875\n",
      "Batch: 8, Loss: 0.893854022026062, Accuracy: 0.7001953125\n",
      "Batch: 9, Loss: 0.875320315361023, Accuracy: 0.7255859375\n",
      "Batch: 10, Loss: 0.8716374635696411, Accuracy: 0.70703125\n",
      "Batch: 11, Loss: 1.0209202766418457, Accuracy: 0.6591796875\n",
      "Batch: 12, Loss: 1.0234906673431396, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 0.8175570964813232, Accuracy: 0.7333984375\n",
      "Batch: 14, Loss: 1.0840263366699219, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.9252307415008545, Accuracy: 0.7265625\n",
      "Batch: 16, Loss: 0.9238663911819458, Accuracy: 0.7158203125\n",
      "Batch: 17, Loss: 0.9818416237831116, Accuracy: 0.685546875\n",
      "Batch: 18, Loss: 1.0223240852355957, Accuracy: 0.67578125\n",
      "Batch: 19, Loss: 1.0062458515167236, Accuracy: 0.67578125\n",
      "Batch: 20, Loss: 0.8975586891174316, Accuracy: 0.7099609375\n",
      "Batch: 21, Loss: 0.916191816329956, Accuracy: 0.6962890625\n",
      "Batch: 22, Loss: 0.9972856044769287, Accuracy: 0.6884765625\n",
      "Batch: 23, Loss: 0.9465264081954956, Accuracy: 0.685546875\n",
      "Batch: 24, Loss: 0.9700106382369995, Accuracy: 0.69140625\n",
      "Batch: 25, Loss: 0.9436395168304443, Accuracy: 0.708984375\n",
      "Batch: 26, Loss: 0.8441981077194214, Accuracy: 0.728515625\n",
      "Batch: 27, Loss: 0.8857487440109253, Accuracy: 0.701171875\n",
      "Batch: 28, Loss: 1.0004853010177612, Accuracy: 0.6748046875\n",
      "Batch: 29, Loss: 0.9778582453727722, Accuracy: 0.6796875\n",
      "Batch: 30, Loss: 0.9018598794937134, Accuracy: 0.7314453125\n",
      "Batch: 31, Loss: 0.8733041286468506, Accuracy: 0.7373046875\n",
      "Batch: 32, Loss: 0.9028063416481018, Accuracy: 0.7060546875\n",
      "Batch: 33, Loss: 1.0514514446258545, Accuracy: 0.6748046875\n",
      "Batch: 34, Loss: 1.107269048690796, Accuracy: 0.650390625\n",
      "Batch: 35, Loss: 0.9877141714096069, Accuracy: 0.6865234375\n",
      "Batch: 36, Loss: 1.0171650648117065, Accuracy: 0.6845703125\n",
      "Batch: 37, Loss: 0.9496988654136658, Accuracy: 0.7021484375\n",
      "Batch: 38, Loss: 0.9701408743858337, Accuracy: 0.6923828125\n",
      "Batch: 39, Loss: 0.9897944927215576, Accuracy: 0.685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 0.9734481573104858, Accuracy: 0.689453125\n",
      "Batch: 41, Loss: 0.9465116858482361, Accuracy: 0.7021484375\n",
      "Batch: 42, Loss: 0.7594903111457825, Accuracy: 0.7451171875\n",
      "Batch: 43, Loss: 0.954099714756012, Accuracy: 0.6796875\n",
      "Batch: 44, Loss: 0.9595791101455688, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 0.8579839468002319, Accuracy: 0.7265625\n",
      "Batch: 46, Loss: 0.8823541402816772, Accuracy: 0.7255859375\n",
      "Batch: 47, Loss: 0.9163516163825989, Accuracy: 0.7197265625\n",
      "Batch: 48, Loss: 0.8473072052001953, Accuracy: 0.7265625\n",
      "Batch: 49, Loss: 1.0291285514831543, Accuracy: 0.6669921875\n",
      "Batch: 50, Loss: 0.9995911121368408, Accuracy: 0.6630859375\n",
      "Batch: 51, Loss: 1.0664258003234863, Accuracy: 0.666015625\n",
      "Batch: 52, Loss: 1.0180039405822754, Accuracy: 0.6796875\n",
      "Batch: 53, Loss: 0.8505526781082153, Accuracy: 0.7158203125\n",
      "Batch: 54, Loss: 0.9529792666435242, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 1.0323134660720825, Accuracy: 0.662109375\n",
      "Batch: 56, Loss: 1.007901668548584, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 0.9735497236251831, Accuracy: 0.6923828125\n",
      "Batch: 58, Loss: 1.036252737045288, Accuracy: 0.6806640625\n",
      "Batch: 59, Loss: 0.8551764488220215, Accuracy: 0.732421875\n",
      "Batch: 60, Loss: 0.8466813564300537, Accuracy: 0.734375\n",
      "Batch: 61, Loss: 0.9946821331977844, Accuracy: 0.6806640625\n",
      "Batch: 62, Loss: 0.8939932584762573, Accuracy: 0.7158203125\n",
      "Batch: 63, Loss: 0.9324098229408264, Accuracy: 0.7099609375\n",
      "Batch: 64, Loss: 0.9342235922813416, Accuracy: 0.7041015625\n",
      "Batch: 65, Loss: 0.9394274950027466, Accuracy: 0.716796875\n",
      "Batch: 66, Loss: 0.9334346055984497, Accuracy: 0.705078125\n",
      "Batch: 67, Loss: 0.9888988137245178, Accuracy: 0.689453125\n",
      "Batch: 68, Loss: 1.0191154479980469, Accuracy: 0.6845703125\n",
      "Batch: 69, Loss: 0.975838303565979, Accuracy: 0.6865234375\n",
      "Batch: 70, Loss: 0.9448307156562805, Accuracy: 0.70703125\n",
      "Batch: 71, Loss: 0.9915456175804138, Accuracy: 0.6728515625\n",
      "Batch: 72, Loss: 0.8406665325164795, Accuracy: 0.7236328125\n",
      "Batch: 73, Loss: 0.9021201133728027, Accuracy: 0.7060546875\n",
      "Batch: 74, Loss: 0.869644284248352, Accuracy: 0.7197265625\n",
      "Batch: 75, Loss: 0.8346763849258423, Accuracy: 0.7265625\n",
      "Batch: 76, Loss: 0.9485783576965332, Accuracy: 0.6796875\n",
      "Batch: 77, Loss: 0.9004076719284058, Accuracy: 0.7109375\n",
      "Batch: 78, Loss: 0.921585202217102, Accuracy: 0.724609375\n",
      "Batch: 79, Loss: 0.8631131052970886, Accuracy: 0.7412109375\n",
      "Batch: 80, Loss: 0.8858753442764282, Accuracy: 0.697265625\n",
      "Batch: 81, Loss: 0.99088054895401, Accuracy: 0.6708984375\n",
      "Batch: 82, Loss: 0.9685696363449097, Accuracy: 0.6884765625\n",
      "Batch: 83, Loss: 0.8124618530273438, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.9262394905090332, Accuracy: 0.708984375\n",
      "Batch: 85, Loss: 0.8628244996070862, Accuracy: 0.7265625\n",
      "Batch: 86, Loss: 1.0985170602798462, Accuracy: 0.65625\n",
      "Batch: 87, Loss: 0.8916210532188416, Accuracy: 0.7197265625\n",
      "Batch: 88, Loss: 1.0064258575439453, Accuracy: 0.6962890625\n",
      "Batch: 89, Loss: 0.9760221242904663, Accuracy: 0.7041015625\n",
      "Batch: 90, Loss: 0.9046514630317688, Accuracy: 0.708984375\n",
      "Batch: 91, Loss: 0.9124209880828857, Accuracy: 0.7001953125\n",
      "Batch: 92, Loss: 0.9615126848220825, Accuracy: 0.693359375\n",
      "Batch: 93, Loss: 0.9047048091888428, Accuracy: 0.7060546875\n",
      "Batch: 94, Loss: 0.9067797660827637, Accuracy: 0.7060546875\n",
      "Batch: 95, Loss: 0.9832864999771118, Accuracy: 0.66796875\n",
      "Batch: 96, Loss: 0.9412829875946045, Accuracy: 0.6943359375\n",
      "Batch: 97, Loss: 0.7989046573638916, Accuracy: 0.7294921875\n",
      "Batch: 98, Loss: 0.8609868884086609, Accuracy: 0.716796875\n",
      "Batch: 99, Loss: 0.886885404586792, Accuracy: 0.7021484375\n",
      "Batch: 100, Loss: 0.9242489337921143, Accuracy: 0.7080078125\n",
      "Batch: 101, Loss: 0.984094500541687, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.9006103277206421, Accuracy: 0.7060546875\n",
      "Batch: 103, Loss: 0.9557704925537109, Accuracy: 0.7138671875\n",
      "Batch: 104, Loss: 0.8700493574142456, Accuracy: 0.7197265625\n",
      "Batch: 105, Loss: 1.0129742622375488, Accuracy: 0.681640625\n",
      "Batch: 106, Loss: 0.9175574779510498, Accuracy: 0.7138671875\n",
      "Batch: 107, Loss: 0.9720064401626587, Accuracy: 0.7060546875\n",
      "Batch: 108, Loss: 0.958541750907898, Accuracy: 0.6708984375\n",
      "Batch: 109, Loss: 1.0698442459106445, Accuracy: 0.6513671875\n",
      "Batch: 110, Loss: 0.8151320219039917, Accuracy: 0.744140625\n",
      "Batch: 111, Loss: 1.0089008808135986, Accuracy: 0.662109375\n",
      "Batch: 112, Loss: 0.9663035869598389, Accuracy: 0.6923828125\n",
      "Batch: 113, Loss: 0.973609447479248, Accuracy: 0.6982421875\n",
      "Batch: 114, Loss: 1.0482845306396484, Accuracy: 0.650390625\n",
      "Batch: 115, Loss: 1.0564043521881104, Accuracy: 0.6748046875\n",
      "Batch: 116, Loss: 0.9798159599304199, Accuracy: 0.677734375\n",
      "Batch: 117, Loss: 1.0005583763122559, Accuracy: 0.67578125\n",
      "Batch: 118, Loss: 0.8494540452957153, Accuracy: 0.734375\n",
      "Batch: 119, Loss: 0.8729925155639648, Accuracy: 0.712890625\n",
      "Batch: 120, Loss: 0.980914831161499, Accuracy: 0.6767578125\n",
      "Batch: 121, Loss: 1.020094633102417, Accuracy: 0.6796875\n",
      "Batch: 122, Loss: 0.9013924598693848, Accuracy: 0.708984375\n",
      "Batch: 123, Loss: 0.8953514695167542, Accuracy: 0.7158203125\n",
      "Batch: 124, Loss: 0.9621298909187317, Accuracy: 0.6943359375\n",
      "Batch: 125, Loss: 1.0009562969207764, Accuracy: 0.6796875\n",
      "Batch: 126, Loss: 0.9515461921691895, Accuracy: 0.7021484375\n",
      "Batch: 127, Loss: 0.8846704363822937, Accuracy: 0.728515625\n",
      "Batch: 128, Loss: 1.0828355550765991, Accuracy: 0.6708984375\n",
      "Batch: 129, Loss: 0.9275182485580444, Accuracy: 0.7119140625\n",
      "Batch: 130, Loss: 1.1124532222747803, Accuracy: 0.6484375\n",
      "Batch: 131, Loss: 1.016737461090088, Accuracy: 0.6796875\n",
      "Batch: 132, Loss: 1.0110100507736206, Accuracy: 0.681640625\n",
      "Batch: 133, Loss: 0.8978592157363892, Accuracy: 0.7177734375\n",
      "Batch: 134, Loss: 0.9476206302642822, Accuracy: 0.6953125\n",
      "Batch: 135, Loss: 0.865053653717041, Accuracy: 0.7392578125\n",
      "Batch: 136, Loss: 0.9653459787368774, Accuracy: 0.7001953125\n",
      "Batch: 137, Loss: 0.9354609251022339, Accuracy: 0.6884765625\n",
      "Batch: 138, Loss: 0.8119525909423828, Accuracy: 0.7470703125\n",
      "Batch: 139, Loss: 0.8889462947845459, Accuracy: 0.7197265625\n",
      "Batch: 140, Loss: 0.9168470501899719, Accuracy: 0.701171875\n",
      "Batch: 141, Loss: 0.983765721321106, Accuracy: 0.6787109375\n",
      "Batch: 142, Loss: 0.9895619750022888, Accuracy: 0.681640625\n",
      "Batch: 143, Loss: 0.9820915460586548, Accuracy: 0.6787109375\n",
      "Batch: 144, Loss: 0.9742845296859741, Accuracy: 0.6767578125\n",
      "Batch: 145, Loss: 0.8862911462783813, Accuracy: 0.6884765625\n",
      "Batch: 146, Loss: 1.0014407634735107, Accuracy: 0.681640625\n",
      "Batch: 147, Loss: 1.0033029317855835, Accuracy: 0.6826171875\n",
      "Batch: 148, Loss: 1.1137877702713013, Accuracy: 0.6416015625\n",
      "Batch: 149, Loss: 0.9494742155075073, Accuracy: 0.7099609375\n",
      "Batch: 150, Loss: 0.9280253648757935, Accuracy: 0.68359375\n",
      "Batch: 151, Loss: 0.840994656085968, Accuracy: 0.734375\n",
      "Epoch 22/80\n",
      "Batch: 1, Loss: 1.1842491626739502, Accuracy: 0.6220703125\n",
      "Batch: 2, Loss: 1.0356031656265259, Accuracy: 0.6513671875\n",
      "Batch: 3, Loss: 0.9019351005554199, Accuracy: 0.7021484375\n",
      "Batch: 4, Loss: 0.8718694448471069, Accuracy: 0.724609375\n",
      "Batch: 5, Loss: 0.8792023062705994, Accuracy: 0.732421875\n",
      "Batch: 6, Loss: 0.9778791666030884, Accuracy: 0.6875\n",
      "Batch: 7, Loss: 0.9492921829223633, Accuracy: 0.67578125\n",
      "Batch: 8, Loss: 0.8864519596099854, Accuracy: 0.708984375\n",
      "Batch: 9, Loss: 0.8488600254058838, Accuracy: 0.744140625\n",
      "Batch: 10, Loss: 0.861585259437561, Accuracy: 0.7216796875\n",
      "Batch: 11, Loss: 0.9959160089492798, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 0.9836053848266602, Accuracy: 0.677734375\n",
      "Batch: 13, Loss: 0.7685387134552002, Accuracy: 0.751953125\n",
      "Batch: 14, Loss: 1.0432671308517456, Accuracy: 0.66796875\n",
      "Batch: 15, Loss: 0.8668649196624756, Accuracy: 0.7392578125\n",
      "Batch: 16, Loss: 0.9105183482170105, Accuracy: 0.716796875\n",
      "Batch: 17, Loss: 0.9483828544616699, Accuracy: 0.6943359375\n",
      "Batch: 18, Loss: 0.98264479637146, Accuracy: 0.6826171875\n",
      "Batch: 19, Loss: 0.957368016242981, Accuracy: 0.6953125\n",
      "Batch: 20, Loss: 0.8697687387466431, Accuracy: 0.734375\n",
      "Batch: 21, Loss: 0.9046138525009155, Accuracy: 0.7109375\n",
      "Batch: 22, Loss: 1.0316822528839111, Accuracy: 0.68359375\n",
      "Batch: 23, Loss: 0.9380329847335815, Accuracy: 0.6884765625\n",
      "Batch: 24, Loss: 0.9656864404678345, Accuracy: 0.685546875\n",
      "Batch: 25, Loss: 0.9326788783073425, Accuracy: 0.71875\n",
      "Batch: 26, Loss: 0.841504693031311, Accuracy: 0.7333984375\n",
      "Batch: 27, Loss: 0.8837458491325378, Accuracy: 0.7080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28, Loss: 0.9650105834007263, Accuracy: 0.6796875\n",
      "Batch: 29, Loss: 0.947954535484314, Accuracy: 0.689453125\n",
      "Batch: 30, Loss: 0.8795532584190369, Accuracy: 0.7314453125\n",
      "Batch: 31, Loss: 0.876518189907074, Accuracy: 0.720703125\n",
      "Batch: 32, Loss: 0.8689392805099487, Accuracy: 0.7099609375\n",
      "Batch: 33, Loss: 1.0162723064422607, Accuracy: 0.6845703125\n",
      "Batch: 34, Loss: 1.0883252620697021, Accuracy: 0.6416015625\n",
      "Batch: 35, Loss: 0.9632875919342041, Accuracy: 0.6748046875\n",
      "Batch: 36, Loss: 0.9852151870727539, Accuracy: 0.7060546875\n",
      "Batch: 37, Loss: 0.969202995300293, Accuracy: 0.6943359375\n",
      "Batch: 38, Loss: 0.9584156274795532, Accuracy: 0.6953125\n",
      "Batch: 39, Loss: 0.9969854950904846, Accuracy: 0.701171875\n",
      "Batch: 40, Loss: 0.9528381824493408, Accuracy: 0.6982421875\n",
      "Batch: 41, Loss: 0.911731481552124, Accuracy: 0.7119140625\n",
      "Batch: 42, Loss: 0.7423725128173828, Accuracy: 0.748046875\n",
      "Batch: 43, Loss: 0.9242870807647705, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.945733904838562, Accuracy: 0.685546875\n",
      "Batch: 45, Loss: 0.835793137550354, Accuracy: 0.724609375\n",
      "Batch: 46, Loss: 0.8788692951202393, Accuracy: 0.728515625\n",
      "Batch: 47, Loss: 0.8948947191238403, Accuracy: 0.716796875\n",
      "Batch: 48, Loss: 0.839489221572876, Accuracy: 0.7392578125\n",
      "Batch: 49, Loss: 0.9892597794532776, Accuracy: 0.6806640625\n",
      "Batch: 50, Loss: 0.9533905982971191, Accuracy: 0.7001953125\n",
      "Batch: 51, Loss: 1.0342457294464111, Accuracy: 0.677734375\n",
      "Batch: 52, Loss: 0.9727262258529663, Accuracy: 0.685546875\n",
      "Batch: 53, Loss: 0.8669499158859253, Accuracy: 0.7080078125\n",
      "Batch: 54, Loss: 0.9577008485794067, Accuracy: 0.6923828125\n",
      "Batch: 55, Loss: 1.0121004581451416, Accuracy: 0.677734375\n",
      "Batch: 56, Loss: 0.9851397275924683, Accuracy: 0.6884765625\n",
      "Batch: 57, Loss: 0.9328120350837708, Accuracy: 0.716796875\n",
      "Batch: 58, Loss: 1.0359567403793335, Accuracy: 0.685546875\n",
      "Batch: 59, Loss: 0.8603354692459106, Accuracy: 0.7294921875\n",
      "Batch: 60, Loss: 0.820885419845581, Accuracy: 0.7353515625\n",
      "Batch: 61, Loss: 0.993701159954071, Accuracy: 0.6806640625\n",
      "Batch: 62, Loss: 0.8711169362068176, Accuracy: 0.7119140625\n",
      "Batch: 63, Loss: 0.9168697595596313, Accuracy: 0.7109375\n",
      "Batch: 64, Loss: 0.8980260491371155, Accuracy: 0.7109375\n",
      "Batch: 65, Loss: 0.9374201893806458, Accuracy: 0.7119140625\n",
      "Batch: 66, Loss: 0.9146307706832886, Accuracy: 0.71484375\n",
      "Batch: 67, Loss: 0.9679901599884033, Accuracy: 0.697265625\n",
      "Batch: 68, Loss: 1.040079951286316, Accuracy: 0.677734375\n",
      "Batch: 69, Loss: 0.9632127285003662, Accuracy: 0.6923828125\n",
      "Batch: 70, Loss: 0.9389541745185852, Accuracy: 0.7138671875\n",
      "Batch: 71, Loss: 0.9315418004989624, Accuracy: 0.6875\n",
      "Batch: 72, Loss: 0.8322685360908508, Accuracy: 0.7275390625\n",
      "Batch: 73, Loss: 0.8582379817962646, Accuracy: 0.734375\n",
      "Batch: 74, Loss: 0.851738452911377, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.8107384443283081, Accuracy: 0.7353515625\n",
      "Batch: 76, Loss: 0.9010794758796692, Accuracy: 0.7158203125\n",
      "Batch: 77, Loss: 0.8736231327056885, Accuracy: 0.7158203125\n",
      "Batch: 78, Loss: 0.8981099128723145, Accuracy: 0.7265625\n",
      "Batch: 79, Loss: 0.8343164920806885, Accuracy: 0.7470703125\n",
      "Batch: 80, Loss: 0.8540129661560059, Accuracy: 0.7080078125\n",
      "Batch: 81, Loss: 1.0027204751968384, Accuracy: 0.6533203125\n",
      "Batch: 82, Loss: 0.9352657794952393, Accuracy: 0.6923828125\n",
      "Batch: 83, Loss: 0.8039760589599609, Accuracy: 0.7421875\n",
      "Batch: 84, Loss: 0.8861443996429443, Accuracy: 0.7197265625\n",
      "Batch: 85, Loss: 0.8395154476165771, Accuracy: 0.734375\n",
      "Batch: 86, Loss: 1.074105978012085, Accuracy: 0.673828125\n",
      "Batch: 87, Loss: 0.8400108814239502, Accuracy: 0.7392578125\n",
      "Batch: 88, Loss: 0.977364182472229, Accuracy: 0.708984375\n",
      "Batch: 89, Loss: 0.9577418565750122, Accuracy: 0.69140625\n",
      "Batch: 90, Loss: 0.9005756378173828, Accuracy: 0.7197265625\n",
      "Batch: 91, Loss: 0.9104700088500977, Accuracy: 0.7021484375\n",
      "Batch: 92, Loss: 0.9124845266342163, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.8746351003646851, Accuracy: 0.73828125\n",
      "Batch: 94, Loss: 0.9049842357635498, Accuracy: 0.7021484375\n",
      "Batch: 95, Loss: 0.9612513184547424, Accuracy: 0.6796875\n",
      "Batch: 96, Loss: 0.9255807399749756, Accuracy: 0.7080078125\n",
      "Batch: 97, Loss: 0.7936583161354065, Accuracy: 0.748046875\n",
      "Batch: 98, Loss: 0.8357014656066895, Accuracy: 0.73046875\n",
      "Batch: 99, Loss: 0.8698874711990356, Accuracy: 0.720703125\n",
      "Batch: 100, Loss: 0.9136382341384888, Accuracy: 0.7060546875\n",
      "Batch: 101, Loss: 0.9793199300765991, Accuracy: 0.6796875\n",
      "Batch: 102, Loss: 0.9176145792007446, Accuracy: 0.70703125\n",
      "Batch: 103, Loss: 0.9572247266769409, Accuracy: 0.720703125\n",
      "Batch: 104, Loss: 0.8561164140701294, Accuracy: 0.7177734375\n",
      "Batch: 105, Loss: 0.9513133764266968, Accuracy: 0.69140625\n",
      "Batch: 106, Loss: 0.900759220123291, Accuracy: 0.7109375\n",
      "Batch: 107, Loss: 0.9419810771942139, Accuracy: 0.693359375\n",
      "Batch: 108, Loss: 0.9627413749694824, Accuracy: 0.6943359375\n",
      "Batch: 109, Loss: 1.0501631498336792, Accuracy: 0.6640625\n",
      "Batch: 110, Loss: 0.7951688766479492, Accuracy: 0.7294921875\n",
      "Batch: 111, Loss: 0.981547474861145, Accuracy: 0.677734375\n",
      "Batch: 112, Loss: 0.9490704536437988, Accuracy: 0.703125\n",
      "Batch: 113, Loss: 0.9567088484764099, Accuracy: 0.7099609375\n",
      "Batch: 114, Loss: 1.0458952188491821, Accuracy: 0.6689453125\n",
      "Batch: 115, Loss: 1.0639960765838623, Accuracy: 0.6787109375\n",
      "Batch: 116, Loss: 0.9776750802993774, Accuracy: 0.6845703125\n",
      "Batch: 117, Loss: 0.9958137273788452, Accuracy: 0.689453125\n",
      "Batch: 118, Loss: 0.8321008086204529, Accuracy: 0.736328125\n",
      "Batch: 119, Loss: 0.8233016729354858, Accuracy: 0.7421875\n",
      "Batch: 120, Loss: 0.9728377461433411, Accuracy: 0.6767578125\n",
      "Batch: 121, Loss: 0.9889186024665833, Accuracy: 0.6767578125\n",
      "Batch: 122, Loss: 0.8999778032302856, Accuracy: 0.7216796875\n",
      "Batch: 123, Loss: 0.9049451947212219, Accuracy: 0.6982421875\n",
      "Batch: 124, Loss: 0.9816490411758423, Accuracy: 0.6962890625\n",
      "Batch: 125, Loss: 0.9886280298233032, Accuracy: 0.685546875\n",
      "Batch: 126, Loss: 0.9386409521102905, Accuracy: 0.6884765625\n",
      "Batch: 127, Loss: 0.8517637252807617, Accuracy: 0.7412109375\n",
      "Batch: 128, Loss: 1.035102128982544, Accuracy: 0.6884765625\n",
      "Batch: 129, Loss: 0.9139757752418518, Accuracy: 0.7119140625\n",
      "Batch: 130, Loss: 1.1141040325164795, Accuracy: 0.6533203125\n",
      "Batch: 131, Loss: 0.9872751235961914, Accuracy: 0.6806640625\n",
      "Batch: 132, Loss: 0.9732356071472168, Accuracy: 0.69140625\n",
      "Batch: 133, Loss: 0.889157235622406, Accuracy: 0.7119140625\n",
      "Batch: 134, Loss: 0.9569066762924194, Accuracy: 0.685546875\n",
      "Batch: 135, Loss: 0.8642513155937195, Accuracy: 0.7314453125\n",
      "Batch: 136, Loss: 0.9253993034362793, Accuracy: 0.6982421875\n",
      "Batch: 137, Loss: 0.9150547385215759, Accuracy: 0.697265625\n",
      "Batch: 138, Loss: 0.793744683265686, Accuracy: 0.740234375\n",
      "Batch: 139, Loss: 0.8826555013656616, Accuracy: 0.701171875\n",
      "Batch: 140, Loss: 0.9236471652984619, Accuracy: 0.689453125\n",
      "Batch: 141, Loss: 0.9658374786376953, Accuracy: 0.69140625\n",
      "Batch: 142, Loss: 0.9605066776275635, Accuracy: 0.68359375\n",
      "Batch: 143, Loss: 0.9415973424911499, Accuracy: 0.701171875\n",
      "Batch: 144, Loss: 0.9763181209564209, Accuracy: 0.6875\n",
      "Batch: 145, Loss: 0.8960031867027283, Accuracy: 0.6845703125\n",
      "Batch: 146, Loss: 0.992394208908081, Accuracy: 0.6787109375\n",
      "Batch: 147, Loss: 0.945623517036438, Accuracy: 0.697265625\n",
      "Batch: 148, Loss: 1.0900721549987793, Accuracy: 0.6513671875\n",
      "Batch: 149, Loss: 0.9283027648925781, Accuracy: 0.6904296875\n",
      "Batch: 150, Loss: 0.8937575817108154, Accuracy: 0.7177734375\n",
      "Batch: 151, Loss: 0.8055516481399536, Accuracy: 0.732421875\n",
      "Epoch 23/80\n",
      "Batch: 1, Loss: 1.1575706005096436, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 1.006084680557251, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 0.8728790283203125, Accuracy: 0.7119140625\n",
      "Batch: 4, Loss: 0.839881956577301, Accuracy: 0.748046875\n",
      "Batch: 5, Loss: 0.8536802530288696, Accuracy: 0.73828125\n",
      "Batch: 6, Loss: 0.9448128938674927, Accuracy: 0.6904296875\n",
      "Batch: 7, Loss: 0.9397628903388977, Accuracy: 0.6875\n",
      "Batch: 8, Loss: 0.8616752624511719, Accuracy: 0.720703125\n",
      "Batch: 9, Loss: 0.8747816681861877, Accuracy: 0.73046875\n",
      "Batch: 10, Loss: 0.8556941151618958, Accuracy: 0.712890625\n",
      "Batch: 11, Loss: 0.992974042892456, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 0.9767739772796631, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 0.7719091773033142, Accuracy: 0.751953125\n",
      "Batch: 14, Loss: 1.0518906116485596, Accuracy: 0.6552734375\n",
      "Batch: 15, Loss: 0.8631113767623901, Accuracy: 0.72265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 0.9155431985855103, Accuracy: 0.7294921875\n",
      "Batch: 17, Loss: 0.9319822788238525, Accuracy: 0.697265625\n",
      "Batch: 18, Loss: 0.9469900131225586, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 0.9744989275932312, Accuracy: 0.6923828125\n",
      "Batch: 20, Loss: 0.8497563600540161, Accuracy: 0.7314453125\n",
      "Batch: 21, Loss: 0.873729407787323, Accuracy: 0.7138671875\n",
      "Batch: 22, Loss: 1.0012414455413818, Accuracy: 0.6962890625\n",
      "Batch: 23, Loss: 0.9406396150588989, Accuracy: 0.69140625\n",
      "Batch: 24, Loss: 0.9519752264022827, Accuracy: 0.693359375\n",
      "Batch: 25, Loss: 0.937602162361145, Accuracy: 0.705078125\n",
      "Batch: 26, Loss: 0.8285340666770935, Accuracy: 0.712890625\n",
      "Batch: 27, Loss: 0.8514024019241333, Accuracy: 0.708984375\n",
      "Batch: 28, Loss: 0.9344531297683716, Accuracy: 0.6943359375\n",
      "Batch: 29, Loss: 0.9372238516807556, Accuracy: 0.6943359375\n",
      "Batch: 30, Loss: 0.8303025960922241, Accuracy: 0.744140625\n",
      "Batch: 31, Loss: 0.8350868225097656, Accuracy: 0.7373046875\n",
      "Batch: 32, Loss: 0.851702868938446, Accuracy: 0.71484375\n",
      "Batch: 33, Loss: 1.0176770687103271, Accuracy: 0.68359375\n",
      "Batch: 34, Loss: 1.0686184167861938, Accuracy: 0.66015625\n",
      "Batch: 35, Loss: 0.9454827308654785, Accuracy: 0.6904296875\n",
      "Batch: 36, Loss: 0.9968656897544861, Accuracy: 0.6904296875\n",
      "Batch: 37, Loss: 0.9529057741165161, Accuracy: 0.689453125\n",
      "Batch: 38, Loss: 0.9527235627174377, Accuracy: 0.6875\n",
      "Batch: 39, Loss: 0.9393216967582703, Accuracy: 0.693359375\n",
      "Batch: 40, Loss: 0.9506617784500122, Accuracy: 0.693359375\n",
      "Batch: 41, Loss: 0.9149823188781738, Accuracy: 0.7099609375\n",
      "Batch: 42, Loss: 0.7336478233337402, Accuracy: 0.7646484375\n",
      "Batch: 43, Loss: 0.915149450302124, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 0.9314000010490417, Accuracy: 0.697265625\n",
      "Batch: 45, Loss: 0.8145813941955566, Accuracy: 0.728515625\n",
      "Batch: 46, Loss: 0.8584824800491333, Accuracy: 0.734375\n",
      "Batch: 47, Loss: 0.8857529163360596, Accuracy: 0.732421875\n",
      "Batch: 48, Loss: 0.8399512767791748, Accuracy: 0.736328125\n",
      "Batch: 49, Loss: 0.9957777857780457, Accuracy: 0.6689453125\n",
      "Batch: 50, Loss: 0.9606161117553711, Accuracy: 0.6767578125\n",
      "Batch: 51, Loss: 1.0204285383224487, Accuracy: 0.6748046875\n",
      "Batch: 52, Loss: 0.9803519248962402, Accuracy: 0.67578125\n",
      "Batch: 53, Loss: 0.8194114565849304, Accuracy: 0.7333984375\n",
      "Batch: 54, Loss: 0.9301618337631226, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 0.9957503080368042, Accuracy: 0.681640625\n",
      "Batch: 56, Loss: 0.9779329299926758, Accuracy: 0.69140625\n",
      "Batch: 57, Loss: 0.9291530847549438, Accuracy: 0.7080078125\n",
      "Batch: 58, Loss: 1.003321886062622, Accuracy: 0.6904296875\n",
      "Batch: 59, Loss: 0.8451287746429443, Accuracy: 0.732421875\n",
      "Batch: 60, Loss: 0.8316442966461182, Accuracy: 0.7197265625\n",
      "Batch: 61, Loss: 0.9704828262329102, Accuracy: 0.6826171875\n",
      "Batch: 62, Loss: 0.835660457611084, Accuracy: 0.740234375\n",
      "Batch: 63, Loss: 0.908706784248352, Accuracy: 0.7138671875\n",
      "Batch: 64, Loss: 0.9034973382949829, Accuracy: 0.7080078125\n",
      "Batch: 65, Loss: 0.9130343198776245, Accuracy: 0.712890625\n",
      "Batch: 66, Loss: 0.8715908527374268, Accuracy: 0.7265625\n",
      "Batch: 67, Loss: 0.9638811945915222, Accuracy: 0.6962890625\n",
      "Batch: 68, Loss: 1.0033680200576782, Accuracy: 0.6904296875\n",
      "Batch: 69, Loss: 0.9467946887016296, Accuracy: 0.6796875\n",
      "Batch: 70, Loss: 0.9090039730072021, Accuracy: 0.7158203125\n",
      "Batch: 71, Loss: 0.9497451186180115, Accuracy: 0.6884765625\n",
      "Batch: 72, Loss: 0.8411046266555786, Accuracy: 0.716796875\n",
      "Batch: 73, Loss: 0.8607333898544312, Accuracy: 0.7412109375\n",
      "Batch: 74, Loss: 0.8675397038459778, Accuracy: 0.7255859375\n",
      "Batch: 75, Loss: 0.7891343832015991, Accuracy: 0.740234375\n",
      "Batch: 76, Loss: 0.8983641862869263, Accuracy: 0.7060546875\n",
      "Batch: 77, Loss: 0.854404866695404, Accuracy: 0.724609375\n",
      "Batch: 78, Loss: 0.869020938873291, Accuracy: 0.7314453125\n",
      "Batch: 79, Loss: 0.8555936217308044, Accuracy: 0.73828125\n",
      "Batch: 80, Loss: 0.8441694378852844, Accuracy: 0.701171875\n",
      "Batch: 81, Loss: 0.9910975694656372, Accuracy: 0.6806640625\n",
      "Batch: 82, Loss: 0.9249629974365234, Accuracy: 0.6845703125\n",
      "Batch: 83, Loss: 0.7733805775642395, Accuracy: 0.755859375\n",
      "Batch: 84, Loss: 0.897200345993042, Accuracy: 0.720703125\n",
      "Batch: 85, Loss: 0.8433642387390137, Accuracy: 0.7392578125\n",
      "Batch: 86, Loss: 1.0339205265045166, Accuracy: 0.69140625\n",
      "Batch: 87, Loss: 0.8356921672821045, Accuracy: 0.740234375\n",
      "Batch: 88, Loss: 0.9832427501678467, Accuracy: 0.703125\n",
      "Batch: 89, Loss: 0.9207521080970764, Accuracy: 0.7275390625\n",
      "Batch: 90, Loss: 0.8577070236206055, Accuracy: 0.734375\n",
      "Batch: 91, Loss: 0.8840901851654053, Accuracy: 0.70703125\n",
      "Batch: 92, Loss: 0.9169663190841675, Accuracy: 0.6865234375\n",
      "Batch: 93, Loss: 0.8641144037246704, Accuracy: 0.728515625\n",
      "Batch: 94, Loss: 0.8926186561584473, Accuracy: 0.69921875\n",
      "Batch: 95, Loss: 0.9356338977813721, Accuracy: 0.671875\n",
      "Batch: 96, Loss: 0.8825850486755371, Accuracy: 0.7216796875\n",
      "Batch: 97, Loss: 0.780432403087616, Accuracy: 0.7373046875\n",
      "Batch: 98, Loss: 0.8417823314666748, Accuracy: 0.7255859375\n",
      "Batch: 99, Loss: 0.8510460257530212, Accuracy: 0.728515625\n",
      "Batch: 100, Loss: 0.9202543497085571, Accuracy: 0.7099609375\n",
      "Batch: 101, Loss: 0.9837204813957214, Accuracy: 0.6845703125\n",
      "Batch: 102, Loss: 0.9002429246902466, Accuracy: 0.701171875\n",
      "Batch: 103, Loss: 0.9462543725967407, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8420398235321045, Accuracy: 0.7119140625\n",
      "Batch: 105, Loss: 0.9571816921234131, Accuracy: 0.69140625\n",
      "Batch: 106, Loss: 0.8715038299560547, Accuracy: 0.732421875\n",
      "Batch: 107, Loss: 0.9385963678359985, Accuracy: 0.7080078125\n",
      "Batch: 108, Loss: 0.9224792718887329, Accuracy: 0.69140625\n",
      "Batch: 109, Loss: 1.0443949699401855, Accuracy: 0.666015625\n",
      "Batch: 110, Loss: 0.8127656579017639, Accuracy: 0.7333984375\n",
      "Batch: 111, Loss: 0.9786098003387451, Accuracy: 0.6748046875\n",
      "Batch: 112, Loss: 0.9091269969940186, Accuracy: 0.7177734375\n",
      "Batch: 113, Loss: 0.9349878430366516, Accuracy: 0.6923828125\n",
      "Batch: 114, Loss: 1.0056661367416382, Accuracy: 0.6923828125\n",
      "Batch: 115, Loss: 1.0075722932815552, Accuracy: 0.69921875\n",
      "Batch: 116, Loss: 0.9226264357566833, Accuracy: 0.70703125\n",
      "Batch: 117, Loss: 0.9629510641098022, Accuracy: 0.701171875\n",
      "Batch: 118, Loss: 0.8010835647583008, Accuracy: 0.7451171875\n",
      "Batch: 119, Loss: 0.7974477410316467, Accuracy: 0.7568359375\n",
      "Batch: 120, Loss: 0.9297793507575989, Accuracy: 0.69921875\n",
      "Batch: 121, Loss: 0.9882076978683472, Accuracy: 0.6845703125\n",
      "Batch: 122, Loss: 0.9004731178283691, Accuracy: 0.7265625\n",
      "Batch: 123, Loss: 0.8846643567085266, Accuracy: 0.7177734375\n",
      "Batch: 124, Loss: 0.9312753677368164, Accuracy: 0.6875\n",
      "Batch: 125, Loss: 0.9610855579376221, Accuracy: 0.68359375\n",
      "Batch: 126, Loss: 0.9181281924247742, Accuracy: 0.6884765625\n",
      "Batch: 127, Loss: 0.8326370716094971, Accuracy: 0.748046875\n",
      "Batch: 128, Loss: 1.023563265800476, Accuracy: 0.689453125\n",
      "Batch: 129, Loss: 0.8665499091148376, Accuracy: 0.73046875\n",
      "Batch: 130, Loss: 1.0811233520507812, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 0.9939205646514893, Accuracy: 0.671875\n",
      "Batch: 132, Loss: 0.9692919850349426, Accuracy: 0.6875\n",
      "Batch: 133, Loss: 0.8933139443397522, Accuracy: 0.7109375\n",
      "Batch: 134, Loss: 0.9170933961868286, Accuracy: 0.689453125\n",
      "Batch: 135, Loss: 0.8374007344245911, Accuracy: 0.7412109375\n",
      "Batch: 136, Loss: 0.9529796838760376, Accuracy: 0.7080078125\n",
      "Batch: 137, Loss: 0.8769293427467346, Accuracy: 0.7060546875\n",
      "Batch: 138, Loss: 0.7912955284118652, Accuracy: 0.7412109375\n",
      "Batch: 139, Loss: 0.8675476312637329, Accuracy: 0.716796875\n",
      "Batch: 140, Loss: 0.8887494802474976, Accuracy: 0.7021484375\n",
      "Batch: 141, Loss: 0.9626210927963257, Accuracy: 0.6845703125\n",
      "Batch: 142, Loss: 0.9321261644363403, Accuracy: 0.6953125\n",
      "Batch: 143, Loss: 0.9466484189033508, Accuracy: 0.6982421875\n",
      "Batch: 144, Loss: 0.9397170543670654, Accuracy: 0.6982421875\n",
      "Batch: 145, Loss: 0.858719527721405, Accuracy: 0.7001953125\n",
      "Batch: 146, Loss: 0.94720858335495, Accuracy: 0.6943359375\n",
      "Batch: 147, Loss: 0.9436780214309692, Accuracy: 0.6953125\n",
      "Batch: 148, Loss: 1.0442266464233398, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9166274070739746, Accuracy: 0.7109375\n",
      "Batch: 150, Loss: 0.880120038986206, Accuracy: 0.7080078125\n",
      "Batch: 151, Loss: 0.8174805045127869, Accuracy: 0.7392578125\n",
      "Epoch 24/80\n",
      "Batch: 1, Loss: 1.1491174697875977, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 0.9811814427375793, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3, Loss: 0.8865512609481812, Accuracy: 0.703125\n",
      "Batch: 4, Loss: 0.8366696834564209, Accuracy: 0.734375\n",
      "Batch: 5, Loss: 0.8471982479095459, Accuracy: 0.7197265625\n",
      "Batch: 6, Loss: 0.9363679885864258, Accuracy: 0.69140625\n",
      "Batch: 7, Loss: 0.9057281017303467, Accuracy: 0.6943359375\n",
      "Batch: 8, Loss: 0.8349989652633667, Accuracy: 0.7373046875\n",
      "Batch: 9, Loss: 0.8549379706382751, Accuracy: 0.740234375\n",
      "Batch: 10, Loss: 0.8416939973831177, Accuracy: 0.73046875\n",
      "Batch: 11, Loss: 0.9662214517593384, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.93555748462677, Accuracy: 0.70703125\n",
      "Batch: 13, Loss: 0.7769377827644348, Accuracy: 0.7392578125\n",
      "Batch: 14, Loss: 1.0254706144332886, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.8684449791908264, Accuracy: 0.7373046875\n",
      "Batch: 16, Loss: 0.8736447691917419, Accuracy: 0.7236328125\n",
      "Batch: 17, Loss: 0.9186141490936279, Accuracy: 0.7099609375\n",
      "Batch: 18, Loss: 0.9201381206512451, Accuracy: 0.7060546875\n",
      "Batch: 19, Loss: 0.950283408164978, Accuracy: 0.6962890625\n",
      "Batch: 20, Loss: 0.8152823448181152, Accuracy: 0.732421875\n",
      "Batch: 21, Loss: 0.8744313716888428, Accuracy: 0.712890625\n",
      "Batch: 22, Loss: 0.9855634570121765, Accuracy: 0.6923828125\n",
      "Batch: 23, Loss: 0.9465196132659912, Accuracy: 0.701171875\n",
      "Batch: 24, Loss: 0.9240254163742065, Accuracy: 0.708984375\n",
      "Batch: 25, Loss: 0.8906326293945312, Accuracy: 0.712890625\n",
      "Batch: 26, Loss: 0.8035187125205994, Accuracy: 0.734375\n",
      "Batch: 27, Loss: 0.8485994338989258, Accuracy: 0.7060546875\n",
      "Batch: 28, Loss: 0.9342590570449829, Accuracy: 0.7001953125\n",
      "Batch: 29, Loss: 0.9182153344154358, Accuracy: 0.705078125\n",
      "Batch: 30, Loss: 0.848369300365448, Accuracy: 0.744140625\n",
      "Batch: 31, Loss: 0.8429148197174072, Accuracy: 0.73046875\n",
      "Batch: 32, Loss: 0.8318612575531006, Accuracy: 0.734375\n",
      "Batch: 33, Loss: 1.015686273574829, Accuracy: 0.6904296875\n",
      "Batch: 34, Loss: 1.0612032413482666, Accuracy: 0.6650390625\n",
      "Batch: 35, Loss: 0.9198477268218994, Accuracy: 0.703125\n",
      "Batch: 36, Loss: 0.9822529554367065, Accuracy: 0.7021484375\n",
      "Batch: 37, Loss: 0.8852137327194214, Accuracy: 0.7109375\n",
      "Batch: 38, Loss: 0.922568678855896, Accuracy: 0.7001953125\n",
      "Batch: 39, Loss: 0.9262614250183105, Accuracy: 0.708984375\n",
      "Batch: 40, Loss: 0.9057458639144897, Accuracy: 0.7197265625\n",
      "Batch: 41, Loss: 0.8803679943084717, Accuracy: 0.71484375\n",
      "Batch: 42, Loss: 0.7143646478652954, Accuracy: 0.7626953125\n",
      "Batch: 43, Loss: 0.8884419202804565, Accuracy: 0.697265625\n",
      "Batch: 44, Loss: 0.914616048336029, Accuracy: 0.701171875\n",
      "Batch: 45, Loss: 0.7922747731208801, Accuracy: 0.7431640625\n",
      "Batch: 46, Loss: 0.8277573585510254, Accuracy: 0.734375\n",
      "Batch: 47, Loss: 0.8425300121307373, Accuracy: 0.7353515625\n",
      "Batch: 48, Loss: 0.8079397678375244, Accuracy: 0.7353515625\n",
      "Batch: 49, Loss: 0.9376860857009888, Accuracy: 0.697265625\n",
      "Batch: 50, Loss: 0.9320579767227173, Accuracy: 0.693359375\n",
      "Batch: 51, Loss: 1.0294747352600098, Accuracy: 0.6884765625\n",
      "Batch: 52, Loss: 0.9457529783248901, Accuracy: 0.7138671875\n",
      "Batch: 53, Loss: 0.8216394782066345, Accuracy: 0.732421875\n",
      "Batch: 54, Loss: 0.9099840521812439, Accuracy: 0.7080078125\n",
      "Batch: 55, Loss: 0.9737821817398071, Accuracy: 0.6787109375\n",
      "Batch: 56, Loss: 0.9475302696228027, Accuracy: 0.693359375\n",
      "Batch: 57, Loss: 0.8901307582855225, Accuracy: 0.7216796875\n",
      "Batch: 58, Loss: 0.9914029836654663, Accuracy: 0.689453125\n",
      "Batch: 59, Loss: 0.843408465385437, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.8201467394828796, Accuracy: 0.7255859375\n",
      "Batch: 61, Loss: 0.9582027792930603, Accuracy: 0.681640625\n",
      "Batch: 62, Loss: 0.8358442783355713, Accuracy: 0.7421875\n",
      "Batch: 63, Loss: 0.8959230780601501, Accuracy: 0.7275390625\n",
      "Batch: 64, Loss: 0.9021416902542114, Accuracy: 0.7119140625\n",
      "Batch: 65, Loss: 0.8957138061523438, Accuracy: 0.732421875\n",
      "Batch: 66, Loss: 0.8670457005500793, Accuracy: 0.728515625\n",
      "Batch: 67, Loss: 0.9370357990264893, Accuracy: 0.7080078125\n",
      "Batch: 68, Loss: 0.9816089272499084, Accuracy: 0.697265625\n",
      "Batch: 69, Loss: 0.9258509278297424, Accuracy: 0.6943359375\n",
      "Batch: 70, Loss: 0.8973664045333862, Accuracy: 0.716796875\n",
      "Batch: 71, Loss: 0.9227946996688843, Accuracy: 0.701171875\n",
      "Batch: 72, Loss: 0.7930289506912231, Accuracy: 0.744140625\n",
      "Batch: 73, Loss: 0.8316777944564819, Accuracy: 0.74609375\n",
      "Batch: 74, Loss: 0.813581109046936, Accuracy: 0.75\n",
      "Batch: 75, Loss: 0.7794934511184692, Accuracy: 0.744140625\n",
      "Batch: 76, Loss: 0.8805733323097229, Accuracy: 0.7158203125\n",
      "Batch: 77, Loss: 0.8375187516212463, Accuracy: 0.724609375\n",
      "Batch: 78, Loss: 0.857860803604126, Accuracy: 0.7216796875\n",
      "Batch: 79, Loss: 0.8020849823951721, Accuracy: 0.7548828125\n",
      "Batch: 80, Loss: 0.8477799296379089, Accuracy: 0.7109375\n",
      "Batch: 81, Loss: 0.9473623037338257, Accuracy: 0.677734375\n",
      "Batch: 82, Loss: 0.9081412553787231, Accuracy: 0.697265625\n",
      "Batch: 83, Loss: 0.7854832410812378, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.9221063852310181, Accuracy: 0.70703125\n",
      "Batch: 85, Loss: 0.8260992169380188, Accuracy: 0.736328125\n",
      "Batch: 86, Loss: 1.0413928031921387, Accuracy: 0.6796875\n",
      "Batch: 87, Loss: 0.8117359280586243, Accuracy: 0.7412109375\n",
      "Batch: 88, Loss: 0.9687013030052185, Accuracy: 0.7080078125\n",
      "Batch: 89, Loss: 0.9196575284004211, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.8656824827194214, Accuracy: 0.7177734375\n",
      "Batch: 91, Loss: 0.9010725617408752, Accuracy: 0.705078125\n",
      "Batch: 92, Loss: 0.9083393812179565, Accuracy: 0.7177734375\n",
      "Batch: 93, Loss: 0.8598202466964722, Accuracy: 0.7216796875\n",
      "Batch: 94, Loss: 0.8687078952789307, Accuracy: 0.708984375\n",
      "Batch: 95, Loss: 0.9304293394088745, Accuracy: 0.6796875\n",
      "Batch: 96, Loss: 0.8832898736000061, Accuracy: 0.7021484375\n",
      "Batch: 97, Loss: 0.7743755578994751, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.828761100769043, Accuracy: 0.7197265625\n",
      "Batch: 99, Loss: 0.825324535369873, Accuracy: 0.73046875\n",
      "Batch: 100, Loss: 0.8875072598457336, Accuracy: 0.7080078125\n",
      "Batch: 101, Loss: 0.9490785598754883, Accuracy: 0.697265625\n",
      "Batch: 102, Loss: 0.8820834159851074, Accuracy: 0.7158203125\n",
      "Batch: 103, Loss: 0.9333232641220093, Accuracy: 0.7060546875\n",
      "Batch: 104, Loss: 0.8183114528656006, Accuracy: 0.732421875\n",
      "Batch: 105, Loss: 0.9149495363235474, Accuracy: 0.701171875\n",
      "Batch: 106, Loss: 0.8651154637336731, Accuracy: 0.7255859375\n",
      "Batch: 107, Loss: 0.88013756275177, Accuracy: 0.72265625\n",
      "Batch: 108, Loss: 0.8966573476791382, Accuracy: 0.6982421875\n",
      "Batch: 109, Loss: 1.0173240900039673, Accuracy: 0.6767578125\n",
      "Batch: 110, Loss: 0.7976465225219727, Accuracy: 0.7373046875\n",
      "Batch: 111, Loss: 0.9598674774169922, Accuracy: 0.689453125\n",
      "Batch: 112, Loss: 0.9221559762954712, Accuracy: 0.7060546875\n",
      "Batch: 113, Loss: 0.9126278162002563, Accuracy: 0.7060546875\n",
      "Batch: 114, Loss: 0.9920077919960022, Accuracy: 0.6826171875\n",
      "Batch: 115, Loss: 1.0193235874176025, Accuracy: 0.68359375\n",
      "Batch: 116, Loss: 0.9306051731109619, Accuracy: 0.703125\n",
      "Batch: 117, Loss: 0.9313533306121826, Accuracy: 0.69921875\n",
      "Batch: 118, Loss: 0.8276274800300598, Accuracy: 0.734375\n",
      "Batch: 119, Loss: 0.814926266670227, Accuracy: 0.748046875\n",
      "Batch: 120, Loss: 0.9071105122566223, Accuracy: 0.701171875\n",
      "Batch: 121, Loss: 0.9526960849761963, Accuracy: 0.69140625\n",
      "Batch: 122, Loss: 0.8735274076461792, Accuracy: 0.7236328125\n",
      "Batch: 123, Loss: 0.8643811941146851, Accuracy: 0.7265625\n",
      "Batch: 124, Loss: 0.9244560599327087, Accuracy: 0.712890625\n",
      "Batch: 125, Loss: 0.9506632089614868, Accuracy: 0.6962890625\n",
      "Batch: 126, Loss: 0.9122024178504944, Accuracy: 0.720703125\n",
      "Batch: 127, Loss: 0.8087966442108154, Accuracy: 0.748046875\n",
      "Batch: 128, Loss: 0.9971803426742554, Accuracy: 0.69921875\n",
      "Batch: 129, Loss: 0.8536291122436523, Accuracy: 0.7275390625\n",
      "Batch: 130, Loss: 1.0644282102584839, Accuracy: 0.662109375\n",
      "Batch: 131, Loss: 0.9821797609329224, Accuracy: 0.6748046875\n",
      "Batch: 132, Loss: 0.9687619209289551, Accuracy: 0.6865234375\n",
      "Batch: 133, Loss: 0.8572917580604553, Accuracy: 0.7138671875\n",
      "Batch: 134, Loss: 0.9127259254455566, Accuracy: 0.697265625\n",
      "Batch: 135, Loss: 0.8453993797302246, Accuracy: 0.7353515625\n",
      "Batch: 136, Loss: 0.913389265537262, Accuracy: 0.7001953125\n",
      "Batch: 137, Loss: 0.8677898645401001, Accuracy: 0.7119140625\n",
      "Batch: 138, Loss: 0.7368751168251038, Accuracy: 0.7607421875\n",
      "Batch: 139, Loss: 0.8738231658935547, Accuracy: 0.716796875\n",
      "Batch: 140, Loss: 0.9079569578170776, Accuracy: 0.708984375\n",
      "Batch: 141, Loss: 0.925767183303833, Accuracy: 0.701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 142, Loss: 0.9070845246315002, Accuracy: 0.7138671875\n",
      "Batch: 143, Loss: 0.8965889811515808, Accuracy: 0.712890625\n",
      "Batch: 144, Loss: 0.9312440156936646, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.8662313222885132, Accuracy: 0.701171875\n",
      "Batch: 146, Loss: 0.9028274416923523, Accuracy: 0.7099609375\n",
      "Batch: 147, Loss: 0.9258735775947571, Accuracy: 0.6943359375\n",
      "Batch: 148, Loss: 1.0194270610809326, Accuracy: 0.6806640625\n",
      "Batch: 149, Loss: 0.9145406484603882, Accuracy: 0.697265625\n",
      "Batch: 150, Loss: 0.8763629198074341, Accuracy: 0.7236328125\n",
      "Batch: 151, Loss: 0.786452054977417, Accuracy: 0.7451171875\n",
      "Epoch 25/80\n",
      "Batch: 1, Loss: 1.1422977447509766, Accuracy: 0.630859375\n",
      "Batch: 2, Loss: 0.9819498658180237, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 0.8660891056060791, Accuracy: 0.703125\n",
      "Batch: 4, Loss: 0.8185232281684875, Accuracy: 0.73828125\n",
      "Batch: 5, Loss: 0.8487067222595215, Accuracy: 0.720703125\n",
      "Batch: 6, Loss: 0.9134559035301208, Accuracy: 0.701171875\n",
      "Batch: 7, Loss: 0.8853771090507507, Accuracy: 0.705078125\n",
      "Batch: 8, Loss: 0.8525388240814209, Accuracy: 0.720703125\n",
      "Batch: 9, Loss: 0.832694411277771, Accuracy: 0.740234375\n",
      "Batch: 10, Loss: 0.8013260364532471, Accuracy: 0.740234375\n",
      "Batch: 11, Loss: 0.9311966896057129, Accuracy: 0.708984375\n",
      "Batch: 12, Loss: 0.9389024972915649, Accuracy: 0.6962890625\n",
      "Batch: 13, Loss: 0.7494799494743347, Accuracy: 0.7529296875\n",
      "Batch: 14, Loss: 0.9848023653030396, Accuracy: 0.6845703125\n",
      "Batch: 15, Loss: 0.862108051776886, Accuracy: 0.7490234375\n",
      "Batch: 16, Loss: 0.9191127419471741, Accuracy: 0.7373046875\n",
      "Batch: 17, Loss: 0.99006587266922, Accuracy: 0.697265625\n",
      "Batch: 18, Loss: 0.9740415811538696, Accuracy: 0.6904296875\n",
      "Batch: 19, Loss: 0.9559624195098877, Accuracy: 0.6982421875\n",
      "Batch: 20, Loss: 0.8677354454994202, Accuracy: 0.7177734375\n",
      "Batch: 21, Loss: 0.869498074054718, Accuracy: 0.716796875\n",
      "Batch: 22, Loss: 0.991387128829956, Accuracy: 0.71875\n",
      "Batch: 23, Loss: 1.0022584199905396, Accuracy: 0.693359375\n",
      "Batch: 24, Loss: 1.012746810913086, Accuracy: 0.689453125\n",
      "Batch: 25, Loss: 0.9617743492126465, Accuracy: 0.6923828125\n",
      "Batch: 26, Loss: 0.8265135288238525, Accuracy: 0.732421875\n",
      "Batch: 27, Loss: 0.822553277015686, Accuracy: 0.716796875\n",
      "Batch: 28, Loss: 0.9320530891418457, Accuracy: 0.6943359375\n",
      "Batch: 29, Loss: 0.8994404077529907, Accuracy: 0.703125\n",
      "Batch: 30, Loss: 0.8149236440658569, Accuracy: 0.75\n",
      "Batch: 31, Loss: 0.836294412612915, Accuracy: 0.7216796875\n",
      "Batch: 32, Loss: 0.8327257633209229, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 0.9873361587524414, Accuracy: 0.69921875\n",
      "Batch: 34, Loss: 1.0427947044372559, Accuracy: 0.6728515625\n",
      "Batch: 35, Loss: 0.9369004368782043, Accuracy: 0.6904296875\n",
      "Batch: 36, Loss: 0.9622343182563782, Accuracy: 0.712890625\n",
      "Batch: 37, Loss: 0.9132470488548279, Accuracy: 0.703125\n",
      "Batch: 38, Loss: 0.9340994954109192, Accuracy: 0.6962890625\n",
      "Batch: 39, Loss: 0.9336367845535278, Accuracy: 0.7109375\n",
      "Batch: 40, Loss: 0.9094194769859314, Accuracy: 0.6953125\n",
      "Batch: 41, Loss: 0.8693345785140991, Accuracy: 0.724609375\n",
      "Batch: 42, Loss: 0.71053147315979, Accuracy: 0.7646484375\n",
      "Batch: 43, Loss: 0.8702394962310791, Accuracy: 0.70703125\n",
      "Batch: 44, Loss: 0.9012058973312378, Accuracy: 0.7099609375\n",
      "Batch: 45, Loss: 0.7884032726287842, Accuracy: 0.7490234375\n",
      "Batch: 46, Loss: 0.8368227481842041, Accuracy: 0.7421875\n",
      "Batch: 47, Loss: 0.859836995601654, Accuracy: 0.73046875\n",
      "Batch: 48, Loss: 0.7919015884399414, Accuracy: 0.7392578125\n",
      "Batch: 49, Loss: 1.0036287307739258, Accuracy: 0.6708984375\n",
      "Batch: 50, Loss: 0.9253004789352417, Accuracy: 0.703125\n",
      "Batch: 51, Loss: 1.0013694763183594, Accuracy: 0.685546875\n",
      "Batch: 52, Loss: 0.9225271940231323, Accuracy: 0.712890625\n",
      "Batch: 53, Loss: 0.8258419632911682, Accuracy: 0.72265625\n",
      "Batch: 54, Loss: 0.8765404224395752, Accuracy: 0.7109375\n",
      "Batch: 55, Loss: 0.9717811942100525, Accuracy: 0.669921875\n",
      "Batch: 56, Loss: 0.9586829543113708, Accuracy: 0.689453125\n",
      "Batch: 57, Loss: 0.9032285213470459, Accuracy: 0.712890625\n",
      "Batch: 58, Loss: 0.9508175849914551, Accuracy: 0.7177734375\n",
      "Batch: 59, Loss: 0.8274902701377869, Accuracy: 0.740234375\n",
      "Batch: 60, Loss: 0.8136286735534668, Accuracy: 0.7236328125\n",
      "Batch: 61, Loss: 0.9209234714508057, Accuracy: 0.693359375\n",
      "Batch: 62, Loss: 0.8197320699691772, Accuracy: 0.736328125\n",
      "Batch: 63, Loss: 0.8727549910545349, Accuracy: 0.724609375\n",
      "Batch: 64, Loss: 0.883333683013916, Accuracy: 0.7080078125\n",
      "Batch: 65, Loss: 0.8857387900352478, Accuracy: 0.7119140625\n",
      "Batch: 66, Loss: 0.8532779216766357, Accuracy: 0.728515625\n",
      "Batch: 67, Loss: 0.9292528629302979, Accuracy: 0.712890625\n",
      "Batch: 68, Loss: 0.9605684280395508, Accuracy: 0.693359375\n",
      "Batch: 69, Loss: 0.9190055131912231, Accuracy: 0.697265625\n",
      "Batch: 70, Loss: 0.8901349306106567, Accuracy: 0.7158203125\n",
      "Batch: 71, Loss: 0.8940907716751099, Accuracy: 0.7041015625\n",
      "Batch: 72, Loss: 0.792530357837677, Accuracy: 0.7373046875\n",
      "Batch: 73, Loss: 0.8426113724708557, Accuracy: 0.73046875\n",
      "Batch: 74, Loss: 0.7940971851348877, Accuracy: 0.755859375\n",
      "Batch: 75, Loss: 0.7827726602554321, Accuracy: 0.7421875\n",
      "Batch: 76, Loss: 0.8733514547348022, Accuracy: 0.7099609375\n",
      "Batch: 77, Loss: 0.8436310291290283, Accuracy: 0.7314453125\n",
      "Batch: 78, Loss: 0.8365464210510254, Accuracy: 0.7265625\n",
      "Batch: 79, Loss: 0.7984144687652588, Accuracy: 0.7587890625\n",
      "Batch: 80, Loss: 0.8248310089111328, Accuracy: 0.7373046875\n",
      "Batch: 81, Loss: 0.9396806955337524, Accuracy: 0.6826171875\n",
      "Batch: 82, Loss: 0.8892132043838501, Accuracy: 0.712890625\n",
      "Batch: 83, Loss: 0.7700416445732117, Accuracy: 0.7646484375\n",
      "Batch: 84, Loss: 0.8744634985923767, Accuracy: 0.7177734375\n",
      "Batch: 85, Loss: 0.8244726657867432, Accuracy: 0.7373046875\n",
      "Batch: 86, Loss: 1.0435206890106201, Accuracy: 0.6806640625\n",
      "Batch: 87, Loss: 0.8252930641174316, Accuracy: 0.7431640625\n",
      "Batch: 88, Loss: 0.9344488382339478, Accuracy: 0.7099609375\n",
      "Batch: 89, Loss: 0.8891624212265015, Accuracy: 0.7353515625\n",
      "Batch: 90, Loss: 0.831162691116333, Accuracy: 0.740234375\n",
      "Batch: 91, Loss: 0.8825840353965759, Accuracy: 0.7109375\n",
      "Batch: 92, Loss: 0.8894469738006592, Accuracy: 0.716796875\n",
      "Batch: 93, Loss: 0.8252548575401306, Accuracy: 0.728515625\n",
      "Batch: 94, Loss: 0.8489277362823486, Accuracy: 0.7236328125\n",
      "Batch: 95, Loss: 0.905953049659729, Accuracy: 0.6953125\n",
      "Batch: 96, Loss: 0.8754111528396606, Accuracy: 0.7255859375\n",
      "Batch: 97, Loss: 0.7585722208023071, Accuracy: 0.74609375\n",
      "Batch: 98, Loss: 0.8016523122787476, Accuracy: 0.751953125\n",
      "Batch: 99, Loss: 0.7881959080696106, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.8894429802894592, Accuracy: 0.7109375\n",
      "Batch: 101, Loss: 0.9204562902450562, Accuracy: 0.7041015625\n",
      "Batch: 102, Loss: 0.8830322623252869, Accuracy: 0.708984375\n",
      "Batch: 103, Loss: 0.9043776988983154, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.8099489808082581, Accuracy: 0.7333984375\n",
      "Batch: 105, Loss: 0.9090477824211121, Accuracy: 0.708984375\n",
      "Batch: 106, Loss: 0.8370583653450012, Accuracy: 0.7392578125\n",
      "Batch: 107, Loss: 0.8719965815544128, Accuracy: 0.712890625\n",
      "Batch: 108, Loss: 0.8596218824386597, Accuracy: 0.708984375\n",
      "Batch: 109, Loss: 1.003365397453308, Accuracy: 0.6767578125\n",
      "Batch: 110, Loss: 0.7944735288619995, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.9344965219497681, Accuracy: 0.6845703125\n",
      "Batch: 112, Loss: 0.8875411748886108, Accuracy: 0.7236328125\n",
      "Batch: 113, Loss: 0.9199262857437134, Accuracy: 0.716796875\n",
      "Batch: 114, Loss: 0.999972403049469, Accuracy: 0.68359375\n",
      "Batch: 115, Loss: 0.9867246747016907, Accuracy: 0.693359375\n",
      "Batch: 116, Loss: 0.9293837547302246, Accuracy: 0.703125\n",
      "Batch: 117, Loss: 0.937595546245575, Accuracy: 0.7119140625\n",
      "Batch: 118, Loss: 0.7920303344726562, Accuracy: 0.7578125\n",
      "Batch: 119, Loss: 0.8007720708847046, Accuracy: 0.7578125\n",
      "Batch: 120, Loss: 0.9033941030502319, Accuracy: 0.7099609375\n",
      "Batch: 121, Loss: 0.9806363582611084, Accuracy: 0.6806640625\n",
      "Batch: 122, Loss: 0.8697263598442078, Accuracy: 0.7294921875\n",
      "Batch: 123, Loss: 0.8547093868255615, Accuracy: 0.7255859375\n",
      "Batch: 124, Loss: 0.9177097678184509, Accuracy: 0.6982421875\n",
      "Batch: 125, Loss: 0.9237948656082153, Accuracy: 0.703125\n",
      "Batch: 126, Loss: 0.8979712128639221, Accuracy: 0.69921875\n",
      "Batch: 127, Loss: 0.8000894784927368, Accuracy: 0.763671875\n",
      "Batch: 128, Loss: 1.0334845781326294, Accuracy: 0.693359375\n",
      "Batch: 129, Loss: 0.867639422416687, Accuracy: 0.7412109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 1.0691728591918945, Accuracy: 0.66015625\n",
      "Batch: 131, Loss: 0.9337061643600464, Accuracy: 0.69140625\n",
      "Batch: 132, Loss: 0.9421664476394653, Accuracy: 0.6953125\n",
      "Batch: 133, Loss: 0.8588075637817383, Accuracy: 0.7265625\n",
      "Batch: 134, Loss: 0.9210567474365234, Accuracy: 0.703125\n",
      "Batch: 135, Loss: 0.8355282545089722, Accuracy: 0.73046875\n",
      "Batch: 136, Loss: 0.918610692024231, Accuracy: 0.7119140625\n",
      "Batch: 137, Loss: 0.8770760297775269, Accuracy: 0.7001953125\n",
      "Batch: 138, Loss: 0.7687616348266602, Accuracy: 0.74609375\n",
      "Batch: 139, Loss: 0.8554452657699585, Accuracy: 0.7158203125\n",
      "Batch: 140, Loss: 0.8789328336715698, Accuracy: 0.6982421875\n",
      "Batch: 141, Loss: 0.9457782506942749, Accuracy: 0.6943359375\n",
      "Batch: 142, Loss: 0.9179186820983887, Accuracy: 0.6943359375\n",
      "Batch: 143, Loss: 0.9205985069274902, Accuracy: 0.69921875\n",
      "Batch: 144, Loss: 0.914089024066925, Accuracy: 0.705078125\n",
      "Batch: 145, Loss: 0.8353015780448914, Accuracy: 0.708984375\n",
      "Batch: 146, Loss: 0.9356195330619812, Accuracy: 0.6943359375\n",
      "Batch: 147, Loss: 0.9014491438865662, Accuracy: 0.703125\n",
      "Batch: 148, Loss: 1.0441367626190186, Accuracy: 0.6650390625\n",
      "Batch: 149, Loss: 0.8858643770217896, Accuracy: 0.7197265625\n",
      "Batch: 150, Loss: 0.874869704246521, Accuracy: 0.703125\n",
      "Batch: 151, Loss: 0.7856051921844482, Accuracy: 0.7470703125\n",
      "Epoch 26/80\n",
      "Batch: 1, Loss: 1.1230731010437012, Accuracy: 0.6416015625\n",
      "Batch: 2, Loss: 0.9504966139793396, Accuracy: 0.6728515625\n",
      "Batch: 3, Loss: 0.8548122644424438, Accuracy: 0.7158203125\n",
      "Batch: 4, Loss: 0.8270329236984253, Accuracy: 0.755859375\n",
      "Batch: 5, Loss: 0.8385454416275024, Accuracy: 0.7275390625\n",
      "Batch: 6, Loss: 0.9076443910598755, Accuracy: 0.708984375\n",
      "Batch: 7, Loss: 0.8686655163764954, Accuracy: 0.7119140625\n",
      "Batch: 8, Loss: 0.806527316570282, Accuracy: 0.728515625\n",
      "Batch: 9, Loss: 0.8224936723709106, Accuracy: 0.7451171875\n",
      "Batch: 10, Loss: 0.8070246577262878, Accuracy: 0.7373046875\n",
      "Batch: 11, Loss: 0.9542278051376343, Accuracy: 0.68359375\n",
      "Batch: 12, Loss: 0.9314188957214355, Accuracy: 0.701171875\n",
      "Batch: 13, Loss: 0.718925952911377, Accuracy: 0.7646484375\n",
      "Batch: 14, Loss: 0.9555711150169373, Accuracy: 0.6875\n",
      "Batch: 15, Loss: 0.8078486323356628, Accuracy: 0.7431640625\n",
      "Batch: 16, Loss: 0.8503313660621643, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.9083577394485474, Accuracy: 0.7080078125\n",
      "Batch: 18, Loss: 0.915203869342804, Accuracy: 0.7177734375\n",
      "Batch: 19, Loss: 0.936985433101654, Accuracy: 0.720703125\n",
      "Batch: 20, Loss: 0.8406505584716797, Accuracy: 0.7333984375\n",
      "Batch: 21, Loss: 0.8651771545410156, Accuracy: 0.7109375\n",
      "Batch: 22, Loss: 0.9679059982299805, Accuracy: 0.6865234375\n",
      "Batch: 23, Loss: 0.8882609009742737, Accuracy: 0.7099609375\n",
      "Batch: 24, Loss: 0.9008267521858215, Accuracy: 0.712890625\n",
      "Batch: 25, Loss: 0.8850444555282593, Accuracy: 0.7314453125\n",
      "Batch: 26, Loss: 0.7836228609085083, Accuracy: 0.7470703125\n",
      "Batch: 27, Loss: 0.8316389918327332, Accuracy: 0.705078125\n",
      "Batch: 28, Loss: 0.9099595546722412, Accuracy: 0.6953125\n",
      "Batch: 29, Loss: 0.8438788652420044, Accuracy: 0.740234375\n",
      "Batch: 30, Loss: 0.8274984359741211, Accuracy: 0.744140625\n",
      "Batch: 31, Loss: 0.8085647821426392, Accuracy: 0.7470703125\n",
      "Batch: 32, Loss: 0.8111396431922913, Accuracy: 0.740234375\n",
      "Batch: 33, Loss: 0.9672286510467529, Accuracy: 0.7021484375\n",
      "Batch: 34, Loss: 1.010892391204834, Accuracy: 0.6796875\n",
      "Batch: 35, Loss: 0.9067546129226685, Accuracy: 0.71484375\n",
      "Batch: 36, Loss: 0.933367908000946, Accuracy: 0.7119140625\n",
      "Batch: 37, Loss: 0.8765348196029663, Accuracy: 0.7041015625\n",
      "Batch: 38, Loss: 0.9036722183227539, Accuracy: 0.7060546875\n",
      "Batch: 39, Loss: 0.9126871228218079, Accuracy: 0.69921875\n",
      "Batch: 40, Loss: 0.8928588032722473, Accuracy: 0.712890625\n",
      "Batch: 41, Loss: 0.8731177449226379, Accuracy: 0.716796875\n",
      "Batch: 42, Loss: 0.7089368104934692, Accuracy: 0.759765625\n",
      "Batch: 43, Loss: 0.8707924485206604, Accuracy: 0.7138671875\n",
      "Batch: 44, Loss: 0.906777024269104, Accuracy: 0.697265625\n",
      "Batch: 45, Loss: 0.7864218354225159, Accuracy: 0.744140625\n",
      "Batch: 46, Loss: 0.8131272196769714, Accuracy: 0.73046875\n",
      "Batch: 47, Loss: 0.8796407580375671, Accuracy: 0.744140625\n",
      "Batch: 48, Loss: 0.8045538663864136, Accuracy: 0.7373046875\n",
      "Batch: 49, Loss: 0.966302752494812, Accuracy: 0.677734375\n",
      "Batch: 50, Loss: 0.8976055383682251, Accuracy: 0.703125\n",
      "Batch: 51, Loss: 0.9912772178649902, Accuracy: 0.6884765625\n",
      "Batch: 52, Loss: 0.9131673574447632, Accuracy: 0.7158203125\n",
      "Batch: 53, Loss: 0.8056018352508545, Accuracy: 0.7314453125\n",
      "Batch: 54, Loss: 0.8964483737945557, Accuracy: 0.6982421875\n",
      "Batch: 55, Loss: 0.9693641066551208, Accuracy: 0.68359375\n",
      "Batch: 56, Loss: 0.915723443031311, Accuracy: 0.7080078125\n",
      "Batch: 57, Loss: 0.8918835520744324, Accuracy: 0.716796875\n",
      "Batch: 58, Loss: 0.9541016817092896, Accuracy: 0.7021484375\n",
      "Batch: 59, Loss: 0.8408414721488953, Accuracy: 0.7333984375\n",
      "Batch: 60, Loss: 0.7990853190422058, Accuracy: 0.744140625\n",
      "Batch: 61, Loss: 0.920150101184845, Accuracy: 0.689453125\n",
      "Batch: 62, Loss: 0.808506965637207, Accuracy: 0.74609375\n",
      "Batch: 63, Loss: 0.8927666544914246, Accuracy: 0.708984375\n",
      "Batch: 64, Loss: 0.8372193574905396, Accuracy: 0.732421875\n",
      "Batch: 65, Loss: 0.8732107281684875, Accuracy: 0.724609375\n",
      "Batch: 66, Loss: 0.8369073271751404, Accuracy: 0.732421875\n",
      "Batch: 67, Loss: 0.9137122631072998, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.9473361968994141, Accuracy: 0.7080078125\n",
      "Batch: 69, Loss: 0.8980739116668701, Accuracy: 0.7001953125\n",
      "Batch: 70, Loss: 0.8613544702529907, Accuracy: 0.7265625\n",
      "Batch: 71, Loss: 0.9048807621002197, Accuracy: 0.7060546875\n",
      "Batch: 72, Loss: 0.7719141840934753, Accuracy: 0.7412109375\n",
      "Batch: 73, Loss: 0.8047235012054443, Accuracy: 0.7470703125\n",
      "Batch: 74, Loss: 0.796090841293335, Accuracy: 0.7568359375\n",
      "Batch: 75, Loss: 0.7618436217308044, Accuracy: 0.7587890625\n",
      "Batch: 76, Loss: 0.8722436428070068, Accuracy: 0.7138671875\n",
      "Batch: 77, Loss: 0.8229241967201233, Accuracy: 0.7294921875\n",
      "Batch: 78, Loss: 0.8292415142059326, Accuracy: 0.7412109375\n",
      "Batch: 79, Loss: 0.7765882015228271, Accuracy: 0.755859375\n",
      "Batch: 80, Loss: 0.832609236240387, Accuracy: 0.728515625\n",
      "Batch: 81, Loss: 0.9350135326385498, Accuracy: 0.6826171875\n",
      "Batch: 82, Loss: 0.89380943775177, Accuracy: 0.7099609375\n",
      "Batch: 83, Loss: 0.773442804813385, Accuracy: 0.759765625\n",
      "Batch: 84, Loss: 0.8488945960998535, Accuracy: 0.7236328125\n",
      "Batch: 85, Loss: 0.7966907620429993, Accuracy: 0.744140625\n",
      "Batch: 86, Loss: 1.0102038383483887, Accuracy: 0.6865234375\n",
      "Batch: 87, Loss: 0.8055498600006104, Accuracy: 0.755859375\n",
      "Batch: 88, Loss: 0.924631655216217, Accuracy: 0.73046875\n",
      "Batch: 89, Loss: 0.8836092948913574, Accuracy: 0.7265625\n",
      "Batch: 90, Loss: 0.8334230184555054, Accuracy: 0.734375\n",
      "Batch: 91, Loss: 0.8663066625595093, Accuracy: 0.728515625\n",
      "Batch: 92, Loss: 0.8716650009155273, Accuracy: 0.7265625\n",
      "Batch: 93, Loss: 0.8154743909835815, Accuracy: 0.75\n",
      "Batch: 94, Loss: 0.872962474822998, Accuracy: 0.7138671875\n",
      "Batch: 95, Loss: 0.8931136727333069, Accuracy: 0.7021484375\n",
      "Batch: 96, Loss: 0.8489639163017273, Accuracy: 0.7216796875\n",
      "Batch: 97, Loss: 0.7410616874694824, Accuracy: 0.7353515625\n",
      "Batch: 98, Loss: 0.7904629111289978, Accuracy: 0.75\n",
      "Batch: 99, Loss: 0.7916915416717529, Accuracy: 0.73046875\n",
      "Batch: 100, Loss: 0.8731119632720947, Accuracy: 0.7158203125\n",
      "Batch: 101, Loss: 0.897512674331665, Accuracy: 0.708984375\n",
      "Batch: 102, Loss: 0.8750249147415161, Accuracy: 0.712890625\n",
      "Batch: 103, Loss: 0.9023410677909851, Accuracy: 0.7216796875\n",
      "Batch: 104, Loss: 0.7977031469345093, Accuracy: 0.7373046875\n",
      "Batch: 105, Loss: 0.9031478762626648, Accuracy: 0.708984375\n",
      "Batch: 106, Loss: 0.858502209186554, Accuracy: 0.724609375\n",
      "Batch: 107, Loss: 0.8692914247512817, Accuracy: 0.71484375\n",
      "Batch: 108, Loss: 0.8765043020248413, Accuracy: 0.7119140625\n",
      "Batch: 109, Loss: 0.9947754144668579, Accuracy: 0.6796875\n",
      "Batch: 110, Loss: 0.7534976601600647, Accuracy: 0.7607421875\n",
      "Batch: 111, Loss: 0.8970309495925903, Accuracy: 0.6962890625\n",
      "Batch: 112, Loss: 0.8684303164482117, Accuracy: 0.7275390625\n",
      "Batch: 113, Loss: 0.8812241554260254, Accuracy: 0.736328125\n",
      "Batch: 114, Loss: 0.981898307800293, Accuracy: 0.6865234375\n",
      "Batch: 115, Loss: 0.9900892972946167, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.8931414484977722, Accuracy: 0.7041015625\n",
      "Batch: 117, Loss: 0.912222146987915, Accuracy: 0.701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 0.7574069499969482, Accuracy: 0.76171875\n",
      "Batch: 119, Loss: 0.7846542596817017, Accuracy: 0.744140625\n",
      "Batch: 120, Loss: 0.872515082359314, Accuracy: 0.712890625\n",
      "Batch: 121, Loss: 0.9316665530204773, Accuracy: 0.7041015625\n",
      "Batch: 122, Loss: 0.8324028849601746, Accuracy: 0.7333984375\n",
      "Batch: 123, Loss: 0.8138267993927002, Accuracy: 0.7451171875\n",
      "Batch: 124, Loss: 0.9163810014724731, Accuracy: 0.70703125\n",
      "Batch: 125, Loss: 0.9255861043930054, Accuracy: 0.7021484375\n",
      "Batch: 126, Loss: 0.9235897064208984, Accuracy: 0.6884765625\n",
      "Batch: 127, Loss: 0.7779958248138428, Accuracy: 0.7431640625\n",
      "Batch: 128, Loss: 0.9689173698425293, Accuracy: 0.708984375\n",
      "Batch: 129, Loss: 0.8765357136726379, Accuracy: 0.73046875\n",
      "Batch: 130, Loss: 1.038375735282898, Accuracy: 0.67578125\n",
      "Batch: 131, Loss: 0.9247934222221375, Accuracy: 0.701171875\n",
      "Batch: 132, Loss: 0.8905220031738281, Accuracy: 0.7236328125\n",
      "Batch: 133, Loss: 0.8174961805343628, Accuracy: 0.7294921875\n",
      "Batch: 134, Loss: 0.9024046659469604, Accuracy: 0.701171875\n",
      "Batch: 135, Loss: 0.800972580909729, Accuracy: 0.75\n",
      "Batch: 136, Loss: 0.8933466672897339, Accuracy: 0.7138671875\n",
      "Batch: 137, Loss: 0.8726503849029541, Accuracy: 0.7041015625\n",
      "Batch: 138, Loss: 0.7434244155883789, Accuracy: 0.7470703125\n",
      "Batch: 139, Loss: 0.8409178256988525, Accuracy: 0.7236328125\n",
      "Batch: 140, Loss: 0.844161868095398, Accuracy: 0.7109375\n",
      "Batch: 141, Loss: 0.9343891739845276, Accuracy: 0.716796875\n",
      "Batch: 142, Loss: 0.8931515216827393, Accuracy: 0.7001953125\n",
      "Batch: 143, Loss: 0.9144926071166992, Accuracy: 0.7021484375\n",
      "Batch: 144, Loss: 0.8853985071182251, Accuracy: 0.7099609375\n",
      "Batch: 145, Loss: 0.8198350667953491, Accuracy: 0.712890625\n",
      "Batch: 146, Loss: 0.9017653465270996, Accuracy: 0.71484375\n",
      "Batch: 147, Loss: 0.8857526779174805, Accuracy: 0.716796875\n",
      "Batch: 148, Loss: 1.0338208675384521, Accuracy: 0.6748046875\n",
      "Batch: 149, Loss: 0.8667477369308472, Accuracy: 0.7177734375\n",
      "Batch: 150, Loss: 0.8555517196655273, Accuracy: 0.720703125\n",
      "Batch: 151, Loss: 0.7497165203094482, Accuracy: 0.7509765625\n",
      "Epoch 27/80\n",
      "Batch: 1, Loss: 1.0916180610656738, Accuracy: 0.6591796875\n",
      "Batch: 2, Loss: 0.9737863540649414, Accuracy: 0.66796875\n",
      "Batch: 3, Loss: 0.8522360324859619, Accuracy: 0.7197265625\n",
      "Batch: 4, Loss: 0.7980741262435913, Accuracy: 0.7470703125\n",
      "Batch: 5, Loss: 0.8045709133148193, Accuracy: 0.751953125\n",
      "Batch: 6, Loss: 0.8876399993896484, Accuracy: 0.7041015625\n",
      "Batch: 7, Loss: 0.8779648542404175, Accuracy: 0.708984375\n",
      "Batch: 8, Loss: 0.8004680871963501, Accuracy: 0.7392578125\n",
      "Batch: 9, Loss: 0.8081912994384766, Accuracy: 0.73828125\n",
      "Batch: 10, Loss: 0.7873418927192688, Accuracy: 0.73828125\n",
      "Batch: 11, Loss: 0.9519124031066895, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.930490255355835, Accuracy: 0.703125\n",
      "Batch: 13, Loss: 0.7062017917633057, Accuracy: 0.78125\n",
      "Batch: 14, Loss: 0.928507924079895, Accuracy: 0.6884765625\n",
      "Batch: 15, Loss: 0.7935748100280762, Accuracy: 0.7451171875\n",
      "Batch: 16, Loss: 0.8451544642448425, Accuracy: 0.736328125\n",
      "Batch: 17, Loss: 0.8861416578292847, Accuracy: 0.7216796875\n",
      "Batch: 18, Loss: 0.8841595649719238, Accuracy: 0.7275390625\n",
      "Batch: 19, Loss: 0.9301264882087708, Accuracy: 0.7021484375\n",
      "Batch: 20, Loss: 0.7957584857940674, Accuracy: 0.744140625\n",
      "Batch: 21, Loss: 0.8630498647689819, Accuracy: 0.7216796875\n",
      "Batch: 22, Loss: 0.9564101696014404, Accuracy: 0.7138671875\n",
      "Batch: 23, Loss: 0.9075616598129272, Accuracy: 0.7099609375\n",
      "Batch: 24, Loss: 0.897849440574646, Accuracy: 0.7021484375\n",
      "Batch: 25, Loss: 0.8563784956932068, Accuracy: 0.7236328125\n",
      "Batch: 26, Loss: 0.7850093245506287, Accuracy: 0.7421875\n",
      "Batch: 27, Loss: 0.8262460231781006, Accuracy: 0.7138671875\n",
      "Batch: 28, Loss: 0.8953658938407898, Accuracy: 0.7041015625\n",
      "Batch: 29, Loss: 0.8810906410217285, Accuracy: 0.71484375\n",
      "Batch: 30, Loss: 0.7828154563903809, Accuracy: 0.7646484375\n",
      "Batch: 31, Loss: 0.7836734652519226, Accuracy: 0.748046875\n",
      "Batch: 32, Loss: 0.7888126373291016, Accuracy: 0.7470703125\n",
      "Batch: 33, Loss: 0.9402385354042053, Accuracy: 0.716796875\n",
      "Batch: 34, Loss: 1.0230690240859985, Accuracy: 0.6708984375\n",
      "Batch: 35, Loss: 0.8962048292160034, Accuracy: 0.7109375\n",
      "Batch: 36, Loss: 0.9163850545883179, Accuracy: 0.7060546875\n",
      "Batch: 37, Loss: 0.8643046617507935, Accuracy: 0.72265625\n",
      "Batch: 38, Loss: 0.8953900337219238, Accuracy: 0.701171875\n",
      "Batch: 39, Loss: 0.9012136459350586, Accuracy: 0.71875\n",
      "Batch: 40, Loss: 0.8513364791870117, Accuracy: 0.7373046875\n",
      "Batch: 41, Loss: 0.8465538024902344, Accuracy: 0.7158203125\n",
      "Batch: 42, Loss: 0.6871500015258789, Accuracy: 0.7724609375\n",
      "Batch: 43, Loss: 0.8148016929626465, Accuracy: 0.71484375\n",
      "Batch: 44, Loss: 0.8808903694152832, Accuracy: 0.69921875\n",
      "Batch: 45, Loss: 0.7469791173934937, Accuracy: 0.751953125\n",
      "Batch: 46, Loss: 0.7850517630577087, Accuracy: 0.74609375\n",
      "Batch: 47, Loss: 0.8259550929069519, Accuracy: 0.744140625\n",
      "Batch: 48, Loss: 0.7763355374336243, Accuracy: 0.7529296875\n",
      "Batch: 49, Loss: 0.9376707077026367, Accuracy: 0.7001953125\n",
      "Batch: 50, Loss: 0.8854893445968628, Accuracy: 0.7109375\n",
      "Batch: 51, Loss: 0.9491639733314514, Accuracy: 0.705078125\n",
      "Batch: 52, Loss: 0.9151333570480347, Accuracy: 0.724609375\n",
      "Batch: 53, Loss: 0.8155792951583862, Accuracy: 0.720703125\n",
      "Batch: 54, Loss: 0.8637723922729492, Accuracy: 0.72265625\n",
      "Batch: 55, Loss: 0.9603772759437561, Accuracy: 0.673828125\n",
      "Batch: 56, Loss: 0.9301902055740356, Accuracy: 0.70703125\n",
      "Batch: 57, Loss: 0.8949989080429077, Accuracy: 0.716796875\n",
      "Batch: 58, Loss: 0.9508363604545593, Accuracy: 0.7197265625\n",
      "Batch: 59, Loss: 0.7949761152267456, Accuracy: 0.7548828125\n",
      "Batch: 60, Loss: 0.7796938419342041, Accuracy: 0.7509765625\n",
      "Batch: 61, Loss: 0.8862192630767822, Accuracy: 0.7197265625\n",
      "Batch: 62, Loss: 0.7696199417114258, Accuracy: 0.7421875\n",
      "Batch: 63, Loss: 0.869861364364624, Accuracy: 0.716796875\n",
      "Batch: 64, Loss: 0.8231667280197144, Accuracy: 0.7294921875\n",
      "Batch: 65, Loss: 0.8824238777160645, Accuracy: 0.7080078125\n",
      "Batch: 66, Loss: 0.8304263353347778, Accuracy: 0.732421875\n",
      "Batch: 67, Loss: 0.917304515838623, Accuracy: 0.7099609375\n",
      "Batch: 68, Loss: 0.9310686588287354, Accuracy: 0.7109375\n",
      "Batch: 69, Loss: 0.8810271620750427, Accuracy: 0.7265625\n",
      "Batch: 70, Loss: 0.8812260031700134, Accuracy: 0.734375\n",
      "Batch: 71, Loss: 0.8873987197875977, Accuracy: 0.716796875\n",
      "Batch: 72, Loss: 0.7675174474716187, Accuracy: 0.763671875\n",
      "Batch: 73, Loss: 0.784393310546875, Accuracy: 0.75\n",
      "Batch: 74, Loss: 0.7832558155059814, Accuracy: 0.74609375\n",
      "Batch: 75, Loss: 0.7501269578933716, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.866025447845459, Accuracy: 0.705078125\n",
      "Batch: 77, Loss: 0.7800281047821045, Accuracy: 0.751953125\n",
      "Batch: 78, Loss: 0.8256666660308838, Accuracy: 0.7529296875\n",
      "Batch: 79, Loss: 0.7797031402587891, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.789654016494751, Accuracy: 0.7294921875\n",
      "Batch: 81, Loss: 0.9014607667922974, Accuracy: 0.681640625\n",
      "Batch: 82, Loss: 0.8448856472969055, Accuracy: 0.7177734375\n",
      "Batch: 83, Loss: 0.7456773519515991, Accuracy: 0.7724609375\n",
      "Batch: 84, Loss: 0.8310185074806213, Accuracy: 0.7236328125\n",
      "Batch: 85, Loss: 0.786891758441925, Accuracy: 0.7451171875\n",
      "Batch: 86, Loss: 0.9825491905212402, Accuracy: 0.69921875\n",
      "Batch: 87, Loss: 0.7806390523910522, Accuracy: 0.7587890625\n",
      "Batch: 88, Loss: 0.9015404582023621, Accuracy: 0.728515625\n",
      "Batch: 89, Loss: 0.8871787786483765, Accuracy: 0.7265625\n",
      "Batch: 90, Loss: 0.8205503225326538, Accuracy: 0.736328125\n",
      "Batch: 91, Loss: 0.8262466192245483, Accuracy: 0.724609375\n",
      "Batch: 92, Loss: 0.8801429867744446, Accuracy: 0.724609375\n",
      "Batch: 93, Loss: 0.8026575446128845, Accuracy: 0.7490234375\n",
      "Batch: 94, Loss: 0.847538411617279, Accuracy: 0.7197265625\n",
      "Batch: 95, Loss: 0.8790014982223511, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.8419027328491211, Accuracy: 0.73046875\n",
      "Batch: 97, Loss: 0.7160524129867554, Accuracy: 0.763671875\n",
      "Batch: 98, Loss: 0.7806956768035889, Accuracy: 0.7392578125\n",
      "Batch: 99, Loss: 0.8115973472595215, Accuracy: 0.732421875\n",
      "Batch: 100, Loss: 0.8772397041320801, Accuracy: 0.705078125\n",
      "Batch: 101, Loss: 0.9097790718078613, Accuracy: 0.7109375\n",
      "Batch: 102, Loss: 0.8284463882446289, Accuracy: 0.7353515625\n",
      "Batch: 103, Loss: 0.8804135918617249, Accuracy: 0.724609375\n",
      "Batch: 104, Loss: 0.7842379808425903, Accuracy: 0.7314453125\n",
      "Batch: 105, Loss: 0.9099342823028564, Accuracy: 0.7080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 0.8169349431991577, Accuracy: 0.73828125\n",
      "Batch: 107, Loss: 0.8463601469993591, Accuracy: 0.734375\n",
      "Batch: 108, Loss: 0.8559463024139404, Accuracy: 0.7255859375\n",
      "Batch: 109, Loss: 0.9680525064468384, Accuracy: 0.693359375\n",
      "Batch: 110, Loss: 0.7430689334869385, Accuracy: 0.7548828125\n",
      "Batch: 111, Loss: 0.8784290552139282, Accuracy: 0.7216796875\n",
      "Batch: 112, Loss: 0.8612071871757507, Accuracy: 0.740234375\n",
      "Batch: 113, Loss: 0.8478940725326538, Accuracy: 0.734375\n",
      "Batch: 114, Loss: 0.9301967620849609, Accuracy: 0.7041015625\n",
      "Batch: 115, Loss: 0.9541130065917969, Accuracy: 0.6923828125\n",
      "Batch: 116, Loss: 0.8839198350906372, Accuracy: 0.71875\n",
      "Batch: 117, Loss: 0.8892108798027039, Accuracy: 0.7255859375\n",
      "Batch: 118, Loss: 0.7708187103271484, Accuracy: 0.7568359375\n",
      "Batch: 119, Loss: 0.759543776512146, Accuracy: 0.7626953125\n",
      "Batch: 120, Loss: 0.8655540943145752, Accuracy: 0.716796875\n",
      "Batch: 121, Loss: 0.9098304510116577, Accuracy: 0.7099609375\n",
      "Batch: 122, Loss: 0.8277051448822021, Accuracy: 0.7509765625\n",
      "Batch: 123, Loss: 0.8180257081985474, Accuracy: 0.7470703125\n",
      "Batch: 124, Loss: 0.8424773216247559, Accuracy: 0.73046875\n",
      "Batch: 125, Loss: 0.9068872332572937, Accuracy: 0.705078125\n",
      "Batch: 126, Loss: 0.8759249448776245, Accuracy: 0.724609375\n",
      "Batch: 127, Loss: 0.7840516567230225, Accuracy: 0.759765625\n",
      "Batch: 128, Loss: 0.9883455038070679, Accuracy: 0.7138671875\n",
      "Batch: 129, Loss: 0.8307743072509766, Accuracy: 0.7294921875\n",
      "Batch: 130, Loss: 1.020075798034668, Accuracy: 0.6767578125\n",
      "Batch: 131, Loss: 0.9164053797721863, Accuracy: 0.70703125\n",
      "Batch: 132, Loss: 0.9033925533294678, Accuracy: 0.7158203125\n",
      "Batch: 133, Loss: 0.8217735886573792, Accuracy: 0.732421875\n",
      "Batch: 134, Loss: 0.8815207481384277, Accuracy: 0.7060546875\n",
      "Batch: 135, Loss: 0.8005651831626892, Accuracy: 0.7431640625\n",
      "Batch: 136, Loss: 0.8781970739364624, Accuracy: 0.7138671875\n",
      "Batch: 137, Loss: 0.8480328321456909, Accuracy: 0.71875\n",
      "Batch: 138, Loss: 0.7463048696517944, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.8316949009895325, Accuracy: 0.732421875\n",
      "Batch: 140, Loss: 0.8271456360816956, Accuracy: 0.7294921875\n",
      "Batch: 141, Loss: 0.8825481534004211, Accuracy: 0.712890625\n",
      "Batch: 142, Loss: 0.8793529272079468, Accuracy: 0.71484375\n",
      "Batch: 143, Loss: 0.8622459173202515, Accuracy: 0.7109375\n",
      "Batch: 144, Loss: 0.8836528062820435, Accuracy: 0.7197265625\n",
      "Batch: 145, Loss: 0.8359980583190918, Accuracy: 0.7138671875\n",
      "Batch: 146, Loss: 0.8974184989929199, Accuracy: 0.703125\n",
      "Batch: 147, Loss: 0.9001222848892212, Accuracy: 0.7197265625\n",
      "Batch: 148, Loss: 1.0010629892349243, Accuracy: 0.673828125\n",
      "Batch: 149, Loss: 0.8576337099075317, Accuracy: 0.7109375\n",
      "Batch: 150, Loss: 0.8359153866767883, Accuracy: 0.724609375\n",
      "Batch: 151, Loss: 0.7830773591995239, Accuracy: 0.736328125\n",
      "Epoch 28/80\n",
      "Batch: 1, Loss: 1.088277816772461, Accuracy: 0.6591796875\n",
      "Batch: 2, Loss: 0.9381054639816284, Accuracy: 0.6728515625\n",
      "Batch: 3, Loss: 0.8587883710861206, Accuracy: 0.71875\n",
      "Batch: 4, Loss: 0.7916372418403625, Accuracy: 0.7421875\n",
      "Batch: 5, Loss: 0.8082315325737, Accuracy: 0.7421875\n",
      "Batch: 6, Loss: 0.8625141382217407, Accuracy: 0.7119140625\n",
      "Batch: 7, Loss: 0.8560506105422974, Accuracy: 0.7353515625\n",
      "Batch: 8, Loss: 0.8215240240097046, Accuracy: 0.7236328125\n",
      "Batch: 9, Loss: 0.7680065035820007, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.7896981835365295, Accuracy: 0.7412109375\n",
      "Batch: 11, Loss: 0.9161703586578369, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.9072943925857544, Accuracy: 0.7041015625\n",
      "Batch: 13, Loss: 0.7160492539405823, Accuracy: 0.763671875\n",
      "Batch: 14, Loss: 0.9649674892425537, Accuracy: 0.6865234375\n",
      "Batch: 15, Loss: 0.814041018486023, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.7936944961547852, Accuracy: 0.744140625\n",
      "Batch: 17, Loss: 0.8840855956077576, Accuracy: 0.72265625\n",
      "Batch: 18, Loss: 0.8855798244476318, Accuracy: 0.7060546875\n",
      "Batch: 19, Loss: 0.8829291462898254, Accuracy: 0.7138671875\n",
      "Batch: 20, Loss: 0.7834316492080688, Accuracy: 0.7470703125\n",
      "Batch: 21, Loss: 0.8125721216201782, Accuracy: 0.7294921875\n",
      "Batch: 22, Loss: 0.9347630739212036, Accuracy: 0.712890625\n",
      "Batch: 23, Loss: 0.8813573122024536, Accuracy: 0.703125\n",
      "Batch: 24, Loss: 0.8960306644439697, Accuracy: 0.7001953125\n",
      "Batch: 25, Loss: 0.8601590394973755, Accuracy: 0.7314453125\n",
      "Batch: 26, Loss: 0.7509556412696838, Accuracy: 0.7587890625\n",
      "Batch: 27, Loss: 0.8189757466316223, Accuracy: 0.7099609375\n",
      "Batch: 28, Loss: 0.8627774715423584, Accuracy: 0.7158203125\n",
      "Batch: 29, Loss: 0.8521534204483032, Accuracy: 0.7275390625\n",
      "Batch: 30, Loss: 0.7688283324241638, Accuracy: 0.771484375\n",
      "Batch: 31, Loss: 0.7865705490112305, Accuracy: 0.7431640625\n",
      "Batch: 32, Loss: 0.7914897203445435, Accuracy: 0.736328125\n",
      "Batch: 33, Loss: 0.9301859140396118, Accuracy: 0.7255859375\n",
      "Batch: 34, Loss: 0.9940061569213867, Accuracy: 0.6826171875\n",
      "Batch: 35, Loss: 0.8793125748634338, Accuracy: 0.716796875\n",
      "Batch: 36, Loss: 0.9049850106239319, Accuracy: 0.7119140625\n",
      "Batch: 37, Loss: 0.8552331328392029, Accuracy: 0.734375\n",
      "Batch: 38, Loss: 0.8849778175354004, Accuracy: 0.70703125\n",
      "Batch: 39, Loss: 0.8924667239189148, Accuracy: 0.716796875\n",
      "Batch: 40, Loss: 0.8630720973014832, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.820547342300415, Accuracy: 0.744140625\n",
      "Batch: 42, Loss: 0.6782741546630859, Accuracy: 0.7763671875\n",
      "Batch: 43, Loss: 0.848726749420166, Accuracy: 0.7001953125\n",
      "Batch: 44, Loss: 0.8518859148025513, Accuracy: 0.72265625\n",
      "Batch: 45, Loss: 0.742489218711853, Accuracy: 0.7509765625\n",
      "Batch: 46, Loss: 0.7988722324371338, Accuracy: 0.74609375\n",
      "Batch: 47, Loss: 0.814220130443573, Accuracy: 0.7412109375\n",
      "Batch: 48, Loss: 0.7682051062583923, Accuracy: 0.7607421875\n",
      "Batch: 49, Loss: 0.932278573513031, Accuracy: 0.697265625\n",
      "Batch: 50, Loss: 0.8876408338546753, Accuracy: 0.69921875\n",
      "Batch: 51, Loss: 0.9248003363609314, Accuracy: 0.7138671875\n",
      "Batch: 52, Loss: 0.8751394748687744, Accuracy: 0.72265625\n",
      "Batch: 53, Loss: 0.7665631771087646, Accuracy: 0.740234375\n",
      "Batch: 54, Loss: 0.852299690246582, Accuracy: 0.72265625\n",
      "Batch: 55, Loss: 0.8946201205253601, Accuracy: 0.705078125\n",
      "Batch: 56, Loss: 0.904081404209137, Accuracy: 0.6982421875\n",
      "Batch: 57, Loss: 0.8605616092681885, Accuracy: 0.71875\n",
      "Batch: 58, Loss: 0.9382786750793457, Accuracy: 0.7119140625\n",
      "Batch: 59, Loss: 0.7941103577613831, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.7836388945579529, Accuracy: 0.740234375\n",
      "Batch: 61, Loss: 0.86513352394104, Accuracy: 0.7197265625\n",
      "Batch: 62, Loss: 0.7755709886550903, Accuracy: 0.744140625\n",
      "Batch: 63, Loss: 0.8500856757164001, Accuracy: 0.732421875\n",
      "Batch: 64, Loss: 0.8434545993804932, Accuracy: 0.72265625\n",
      "Batch: 65, Loss: 0.839423656463623, Accuracy: 0.7353515625\n",
      "Batch: 66, Loss: 0.8427670001983643, Accuracy: 0.736328125\n",
      "Batch: 67, Loss: 0.9065796732902527, Accuracy: 0.716796875\n",
      "Batch: 68, Loss: 0.9318983554840088, Accuracy: 0.6982421875\n",
      "Batch: 69, Loss: 0.8658497929573059, Accuracy: 0.7236328125\n",
      "Batch: 70, Loss: 0.8562676906585693, Accuracy: 0.7265625\n",
      "Batch: 71, Loss: 0.8691236972808838, Accuracy: 0.7216796875\n",
      "Batch: 72, Loss: 0.7527585029602051, Accuracy: 0.740234375\n",
      "Batch: 73, Loss: 0.7720728516578674, Accuracy: 0.7587890625\n",
      "Batch: 74, Loss: 0.7628906965255737, Accuracy: 0.7666015625\n",
      "Batch: 75, Loss: 0.7506220936775208, Accuracy: 0.751953125\n",
      "Batch: 76, Loss: 0.8513745069503784, Accuracy: 0.7236328125\n",
      "Batch: 77, Loss: 0.7958387136459351, Accuracy: 0.7353515625\n",
      "Batch: 78, Loss: 0.7961691617965698, Accuracy: 0.7431640625\n",
      "Batch: 79, Loss: 0.7600499391555786, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.7857400178909302, Accuracy: 0.736328125\n",
      "Batch: 81, Loss: 0.891906201839447, Accuracy: 0.69921875\n",
      "Batch: 82, Loss: 0.8588976860046387, Accuracy: 0.724609375\n",
      "Batch: 83, Loss: 0.7321516871452332, Accuracy: 0.7841796875\n",
      "Batch: 84, Loss: 0.848229706287384, Accuracy: 0.7265625\n",
      "Batch: 85, Loss: 0.7741767764091492, Accuracy: 0.744140625\n",
      "Batch: 86, Loss: 0.9622651934623718, Accuracy: 0.7138671875\n",
      "Batch: 87, Loss: 0.7772940993309021, Accuracy: 0.759765625\n",
      "Batch: 88, Loss: 0.8872073888778687, Accuracy: 0.7255859375\n",
      "Batch: 89, Loss: 0.88936847448349, Accuracy: 0.732421875\n",
      "Batch: 90, Loss: 0.8183539509773254, Accuracy: 0.7421875\n",
      "Batch: 91, Loss: 0.8351885080337524, Accuracy: 0.7373046875\n",
      "Batch: 92, Loss: 0.8620086312294006, Accuracy: 0.7197265625\n",
      "Batch: 93, Loss: 0.8132973909378052, Accuracy: 0.744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 0.8155782222747803, Accuracy: 0.7431640625\n",
      "Batch: 95, Loss: 0.8794516324996948, Accuracy: 0.705078125\n",
      "Batch: 96, Loss: 0.8178134560585022, Accuracy: 0.7421875\n",
      "Batch: 97, Loss: 0.7071681022644043, Accuracy: 0.7666015625\n",
      "Batch: 98, Loss: 0.766767144203186, Accuracy: 0.7421875\n",
      "Batch: 99, Loss: 0.7873786687850952, Accuracy: 0.7421875\n",
      "Batch: 100, Loss: 0.844477117061615, Accuracy: 0.720703125\n",
      "Batch: 101, Loss: 0.8700184226036072, Accuracy: 0.7001953125\n",
      "Batch: 102, Loss: 0.8231331706047058, Accuracy: 0.736328125\n",
      "Batch: 103, Loss: 0.8587313890457153, Accuracy: 0.740234375\n",
      "Batch: 104, Loss: 0.7791637182235718, Accuracy: 0.73046875\n",
      "Batch: 105, Loss: 0.8769574761390686, Accuracy: 0.7158203125\n",
      "Batch: 106, Loss: 0.8265379071235657, Accuracy: 0.732421875\n",
      "Batch: 107, Loss: 0.8117499351501465, Accuracy: 0.75\n",
      "Batch: 108, Loss: 0.8217751979827881, Accuracy: 0.716796875\n",
      "Batch: 109, Loss: 0.9228187799453735, Accuracy: 0.701171875\n",
      "Batch: 110, Loss: 0.718055009841919, Accuracy: 0.7568359375\n",
      "Batch: 111, Loss: 0.861448347568512, Accuracy: 0.708984375\n",
      "Batch: 112, Loss: 0.8464837074279785, Accuracy: 0.7333984375\n",
      "Batch: 113, Loss: 0.8432338237762451, Accuracy: 0.7548828125\n",
      "Batch: 114, Loss: 0.9640124440193176, Accuracy: 0.6953125\n",
      "Batch: 115, Loss: 0.9394678473472595, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.8640380501747131, Accuracy: 0.7138671875\n",
      "Batch: 117, Loss: 0.8900697827339172, Accuracy: 0.712890625\n",
      "Batch: 118, Loss: 0.7682502865791321, Accuracy: 0.7587890625\n",
      "Batch: 119, Loss: 0.7274686098098755, Accuracy: 0.7705078125\n",
      "Batch: 120, Loss: 0.8323042392730713, Accuracy: 0.7216796875\n",
      "Batch: 121, Loss: 0.9112235307693481, Accuracy: 0.6962890625\n",
      "Batch: 122, Loss: 0.8159238696098328, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.8043361902236938, Accuracy: 0.76171875\n",
      "Batch: 124, Loss: 0.866716742515564, Accuracy: 0.7275390625\n",
      "Batch: 125, Loss: 0.9023144245147705, Accuracy: 0.6982421875\n",
      "Batch: 126, Loss: 0.8621507883071899, Accuracy: 0.724609375\n",
      "Batch: 127, Loss: 0.7502921223640442, Accuracy: 0.7685546875\n",
      "Batch: 128, Loss: 0.957328200340271, Accuracy: 0.7119140625\n",
      "Batch: 129, Loss: 0.802848756313324, Accuracy: 0.7490234375\n",
      "Batch: 130, Loss: 0.9792648553848267, Accuracy: 0.6865234375\n",
      "Batch: 131, Loss: 0.8799545764923096, Accuracy: 0.720703125\n",
      "Batch: 132, Loss: 0.8820476531982422, Accuracy: 0.71484375\n",
      "Batch: 133, Loss: 0.7978321313858032, Accuracy: 0.7314453125\n",
      "Batch: 134, Loss: 0.8660955429077148, Accuracy: 0.71875\n",
      "Batch: 135, Loss: 0.7686619758605957, Accuracy: 0.765625\n",
      "Batch: 136, Loss: 0.8764874935150146, Accuracy: 0.7275390625\n",
      "Batch: 137, Loss: 0.8467110991477966, Accuracy: 0.71484375\n",
      "Batch: 138, Loss: 0.7180516719818115, Accuracy: 0.7509765625\n",
      "Batch: 139, Loss: 0.8093397617340088, Accuracy: 0.7314453125\n",
      "Batch: 140, Loss: 0.8254137635231018, Accuracy: 0.7236328125\n",
      "Batch: 141, Loss: 0.8871514797210693, Accuracy: 0.7216796875\n",
      "Batch: 142, Loss: 0.8712350726127625, Accuracy: 0.728515625\n",
      "Batch: 143, Loss: 0.8570610284805298, Accuracy: 0.7255859375\n",
      "Batch: 144, Loss: 0.8700359463691711, Accuracy: 0.720703125\n",
      "Batch: 145, Loss: 0.7758551836013794, Accuracy: 0.740234375\n",
      "Batch: 146, Loss: 0.8753058910369873, Accuracy: 0.71875\n",
      "Batch: 147, Loss: 0.8593496084213257, Accuracy: 0.7138671875\n",
      "Batch: 148, Loss: 0.9720339775085449, Accuracy: 0.6923828125\n",
      "Batch: 149, Loss: 0.831116795539856, Accuracy: 0.720703125\n",
      "Batch: 150, Loss: 0.8263711333274841, Accuracy: 0.728515625\n",
      "Batch: 151, Loss: 0.7472385764122009, Accuracy: 0.7529296875\n",
      "Epoch 29/80\n",
      "Batch: 1, Loss: 1.0755226612091064, Accuracy: 0.6435546875\n",
      "Batch: 2, Loss: 0.9413691759109497, Accuracy: 0.6943359375\n",
      "Batch: 3, Loss: 0.8118035793304443, Accuracy: 0.7353515625\n",
      "Batch: 4, Loss: 0.7717007398605347, Accuracy: 0.7626953125\n",
      "Batch: 5, Loss: 0.7809323668479919, Accuracy: 0.7529296875\n",
      "Batch: 6, Loss: 0.8740787506103516, Accuracy: 0.7041015625\n",
      "Batch: 7, Loss: 0.824921727180481, Accuracy: 0.7353515625\n",
      "Batch: 8, Loss: 0.8062787652015686, Accuracy: 0.73046875\n",
      "Batch: 9, Loss: 0.781092643737793, Accuracy: 0.7646484375\n",
      "Batch: 10, Loss: 0.7628053426742554, Accuracy: 0.7578125\n",
      "Batch: 11, Loss: 0.8914191126823425, Accuracy: 0.6953125\n",
      "Batch: 12, Loss: 0.8730111122131348, Accuracy: 0.7216796875\n",
      "Batch: 13, Loss: 0.6808815002441406, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.9231235980987549, Accuracy: 0.701171875\n",
      "Batch: 15, Loss: 0.8124830722808838, Accuracy: 0.7421875\n",
      "Batch: 16, Loss: 0.8029779195785522, Accuracy: 0.75390625\n",
      "Batch: 17, Loss: 0.8726304769515991, Accuracy: 0.728515625\n",
      "Batch: 18, Loss: 0.8685798645019531, Accuracy: 0.7333984375\n",
      "Batch: 19, Loss: 0.8940904140472412, Accuracy: 0.70703125\n",
      "Batch: 20, Loss: 0.7808985710144043, Accuracy: 0.736328125\n",
      "Batch: 21, Loss: 0.804223895072937, Accuracy: 0.716796875\n",
      "Batch: 22, Loss: 0.9130469560623169, Accuracy: 0.7236328125\n",
      "Batch: 23, Loss: 0.8917669057846069, Accuracy: 0.7158203125\n",
      "Batch: 24, Loss: 0.8609488010406494, Accuracy: 0.7255859375\n",
      "Batch: 25, Loss: 0.8425673246383667, Accuracy: 0.7431640625\n",
      "Batch: 26, Loss: 0.7448344230651855, Accuracy: 0.775390625\n",
      "Batch: 27, Loss: 0.7566519975662231, Accuracy: 0.7392578125\n",
      "Batch: 28, Loss: 0.8683698177337646, Accuracy: 0.7158203125\n",
      "Batch: 29, Loss: 0.8339394330978394, Accuracy: 0.7373046875\n",
      "Batch: 30, Loss: 0.7476714849472046, Accuracy: 0.7744140625\n",
      "Batch: 31, Loss: 0.7529882788658142, Accuracy: 0.7509765625\n",
      "Batch: 32, Loss: 0.7639198303222656, Accuracy: 0.7412109375\n",
      "Batch: 33, Loss: 0.9154954552650452, Accuracy: 0.7255859375\n",
      "Batch: 34, Loss: 0.964634120464325, Accuracy: 0.6884765625\n",
      "Batch: 35, Loss: 0.8906458616256714, Accuracy: 0.693359375\n",
      "Batch: 36, Loss: 0.8844574093818665, Accuracy: 0.7314453125\n",
      "Batch: 37, Loss: 0.8216348886489868, Accuracy: 0.7275390625\n",
      "Batch: 38, Loss: 0.8582033514976501, Accuracy: 0.71875\n",
      "Batch: 39, Loss: 0.8869880437850952, Accuracy: 0.7060546875\n",
      "Batch: 40, Loss: 0.8535482883453369, Accuracy: 0.720703125\n",
      "Batch: 41, Loss: 0.789082944393158, Accuracy: 0.7412109375\n",
      "Batch: 42, Loss: 0.6721774339675903, Accuracy: 0.7744140625\n",
      "Batch: 43, Loss: 0.846903920173645, Accuracy: 0.7158203125\n",
      "Batch: 44, Loss: 0.8446553945541382, Accuracy: 0.716796875\n",
      "Batch: 45, Loss: 0.7398923635482788, Accuracy: 0.7626953125\n",
      "Batch: 46, Loss: 0.7498478889465332, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.7941584587097168, Accuracy: 0.75390625\n",
      "Batch: 48, Loss: 0.76311194896698, Accuracy: 0.75\n",
      "Batch: 49, Loss: 0.9296554327011108, Accuracy: 0.697265625\n",
      "Batch: 50, Loss: 0.8900922536849976, Accuracy: 0.720703125\n",
      "Batch: 51, Loss: 0.8918120861053467, Accuracy: 0.7158203125\n",
      "Batch: 52, Loss: 0.858792781829834, Accuracy: 0.7265625\n",
      "Batch: 53, Loss: 0.7664370536804199, Accuracy: 0.7373046875\n",
      "Batch: 54, Loss: 0.8286032676696777, Accuracy: 0.7236328125\n",
      "Batch: 55, Loss: 0.9058117866516113, Accuracy: 0.6982421875\n",
      "Batch: 56, Loss: 0.8959010243415833, Accuracy: 0.7177734375\n",
      "Batch: 57, Loss: 0.8485046625137329, Accuracy: 0.7373046875\n",
      "Batch: 58, Loss: 0.9436006546020508, Accuracy: 0.716796875\n",
      "Batch: 59, Loss: 0.7912677526473999, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.760604977607727, Accuracy: 0.7490234375\n",
      "Batch: 61, Loss: 0.8792460560798645, Accuracy: 0.712890625\n",
      "Batch: 62, Loss: 0.7525419592857361, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.8362478017807007, Accuracy: 0.7353515625\n",
      "Batch: 64, Loss: 0.8002973794937134, Accuracy: 0.7451171875\n",
      "Batch: 65, Loss: 0.838432252407074, Accuracy: 0.7294921875\n",
      "Batch: 66, Loss: 0.8069839477539062, Accuracy: 0.7490234375\n",
      "Batch: 67, Loss: 0.8851139545440674, Accuracy: 0.7138671875\n",
      "Batch: 68, Loss: 0.9183785319328308, Accuracy: 0.7177734375\n",
      "Batch: 69, Loss: 0.8702521324157715, Accuracy: 0.7138671875\n",
      "Batch: 70, Loss: 0.8367405533790588, Accuracy: 0.728515625\n",
      "Batch: 71, Loss: 0.8659539222717285, Accuracy: 0.7001953125\n",
      "Batch: 72, Loss: 0.7469199895858765, Accuracy: 0.7626953125\n",
      "Batch: 73, Loss: 0.7671341896057129, Accuracy: 0.7646484375\n",
      "Batch: 74, Loss: 0.7451276183128357, Accuracy: 0.767578125\n",
      "Batch: 75, Loss: 0.730736255645752, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.8344154357910156, Accuracy: 0.71875\n",
      "Batch: 77, Loss: 0.7737081050872803, Accuracy: 0.732421875\n",
      "Batch: 78, Loss: 0.7763586044311523, Accuracy: 0.76171875\n",
      "Batch: 79, Loss: 0.7731900215148926, Accuracy: 0.7529296875\n",
      "Batch: 80, Loss: 0.7682356834411621, Accuracy: 0.7431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 0.8571879863739014, Accuracy: 0.7021484375\n",
      "Batch: 82, Loss: 0.8386735320091248, Accuracy: 0.7119140625\n",
      "Batch: 83, Loss: 0.6997314095497131, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.8150218725204468, Accuracy: 0.7451171875\n",
      "Batch: 85, Loss: 0.7720597982406616, Accuracy: 0.7587890625\n",
      "Batch: 86, Loss: 0.9847840070724487, Accuracy: 0.7138671875\n",
      "Batch: 87, Loss: 0.7642574906349182, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.8971951603889465, Accuracy: 0.73828125\n",
      "Batch: 89, Loss: 0.8525621891021729, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.78741455078125, Accuracy: 0.75390625\n",
      "Batch: 91, Loss: 0.8031402826309204, Accuracy: 0.7275390625\n",
      "Batch: 92, Loss: 0.8308061957359314, Accuracy: 0.72265625\n",
      "Batch: 93, Loss: 0.7903591990470886, Accuracy: 0.744140625\n",
      "Batch: 94, Loss: 0.8044036626815796, Accuracy: 0.7373046875\n",
      "Batch: 95, Loss: 0.8562780022621155, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.7998888492584229, Accuracy: 0.7314453125\n",
      "Batch: 97, Loss: 0.6742769479751587, Accuracy: 0.775390625\n",
      "Batch: 98, Loss: 0.7711434364318848, Accuracy: 0.7490234375\n",
      "Batch: 99, Loss: 0.7779137492179871, Accuracy: 0.7392578125\n",
      "Batch: 100, Loss: 0.8465503454208374, Accuracy: 0.7265625\n",
      "Batch: 101, Loss: 0.9061968922615051, Accuracy: 0.7138671875\n",
      "Batch: 102, Loss: 0.822230339050293, Accuracy: 0.7265625\n",
      "Batch: 103, Loss: 0.8190074563026428, Accuracy: 0.736328125\n",
      "Batch: 104, Loss: 0.7776002883911133, Accuracy: 0.7412109375\n",
      "Batch: 105, Loss: 0.8591099381446838, Accuracy: 0.7255859375\n",
      "Batch: 106, Loss: 0.7769988179206848, Accuracy: 0.7587890625\n",
      "Batch: 107, Loss: 0.8140597939491272, Accuracy: 0.7490234375\n",
      "Batch: 108, Loss: 0.8313454389572144, Accuracy: 0.7236328125\n",
      "Batch: 109, Loss: 0.9241521954536438, Accuracy: 0.6904296875\n",
      "Batch: 110, Loss: 0.7179062366485596, Accuracy: 0.7685546875\n",
      "Batch: 111, Loss: 0.8751000165939331, Accuracy: 0.720703125\n",
      "Batch: 112, Loss: 0.8490933179855347, Accuracy: 0.728515625\n",
      "Batch: 113, Loss: 0.8558502197265625, Accuracy: 0.73828125\n",
      "Batch: 114, Loss: 0.9090734720230103, Accuracy: 0.7177734375\n",
      "Batch: 115, Loss: 0.9396219253540039, Accuracy: 0.7119140625\n",
      "Batch: 116, Loss: 0.8338485956192017, Accuracy: 0.7216796875\n",
      "Batch: 117, Loss: 0.8665485382080078, Accuracy: 0.71484375\n",
      "Batch: 118, Loss: 0.7688204050064087, Accuracy: 0.75390625\n",
      "Batch: 119, Loss: 0.7215709686279297, Accuracy: 0.76953125\n",
      "Batch: 120, Loss: 0.8307201862335205, Accuracy: 0.7236328125\n",
      "Batch: 121, Loss: 0.8902857899665833, Accuracy: 0.705078125\n",
      "Batch: 122, Loss: 0.7987476587295532, Accuracy: 0.740234375\n",
      "Batch: 123, Loss: 0.7711957693099976, Accuracy: 0.755859375\n",
      "Batch: 124, Loss: 0.8378201723098755, Accuracy: 0.732421875\n",
      "Batch: 125, Loss: 0.8734768629074097, Accuracy: 0.7099609375\n",
      "Batch: 126, Loss: 0.8401520252227783, Accuracy: 0.720703125\n",
      "Batch: 127, Loss: 0.73347407579422, Accuracy: 0.77734375\n",
      "Batch: 128, Loss: 0.9410803318023682, Accuracy: 0.7236328125\n",
      "Batch: 129, Loss: 0.8126226663589478, Accuracy: 0.748046875\n",
      "Batch: 130, Loss: 0.9845191240310669, Accuracy: 0.6787109375\n",
      "Batch: 131, Loss: 0.8843938112258911, Accuracy: 0.7119140625\n",
      "Batch: 132, Loss: 0.8735326528549194, Accuracy: 0.7138671875\n",
      "Batch: 133, Loss: 0.8155577182769775, Accuracy: 0.720703125\n",
      "Batch: 134, Loss: 0.8440648317337036, Accuracy: 0.70703125\n",
      "Batch: 135, Loss: 0.7445899248123169, Accuracy: 0.755859375\n",
      "Batch: 136, Loss: 0.836115837097168, Accuracy: 0.73828125\n",
      "Batch: 137, Loss: 0.8017628192901611, Accuracy: 0.73046875\n",
      "Batch: 138, Loss: 0.7218388319015503, Accuracy: 0.7626953125\n",
      "Batch: 139, Loss: 0.8118396997451782, Accuracy: 0.732421875\n",
      "Batch: 140, Loss: 0.7916810512542725, Accuracy: 0.7314453125\n",
      "Batch: 141, Loss: 0.8840830326080322, Accuracy: 0.712890625\n",
      "Batch: 142, Loss: 0.8330309987068176, Accuracy: 0.7314453125\n",
      "Batch: 143, Loss: 0.8731943964958191, Accuracy: 0.7158203125\n",
      "Batch: 144, Loss: 0.8558627367019653, Accuracy: 0.7275390625\n",
      "Batch: 145, Loss: 0.766067385673523, Accuracy: 0.7392578125\n",
      "Batch: 146, Loss: 0.8597264289855957, Accuracy: 0.7314453125\n",
      "Batch: 147, Loss: 0.8520243167877197, Accuracy: 0.7158203125\n",
      "Batch: 148, Loss: 0.9662761688232422, Accuracy: 0.6748046875\n",
      "Batch: 149, Loss: 0.8233476281166077, Accuracy: 0.7314453125\n",
      "Batch: 150, Loss: 0.7883033752441406, Accuracy: 0.748046875\n",
      "Batch: 151, Loss: 0.7476674318313599, Accuracy: 0.7490234375\n",
      "Epoch 30/80\n",
      "Batch: 1, Loss: 1.0472829341888428, Accuracy: 0.6728515625\n",
      "Batch: 2, Loss: 0.9011635780334473, Accuracy: 0.6962890625\n",
      "Batch: 3, Loss: 0.8144526481628418, Accuracy: 0.72265625\n",
      "Batch: 4, Loss: 0.7433788776397705, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.7869220972061157, Accuracy: 0.744140625\n",
      "Batch: 6, Loss: 0.8379501104354858, Accuracy: 0.720703125\n",
      "Batch: 7, Loss: 0.83719801902771, Accuracy: 0.7255859375\n",
      "Batch: 8, Loss: 0.774031937122345, Accuracy: 0.7529296875\n",
      "Batch: 9, Loss: 0.7832417488098145, Accuracy: 0.7626953125\n",
      "Batch: 10, Loss: 0.7780776023864746, Accuracy: 0.7294921875\n",
      "Batch: 11, Loss: 0.8905024528503418, Accuracy: 0.7197265625\n",
      "Batch: 12, Loss: 0.8854312896728516, Accuracy: 0.7119140625\n",
      "Batch: 13, Loss: 0.6516566276550293, Accuracy: 0.79296875\n",
      "Batch: 14, Loss: 0.9167582988739014, Accuracy: 0.71484375\n",
      "Batch: 15, Loss: 0.7805874943733215, Accuracy: 0.751953125\n",
      "Batch: 16, Loss: 0.7750785946846008, Accuracy: 0.7646484375\n",
      "Batch: 17, Loss: 0.8494380712509155, Accuracy: 0.7236328125\n",
      "Batch: 18, Loss: 0.881116509437561, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.8848348259925842, Accuracy: 0.7158203125\n",
      "Batch: 20, Loss: 0.7205278873443604, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.7963108420372009, Accuracy: 0.7197265625\n",
      "Batch: 22, Loss: 0.9056661128997803, Accuracy: 0.701171875\n",
      "Batch: 23, Loss: 0.8766200542449951, Accuracy: 0.7041015625\n",
      "Batch: 24, Loss: 0.8718050718307495, Accuracy: 0.728515625\n",
      "Batch: 25, Loss: 0.8455693125724792, Accuracy: 0.736328125\n",
      "Batch: 26, Loss: 0.727159857749939, Accuracy: 0.7607421875\n",
      "Batch: 27, Loss: 0.7925172448158264, Accuracy: 0.72265625\n",
      "Batch: 28, Loss: 0.8556481599807739, Accuracy: 0.7216796875\n",
      "Batch: 29, Loss: 0.8205720782279968, Accuracy: 0.73828125\n",
      "Batch: 30, Loss: 0.7307805418968201, Accuracy: 0.7734375\n",
      "Batch: 31, Loss: 0.7488096952438354, Accuracy: 0.76171875\n",
      "Batch: 32, Loss: 0.7601110339164734, Accuracy: 0.755859375\n",
      "Batch: 33, Loss: 0.8952735662460327, Accuracy: 0.7158203125\n",
      "Batch: 34, Loss: 0.9620927572250366, Accuracy: 0.6923828125\n",
      "Batch: 35, Loss: 0.8664251565933228, Accuracy: 0.71484375\n",
      "Batch: 36, Loss: 0.8464813828468323, Accuracy: 0.7373046875\n",
      "Batch: 37, Loss: 0.8255941867828369, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.8157421350479126, Accuracy: 0.736328125\n",
      "Batch: 39, Loss: 0.8636372089385986, Accuracy: 0.7099609375\n",
      "Batch: 40, Loss: 0.8160750865936279, Accuracy: 0.7294921875\n",
      "Batch: 41, Loss: 0.8009037971496582, Accuracy: 0.7373046875\n",
      "Batch: 42, Loss: 0.639252245426178, Accuracy: 0.79296875\n",
      "Batch: 43, Loss: 0.8135786056518555, Accuracy: 0.72265625\n",
      "Batch: 44, Loss: 0.847667932510376, Accuracy: 0.7216796875\n",
      "Batch: 45, Loss: 0.7169634699821472, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.7615158557891846, Accuracy: 0.7529296875\n",
      "Batch: 47, Loss: 0.7587957382202148, Accuracy: 0.7568359375\n",
      "Batch: 48, Loss: 0.7257159352302551, Accuracy: 0.7685546875\n",
      "Batch: 49, Loss: 0.8986547589302063, Accuracy: 0.7021484375\n",
      "Batch: 50, Loss: 0.836596667766571, Accuracy: 0.73046875\n",
      "Batch: 51, Loss: 0.9126588702201843, Accuracy: 0.7001953125\n",
      "Batch: 52, Loss: 0.8406254053115845, Accuracy: 0.7333984375\n",
      "Batch: 53, Loss: 0.7408360242843628, Accuracy: 0.755859375\n",
      "Batch: 54, Loss: 0.7971637845039368, Accuracy: 0.734375\n",
      "Batch: 55, Loss: 0.8929349184036255, Accuracy: 0.6982421875\n",
      "Batch: 56, Loss: 0.8824590444564819, Accuracy: 0.7177734375\n",
      "Batch: 57, Loss: 0.8236790895462036, Accuracy: 0.7392578125\n",
      "Batch: 58, Loss: 0.9275454878807068, Accuracy: 0.7158203125\n",
      "Batch: 59, Loss: 0.7897342443466187, Accuracy: 0.7421875\n",
      "Batch: 60, Loss: 0.7606991529464722, Accuracy: 0.755859375\n",
      "Batch: 61, Loss: 0.848212718963623, Accuracy: 0.7294921875\n",
      "Batch: 62, Loss: 0.7637413740158081, Accuracy: 0.763671875\n",
      "Batch: 63, Loss: 0.8291984796524048, Accuracy: 0.73046875\n",
      "Batch: 64, Loss: 0.7742742300033569, Accuracy: 0.751953125\n",
      "Batch: 65, Loss: 0.8355329036712646, Accuracy: 0.73046875\n",
      "Batch: 66, Loss: 0.8060951232910156, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.8610641956329346, Accuracy: 0.7294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 68, Loss: 0.903061032295227, Accuracy: 0.716796875\n",
      "Batch: 69, Loss: 0.8639223575592041, Accuracy: 0.7255859375\n",
      "Batch: 70, Loss: 0.8224933743476868, Accuracy: 0.748046875\n",
      "Batch: 71, Loss: 0.8391435146331787, Accuracy: 0.724609375\n",
      "Batch: 72, Loss: 0.7314120531082153, Accuracy: 0.759765625\n",
      "Batch: 73, Loss: 0.7360701560974121, Accuracy: 0.767578125\n",
      "Batch: 74, Loss: 0.7170314192771912, Accuracy: 0.787109375\n",
      "Batch: 75, Loss: 0.7209815979003906, Accuracy: 0.7646484375\n",
      "Batch: 76, Loss: 0.7915995121002197, Accuracy: 0.7431640625\n",
      "Batch: 77, Loss: 0.7737191915512085, Accuracy: 0.7548828125\n",
      "Batch: 78, Loss: 0.7546054124832153, Accuracy: 0.7607421875\n",
      "Batch: 79, Loss: 0.7257288694381714, Accuracy: 0.771484375\n",
      "Batch: 80, Loss: 0.7437705397605896, Accuracy: 0.7470703125\n",
      "Batch: 81, Loss: 0.8797914981842041, Accuracy: 0.693359375\n",
      "Batch: 82, Loss: 0.8094288110733032, Accuracy: 0.7275390625\n",
      "Batch: 83, Loss: 0.7094361782073975, Accuracy: 0.775390625\n",
      "Batch: 84, Loss: 0.8122023940086365, Accuracy: 0.736328125\n",
      "Batch: 85, Loss: 0.7496304512023926, Accuracy: 0.767578125\n",
      "Batch: 86, Loss: 0.9388307332992554, Accuracy: 0.712890625\n",
      "Batch: 87, Loss: 0.733051061630249, Accuracy: 0.7734375\n",
      "Batch: 88, Loss: 0.8757315874099731, Accuracy: 0.740234375\n",
      "Batch: 89, Loss: 0.8454094529151917, Accuracy: 0.7412109375\n",
      "Batch: 90, Loss: 0.7621452808380127, Accuracy: 0.7578125\n",
      "Batch: 91, Loss: 0.8003810048103333, Accuracy: 0.7236328125\n",
      "Batch: 92, Loss: 0.8391752243041992, Accuracy: 0.732421875\n",
      "Batch: 93, Loss: 0.7764022350311279, Accuracy: 0.751953125\n",
      "Batch: 94, Loss: 0.7935099005699158, Accuracy: 0.7373046875\n",
      "Batch: 95, Loss: 0.8257059454917908, Accuracy: 0.7080078125\n",
      "Batch: 96, Loss: 0.7929267883300781, Accuracy: 0.73828125\n",
      "Batch: 97, Loss: 0.6816416382789612, Accuracy: 0.775390625\n",
      "Batch: 98, Loss: 0.7368136644363403, Accuracy: 0.7607421875\n",
      "Batch: 99, Loss: 0.7774730920791626, Accuracy: 0.759765625\n",
      "Batch: 100, Loss: 0.7979267239570618, Accuracy: 0.7412109375\n",
      "Batch: 101, Loss: 0.8444122076034546, Accuracy: 0.7392578125\n",
      "Batch: 102, Loss: 0.7812505960464478, Accuracy: 0.751953125\n",
      "Batch: 103, Loss: 0.8086066246032715, Accuracy: 0.751953125\n",
      "Batch: 104, Loss: 0.7411618828773499, Accuracy: 0.7548828125\n",
      "Batch: 105, Loss: 0.8487964868545532, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.7533236742019653, Accuracy: 0.759765625\n",
      "Batch: 107, Loss: 0.812505304813385, Accuracy: 0.75\n",
      "Batch: 108, Loss: 0.8028295636177063, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.9150159955024719, Accuracy: 0.7138671875\n",
      "Batch: 110, Loss: 0.7101457715034485, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.8495213985443115, Accuracy: 0.72265625\n",
      "Batch: 112, Loss: 0.8003425598144531, Accuracy: 0.74609375\n",
      "Batch: 113, Loss: 0.8094172477722168, Accuracy: 0.751953125\n",
      "Batch: 114, Loss: 0.9030147194862366, Accuracy: 0.7021484375\n",
      "Batch: 115, Loss: 0.9027043581008911, Accuracy: 0.71484375\n",
      "Batch: 116, Loss: 0.8273972868919373, Accuracy: 0.7314453125\n",
      "Batch: 117, Loss: 0.8226792812347412, Accuracy: 0.728515625\n",
      "Batch: 118, Loss: 0.760557234287262, Accuracy: 0.7685546875\n",
      "Batch: 119, Loss: 0.7213115096092224, Accuracy: 0.783203125\n",
      "Batch: 120, Loss: 0.8142353296279907, Accuracy: 0.7392578125\n",
      "Batch: 121, Loss: 0.8827046155929565, Accuracy: 0.7236328125\n",
      "Batch: 122, Loss: 0.8105084896087646, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.8039400577545166, Accuracy: 0.7470703125\n",
      "Batch: 124, Loss: 0.8542391061782837, Accuracy: 0.7216796875\n",
      "Batch: 125, Loss: 0.8550438284873962, Accuracy: 0.716796875\n",
      "Batch: 126, Loss: 0.797940731048584, Accuracy: 0.748046875\n",
      "Batch: 127, Loss: 0.7203461527824402, Accuracy: 0.7763671875\n",
      "Batch: 128, Loss: 0.9055989980697632, Accuracy: 0.7060546875\n",
      "Batch: 129, Loss: 0.7740001678466797, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 0.9402896165847778, Accuracy: 0.6904296875\n",
      "Batch: 131, Loss: 0.8812280893325806, Accuracy: 0.72265625\n",
      "Batch: 132, Loss: 0.8495358228683472, Accuracy: 0.7333984375\n",
      "Batch: 133, Loss: 0.7765125036239624, Accuracy: 0.732421875\n",
      "Batch: 134, Loss: 0.8461936712265015, Accuracy: 0.712890625\n",
      "Batch: 135, Loss: 0.7393934726715088, Accuracy: 0.771484375\n",
      "Batch: 136, Loss: 0.8206356167793274, Accuracy: 0.7314453125\n",
      "Batch: 137, Loss: 0.8035780191421509, Accuracy: 0.7197265625\n",
      "Batch: 138, Loss: 0.6897535920143127, Accuracy: 0.787109375\n",
      "Batch: 139, Loss: 0.7823613286018372, Accuracy: 0.744140625\n",
      "Batch: 140, Loss: 0.8054182529449463, Accuracy: 0.732421875\n",
      "Batch: 141, Loss: 0.8523017168045044, Accuracy: 0.7373046875\n",
      "Batch: 142, Loss: 0.8556875586509705, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.8353424072265625, Accuracy: 0.7275390625\n",
      "Batch: 144, Loss: 0.8251484632492065, Accuracy: 0.740234375\n",
      "Batch: 145, Loss: 0.7666498422622681, Accuracy: 0.736328125\n",
      "Batch: 146, Loss: 0.8528138399124146, Accuracy: 0.720703125\n",
      "Batch: 147, Loss: 0.8157790303230286, Accuracy: 0.748046875\n",
      "Batch: 148, Loss: 0.9550911784172058, Accuracy: 0.6904296875\n",
      "Batch: 149, Loss: 0.8152563571929932, Accuracy: 0.7275390625\n",
      "Batch: 150, Loss: 0.7930365800857544, Accuracy: 0.7451171875\n",
      "Batch: 151, Loss: 0.726197361946106, Accuracy: 0.763671875\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/80\n",
      "Batch: 1, Loss: 1.0634682178497314, Accuracy: 0.666015625\n",
      "Batch: 2, Loss: 0.9111647009849548, Accuracy: 0.6806640625\n",
      "Batch: 3, Loss: 0.7839498519897461, Accuracy: 0.7373046875\n",
      "Batch: 4, Loss: 0.7294080257415771, Accuracy: 0.76171875\n",
      "Batch: 5, Loss: 0.7548669576644897, Accuracy: 0.7587890625\n",
      "Batch: 6, Loss: 0.8115845918655396, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.848818302154541, Accuracy: 0.71875\n",
      "Batch: 8, Loss: 0.7531259059906006, Accuracy: 0.7392578125\n",
      "Batch: 9, Loss: 0.7645606994628906, Accuracy: 0.7509765625\n",
      "Batch: 10, Loss: 0.7546535134315491, Accuracy: 0.7421875\n",
      "Batch: 11, Loss: 0.870173454284668, Accuracy: 0.7177734375\n",
      "Batch: 12, Loss: 0.891599714756012, Accuracy: 0.7021484375\n",
      "Batch: 13, Loss: 0.6423612833023071, Accuracy: 0.794921875\n",
      "Batch: 14, Loss: 0.9125470519065857, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.7382605075836182, Accuracy: 0.7880859375\n",
      "Batch: 16, Loss: 0.7843987345695496, Accuracy: 0.7509765625\n",
      "Batch: 17, Loss: 0.8751976490020752, Accuracy: 0.7216796875\n",
      "Batch: 18, Loss: 0.8289365172386169, Accuracy: 0.73828125\n",
      "Batch: 19, Loss: 0.8716555833816528, Accuracy: 0.7294921875\n",
      "Batch: 20, Loss: 0.7414978742599487, Accuracy: 0.759765625\n",
      "Batch: 21, Loss: 0.7759578227996826, Accuracy: 0.732421875\n",
      "Batch: 22, Loss: 0.8808465003967285, Accuracy: 0.73046875\n",
      "Batch: 23, Loss: 0.8539477586746216, Accuracy: 0.7138671875\n",
      "Batch: 24, Loss: 0.8237497806549072, Accuracy: 0.736328125\n",
      "Batch: 25, Loss: 0.8259708881378174, Accuracy: 0.74609375\n",
      "Batch: 26, Loss: 0.7027773857116699, Accuracy: 0.77734375\n",
      "Batch: 27, Loss: 0.7438143491744995, Accuracy: 0.740234375\n",
      "Batch: 28, Loss: 0.8196730613708496, Accuracy: 0.7265625\n",
      "Batch: 29, Loss: 0.8245993852615356, Accuracy: 0.7333984375\n",
      "Batch: 30, Loss: 0.7236767411231995, Accuracy: 0.775390625\n",
      "Batch: 31, Loss: 0.7248572111129761, Accuracy: 0.765625\n",
      "Batch: 32, Loss: 0.748525857925415, Accuracy: 0.75390625\n",
      "Batch: 33, Loss: 0.8584526777267456, Accuracy: 0.728515625\n",
      "Batch: 34, Loss: 0.971677839756012, Accuracy: 0.6845703125\n",
      "Batch: 35, Loss: 0.8087637424468994, Accuracy: 0.74609375\n",
      "Batch: 36, Loss: 0.8399072885513306, Accuracy: 0.7490234375\n",
      "Batch: 37, Loss: 0.8115148544311523, Accuracy: 0.736328125\n",
      "Batch: 38, Loss: 0.8198774456977844, Accuracy: 0.7216796875\n",
      "Batch: 39, Loss: 0.8278176188468933, Accuracy: 0.7373046875\n",
      "Batch: 40, Loss: 0.7891803979873657, Accuracy: 0.7412109375\n",
      "Batch: 41, Loss: 0.773628830909729, Accuracy: 0.7490234375\n",
      "Batch: 42, Loss: 0.6187491416931152, Accuracy: 0.8017578125\n",
      "Batch: 43, Loss: 0.7948520183563232, Accuracy: 0.7265625\n",
      "Batch: 44, Loss: 0.7769306302070618, Accuracy: 0.7412109375\n",
      "Batch: 45, Loss: 0.7265933752059937, Accuracy: 0.751953125\n",
      "Batch: 46, Loss: 0.7484650611877441, Accuracy: 0.7607421875\n",
      "Batch: 47, Loss: 0.7790960073471069, Accuracy: 0.75390625\n",
      "Batch: 48, Loss: 0.7192308902740479, Accuracy: 0.765625\n",
      "Batch: 49, Loss: 0.8808887004852295, Accuracy: 0.712890625\n",
      "Batch: 50, Loss: 0.8494218587875366, Accuracy: 0.7314453125\n",
      "Batch: 51, Loss: 0.8822181820869446, Accuracy: 0.7177734375\n",
      "Batch: 52, Loss: 0.8510379791259766, Accuracy: 0.7294921875\n",
      "Batch: 53, Loss: 0.7222268581390381, Accuracy: 0.7587890625\n",
      "Batch: 54, Loss: 0.769263505935669, Accuracy: 0.7431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 0.8692798018455505, Accuracy: 0.7060546875\n",
      "Batch: 56, Loss: 0.8492908477783203, Accuracy: 0.7158203125\n",
      "Batch: 57, Loss: 0.8365052938461304, Accuracy: 0.7265625\n",
      "Batch: 58, Loss: 0.888900637626648, Accuracy: 0.7236328125\n",
      "Batch: 59, Loss: 0.777271032333374, Accuracy: 0.7470703125\n",
      "Batch: 60, Loss: 0.7286146879196167, Accuracy: 0.7587890625\n",
      "Batch: 61, Loss: 0.840570867061615, Accuracy: 0.7216796875\n",
      "Batch: 62, Loss: 0.7630316019058228, Accuracy: 0.7578125\n",
      "Batch: 63, Loss: 0.8246454000473022, Accuracy: 0.73828125\n",
      "Batch: 64, Loss: 0.7806607484817505, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.7654798626899719, Accuracy: 0.7646484375\n",
      "Batch: 66, Loss: 0.785342276096344, Accuracy: 0.74609375\n",
      "Batch: 67, Loss: 0.8298401832580566, Accuracy: 0.7412109375\n",
      "Batch: 68, Loss: 0.8930320739746094, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8648560047149658, Accuracy: 0.7109375\n",
      "Batch: 70, Loss: 0.820349931716919, Accuracy: 0.751953125\n",
      "Batch: 71, Loss: 0.8169617056846619, Accuracy: 0.7333984375\n",
      "Batch: 72, Loss: 0.6996023654937744, Accuracy: 0.7763671875\n",
      "Batch: 73, Loss: 0.7174742221832275, Accuracy: 0.775390625\n",
      "Batch: 74, Loss: 0.7020611763000488, Accuracy: 0.7939453125\n",
      "Batch: 75, Loss: 0.7063446044921875, Accuracy: 0.76953125\n",
      "Batch: 76, Loss: 0.815138578414917, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.7475848197937012, Accuracy: 0.7529296875\n",
      "Batch: 78, Loss: 0.7589869499206543, Accuracy: 0.767578125\n",
      "Batch: 79, Loss: 0.7277045249938965, Accuracy: 0.767578125\n",
      "Batch: 80, Loss: 0.7386767268180847, Accuracy: 0.763671875\n",
      "Batch: 81, Loss: 0.8551653623580933, Accuracy: 0.7138671875\n",
      "Batch: 82, Loss: 0.812734842300415, Accuracy: 0.736328125\n",
      "Batch: 83, Loss: 0.6782538294792175, Accuracy: 0.79296875\n",
      "Batch: 84, Loss: 0.8127574920654297, Accuracy: 0.744140625\n",
      "Batch: 85, Loss: 0.7370003461837769, Accuracy: 0.7626953125\n",
      "Batch: 86, Loss: 0.9168844223022461, Accuracy: 0.7197265625\n",
      "Batch: 87, Loss: 0.7399672269821167, Accuracy: 0.765625\n",
      "Batch: 88, Loss: 0.8934733867645264, Accuracy: 0.736328125\n",
      "Batch: 89, Loss: 0.823181688785553, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.754538893699646, Accuracy: 0.767578125\n",
      "Batch: 91, Loss: 0.786881685256958, Accuracy: 0.7470703125\n",
      "Batch: 92, Loss: 0.8119698166847229, Accuracy: 0.7421875\n",
      "Batch: 93, Loss: 0.7478211522102356, Accuracy: 0.755859375\n",
      "Batch: 94, Loss: 0.7772781848907471, Accuracy: 0.7431640625\n",
      "Batch: 95, Loss: 0.832727313041687, Accuracy: 0.716796875\n",
      "Batch: 96, Loss: 0.7910212278366089, Accuracy: 0.7314453125\n",
      "Batch: 97, Loss: 0.6747375726699829, Accuracy: 0.77734375\n",
      "Batch: 98, Loss: 0.7645771503448486, Accuracy: 0.7529296875\n",
      "Batch: 99, Loss: 0.734248161315918, Accuracy: 0.75\n",
      "Batch: 100, Loss: 0.7885711193084717, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.8444838523864746, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.7765809893608093, Accuracy: 0.755859375\n",
      "Batch: 103, Loss: 0.823844313621521, Accuracy: 0.7529296875\n",
      "Batch: 104, Loss: 0.7306146025657654, Accuracy: 0.75\n",
      "Batch: 105, Loss: 0.8273946046829224, Accuracy: 0.744140625\n",
      "Batch: 106, Loss: 0.7680919766426086, Accuracy: 0.76171875\n",
      "Batch: 107, Loss: 0.7980404496192932, Accuracy: 0.74609375\n",
      "Batch: 108, Loss: 0.8071200847625732, Accuracy: 0.73046875\n",
      "Batch: 109, Loss: 0.8912164568901062, Accuracy: 0.720703125\n",
      "Batch: 110, Loss: 0.6846942901611328, Accuracy: 0.783203125\n",
      "Batch: 111, Loss: 0.8328431844711304, Accuracy: 0.7236328125\n",
      "Batch: 112, Loss: 0.7813360691070557, Accuracy: 0.751953125\n",
      "Batch: 113, Loss: 0.7779591083526611, Accuracy: 0.7509765625\n",
      "Batch: 114, Loss: 0.9208692312240601, Accuracy: 0.70703125\n",
      "Batch: 115, Loss: 0.8860754370689392, Accuracy: 0.7275390625\n",
      "Batch: 116, Loss: 0.8326499462127686, Accuracy: 0.7275390625\n",
      "Batch: 117, Loss: 0.8354945182800293, Accuracy: 0.7158203125\n",
      "Batch: 118, Loss: 0.7337555289268494, Accuracy: 0.775390625\n",
      "Batch: 119, Loss: 0.6962434649467468, Accuracy: 0.77734375\n",
      "Batch: 120, Loss: 0.7918788194656372, Accuracy: 0.7490234375\n",
      "Batch: 121, Loss: 0.8699530959129333, Accuracy: 0.7177734375\n",
      "Batch: 122, Loss: 0.7646549940109253, Accuracy: 0.7626953125\n",
      "Batch: 123, Loss: 0.7685754895210266, Accuracy: 0.7626953125\n",
      "Batch: 124, Loss: 0.8279761672019958, Accuracy: 0.7265625\n",
      "Batch: 125, Loss: 0.8268120288848877, Accuracy: 0.7373046875\n",
      "Batch: 126, Loss: 0.8124455213546753, Accuracy: 0.7373046875\n",
      "Batch: 127, Loss: 0.7097298502922058, Accuracy: 0.7861328125\n",
      "Batch: 128, Loss: 0.8851104974746704, Accuracy: 0.7529296875\n",
      "Batch: 129, Loss: 0.7582824230194092, Accuracy: 0.7685546875\n",
      "Batch: 130, Loss: 0.9255819916725159, Accuracy: 0.7041015625\n",
      "Batch: 131, Loss: 0.854357123374939, Accuracy: 0.720703125\n",
      "Batch: 132, Loss: 0.8364970684051514, Accuracy: 0.72265625\n",
      "Batch: 133, Loss: 0.7884970903396606, Accuracy: 0.7373046875\n",
      "Batch: 134, Loss: 0.8429521918296814, Accuracy: 0.7177734375\n",
      "Batch: 135, Loss: 0.7278344631195068, Accuracy: 0.7666015625\n",
      "Batch: 136, Loss: 0.8449090719223022, Accuracy: 0.7421875\n",
      "Batch: 137, Loss: 0.8010579347610474, Accuracy: 0.732421875\n",
      "Batch: 138, Loss: 0.6838520765304565, Accuracy: 0.78125\n",
      "Batch: 139, Loss: 0.8027575016021729, Accuracy: 0.744140625\n",
      "Batch: 140, Loss: 0.7779818773269653, Accuracy: 0.7392578125\n",
      "Batch: 141, Loss: 0.856237530708313, Accuracy: 0.7255859375\n",
      "Batch: 142, Loss: 0.8363301753997803, Accuracy: 0.7392578125\n",
      "Batch: 143, Loss: 0.8345226049423218, Accuracy: 0.7265625\n",
      "Batch: 144, Loss: 0.8327065706253052, Accuracy: 0.7177734375\n",
      "Batch: 145, Loss: 0.7889946699142456, Accuracy: 0.720703125\n",
      "Batch: 146, Loss: 0.8375394344329834, Accuracy: 0.7255859375\n",
      "Batch: 147, Loss: 0.811832845211029, Accuracy: 0.7333984375\n",
      "Batch: 148, Loss: 0.922091007232666, Accuracy: 0.701171875\n",
      "Batch: 149, Loss: 0.8122710585594177, Accuracy: 0.7333984375\n",
      "Batch: 150, Loss: 0.7879281044006348, Accuracy: 0.736328125\n",
      "Batch: 151, Loss: 0.7292478084564209, Accuracy: 0.7587890625\n",
      "Epoch 32/80\n",
      "Batch: 1, Loss: 1.0259159803390503, Accuracy: 0.66796875\n",
      "Batch: 2, Loss: 0.9079317450523376, Accuracy: 0.705078125\n",
      "Batch: 3, Loss: 0.7770283222198486, Accuracy: 0.7421875\n",
      "Batch: 4, Loss: 0.7381048798561096, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.7327611446380615, Accuracy: 0.7587890625\n",
      "Batch: 6, Loss: 0.8122519850730896, Accuracy: 0.734375\n",
      "Batch: 7, Loss: 0.8067615032196045, Accuracy: 0.7373046875\n",
      "Batch: 8, Loss: 0.7479923963546753, Accuracy: 0.7490234375\n",
      "Batch: 9, Loss: 0.7579171061515808, Accuracy: 0.74609375\n",
      "Batch: 10, Loss: 0.7591750621795654, Accuracy: 0.744140625\n",
      "Batch: 11, Loss: 0.8729528784751892, Accuracy: 0.7236328125\n",
      "Batch: 12, Loss: 0.8676352500915527, Accuracy: 0.7138671875\n",
      "Batch: 13, Loss: 0.6684850454330444, Accuracy: 0.791015625\n",
      "Batch: 14, Loss: 0.8703000545501709, Accuracy: 0.71484375\n",
      "Batch: 15, Loss: 0.7548147439956665, Accuracy: 0.759765625\n",
      "Batch: 16, Loss: 0.7561878561973572, Accuracy: 0.7705078125\n",
      "Batch: 17, Loss: 0.8073666095733643, Accuracy: 0.7392578125\n",
      "Batch: 18, Loss: 0.8432456851005554, Accuracy: 0.7373046875\n",
      "Batch: 19, Loss: 0.8380374312400818, Accuracy: 0.734375\n",
      "Batch: 20, Loss: 0.7313611507415771, Accuracy: 0.7705078125\n",
      "Batch: 21, Loss: 0.764697790145874, Accuracy: 0.7431640625\n",
      "Batch: 22, Loss: 0.8527889847755432, Accuracy: 0.73828125\n",
      "Batch: 23, Loss: 0.839522659778595, Accuracy: 0.7265625\n",
      "Batch: 24, Loss: 0.8320547342300415, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.7988232374191284, Accuracy: 0.759765625\n",
      "Batch: 26, Loss: 0.7087980508804321, Accuracy: 0.7744140625\n",
      "Batch: 27, Loss: 0.737129807472229, Accuracy: 0.7451171875\n",
      "Batch: 28, Loss: 0.7951031923294067, Accuracy: 0.7373046875\n",
      "Batch: 29, Loss: 0.7855441570281982, Accuracy: 0.748046875\n",
      "Batch: 30, Loss: 0.7110555171966553, Accuracy: 0.78125\n",
      "Batch: 31, Loss: 0.7069857716560364, Accuracy: 0.7666015625\n",
      "Batch: 32, Loss: 0.7101353406906128, Accuracy: 0.7646484375\n",
      "Batch: 33, Loss: 0.8499188423156738, Accuracy: 0.7333984375\n",
      "Batch: 34, Loss: 0.9273287057876587, Accuracy: 0.6962890625\n",
      "Batch: 35, Loss: 0.7887526750564575, Accuracy: 0.75\n",
      "Batch: 36, Loss: 0.8217121362686157, Accuracy: 0.7626953125\n",
      "Batch: 37, Loss: 0.8132892847061157, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.807076632976532, Accuracy: 0.7314453125\n",
      "Batch: 39, Loss: 0.8288130760192871, Accuracy: 0.7353515625\n",
      "Batch: 40, Loss: 0.7886092066764832, Accuracy: 0.7412109375\n",
      "Batch: 41, Loss: 0.7548918724060059, Accuracy: 0.76171875\n",
      "Batch: 42, Loss: 0.6269745826721191, Accuracy: 0.78515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 43, Loss: 0.7757954597473145, Accuracy: 0.7392578125\n",
      "Batch: 44, Loss: 0.8213926553726196, Accuracy: 0.732421875\n",
      "Batch: 45, Loss: 0.6909691095352173, Accuracy: 0.7744140625\n",
      "Batch: 46, Loss: 0.7339612245559692, Accuracy: 0.77734375\n",
      "Batch: 47, Loss: 0.7668005228042603, Accuracy: 0.7626953125\n",
      "Batch: 48, Loss: 0.710931122303009, Accuracy: 0.7724609375\n",
      "Batch: 49, Loss: 0.8247646689414978, Accuracy: 0.7373046875\n",
      "Batch: 50, Loss: 0.820561408996582, Accuracy: 0.7275390625\n",
      "Batch: 51, Loss: 0.8970315456390381, Accuracy: 0.7265625\n",
      "Batch: 52, Loss: 0.836866557598114, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.7283034324645996, Accuracy: 0.7587890625\n",
      "Batch: 54, Loss: 0.7866291999816895, Accuracy: 0.7412109375\n",
      "Batch: 55, Loss: 0.8523953557014465, Accuracy: 0.7294921875\n",
      "Batch: 56, Loss: 0.8802545666694641, Accuracy: 0.7177734375\n",
      "Batch: 57, Loss: 0.8011766076087952, Accuracy: 0.7333984375\n",
      "Batch: 58, Loss: 0.886540412902832, Accuracy: 0.724609375\n",
      "Batch: 59, Loss: 0.7774001955986023, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.7137748003005981, Accuracy: 0.7705078125\n",
      "Batch: 61, Loss: 0.8138678073883057, Accuracy: 0.7333984375\n",
      "Batch: 62, Loss: 0.742090106010437, Accuracy: 0.7734375\n",
      "Batch: 63, Loss: 0.7961118221282959, Accuracy: 0.748046875\n",
      "Batch: 64, Loss: 0.8093106746673584, Accuracy: 0.740234375\n",
      "Batch: 65, Loss: 0.7980401515960693, Accuracy: 0.7568359375\n",
      "Batch: 66, Loss: 0.7673171162605286, Accuracy: 0.7607421875\n",
      "Batch: 67, Loss: 0.8356503248214722, Accuracy: 0.7373046875\n",
      "Batch: 68, Loss: 0.885748565196991, Accuracy: 0.7275390625\n",
      "Batch: 69, Loss: 0.840133547782898, Accuracy: 0.7138671875\n",
      "Batch: 70, Loss: 0.8046629428863525, Accuracy: 0.7607421875\n",
      "Batch: 71, Loss: 0.8108493685722351, Accuracy: 0.7216796875\n",
      "Batch: 72, Loss: 0.7062456011772156, Accuracy: 0.775390625\n",
      "Batch: 73, Loss: 0.7475078105926514, Accuracy: 0.7607421875\n",
      "Batch: 74, Loss: 0.7018824815750122, Accuracy: 0.7783203125\n",
      "Batch: 75, Loss: 0.6926829814910889, Accuracy: 0.771484375\n",
      "Batch: 76, Loss: 0.7939252853393555, Accuracy: 0.736328125\n",
      "Batch: 77, Loss: 0.7386821508407593, Accuracy: 0.7607421875\n",
      "Batch: 78, Loss: 0.7445916533470154, Accuracy: 0.755859375\n",
      "Batch: 79, Loss: 0.7186589241027832, Accuracy: 0.79296875\n",
      "Batch: 80, Loss: 0.7316089868545532, Accuracy: 0.75390625\n",
      "Batch: 81, Loss: 0.8437625169754028, Accuracy: 0.701171875\n",
      "Batch: 82, Loss: 0.8115843534469604, Accuracy: 0.73828125\n",
      "Batch: 83, Loss: 0.6756428480148315, Accuracy: 0.7822265625\n",
      "Batch: 84, Loss: 0.7845988273620605, Accuracy: 0.751953125\n",
      "Batch: 85, Loss: 0.7223228216171265, Accuracy: 0.7744140625\n",
      "Batch: 86, Loss: 0.9186981916427612, Accuracy: 0.712890625\n",
      "Batch: 87, Loss: 0.7041991353034973, Accuracy: 0.76171875\n",
      "Batch: 88, Loss: 0.8485137820243835, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.7772518396377563, Accuracy: 0.7490234375\n",
      "Batch: 90, Loss: 0.7547060251235962, Accuracy: 0.76171875\n",
      "Batch: 91, Loss: 0.749748945236206, Accuracy: 0.74609375\n",
      "Batch: 92, Loss: 0.8009485602378845, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.7544134855270386, Accuracy: 0.7578125\n",
      "Batch: 94, Loss: 0.7756547927856445, Accuracy: 0.7529296875\n",
      "Batch: 95, Loss: 0.8023280501365662, Accuracy: 0.7255859375\n",
      "Batch: 96, Loss: 0.7491525411605835, Accuracy: 0.7490234375\n",
      "Batch: 97, Loss: 0.6627190113067627, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.7368825078010559, Accuracy: 0.751953125\n",
      "Batch: 99, Loss: 0.7223522067070007, Accuracy: 0.759765625\n",
      "Batch: 100, Loss: 0.7592966556549072, Accuracy: 0.7451171875\n",
      "Batch: 101, Loss: 0.840458869934082, Accuracy: 0.720703125\n",
      "Batch: 102, Loss: 0.7782681584358215, Accuracy: 0.740234375\n",
      "Batch: 103, Loss: 0.8081271648406982, Accuracy: 0.748046875\n",
      "Batch: 104, Loss: 0.731492817401886, Accuracy: 0.7578125\n",
      "Batch: 105, Loss: 0.8017828464508057, Accuracy: 0.748046875\n",
      "Batch: 106, Loss: 0.7446938157081604, Accuracy: 0.759765625\n",
      "Batch: 107, Loss: 0.7671051025390625, Accuracy: 0.7587890625\n",
      "Batch: 108, Loss: 0.7896360158920288, Accuracy: 0.740234375\n",
      "Batch: 109, Loss: 0.8804792165756226, Accuracy: 0.7119140625\n",
      "Batch: 110, Loss: 0.6725431680679321, Accuracy: 0.7783203125\n",
      "Batch: 111, Loss: 0.81253582239151, Accuracy: 0.7314453125\n",
      "Batch: 112, Loss: 0.8215337991714478, Accuracy: 0.7490234375\n",
      "Batch: 113, Loss: 0.7955303192138672, Accuracy: 0.7587890625\n",
      "Batch: 114, Loss: 0.8833425641059875, Accuracy: 0.7216796875\n",
      "Batch: 115, Loss: 0.8699416518211365, Accuracy: 0.720703125\n",
      "Batch: 116, Loss: 0.7955054640769958, Accuracy: 0.744140625\n",
      "Batch: 117, Loss: 0.8150514364242554, Accuracy: 0.7333984375\n",
      "Batch: 118, Loss: 0.7079970836639404, Accuracy: 0.783203125\n",
      "Batch: 119, Loss: 0.6913326978683472, Accuracy: 0.7822265625\n",
      "Batch: 120, Loss: 0.7998889088630676, Accuracy: 0.740234375\n",
      "Batch: 121, Loss: 0.8432455062866211, Accuracy: 0.724609375\n",
      "Batch: 122, Loss: 0.7725467681884766, Accuracy: 0.7548828125\n",
      "Batch: 123, Loss: 0.7504602670669556, Accuracy: 0.76171875\n",
      "Batch: 124, Loss: 0.8149712681770325, Accuracy: 0.7421875\n",
      "Batch: 125, Loss: 0.822697639465332, Accuracy: 0.73046875\n",
      "Batch: 126, Loss: 0.8234505653381348, Accuracy: 0.7353515625\n",
      "Batch: 127, Loss: 0.7053537368774414, Accuracy: 0.78125\n",
      "Batch: 128, Loss: 0.8751893043518066, Accuracy: 0.7373046875\n",
      "Batch: 129, Loss: 0.7246856689453125, Accuracy: 0.775390625\n",
      "Batch: 130, Loss: 0.8859480619430542, Accuracy: 0.716796875\n",
      "Batch: 131, Loss: 0.8184815049171448, Accuracy: 0.7216796875\n",
      "Batch: 132, Loss: 0.8237017393112183, Accuracy: 0.7333984375\n",
      "Batch: 133, Loss: 0.771428644657135, Accuracy: 0.7392578125\n",
      "Batch: 134, Loss: 0.8174210786819458, Accuracy: 0.7265625\n",
      "Batch: 135, Loss: 0.731128990650177, Accuracy: 0.7763671875\n",
      "Batch: 136, Loss: 0.8096467852592468, Accuracy: 0.75\n",
      "Batch: 137, Loss: 0.7897683382034302, Accuracy: 0.728515625\n",
      "Batch: 138, Loss: 0.7013585567474365, Accuracy: 0.76953125\n",
      "Batch: 139, Loss: 0.8004215359687805, Accuracy: 0.7216796875\n",
      "Batch: 140, Loss: 0.7793124914169312, Accuracy: 0.7451171875\n",
      "Batch: 141, Loss: 0.8460881114006042, Accuracy: 0.716796875\n",
      "Batch: 142, Loss: 0.8151410818099976, Accuracy: 0.75\n",
      "Batch: 143, Loss: 0.8300338983535767, Accuracy: 0.7353515625\n",
      "Batch: 144, Loss: 0.8207985758781433, Accuracy: 0.7392578125\n",
      "Batch: 145, Loss: 0.7738364934921265, Accuracy: 0.7294921875\n",
      "Batch: 146, Loss: 0.8252576589584351, Accuracy: 0.734375\n",
      "Batch: 147, Loss: 0.8234376907348633, Accuracy: 0.7333984375\n",
      "Batch: 148, Loss: 0.9104152321815491, Accuracy: 0.70703125\n",
      "Batch: 149, Loss: 0.7784264087677002, Accuracy: 0.740234375\n",
      "Batch: 150, Loss: 0.7580551505088806, Accuracy: 0.751953125\n",
      "Batch: 151, Loss: 0.7180763483047485, Accuracy: 0.763671875\n",
      "Epoch 33/80\n",
      "Batch: 1, Loss: 0.984822154045105, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.9005666971206665, Accuracy: 0.6884765625\n",
      "Batch: 3, Loss: 0.7640475034713745, Accuracy: 0.7373046875\n",
      "Batch: 4, Loss: 0.7196842432022095, Accuracy: 0.77734375\n",
      "Batch: 5, Loss: 0.7262460589408875, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7975736856460571, Accuracy: 0.7294921875\n",
      "Batch: 7, Loss: 0.7810044288635254, Accuracy: 0.75\n",
      "Batch: 8, Loss: 0.7383824586868286, Accuracy: 0.767578125\n",
      "Batch: 9, Loss: 0.736062228679657, Accuracy: 0.76171875\n",
      "Batch: 10, Loss: 0.7471129298210144, Accuracy: 0.75\n",
      "Batch: 11, Loss: 0.8513953685760498, Accuracy: 0.73046875\n",
      "Batch: 12, Loss: 0.8521397709846497, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.6549994349479675, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.8666882514953613, Accuracy: 0.7060546875\n",
      "Batch: 15, Loss: 0.7407139539718628, Accuracy: 0.7763671875\n",
      "Batch: 16, Loss: 0.7517307996749878, Accuracy: 0.765625\n",
      "Batch: 17, Loss: 0.8306875228881836, Accuracy: 0.728515625\n",
      "Batch: 18, Loss: 0.8090654611587524, Accuracy: 0.751953125\n",
      "Batch: 19, Loss: 0.8089764714241028, Accuracy: 0.73828125\n",
      "Batch: 20, Loss: 0.7202522158622742, Accuracy: 0.77734375\n",
      "Batch: 21, Loss: 0.7632536888122559, Accuracy: 0.7412109375\n",
      "Batch: 22, Loss: 0.840871274471283, Accuracy: 0.73046875\n",
      "Batch: 23, Loss: 0.8060699105262756, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.7997643351554871, Accuracy: 0.74609375\n",
      "Batch: 25, Loss: 0.7862247228622437, Accuracy: 0.7548828125\n",
      "Batch: 26, Loss: 0.6915379166603088, Accuracy: 0.7607421875\n",
      "Batch: 27, Loss: 0.7278302907943726, Accuracy: 0.744140625\n",
      "Batch: 28, Loss: 0.7867829203605652, Accuracy: 0.720703125\n",
      "Batch: 29, Loss: 0.7867710590362549, Accuracy: 0.724609375\n",
      "Batch: 30, Loss: 0.6930543184280396, Accuracy: 0.77734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31, Loss: 0.7069664001464844, Accuracy: 0.7724609375\n",
      "Batch: 32, Loss: 0.7145665884017944, Accuracy: 0.7724609375\n",
      "Batch: 33, Loss: 0.8413315415382385, Accuracy: 0.7412109375\n",
      "Batch: 34, Loss: 0.8950610160827637, Accuracy: 0.705078125\n",
      "Batch: 35, Loss: 0.8094748258590698, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.8078118562698364, Accuracy: 0.759765625\n",
      "Batch: 37, Loss: 0.8026576638221741, Accuracy: 0.732421875\n",
      "Batch: 38, Loss: 0.7943021059036255, Accuracy: 0.751953125\n",
      "Batch: 39, Loss: 0.8043885827064514, Accuracy: 0.7392578125\n",
      "Batch: 40, Loss: 0.7711703777313232, Accuracy: 0.76171875\n",
      "Batch: 41, Loss: 0.7468619346618652, Accuracy: 0.759765625\n",
      "Batch: 42, Loss: 0.6029967069625854, Accuracy: 0.794921875\n",
      "Batch: 43, Loss: 0.7760512828826904, Accuracy: 0.7412109375\n",
      "Batch: 44, Loss: 0.7994487285614014, Accuracy: 0.732421875\n",
      "Batch: 45, Loss: 0.6734183430671692, Accuracy: 0.77734375\n",
      "Batch: 46, Loss: 0.7173075079917908, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.7394900321960449, Accuracy: 0.7578125\n",
      "Batch: 48, Loss: 0.6988728642463684, Accuracy: 0.7724609375\n",
      "Batch: 49, Loss: 0.8556976318359375, Accuracy: 0.7294921875\n",
      "Batch: 50, Loss: 0.8093451857566833, Accuracy: 0.734375\n",
      "Batch: 51, Loss: 0.8489096164703369, Accuracy: 0.7373046875\n",
      "Batch: 52, Loss: 0.8296750783920288, Accuracy: 0.7412109375\n",
      "Batch: 53, Loss: 0.7230074405670166, Accuracy: 0.759765625\n",
      "Batch: 54, Loss: 0.7744511961936951, Accuracy: 0.740234375\n",
      "Batch: 55, Loss: 0.8362689018249512, Accuracy: 0.732421875\n",
      "Batch: 56, Loss: 0.8423746228218079, Accuracy: 0.7255859375\n",
      "Batch: 57, Loss: 0.8171945214271545, Accuracy: 0.7412109375\n",
      "Batch: 58, Loss: 0.8542402386665344, Accuracy: 0.7255859375\n",
      "Batch: 59, Loss: 0.7188534736633301, Accuracy: 0.7646484375\n",
      "Batch: 60, Loss: 0.7200825810432434, Accuracy: 0.763671875\n",
      "Batch: 61, Loss: 0.8119023442268372, Accuracy: 0.75\n",
      "Batch: 62, Loss: 0.720720648765564, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.8058414459228516, Accuracy: 0.7392578125\n",
      "Batch: 64, Loss: 0.7654482126235962, Accuracy: 0.7529296875\n",
      "Batch: 65, Loss: 0.788750410079956, Accuracy: 0.7607421875\n",
      "Batch: 66, Loss: 0.7649554014205933, Accuracy: 0.76953125\n",
      "Batch: 67, Loss: 0.8224074244499207, Accuracy: 0.7548828125\n",
      "Batch: 68, Loss: 0.8626716136932373, Accuracy: 0.7314453125\n",
      "Batch: 69, Loss: 0.8407700061798096, Accuracy: 0.740234375\n",
      "Batch: 70, Loss: 0.7798765301704407, Accuracy: 0.751953125\n",
      "Batch: 71, Loss: 0.8352857232093811, Accuracy: 0.71875\n",
      "Batch: 72, Loss: 0.7032391428947449, Accuracy: 0.76171875\n",
      "Batch: 73, Loss: 0.7130947113037109, Accuracy: 0.7734375\n",
      "Batch: 74, Loss: 0.6861293911933899, Accuracy: 0.791015625\n",
      "Batch: 75, Loss: 0.678588330745697, Accuracy: 0.7763671875\n",
      "Batch: 76, Loss: 0.7899261713027954, Accuracy: 0.7275390625\n",
      "Batch: 77, Loss: 0.7353282570838928, Accuracy: 0.759765625\n",
      "Batch: 78, Loss: 0.7460041642189026, Accuracy: 0.7568359375\n",
      "Batch: 79, Loss: 0.6662517189979553, Accuracy: 0.791015625\n",
      "Batch: 80, Loss: 0.7453079223632812, Accuracy: 0.7626953125\n",
      "Batch: 81, Loss: 0.8240395784378052, Accuracy: 0.7265625\n",
      "Batch: 82, Loss: 0.8053517937660217, Accuracy: 0.7353515625\n",
      "Batch: 83, Loss: 0.6946660876274109, Accuracy: 0.7919921875\n",
      "Batch: 84, Loss: 0.8182110786437988, Accuracy: 0.7333984375\n",
      "Batch: 85, Loss: 0.7135671377182007, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.9045789837837219, Accuracy: 0.724609375\n",
      "Batch: 87, Loss: 0.692080020904541, Accuracy: 0.787109375\n",
      "Batch: 88, Loss: 0.8392270803451538, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7845211625099182, Accuracy: 0.755859375\n",
      "Batch: 90, Loss: 0.7549093961715698, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7647634148597717, Accuracy: 0.74609375\n",
      "Batch: 92, Loss: 0.7719535827636719, Accuracy: 0.7353515625\n",
      "Batch: 93, Loss: 0.7381304502487183, Accuracy: 0.76171875\n",
      "Batch: 94, Loss: 0.7542903423309326, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.8142590522766113, Accuracy: 0.7216796875\n",
      "Batch: 96, Loss: 0.7553526163101196, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.6415744423866272, Accuracy: 0.7939453125\n",
      "Batch: 98, Loss: 0.7195451855659485, Accuracy: 0.7685546875\n",
      "Batch: 99, Loss: 0.73209148645401, Accuracy: 0.7578125\n",
      "Batch: 100, Loss: 0.7960588335990906, Accuracy: 0.74609375\n",
      "Batch: 101, Loss: 0.8138794898986816, Accuracy: 0.74609375\n",
      "Batch: 102, Loss: 0.7545052766799927, Accuracy: 0.75390625\n",
      "Batch: 103, Loss: 0.7826806902885437, Accuracy: 0.7548828125\n",
      "Batch: 104, Loss: 0.7267431020736694, Accuracy: 0.7578125\n",
      "Batch: 105, Loss: 0.8120605945587158, Accuracy: 0.7431640625\n",
      "Batch: 106, Loss: 0.7368428111076355, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.7554091215133667, Accuracy: 0.7578125\n",
      "Batch: 108, Loss: 0.7779310941696167, Accuracy: 0.7470703125\n",
      "Batch: 109, Loss: 0.887815535068512, Accuracy: 0.712890625\n",
      "Batch: 110, Loss: 0.6922576427459717, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.7838448286056519, Accuracy: 0.73828125\n",
      "Batch: 112, Loss: 0.7819945812225342, Accuracy: 0.75390625\n",
      "Batch: 113, Loss: 0.8159514665603638, Accuracy: 0.7421875\n",
      "Batch: 114, Loss: 0.8753048181533813, Accuracy: 0.728515625\n",
      "Batch: 115, Loss: 0.8755466341972351, Accuracy: 0.7294921875\n",
      "Batch: 116, Loss: 0.8064416646957397, Accuracy: 0.7421875\n",
      "Batch: 117, Loss: 0.8254272937774658, Accuracy: 0.73046875\n",
      "Batch: 118, Loss: 0.7128013968467712, Accuracy: 0.7646484375\n",
      "Batch: 119, Loss: 0.702788233757019, Accuracy: 0.78515625\n",
      "Batch: 120, Loss: 0.7889443635940552, Accuracy: 0.7373046875\n",
      "Batch: 121, Loss: 0.8569522500038147, Accuracy: 0.712890625\n",
      "Batch: 122, Loss: 0.755312979221344, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.7589806318283081, Accuracy: 0.759765625\n",
      "Batch: 124, Loss: 0.8141123056411743, Accuracy: 0.734375\n",
      "Batch: 125, Loss: 0.8413310647010803, Accuracy: 0.7216796875\n",
      "Batch: 126, Loss: 0.8183233737945557, Accuracy: 0.734375\n",
      "Batch: 127, Loss: 0.7031348943710327, Accuracy: 0.791015625\n",
      "Batch: 128, Loss: 0.8658978939056396, Accuracy: 0.7294921875\n",
      "Batch: 129, Loss: 0.738972008228302, Accuracy: 0.7626953125\n",
      "Batch: 130, Loss: 0.8772149085998535, Accuracy: 0.724609375\n",
      "Batch: 131, Loss: 0.8189045786857605, Accuracy: 0.7236328125\n",
      "Batch: 132, Loss: 0.8147855997085571, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.7738912105560303, Accuracy: 0.7431640625\n",
      "Batch: 134, Loss: 0.8467167615890503, Accuracy: 0.72265625\n",
      "Batch: 135, Loss: 0.7248605489730835, Accuracy: 0.775390625\n",
      "Batch: 136, Loss: 0.8177515268325806, Accuracy: 0.7490234375\n",
      "Batch: 137, Loss: 0.7987474203109741, Accuracy: 0.7373046875\n",
      "Batch: 138, Loss: 0.6920779347419739, Accuracy: 0.7705078125\n",
      "Batch: 139, Loss: 0.7801437377929688, Accuracy: 0.7373046875\n",
      "Batch: 140, Loss: 0.7377324104309082, Accuracy: 0.748046875\n",
      "Batch: 141, Loss: 0.8094470500946045, Accuracy: 0.734375\n",
      "Batch: 142, Loss: 0.8486254811286926, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.8081713914871216, Accuracy: 0.7265625\n",
      "Batch: 144, Loss: 0.8024507761001587, Accuracy: 0.7353515625\n",
      "Batch: 145, Loss: 0.7520859837532043, Accuracy: 0.740234375\n",
      "Batch: 146, Loss: 0.8031140565872192, Accuracy: 0.7412109375\n",
      "Batch: 147, Loss: 0.8042206764221191, Accuracy: 0.744140625\n",
      "Batch: 148, Loss: 0.9082522392272949, Accuracy: 0.7119140625\n",
      "Batch: 149, Loss: 0.7570608854293823, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.7644528746604919, Accuracy: 0.7490234375\n",
      "Batch: 151, Loss: 0.7065036296844482, Accuracy: 0.7666015625\n",
      "Epoch 34/80\n",
      "Batch: 1, Loss: 0.9894984364509583, Accuracy: 0.681640625\n",
      "Batch: 2, Loss: 0.8704320192337036, Accuracy: 0.69921875\n",
      "Batch: 3, Loss: 0.7550284266471863, Accuracy: 0.740234375\n",
      "Batch: 4, Loss: 0.7106052041053772, Accuracy: 0.7861328125\n",
      "Batch: 5, Loss: 0.7270326614379883, Accuracy: 0.767578125\n",
      "Batch: 6, Loss: 0.7887598276138306, Accuracy: 0.7412109375\n",
      "Batch: 7, Loss: 0.7719714045524597, Accuracy: 0.7373046875\n",
      "Batch: 8, Loss: 0.7344021797180176, Accuracy: 0.759765625\n",
      "Batch: 9, Loss: 0.7532217502593994, Accuracy: 0.7587890625\n",
      "Batch: 10, Loss: 0.7206963300704956, Accuracy: 0.7666015625\n",
      "Batch: 11, Loss: 0.8262746334075928, Accuracy: 0.7216796875\n",
      "Batch: 12, Loss: 0.8460627794265747, Accuracy: 0.716796875\n",
      "Batch: 13, Loss: 0.6132187247276306, Accuracy: 0.80859375\n",
      "Batch: 14, Loss: 0.8368358612060547, Accuracy: 0.7353515625\n",
      "Batch: 15, Loss: 0.7272531986236572, Accuracy: 0.7763671875\n",
      "Batch: 16, Loss: 0.7343747615814209, Accuracy: 0.763671875\n",
      "Batch: 17, Loss: 0.798434853553772, Accuracy: 0.748046875\n",
      "Batch: 18, Loss: 0.8177789449691772, Accuracy: 0.7353515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 0.8141345381736755, Accuracy: 0.734375\n",
      "Batch: 20, Loss: 0.6889299154281616, Accuracy: 0.78125\n",
      "Batch: 21, Loss: 0.7696899175643921, Accuracy: 0.7392578125\n",
      "Batch: 22, Loss: 0.8458305597305298, Accuracy: 0.7392578125\n",
      "Batch: 23, Loss: 0.8114289045333862, Accuracy: 0.740234375\n",
      "Batch: 24, Loss: 0.7961119413375854, Accuracy: 0.751953125\n",
      "Batch: 25, Loss: 0.7623112201690674, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.6843190789222717, Accuracy: 0.7626953125\n",
      "Batch: 27, Loss: 0.7127692103385925, Accuracy: 0.7568359375\n",
      "Batch: 28, Loss: 0.8006787300109863, Accuracy: 0.740234375\n",
      "Batch: 29, Loss: 0.7710939645767212, Accuracy: 0.7548828125\n",
      "Batch: 30, Loss: 0.6989259123802185, Accuracy: 0.775390625\n",
      "Batch: 31, Loss: 0.6901811361312866, Accuracy: 0.7734375\n",
      "Batch: 32, Loss: 0.6980346441268921, Accuracy: 0.7763671875\n",
      "Batch: 33, Loss: 0.8320976495742798, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.8804681897163391, Accuracy: 0.7236328125\n",
      "Batch: 35, Loss: 0.7833559513092041, Accuracy: 0.7412109375\n",
      "Batch: 36, Loss: 0.8021696209907532, Accuracy: 0.7568359375\n",
      "Batch: 37, Loss: 0.7834930419921875, Accuracy: 0.728515625\n",
      "Batch: 38, Loss: 0.7780824899673462, Accuracy: 0.7333984375\n",
      "Batch: 39, Loss: 0.8207504749298096, Accuracy: 0.73828125\n",
      "Batch: 40, Loss: 0.7790018320083618, Accuracy: 0.7548828125\n",
      "Batch: 41, Loss: 0.7212162017822266, Accuracy: 0.7783203125\n",
      "Batch: 42, Loss: 0.6059578657150269, Accuracy: 0.7939453125\n",
      "Batch: 43, Loss: 0.7534064054489136, Accuracy: 0.7421875\n",
      "Batch: 44, Loss: 0.7852007746696472, Accuracy: 0.7431640625\n",
      "Batch: 45, Loss: 0.7018526792526245, Accuracy: 0.76953125\n",
      "Batch: 46, Loss: 0.7200517654418945, Accuracy: 0.7744140625\n",
      "Batch: 47, Loss: 0.7470154166221619, Accuracy: 0.7734375\n",
      "Batch: 48, Loss: 0.6973670721054077, Accuracy: 0.7744140625\n",
      "Batch: 49, Loss: 0.803749144077301, Accuracy: 0.7353515625\n",
      "Batch: 50, Loss: 0.7967577576637268, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.8371173739433289, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.8026601076126099, Accuracy: 0.7451171875\n",
      "Batch: 53, Loss: 0.6927451491355896, Accuracy: 0.76953125\n",
      "Batch: 54, Loss: 0.7596403360366821, Accuracy: 0.7529296875\n",
      "Batch: 55, Loss: 0.860998272895813, Accuracy: 0.720703125\n",
      "Batch: 56, Loss: 0.8365163207054138, Accuracy: 0.7158203125\n",
      "Batch: 57, Loss: 0.8329876661300659, Accuracy: 0.732421875\n",
      "Batch: 58, Loss: 0.8542526364326477, Accuracy: 0.720703125\n",
      "Batch: 59, Loss: 0.7454907894134521, Accuracy: 0.7646484375\n",
      "Batch: 60, Loss: 0.6995334625244141, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.7813237905502319, Accuracy: 0.7373046875\n",
      "Batch: 62, Loss: 0.6965063810348511, Accuracy: 0.7880859375\n",
      "Batch: 63, Loss: 0.7408339977264404, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.7332086563110352, Accuracy: 0.7646484375\n",
      "Batch: 65, Loss: 0.7677779197692871, Accuracy: 0.7578125\n",
      "Batch: 66, Loss: 0.7241535782814026, Accuracy: 0.7783203125\n",
      "Batch: 67, Loss: 0.8192607164382935, Accuracy: 0.7294921875\n",
      "Batch: 68, Loss: 0.8517968654632568, Accuracy: 0.736328125\n",
      "Batch: 69, Loss: 0.8093352913856506, Accuracy: 0.736328125\n",
      "Batch: 70, Loss: 0.7766283750534058, Accuracy: 0.7705078125\n",
      "Batch: 71, Loss: 0.7705115079879761, Accuracy: 0.7353515625\n",
      "Batch: 72, Loss: 0.6924234628677368, Accuracy: 0.7646484375\n",
      "Batch: 73, Loss: 0.7164580821990967, Accuracy: 0.7685546875\n",
      "Batch: 74, Loss: 0.6744097471237183, Accuracy: 0.8037109375\n",
      "Batch: 75, Loss: 0.6803584098815918, Accuracy: 0.775390625\n",
      "Batch: 76, Loss: 0.7722298502922058, Accuracy: 0.7568359375\n",
      "Batch: 77, Loss: 0.7204539775848389, Accuracy: 0.759765625\n",
      "Batch: 78, Loss: 0.7411297559738159, Accuracy: 0.7568359375\n",
      "Batch: 79, Loss: 0.6538110971450806, Accuracy: 0.796875\n",
      "Batch: 80, Loss: 0.7142465114593506, Accuracy: 0.7548828125\n",
      "Batch: 81, Loss: 0.8175243139266968, Accuracy: 0.71484375\n",
      "Batch: 82, Loss: 0.7716124653816223, Accuracy: 0.75\n",
      "Batch: 83, Loss: 0.6717367172241211, Accuracy: 0.798828125\n",
      "Batch: 84, Loss: 0.7894173860549927, Accuracy: 0.75\n",
      "Batch: 85, Loss: 0.7437962293624878, Accuracy: 0.7783203125\n",
      "Batch: 86, Loss: 0.8720047473907471, Accuracy: 0.7392578125\n",
      "Batch: 87, Loss: 0.6895778179168701, Accuracy: 0.767578125\n",
      "Batch: 88, Loss: 0.8145195245742798, Accuracy: 0.7587890625\n",
      "Batch: 89, Loss: 0.7830092906951904, Accuracy: 0.767578125\n",
      "Batch: 90, Loss: 0.7578962445259094, Accuracy: 0.7548828125\n",
      "Batch: 91, Loss: 0.7455787658691406, Accuracy: 0.76171875\n",
      "Batch: 92, Loss: 0.804336428642273, Accuracy: 0.7548828125\n",
      "Batch: 93, Loss: 0.7477515339851379, Accuracy: 0.759765625\n",
      "Batch: 94, Loss: 0.7466176748275757, Accuracy: 0.7646484375\n",
      "Batch: 95, Loss: 0.8100128173828125, Accuracy: 0.7158203125\n",
      "Batch: 96, Loss: 0.7522250413894653, Accuracy: 0.763671875\n",
      "Batch: 97, Loss: 0.6378490328788757, Accuracy: 0.7763671875\n",
      "Batch: 98, Loss: 0.7106324434280396, Accuracy: 0.7587890625\n",
      "Batch: 99, Loss: 0.7013978958129883, Accuracy: 0.7626953125\n",
      "Batch: 100, Loss: 0.7558536529541016, Accuracy: 0.75\n",
      "Batch: 101, Loss: 0.8120750188827515, Accuracy: 0.732421875\n",
      "Batch: 102, Loss: 0.7558392286300659, Accuracy: 0.7568359375\n",
      "Batch: 103, Loss: 0.8120946884155273, Accuracy: 0.7470703125\n",
      "Batch: 104, Loss: 0.672463595867157, Accuracy: 0.7802734375\n",
      "Batch: 105, Loss: 0.7671011090278625, Accuracy: 0.73828125\n",
      "Batch: 106, Loss: 0.7056287527084351, Accuracy: 0.78125\n",
      "Batch: 107, Loss: 0.7367293834686279, Accuracy: 0.7685546875\n",
      "Batch: 108, Loss: 0.7550185918807983, Accuracy: 0.7490234375\n",
      "Batch: 109, Loss: 0.8510662317276001, Accuracy: 0.720703125\n",
      "Batch: 110, Loss: 0.6637846231460571, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.7828854322433472, Accuracy: 0.755859375\n",
      "Batch: 112, Loss: 0.7620514631271362, Accuracy: 0.7685546875\n",
      "Batch: 113, Loss: 0.7807239890098572, Accuracy: 0.765625\n",
      "Batch: 114, Loss: 0.8538447022438049, Accuracy: 0.7275390625\n",
      "Batch: 115, Loss: 0.8308945894241333, Accuracy: 0.7431640625\n",
      "Batch: 116, Loss: 0.7668415307998657, Accuracy: 0.7529296875\n",
      "Batch: 117, Loss: 0.8059117794036865, Accuracy: 0.7431640625\n",
      "Batch: 118, Loss: 0.6921858787536621, Accuracy: 0.78515625\n",
      "Batch: 119, Loss: 0.6883753538131714, Accuracy: 0.78125\n",
      "Batch: 120, Loss: 0.7530807256698608, Accuracy: 0.7509765625\n",
      "Batch: 121, Loss: 0.8342405557632446, Accuracy: 0.728515625\n",
      "Batch: 122, Loss: 0.7492219805717468, Accuracy: 0.767578125\n",
      "Batch: 123, Loss: 0.7380800247192383, Accuracy: 0.7578125\n",
      "Batch: 124, Loss: 0.7944281101226807, Accuracy: 0.7392578125\n",
      "Batch: 125, Loss: 0.8071984052658081, Accuracy: 0.740234375\n",
      "Batch: 126, Loss: 0.7874212265014648, Accuracy: 0.751953125\n",
      "Batch: 127, Loss: 0.6961111426353455, Accuracy: 0.787109375\n",
      "Batch: 128, Loss: 0.8707625865936279, Accuracy: 0.7373046875\n",
      "Batch: 129, Loss: 0.7315864562988281, Accuracy: 0.7666015625\n",
      "Batch: 130, Loss: 0.8808363676071167, Accuracy: 0.7158203125\n",
      "Batch: 131, Loss: 0.7892084717750549, Accuracy: 0.7509765625\n",
      "Batch: 132, Loss: 0.8078173398971558, Accuracy: 0.74609375\n",
      "Batch: 133, Loss: 0.7455147504806519, Accuracy: 0.744140625\n",
      "Batch: 134, Loss: 0.7898935675621033, Accuracy: 0.7275390625\n",
      "Batch: 135, Loss: 0.7121078968048096, Accuracy: 0.7724609375\n",
      "Batch: 136, Loss: 0.7984747290611267, Accuracy: 0.74609375\n",
      "Batch: 137, Loss: 0.8027547597885132, Accuracy: 0.73046875\n",
      "Batch: 138, Loss: 0.6933843493461609, Accuracy: 0.7646484375\n",
      "Batch: 139, Loss: 0.7627588510513306, Accuracy: 0.75390625\n",
      "Batch: 140, Loss: 0.7738721370697021, Accuracy: 0.75\n",
      "Batch: 141, Loss: 0.8258529901504517, Accuracy: 0.724609375\n",
      "Batch: 142, Loss: 0.8011388778686523, Accuracy: 0.732421875\n",
      "Batch: 143, Loss: 0.7721716165542603, Accuracy: 0.75390625\n",
      "Batch: 144, Loss: 0.7901157140731812, Accuracy: 0.7548828125\n",
      "Batch: 145, Loss: 0.7330487966537476, Accuracy: 0.7470703125\n",
      "Batch: 146, Loss: 0.824150562286377, Accuracy: 0.734375\n",
      "Batch: 147, Loss: 0.7968127727508545, Accuracy: 0.7421875\n",
      "Batch: 148, Loss: 0.89051353931427, Accuracy: 0.703125\n",
      "Batch: 149, Loss: 0.7372068166732788, Accuracy: 0.763671875\n",
      "Batch: 150, Loss: 0.7434252500534058, Accuracy: 0.7587890625\n",
      "Batch: 151, Loss: 0.686658501625061, Accuracy: 0.7744140625\n",
      "Epoch 35/80\n",
      "Batch: 1, Loss: 0.9858226776123047, Accuracy: 0.6748046875\n",
      "Batch: 2, Loss: 0.8429415225982666, Accuracy: 0.71484375\n",
      "Batch: 3, Loss: 0.7785177230834961, Accuracy: 0.748046875\n",
      "Batch: 4, Loss: 0.7166666984558105, Accuracy: 0.7685546875\n",
      "Batch: 5, Loss: 0.7004703879356384, Accuracy: 0.7822265625\n",
      "Batch: 6, Loss: 0.7707659006118774, Accuracy: 0.7509765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7, Loss: 0.7851791977882385, Accuracy: 0.7421875\n",
      "Batch: 8, Loss: 0.7188650369644165, Accuracy: 0.7568359375\n",
      "Batch: 9, Loss: 0.7446324825286865, Accuracy: 0.7646484375\n",
      "Batch: 10, Loss: 0.7343894243240356, Accuracy: 0.7626953125\n",
      "Batch: 11, Loss: 0.8197609782218933, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.8140997886657715, Accuracy: 0.744140625\n",
      "Batch: 13, Loss: 0.6489470601081848, Accuracy: 0.7744140625\n",
      "Batch: 14, Loss: 0.8572971224784851, Accuracy: 0.7236328125\n",
      "Batch: 15, Loss: 0.7204892039299011, Accuracy: 0.7705078125\n",
      "Batch: 16, Loss: 0.7413937449455261, Accuracy: 0.759765625\n",
      "Batch: 17, Loss: 0.7951688766479492, Accuracy: 0.7578125\n",
      "Batch: 18, Loss: 0.7976186275482178, Accuracy: 0.7548828125\n",
      "Batch: 19, Loss: 0.8240585327148438, Accuracy: 0.736328125\n",
      "Batch: 20, Loss: 0.704954206943512, Accuracy: 0.76953125\n",
      "Batch: 21, Loss: 0.7772798538208008, Accuracy: 0.734375\n",
      "Batch: 22, Loss: 0.8485736846923828, Accuracy: 0.7314453125\n",
      "Batch: 23, Loss: 0.7983270883560181, Accuracy: 0.7451171875\n",
      "Batch: 24, Loss: 0.7890968918800354, Accuracy: 0.7548828125\n",
      "Batch: 25, Loss: 0.767967700958252, Accuracy: 0.7685546875\n",
      "Batch: 26, Loss: 0.6701368093490601, Accuracy: 0.7724609375\n",
      "Batch: 27, Loss: 0.720329999923706, Accuracy: 0.7490234375\n",
      "Batch: 28, Loss: 0.7568025588989258, Accuracy: 0.75\n",
      "Batch: 29, Loss: 0.76760333776474, Accuracy: 0.748046875\n",
      "Batch: 30, Loss: 0.681702733039856, Accuracy: 0.7919921875\n",
      "Batch: 31, Loss: 0.6511474251747131, Accuracy: 0.787109375\n",
      "Batch: 32, Loss: 0.7068097591400146, Accuracy: 0.767578125\n",
      "Batch: 33, Loss: 0.8088011741638184, Accuracy: 0.7626953125\n",
      "Batch: 34, Loss: 0.8706257939338684, Accuracy: 0.7158203125\n",
      "Batch: 35, Loss: 0.774272620677948, Accuracy: 0.76171875\n",
      "Batch: 36, Loss: 0.7971576452255249, Accuracy: 0.7490234375\n",
      "Batch: 37, Loss: 0.7854504585266113, Accuracy: 0.73828125\n",
      "Batch: 38, Loss: 0.7815593481063843, Accuracy: 0.7373046875\n",
      "Batch: 39, Loss: 0.7913475632667542, Accuracy: 0.748046875\n",
      "Batch: 40, Loss: 0.7642265558242798, Accuracy: 0.7548828125\n",
      "Batch: 41, Loss: 0.7075011730194092, Accuracy: 0.7626953125\n",
      "Batch: 42, Loss: 0.6103415489196777, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.7545484304428101, Accuracy: 0.7294921875\n",
      "Batch: 44, Loss: 0.7882168889045715, Accuracy: 0.736328125\n",
      "Batch: 45, Loss: 0.6695435047149658, Accuracy: 0.7822265625\n",
      "Batch: 46, Loss: 0.7013048529624939, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.7245641946792603, Accuracy: 0.7578125\n",
      "Batch: 48, Loss: 0.7007216215133667, Accuracy: 0.7783203125\n",
      "Batch: 49, Loss: 0.8260147571563721, Accuracy: 0.736328125\n",
      "Batch: 50, Loss: 0.797659158706665, Accuracy: 0.7451171875\n",
      "Batch: 51, Loss: 0.8350825309753418, Accuracy: 0.7421875\n",
      "Batch: 52, Loss: 0.7949975728988647, Accuracy: 0.7490234375\n",
      "Batch: 53, Loss: 0.715225100517273, Accuracy: 0.7607421875\n",
      "Batch: 54, Loss: 0.7356102466583252, Accuracy: 0.7626953125\n",
      "Batch: 55, Loss: 0.8390523195266724, Accuracy: 0.7275390625\n",
      "Batch: 56, Loss: 0.8225483298301697, Accuracy: 0.740234375\n",
      "Batch: 57, Loss: 0.7745129466056824, Accuracy: 0.7509765625\n",
      "Batch: 58, Loss: 0.8412302136421204, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.709612250328064, Accuracy: 0.771484375\n",
      "Batch: 60, Loss: 0.6893285512924194, Accuracy: 0.7724609375\n",
      "Batch: 61, Loss: 0.772276759147644, Accuracy: 0.7470703125\n",
      "Batch: 62, Loss: 0.6993629336357117, Accuracy: 0.7822265625\n",
      "Batch: 63, Loss: 0.7280206680297852, Accuracy: 0.7685546875\n",
      "Batch: 64, Loss: 0.7374395132064819, Accuracy: 0.7646484375\n",
      "Batch: 65, Loss: 0.7588579654693604, Accuracy: 0.7568359375\n",
      "Batch: 66, Loss: 0.7436062097549438, Accuracy: 0.765625\n",
      "Batch: 67, Loss: 0.8339999318122864, Accuracy: 0.7431640625\n",
      "Batch: 68, Loss: 0.8337916135787964, Accuracy: 0.7412109375\n",
      "Batch: 69, Loss: 0.8240741491317749, Accuracy: 0.7333984375\n",
      "Batch: 70, Loss: 0.7439708709716797, Accuracy: 0.7705078125\n",
      "Batch: 71, Loss: 0.8274250030517578, Accuracy: 0.73046875\n",
      "Batch: 72, Loss: 0.6900151371955872, Accuracy: 0.7724609375\n",
      "Batch: 73, Loss: 0.6965119242668152, Accuracy: 0.775390625\n",
      "Batch: 74, Loss: 0.6505951881408691, Accuracy: 0.7998046875\n",
      "Batch: 75, Loss: 0.6655164957046509, Accuracy: 0.7763671875\n",
      "Batch: 76, Loss: 0.772448718547821, Accuracy: 0.736328125\n",
      "Batch: 77, Loss: 0.6852837800979614, Accuracy: 0.7763671875\n",
      "Batch: 78, Loss: 0.725396990776062, Accuracy: 0.7685546875\n",
      "Batch: 79, Loss: 0.660879373550415, Accuracy: 0.7900390625\n",
      "Batch: 80, Loss: 0.7198753356933594, Accuracy: 0.759765625\n",
      "Batch: 81, Loss: 0.821174144744873, Accuracy: 0.6982421875\n",
      "Batch: 82, Loss: 0.7611933946609497, Accuracy: 0.7607421875\n",
      "Batch: 83, Loss: 0.6449466347694397, Accuracy: 0.798828125\n",
      "Batch: 84, Loss: 0.7619857788085938, Accuracy: 0.7587890625\n",
      "Batch: 85, Loss: 0.7046955823898315, Accuracy: 0.7802734375\n",
      "Batch: 86, Loss: 0.8716937303543091, Accuracy: 0.734375\n",
      "Batch: 87, Loss: 0.6913353204727173, Accuracy: 0.783203125\n",
      "Batch: 88, Loss: 0.8183138370513916, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7847321033477783, Accuracy: 0.7431640625\n",
      "Batch: 90, Loss: 0.7485513687133789, Accuracy: 0.775390625\n",
      "Batch: 91, Loss: 0.759198784828186, Accuracy: 0.7587890625\n",
      "Batch: 92, Loss: 0.7770479321479797, Accuracy: 0.7431640625\n",
      "Batch: 93, Loss: 0.7344716787338257, Accuracy: 0.7509765625\n",
      "Batch: 94, Loss: 0.7700648307800293, Accuracy: 0.75390625\n",
      "Batch: 95, Loss: 0.7913558483123779, Accuracy: 0.7412109375\n",
      "Batch: 96, Loss: 0.7213519811630249, Accuracy: 0.7548828125\n",
      "Batch: 97, Loss: 0.6205966472625732, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.6800313591957092, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6841948628425598, Accuracy: 0.7734375\n",
      "Batch: 100, Loss: 0.7643625736236572, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.8213286995887756, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.7260273098945618, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.7545844316482544, Accuracy: 0.755859375\n",
      "Batch: 104, Loss: 0.7083339095115662, Accuracy: 0.7666015625\n",
      "Batch: 105, Loss: 0.7598137855529785, Accuracy: 0.74609375\n",
      "Batch: 106, Loss: 0.677987277507782, Accuracy: 0.7890625\n",
      "Batch: 107, Loss: 0.7351075410842896, Accuracy: 0.7841796875\n",
      "Batch: 108, Loss: 0.7280203104019165, Accuracy: 0.763671875\n",
      "Batch: 109, Loss: 0.8839928507804871, Accuracy: 0.716796875\n",
      "Batch: 110, Loss: 0.6647846102714539, Accuracy: 0.771484375\n",
      "Batch: 111, Loss: 0.7457651495933533, Accuracy: 0.76171875\n",
      "Batch: 112, Loss: 0.7396748065948486, Accuracy: 0.775390625\n",
      "Batch: 113, Loss: 0.7437955737113953, Accuracy: 0.775390625\n",
      "Batch: 114, Loss: 0.828284502029419, Accuracy: 0.7412109375\n",
      "Batch: 115, Loss: 0.8365155458450317, Accuracy: 0.7333984375\n",
      "Batch: 116, Loss: 0.7763165235519409, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.7832914590835571, Accuracy: 0.7509765625\n",
      "Batch: 118, Loss: 0.6606429815292358, Accuracy: 0.7890625\n",
      "Batch: 119, Loss: 0.6697426438331604, Accuracy: 0.7900390625\n",
      "Batch: 120, Loss: 0.7507394552230835, Accuracy: 0.759765625\n",
      "Batch: 121, Loss: 0.8367266654968262, Accuracy: 0.7333984375\n",
      "Batch: 122, Loss: 0.7178329229354858, Accuracy: 0.7724609375\n",
      "Batch: 123, Loss: 0.7057734727859497, Accuracy: 0.765625\n",
      "Batch: 124, Loss: 0.7467879056930542, Accuracy: 0.7626953125\n",
      "Batch: 125, Loss: 0.7943868637084961, Accuracy: 0.73828125\n",
      "Batch: 126, Loss: 0.7822352647781372, Accuracy: 0.7421875\n",
      "Batch: 127, Loss: 0.6709571480751038, Accuracy: 0.7880859375\n",
      "Batch: 128, Loss: 0.8828076124191284, Accuracy: 0.73828125\n",
      "Batch: 129, Loss: 0.7064749598503113, Accuracy: 0.7783203125\n",
      "Batch: 130, Loss: 0.8806661367416382, Accuracy: 0.7255859375\n",
      "Batch: 131, Loss: 0.8276301026344299, Accuracy: 0.7216796875\n",
      "Batch: 132, Loss: 0.7815919518470764, Accuracy: 0.7529296875\n",
      "Batch: 133, Loss: 0.7721291780471802, Accuracy: 0.7451171875\n",
      "Batch: 134, Loss: 0.7837395668029785, Accuracy: 0.740234375\n",
      "Batch: 135, Loss: 0.6807234287261963, Accuracy: 0.7900390625\n",
      "Batch: 136, Loss: 0.7767021059989929, Accuracy: 0.759765625\n",
      "Batch: 137, Loss: 0.759448766708374, Accuracy: 0.7392578125\n",
      "Batch: 138, Loss: 0.6834614872932434, Accuracy: 0.7744140625\n",
      "Batch: 139, Loss: 0.7772576808929443, Accuracy: 0.74609375\n",
      "Batch: 140, Loss: 0.7406699061393738, Accuracy: 0.74609375\n",
      "Batch: 141, Loss: 0.80253666639328, Accuracy: 0.732421875\n",
      "Batch: 142, Loss: 0.7951954007148743, Accuracy: 0.7412109375\n",
      "Batch: 143, Loss: 0.7786871194839478, Accuracy: 0.7470703125\n",
      "Batch: 144, Loss: 0.8134185075759888, Accuracy: 0.736328125\n",
      "Batch: 145, Loss: 0.7233861684799194, Accuracy: 0.763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 146, Loss: 0.7890980243682861, Accuracy: 0.75\n",
      "Batch: 147, Loss: 0.802643895149231, Accuracy: 0.7431640625\n",
      "Batch: 148, Loss: 0.8866183161735535, Accuracy: 0.7216796875\n",
      "Batch: 149, Loss: 0.732624888420105, Accuracy: 0.7568359375\n",
      "Batch: 150, Loss: 0.7343930602073669, Accuracy: 0.7607421875\n",
      "Batch: 151, Loss: 0.6855865716934204, Accuracy: 0.775390625\n",
      "Epoch 36/80\n",
      "Batch: 1, Loss: 0.97785484790802, Accuracy: 0.689453125\n",
      "Batch: 2, Loss: 0.8603445887565613, Accuracy: 0.7138671875\n",
      "Batch: 3, Loss: 0.7361117005348206, Accuracy: 0.744140625\n",
      "Batch: 4, Loss: 0.7027895450592041, Accuracy: 0.7744140625\n",
      "Batch: 5, Loss: 0.7397351264953613, Accuracy: 0.75390625\n",
      "Batch: 6, Loss: 0.7692919969558716, Accuracy: 0.7431640625\n",
      "Batch: 7, Loss: 0.7817643880844116, Accuracy: 0.734375\n",
      "Batch: 8, Loss: 0.7206089496612549, Accuracy: 0.7578125\n",
      "Batch: 9, Loss: 0.7214693427085876, Accuracy: 0.7705078125\n",
      "Batch: 10, Loss: 0.7277511358261108, Accuracy: 0.7578125\n",
      "Batch: 11, Loss: 0.8296974897384644, Accuracy: 0.7236328125\n",
      "Batch: 12, Loss: 0.7798011898994446, Accuracy: 0.75390625\n",
      "Batch: 13, Loss: 0.6061080098152161, Accuracy: 0.8046875\n",
      "Batch: 14, Loss: 0.8469266295433044, Accuracy: 0.7353515625\n",
      "Batch: 15, Loss: 0.6715582013130188, Accuracy: 0.7783203125\n",
      "Batch: 16, Loss: 0.7109985947608948, Accuracy: 0.7841796875\n",
      "Batch: 17, Loss: 0.7727291584014893, Accuracy: 0.759765625\n",
      "Batch: 18, Loss: 0.760246992111206, Accuracy: 0.763671875\n",
      "Batch: 19, Loss: 0.8025146126747131, Accuracy: 0.744140625\n",
      "Batch: 20, Loss: 0.6928019523620605, Accuracy: 0.78125\n",
      "Batch: 21, Loss: 0.7443349361419678, Accuracy: 0.7490234375\n",
      "Batch: 22, Loss: 0.811935544013977, Accuracy: 0.740234375\n",
      "Batch: 23, Loss: 0.8022996187210083, Accuracy: 0.7431640625\n",
      "Batch: 24, Loss: 0.785181999206543, Accuracy: 0.75390625\n",
      "Batch: 25, Loss: 0.7529640197753906, Accuracy: 0.7744140625\n",
      "Batch: 26, Loss: 0.6764479279518127, Accuracy: 0.77734375\n",
      "Batch: 27, Loss: 0.741958737373352, Accuracy: 0.7451171875\n",
      "Batch: 28, Loss: 0.7521076202392578, Accuracy: 0.7548828125\n",
      "Batch: 29, Loss: 0.7271245121955872, Accuracy: 0.759765625\n",
      "Batch: 30, Loss: 0.6693625450134277, Accuracy: 0.7890625\n",
      "Batch: 31, Loss: 0.6638323068618774, Accuracy: 0.7744140625\n",
      "Batch: 32, Loss: 0.6584890484809875, Accuracy: 0.775390625\n",
      "Batch: 33, Loss: 0.8025364279747009, Accuracy: 0.7578125\n",
      "Batch: 34, Loss: 0.874518096446991, Accuracy: 0.716796875\n",
      "Batch: 35, Loss: 0.7605034112930298, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.7846812009811401, Accuracy: 0.755859375\n",
      "Batch: 37, Loss: 0.7709553241729736, Accuracy: 0.7626953125\n",
      "Batch: 38, Loss: 0.7444396018981934, Accuracy: 0.75390625\n",
      "Batch: 39, Loss: 0.7724535465240479, Accuracy: 0.744140625\n",
      "Batch: 40, Loss: 0.7301913499832153, Accuracy: 0.7646484375\n",
      "Batch: 41, Loss: 0.7272964715957642, Accuracy: 0.763671875\n",
      "Batch: 42, Loss: 0.598800539970398, Accuracy: 0.8037109375\n",
      "Batch: 43, Loss: 0.7057746648788452, Accuracy: 0.7705078125\n",
      "Batch: 44, Loss: 0.7403223514556885, Accuracy: 0.7548828125\n",
      "Batch: 45, Loss: 0.6815327405929565, Accuracy: 0.7734375\n",
      "Batch: 46, Loss: 0.6909037828445435, Accuracy: 0.7685546875\n",
      "Batch: 47, Loss: 0.6965567469596863, Accuracy: 0.76953125\n",
      "Batch: 48, Loss: 0.6862797737121582, Accuracy: 0.7802734375\n",
      "Batch: 49, Loss: 0.7943834066390991, Accuracy: 0.748046875\n",
      "Batch: 50, Loss: 0.7556521892547607, Accuracy: 0.7529296875\n",
      "Batch: 51, Loss: 0.8134602904319763, Accuracy: 0.7421875\n",
      "Batch: 52, Loss: 0.7696086168289185, Accuracy: 0.765625\n",
      "Batch: 53, Loss: 0.6948382258415222, Accuracy: 0.7587890625\n",
      "Batch: 54, Loss: 0.7275912761688232, Accuracy: 0.765625\n",
      "Batch: 55, Loss: 0.8212369084358215, Accuracy: 0.71875\n",
      "Batch: 56, Loss: 0.8303618431091309, Accuracy: 0.73046875\n",
      "Batch: 57, Loss: 0.7676259279251099, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8410091996192932, Accuracy: 0.7314453125\n",
      "Batch: 59, Loss: 0.7221530079841614, Accuracy: 0.7763671875\n",
      "Batch: 60, Loss: 0.6749732494354248, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.772392749786377, Accuracy: 0.75\n",
      "Batch: 62, Loss: 0.6497026681900024, Accuracy: 0.7841796875\n",
      "Batch: 63, Loss: 0.7530781030654907, Accuracy: 0.7666015625\n",
      "Batch: 64, Loss: 0.7343238592147827, Accuracy: 0.7587890625\n",
      "Batch: 65, Loss: 0.7387999892234802, Accuracy: 0.7646484375\n",
      "Batch: 66, Loss: 0.7330151796340942, Accuracy: 0.76171875\n",
      "Batch: 67, Loss: 0.8006484508514404, Accuracy: 0.732421875\n",
      "Batch: 68, Loss: 0.8583338260650635, Accuracy: 0.732421875\n",
      "Batch: 69, Loss: 0.8009517788887024, Accuracy: 0.7421875\n",
      "Batch: 70, Loss: 0.7730169296264648, Accuracy: 0.7509765625\n",
      "Batch: 71, Loss: 0.7751493453979492, Accuracy: 0.7333984375\n",
      "Batch: 72, Loss: 0.6679682731628418, Accuracy: 0.78515625\n",
      "Batch: 73, Loss: 0.7224125862121582, Accuracy: 0.7685546875\n",
      "Batch: 74, Loss: 0.6678408980369568, Accuracy: 0.7919921875\n",
      "Batch: 75, Loss: 0.6458867788314819, Accuracy: 0.7861328125\n",
      "Batch: 76, Loss: 0.7624320983886719, Accuracy: 0.740234375\n",
      "Batch: 77, Loss: 0.667441189289093, Accuracy: 0.7666015625\n",
      "Batch: 78, Loss: 0.7074739336967468, Accuracy: 0.7783203125\n",
      "Batch: 79, Loss: 0.6632440090179443, Accuracy: 0.794921875\n",
      "Batch: 80, Loss: 0.719691276550293, Accuracy: 0.7548828125\n",
      "Batch: 81, Loss: 0.7960917949676514, Accuracy: 0.732421875\n",
      "Batch: 82, Loss: 0.7522058486938477, Accuracy: 0.7421875\n",
      "Batch: 83, Loss: 0.6316753029823303, Accuracy: 0.796875\n",
      "Batch: 84, Loss: 0.7475353479385376, Accuracy: 0.751953125\n",
      "Batch: 85, Loss: 0.7092142105102539, Accuracy: 0.779296875\n",
      "Batch: 86, Loss: 0.8467288017272949, Accuracy: 0.740234375\n",
      "Batch: 87, Loss: 0.6754195094108582, Accuracy: 0.7958984375\n",
      "Batch: 88, Loss: 0.7670767307281494, Accuracy: 0.7666015625\n",
      "Batch: 89, Loss: 0.7830272912979126, Accuracy: 0.7587890625\n",
      "Batch: 90, Loss: 0.7291731834411621, Accuracy: 0.76953125\n",
      "Batch: 91, Loss: 0.7306375503540039, Accuracy: 0.7607421875\n",
      "Batch: 92, Loss: 0.778706431388855, Accuracy: 0.7412109375\n",
      "Batch: 93, Loss: 0.7030630111694336, Accuracy: 0.7705078125\n",
      "Batch: 94, Loss: 0.7276326417922974, Accuracy: 0.7646484375\n",
      "Batch: 95, Loss: 0.7624167203903198, Accuracy: 0.7314453125\n",
      "Batch: 96, Loss: 0.7245361804962158, Accuracy: 0.751953125\n",
      "Batch: 97, Loss: 0.6173310279846191, Accuracy: 0.7841796875\n",
      "Batch: 98, Loss: 0.7055940628051758, Accuracy: 0.7685546875\n",
      "Batch: 99, Loss: 0.6923922896385193, Accuracy: 0.77734375\n",
      "Batch: 100, Loss: 0.7556458711624146, Accuracy: 0.7587890625\n",
      "Batch: 101, Loss: 0.7923622131347656, Accuracy: 0.736328125\n",
      "Batch: 102, Loss: 0.746608316898346, Accuracy: 0.755859375\n",
      "Batch: 103, Loss: 0.7551077008247375, Accuracy: 0.7607421875\n",
      "Batch: 104, Loss: 0.6651480793952942, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.770760178565979, Accuracy: 0.7373046875\n",
      "Batch: 106, Loss: 0.694573163986206, Accuracy: 0.7822265625\n",
      "Batch: 107, Loss: 0.7517498731613159, Accuracy: 0.7578125\n",
      "Batch: 108, Loss: 0.7326114773750305, Accuracy: 0.7626953125\n",
      "Batch: 109, Loss: 0.8491314649581909, Accuracy: 0.72265625\n",
      "Batch: 110, Loss: 0.6761751174926758, Accuracy: 0.7744140625\n",
      "Batch: 111, Loss: 0.7659004926681519, Accuracy: 0.7568359375\n",
      "Batch: 112, Loss: 0.754799485206604, Accuracy: 0.7734375\n",
      "Batch: 113, Loss: 0.7525451183319092, Accuracy: 0.7607421875\n",
      "Batch: 114, Loss: 0.841591477394104, Accuracy: 0.71484375\n",
      "Batch: 115, Loss: 0.8313267230987549, Accuracy: 0.73828125\n",
      "Batch: 116, Loss: 0.7604075074195862, Accuracy: 0.7451171875\n",
      "Batch: 117, Loss: 0.7727288007736206, Accuracy: 0.7490234375\n",
      "Batch: 118, Loss: 0.6956241130828857, Accuracy: 0.7783203125\n",
      "Batch: 119, Loss: 0.6492242813110352, Accuracy: 0.7861328125\n",
      "Batch: 120, Loss: 0.7337273359298706, Accuracy: 0.7451171875\n",
      "Batch: 121, Loss: 0.7949215173721313, Accuracy: 0.7294921875\n",
      "Batch: 122, Loss: 0.7085062265396118, Accuracy: 0.7734375\n",
      "Batch: 123, Loss: 0.7169116139411926, Accuracy: 0.7705078125\n",
      "Batch: 124, Loss: 0.7554903626441956, Accuracy: 0.7529296875\n",
      "Batch: 125, Loss: 0.7781367897987366, Accuracy: 0.7275390625\n",
      "Batch: 126, Loss: 0.7618547081947327, Accuracy: 0.7607421875\n",
      "Batch: 127, Loss: 0.6516730785369873, Accuracy: 0.8037109375\n",
      "Batch: 128, Loss: 0.8448652029037476, Accuracy: 0.734375\n",
      "Batch: 129, Loss: 0.709591805934906, Accuracy: 0.767578125\n",
      "Batch: 130, Loss: 0.8639528751373291, Accuracy: 0.7255859375\n",
      "Batch: 131, Loss: 0.7681569457054138, Accuracy: 0.75390625\n",
      "Batch: 132, Loss: 0.7544506788253784, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.7190435528755188, Accuracy: 0.755859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 134, Loss: 0.7757976651191711, Accuracy: 0.7431640625\n",
      "Batch: 135, Loss: 0.6889669895172119, Accuracy: 0.77734375\n",
      "Batch: 136, Loss: 0.7991123199462891, Accuracy: 0.744140625\n",
      "Batch: 137, Loss: 0.7454262375831604, Accuracy: 0.751953125\n",
      "Batch: 138, Loss: 0.701865553855896, Accuracy: 0.7626953125\n",
      "Batch: 139, Loss: 0.7487027645111084, Accuracy: 0.748046875\n",
      "Batch: 140, Loss: 0.7195931673049927, Accuracy: 0.7607421875\n",
      "Batch: 141, Loss: 0.7940266132354736, Accuracy: 0.734375\n",
      "Batch: 142, Loss: 0.786342442035675, Accuracy: 0.7353515625\n",
      "Batch: 143, Loss: 0.7617831230163574, Accuracy: 0.759765625\n",
      "Batch: 144, Loss: 0.7816849946975708, Accuracy: 0.7587890625\n",
      "Batch: 145, Loss: 0.7068659067153931, Accuracy: 0.7548828125\n",
      "Batch: 146, Loss: 0.7784708142280579, Accuracy: 0.7548828125\n",
      "Batch: 147, Loss: 0.7599936127662659, Accuracy: 0.7392578125\n",
      "Batch: 148, Loss: 0.846246600151062, Accuracy: 0.7216796875\n",
      "Batch: 149, Loss: 0.7093435525894165, Accuracy: 0.76953125\n",
      "Batch: 150, Loss: 0.7355521321296692, Accuracy: 0.7568359375\n",
      "Batch: 151, Loss: 0.6628932952880859, Accuracy: 0.77734375\n",
      "Epoch 37/80\n",
      "Batch: 1, Loss: 0.9765098094940186, Accuracy: 0.689453125\n",
      "Batch: 2, Loss: 0.8448342680931091, Accuracy: 0.7138671875\n",
      "Batch: 3, Loss: 0.7313114404678345, Accuracy: 0.765625\n",
      "Batch: 4, Loss: 0.6765449047088623, Accuracy: 0.7880859375\n",
      "Batch: 5, Loss: 0.6839163303375244, Accuracy: 0.7763671875\n",
      "Batch: 6, Loss: 0.7339178323745728, Accuracy: 0.759765625\n",
      "Batch: 7, Loss: 0.7482234835624695, Accuracy: 0.7451171875\n",
      "Batch: 8, Loss: 0.7145602107048035, Accuracy: 0.765625\n",
      "Batch: 9, Loss: 0.7072527408599854, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.7183791399002075, Accuracy: 0.76953125\n",
      "Batch: 11, Loss: 0.794104278087616, Accuracy: 0.7529296875\n",
      "Batch: 12, Loss: 0.7899623513221741, Accuracy: 0.7548828125\n",
      "Batch: 13, Loss: 0.5945318937301636, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.8074157238006592, Accuracy: 0.7392578125\n",
      "Batch: 15, Loss: 0.6827214360237122, Accuracy: 0.7900390625\n",
      "Batch: 16, Loss: 0.6937917470932007, Accuracy: 0.798828125\n",
      "Batch: 17, Loss: 0.7477338314056396, Accuracy: 0.765625\n",
      "Batch: 18, Loss: 0.7622826099395752, Accuracy: 0.7548828125\n",
      "Batch: 19, Loss: 0.7427015900611877, Accuracy: 0.7626953125\n",
      "Batch: 20, Loss: 0.6905128359794617, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.7273727655410767, Accuracy: 0.7587890625\n",
      "Batch: 22, Loss: 0.8044977188110352, Accuracy: 0.759765625\n",
      "Batch: 23, Loss: 0.795574963092804, Accuracy: 0.7548828125\n",
      "Batch: 24, Loss: 0.7664917707443237, Accuracy: 0.748046875\n",
      "Batch: 25, Loss: 0.7399475574493408, Accuracy: 0.7578125\n",
      "Batch: 26, Loss: 0.6385917663574219, Accuracy: 0.796875\n",
      "Batch: 27, Loss: 0.6927882432937622, Accuracy: 0.7587890625\n",
      "Batch: 28, Loss: 0.7394816875457764, Accuracy: 0.7626953125\n",
      "Batch: 29, Loss: 0.7030407190322876, Accuracy: 0.7646484375\n",
      "Batch: 30, Loss: 0.6426248550415039, Accuracy: 0.7958984375\n",
      "Batch: 31, Loss: 0.6710168123245239, Accuracy: 0.76953125\n",
      "Batch: 32, Loss: 0.6798844933509827, Accuracy: 0.771484375\n",
      "Batch: 33, Loss: 0.7775124907493591, Accuracy: 0.7548828125\n",
      "Batch: 34, Loss: 0.8687471747398376, Accuracy: 0.716796875\n",
      "Batch: 35, Loss: 0.7373905777931213, Accuracy: 0.771484375\n",
      "Batch: 36, Loss: 0.7896065711975098, Accuracy: 0.759765625\n",
      "Batch: 37, Loss: 0.74336838722229, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7489229440689087, Accuracy: 0.7626953125\n",
      "Batch: 39, Loss: 0.7511317729949951, Accuracy: 0.7412109375\n",
      "Batch: 40, Loss: 0.7479263544082642, Accuracy: 0.767578125\n",
      "Batch: 41, Loss: 0.711950421333313, Accuracy: 0.7724609375\n",
      "Batch: 42, Loss: 0.5618839263916016, Accuracy: 0.8115234375\n",
      "Batch: 43, Loss: 0.6934822797775269, Accuracy: 0.763671875\n",
      "Batch: 44, Loss: 0.7502667307853699, Accuracy: 0.7509765625\n",
      "Batch: 45, Loss: 0.6695092916488647, Accuracy: 0.76171875\n",
      "Batch: 46, Loss: 0.6717538833618164, Accuracy: 0.7783203125\n",
      "Batch: 47, Loss: 0.6851950883865356, Accuracy: 0.7890625\n",
      "Batch: 48, Loss: 0.634491503238678, Accuracy: 0.8046875\n",
      "Batch: 49, Loss: 0.7562223672866821, Accuracy: 0.7626953125\n",
      "Batch: 50, Loss: 0.7500779032707214, Accuracy: 0.7509765625\n",
      "Batch: 51, Loss: 0.813101053237915, Accuracy: 0.751953125\n",
      "Batch: 52, Loss: 0.7323503494262695, Accuracy: 0.7734375\n",
      "Batch: 53, Loss: 0.6905325055122375, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.7236680388450623, Accuracy: 0.7626953125\n",
      "Batch: 55, Loss: 0.7840108871459961, Accuracy: 0.7421875\n",
      "Batch: 56, Loss: 0.8155918121337891, Accuracy: 0.744140625\n",
      "Batch: 57, Loss: 0.7392624020576477, Accuracy: 0.76953125\n",
      "Batch: 58, Loss: 0.8047598600387573, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.7261399030685425, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.6775974035263062, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7339943647384644, Accuracy: 0.73828125\n",
      "Batch: 62, Loss: 0.6607357263565063, Accuracy: 0.7744140625\n",
      "Batch: 63, Loss: 0.7247952222824097, Accuracy: 0.7626953125\n",
      "Batch: 64, Loss: 0.7022801041603088, Accuracy: 0.7705078125\n",
      "Batch: 65, Loss: 0.7409469485282898, Accuracy: 0.759765625\n",
      "Batch: 66, Loss: 0.7279469966888428, Accuracy: 0.76953125\n",
      "Batch: 67, Loss: 0.7999534606933594, Accuracy: 0.7451171875\n",
      "Batch: 68, Loss: 0.8495248556137085, Accuracy: 0.734375\n",
      "Batch: 69, Loss: 0.7936925888061523, Accuracy: 0.7255859375\n",
      "Batch: 70, Loss: 0.738442063331604, Accuracy: 0.767578125\n",
      "Batch: 71, Loss: 0.7782723307609558, Accuracy: 0.7265625\n",
      "Batch: 72, Loss: 0.6539725065231323, Accuracy: 0.7890625\n",
      "Batch: 73, Loss: 0.6775398254394531, Accuracy: 0.78125\n",
      "Batch: 74, Loss: 0.6472334861755371, Accuracy: 0.8017578125\n",
      "Batch: 75, Loss: 0.6093499660491943, Accuracy: 0.8056640625\n",
      "Batch: 76, Loss: 0.7362586259841919, Accuracy: 0.7685546875\n",
      "Batch: 77, Loss: 0.6916326284408569, Accuracy: 0.7685546875\n",
      "Batch: 78, Loss: 0.6799948215484619, Accuracy: 0.78125\n",
      "Batch: 79, Loss: 0.6406624913215637, Accuracy: 0.806640625\n",
      "Batch: 80, Loss: 0.7030850648880005, Accuracy: 0.7705078125\n",
      "Batch: 81, Loss: 0.7584893703460693, Accuracy: 0.736328125\n",
      "Batch: 82, Loss: 0.7327846884727478, Accuracy: 0.7646484375\n",
      "Batch: 83, Loss: 0.6549437046051025, Accuracy: 0.7900390625\n",
      "Batch: 84, Loss: 0.7517783045768738, Accuracy: 0.7548828125\n",
      "Batch: 85, Loss: 0.6768758296966553, Accuracy: 0.7861328125\n",
      "Batch: 86, Loss: 0.8398252725601196, Accuracy: 0.7275390625\n",
      "Batch: 87, Loss: 0.694911777973175, Accuracy: 0.7763671875\n",
      "Batch: 88, Loss: 0.8083664774894714, Accuracy: 0.755859375\n",
      "Batch: 89, Loss: 0.7821561098098755, Accuracy: 0.7548828125\n",
      "Batch: 90, Loss: 0.7241740822792053, Accuracy: 0.7783203125\n",
      "Batch: 91, Loss: 0.7079357504844666, Accuracy: 0.7685546875\n",
      "Batch: 92, Loss: 0.7932218313217163, Accuracy: 0.759765625\n",
      "Batch: 93, Loss: 0.704924464225769, Accuracy: 0.765625\n",
      "Batch: 94, Loss: 0.7364342212677002, Accuracy: 0.759765625\n",
      "Batch: 95, Loss: 0.7749434113502502, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7239348292350769, Accuracy: 0.75\n",
      "Batch: 97, Loss: 0.6159374713897705, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.6756913661956787, Accuracy: 0.78125\n",
      "Batch: 99, Loss: 0.678532600402832, Accuracy: 0.76953125\n",
      "Batch: 100, Loss: 0.756969690322876, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.7528936862945557, Accuracy: 0.7470703125\n",
      "Batch: 102, Loss: 0.7377256155014038, Accuracy: 0.755859375\n",
      "Batch: 103, Loss: 0.737801730632782, Accuracy: 0.779296875\n",
      "Batch: 104, Loss: 0.6875168085098267, Accuracy: 0.7666015625\n",
      "Batch: 105, Loss: 0.7375526428222656, Accuracy: 0.7646484375\n",
      "Batch: 106, Loss: 0.6762688159942627, Accuracy: 0.7880859375\n",
      "Batch: 107, Loss: 0.7249513864517212, Accuracy: 0.7646484375\n",
      "Batch: 108, Loss: 0.7184106111526489, Accuracy: 0.7548828125\n",
      "Batch: 109, Loss: 0.8148477077484131, Accuracy: 0.7294921875\n",
      "Batch: 110, Loss: 0.6460198163986206, Accuracy: 0.7861328125\n",
      "Batch: 111, Loss: 0.7635082006454468, Accuracy: 0.751953125\n",
      "Batch: 112, Loss: 0.7445641756057739, Accuracy: 0.7607421875\n",
      "Batch: 113, Loss: 0.73127281665802, Accuracy: 0.7734375\n",
      "Batch: 114, Loss: 0.8074955940246582, Accuracy: 0.7333984375\n",
      "Batch: 115, Loss: 0.7979267835617065, Accuracy: 0.740234375\n",
      "Batch: 116, Loss: 0.7460429668426514, Accuracy: 0.759765625\n",
      "Batch: 117, Loss: 0.7335447669029236, Accuracy: 0.7646484375\n",
      "Batch: 118, Loss: 0.6687273383140564, Accuracy: 0.796875\n",
      "Batch: 119, Loss: 0.6385257244110107, Accuracy: 0.794921875\n",
      "Batch: 120, Loss: 0.7474037408828735, Accuracy: 0.7607421875\n",
      "Batch: 121, Loss: 0.7901644110679626, Accuracy: 0.7451171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 0.7272809743881226, Accuracy: 0.767578125\n",
      "Batch: 123, Loss: 0.6872096061706543, Accuracy: 0.7783203125\n",
      "Batch: 124, Loss: 0.7634946703910828, Accuracy: 0.755859375\n",
      "Batch: 125, Loss: 0.7855595946311951, Accuracy: 0.73828125\n",
      "Batch: 126, Loss: 0.7513192892074585, Accuracy: 0.763671875\n",
      "Batch: 127, Loss: 0.6893923282623291, Accuracy: 0.7861328125\n",
      "Batch: 128, Loss: 0.8291023969650269, Accuracy: 0.7373046875\n",
      "Batch: 129, Loss: 0.6972057819366455, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.8347058296203613, Accuracy: 0.73046875\n",
      "Batch: 131, Loss: 0.7517773509025574, Accuracy: 0.751953125\n",
      "Batch: 132, Loss: 0.7411555647850037, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.7101924419403076, Accuracy: 0.771484375\n",
      "Batch: 134, Loss: 0.7530297636985779, Accuracy: 0.7373046875\n",
      "Batch: 135, Loss: 0.674872875213623, Accuracy: 0.7822265625\n",
      "Batch: 136, Loss: 0.7433730363845825, Accuracy: 0.767578125\n",
      "Batch: 137, Loss: 0.7536317110061646, Accuracy: 0.75\n",
      "Batch: 138, Loss: 0.6668409109115601, Accuracy: 0.78125\n",
      "Batch: 139, Loss: 0.7439665198326111, Accuracy: 0.7412109375\n",
      "Batch: 140, Loss: 0.6930752992630005, Accuracy: 0.7646484375\n",
      "Batch: 141, Loss: 0.8146989345550537, Accuracy: 0.75\n",
      "Batch: 142, Loss: 0.7467290759086609, Accuracy: 0.73828125\n",
      "Batch: 143, Loss: 0.7350393533706665, Accuracy: 0.7685546875\n",
      "Batch: 144, Loss: 0.7893940210342407, Accuracy: 0.73046875\n",
      "Batch: 145, Loss: 0.6970530152320862, Accuracy: 0.7724609375\n",
      "Batch: 146, Loss: 0.7715404033660889, Accuracy: 0.75390625\n",
      "Batch: 147, Loss: 0.741662859916687, Accuracy: 0.7568359375\n",
      "Batch: 148, Loss: 0.855090320110321, Accuracy: 0.728515625\n",
      "Batch: 149, Loss: 0.7351124286651611, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.7223577499389648, Accuracy: 0.7685546875\n",
      "Batch: 151, Loss: 0.6498992443084717, Accuracy: 0.7744140625\n",
      "Epoch 38/80\n",
      "Batch: 1, Loss: 0.9512341022491455, Accuracy: 0.69140625\n",
      "Batch: 2, Loss: 0.8094828128814697, Accuracy: 0.7216796875\n",
      "Batch: 3, Loss: 0.7129163146018982, Accuracy: 0.7666015625\n",
      "Batch: 4, Loss: 0.6913312673568726, Accuracy: 0.78125\n",
      "Batch: 5, Loss: 0.6755127906799316, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.7325178384780884, Accuracy: 0.7568359375\n",
      "Batch: 7, Loss: 0.7335941791534424, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.6873030662536621, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.7144775390625, Accuracy: 0.765625\n",
      "Batch: 10, Loss: 0.6877269744873047, Accuracy: 0.7685546875\n",
      "Batch: 11, Loss: 0.7955889105796814, Accuracy: 0.7333984375\n",
      "Batch: 12, Loss: 0.7555238008499146, Accuracy: 0.7548828125\n",
      "Batch: 13, Loss: 0.5929948091506958, Accuracy: 0.810546875\n",
      "Batch: 14, Loss: 0.8074405789375305, Accuracy: 0.75\n",
      "Batch: 15, Loss: 0.6872853636741638, Accuracy: 0.791015625\n",
      "Batch: 16, Loss: 0.7070033550262451, Accuracy: 0.7880859375\n",
      "Batch: 17, Loss: 0.7508314847946167, Accuracy: 0.7509765625\n",
      "Batch: 18, Loss: 0.7697222232818604, Accuracy: 0.7666015625\n",
      "Batch: 19, Loss: 0.772676408290863, Accuracy: 0.7412109375\n",
      "Batch: 20, Loss: 0.6403430104255676, Accuracy: 0.791015625\n",
      "Batch: 21, Loss: 0.7229841947555542, Accuracy: 0.7607421875\n",
      "Batch: 22, Loss: 0.8269378542900085, Accuracy: 0.7490234375\n",
      "Batch: 23, Loss: 0.7739584445953369, Accuracy: 0.7490234375\n",
      "Batch: 24, Loss: 0.7628520727157593, Accuracy: 0.7607421875\n",
      "Batch: 25, Loss: 0.7315544486045837, Accuracy: 0.775390625\n",
      "Batch: 26, Loss: 0.6284092664718628, Accuracy: 0.7822265625\n",
      "Batch: 27, Loss: 0.6857194900512695, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.765592634677887, Accuracy: 0.740234375\n",
      "Batch: 29, Loss: 0.712485134601593, Accuracy: 0.7646484375\n",
      "Batch: 30, Loss: 0.6262240409851074, Accuracy: 0.806640625\n",
      "Batch: 31, Loss: 0.6416157484054565, Accuracy: 0.79296875\n",
      "Batch: 32, Loss: 0.660075843334198, Accuracy: 0.78125\n",
      "Batch: 33, Loss: 0.7818995714187622, Accuracy: 0.7626953125\n",
      "Batch: 34, Loss: 0.8727658987045288, Accuracy: 0.7216796875\n",
      "Batch: 35, Loss: 0.7576701641082764, Accuracy: 0.7529296875\n",
      "Batch: 36, Loss: 0.751427948474884, Accuracy: 0.7763671875\n",
      "Batch: 37, Loss: 0.7434550523757935, Accuracy: 0.7587890625\n",
      "Batch: 38, Loss: 0.7441748380661011, Accuracy: 0.73828125\n",
      "Batch: 39, Loss: 0.7423814535140991, Accuracy: 0.76953125\n",
      "Batch: 40, Loss: 0.7384930849075317, Accuracy: 0.7607421875\n",
      "Batch: 41, Loss: 0.705902099609375, Accuracy: 0.78125\n",
      "Batch: 42, Loss: 0.5740972757339478, Accuracy: 0.8017578125\n",
      "Batch: 43, Loss: 0.7273644208908081, Accuracy: 0.7490234375\n",
      "Batch: 44, Loss: 0.729634165763855, Accuracy: 0.7646484375\n",
      "Batch: 45, Loss: 0.6199436187744141, Accuracy: 0.787109375\n",
      "Batch: 46, Loss: 0.6578059196472168, Accuracy: 0.775390625\n",
      "Batch: 47, Loss: 0.6642494797706604, Accuracy: 0.7890625\n",
      "Batch: 48, Loss: 0.6612555980682373, Accuracy: 0.78515625\n",
      "Batch: 49, Loss: 0.7533800601959229, Accuracy: 0.765625\n",
      "Batch: 50, Loss: 0.7514629364013672, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7805941700935364, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.7190608978271484, Accuracy: 0.7900390625\n",
      "Batch: 53, Loss: 0.6690869331359863, Accuracy: 0.7666015625\n",
      "Batch: 54, Loss: 0.7249181270599365, Accuracy: 0.7685546875\n",
      "Batch: 55, Loss: 0.8010400533676147, Accuracy: 0.7216796875\n",
      "Batch: 56, Loss: 0.7764300107955933, Accuracy: 0.744140625\n",
      "Batch: 57, Loss: 0.7704359292984009, Accuracy: 0.744140625\n",
      "Batch: 58, Loss: 0.787155032157898, Accuracy: 0.7490234375\n",
      "Batch: 59, Loss: 0.7039735317230225, Accuracy: 0.76953125\n",
      "Batch: 60, Loss: 0.6486727595329285, Accuracy: 0.7822265625\n",
      "Batch: 61, Loss: 0.7476503849029541, Accuracy: 0.75390625\n",
      "Batch: 62, Loss: 0.6675618886947632, Accuracy: 0.7802734375\n",
      "Batch: 63, Loss: 0.7144446969032288, Accuracy: 0.7568359375\n",
      "Batch: 64, Loss: 0.6955201029777527, Accuracy: 0.765625\n",
      "Batch: 65, Loss: 0.716514527797699, Accuracy: 0.7763671875\n",
      "Batch: 66, Loss: 0.7010055780410767, Accuracy: 0.76953125\n",
      "Batch: 67, Loss: 0.7714222073554993, Accuracy: 0.7666015625\n",
      "Batch: 68, Loss: 0.7886271476745605, Accuracy: 0.75390625\n",
      "Batch: 69, Loss: 0.7457577586174011, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.7475055456161499, Accuracy: 0.7529296875\n",
      "Batch: 71, Loss: 0.7557898163795471, Accuracy: 0.75390625\n",
      "Batch: 72, Loss: 0.674675464630127, Accuracy: 0.7841796875\n",
      "Batch: 73, Loss: 0.6607030630111694, Accuracy: 0.7763671875\n",
      "Batch: 74, Loss: 0.614124059677124, Accuracy: 0.8056640625\n",
      "Batch: 75, Loss: 0.6381045579910278, Accuracy: 0.7939453125\n",
      "Batch: 76, Loss: 0.7561389207839966, Accuracy: 0.7490234375\n",
      "Batch: 77, Loss: 0.6704699993133545, Accuracy: 0.7724609375\n",
      "Batch: 78, Loss: 0.684952974319458, Accuracy: 0.7802734375\n",
      "Batch: 79, Loss: 0.6276274919509888, Accuracy: 0.802734375\n",
      "Batch: 80, Loss: 0.6596630811691284, Accuracy: 0.783203125\n",
      "Batch: 81, Loss: 0.7623157501220703, Accuracy: 0.736328125\n",
      "Batch: 82, Loss: 0.7275543808937073, Accuracy: 0.7626953125\n",
      "Batch: 83, Loss: 0.6135187149047852, Accuracy: 0.806640625\n",
      "Batch: 84, Loss: 0.6990475058555603, Accuracy: 0.7783203125\n",
      "Batch: 85, Loss: 0.6989073157310486, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.8401417136192322, Accuracy: 0.7490234375\n",
      "Batch: 87, Loss: 0.6449663639068604, Accuracy: 0.802734375\n",
      "Batch: 88, Loss: 0.7717649936676025, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7502743005752563, Accuracy: 0.763671875\n",
      "Batch: 90, Loss: 0.7160767912864685, Accuracy: 0.78125\n",
      "Batch: 91, Loss: 0.6939284801483154, Accuracy: 0.779296875\n",
      "Batch: 92, Loss: 0.7313712239265442, Accuracy: 0.7705078125\n",
      "Batch: 93, Loss: 0.6745761632919312, Accuracy: 0.78125\n",
      "Batch: 94, Loss: 0.7111781239509583, Accuracy: 0.7744140625\n",
      "Batch: 95, Loss: 0.7530527114868164, Accuracy: 0.740234375\n",
      "Batch: 96, Loss: 0.7099878191947937, Accuracy: 0.767578125\n",
      "Batch: 97, Loss: 0.6116766929626465, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.6617226600646973, Accuracy: 0.775390625\n",
      "Batch: 99, Loss: 0.6678788661956787, Accuracy: 0.78515625\n",
      "Batch: 100, Loss: 0.7086662650108337, Accuracy: 0.775390625\n",
      "Batch: 101, Loss: 0.7677820920944214, Accuracy: 0.734375\n",
      "Batch: 102, Loss: 0.7020385265350342, Accuracy: 0.7646484375\n",
      "Batch: 103, Loss: 0.7179391384124756, Accuracy: 0.779296875\n",
      "Batch: 104, Loss: 0.6613246202468872, Accuracy: 0.7646484375\n",
      "Batch: 105, Loss: 0.7507699728012085, Accuracy: 0.755859375\n",
      "Batch: 106, Loss: 0.6734178066253662, Accuracy: 0.7744140625\n",
      "Batch: 107, Loss: 0.7175366878509521, Accuracy: 0.7763671875\n",
      "Batch: 108, Loss: 0.7031974792480469, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.8188856840133667, Accuracy: 0.73046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 110, Loss: 0.6082952618598938, Accuracy: 0.802734375\n",
      "Batch: 111, Loss: 0.7431588172912598, Accuracy: 0.759765625\n",
      "Batch: 112, Loss: 0.7600679397583008, Accuracy: 0.7724609375\n",
      "Batch: 113, Loss: 0.7274396419525146, Accuracy: 0.7841796875\n",
      "Batch: 114, Loss: 0.8127524852752686, Accuracy: 0.7412109375\n",
      "Batch: 115, Loss: 0.781352162361145, Accuracy: 0.7509765625\n",
      "Batch: 116, Loss: 0.7324668169021606, Accuracy: 0.755859375\n",
      "Batch: 117, Loss: 0.7470544576644897, Accuracy: 0.751953125\n",
      "Batch: 118, Loss: 0.6624380350112915, Accuracy: 0.7900390625\n",
      "Batch: 119, Loss: 0.6353271007537842, Accuracy: 0.7998046875\n",
      "Batch: 120, Loss: 0.7248501777648926, Accuracy: 0.7666015625\n",
      "Batch: 121, Loss: 0.8050272464752197, Accuracy: 0.7451171875\n",
      "Batch: 122, Loss: 0.6724311113357544, Accuracy: 0.7861328125\n",
      "Batch: 123, Loss: 0.6732738614082336, Accuracy: 0.7763671875\n",
      "Batch: 124, Loss: 0.7227528095245361, Accuracy: 0.775390625\n",
      "Batch: 125, Loss: 0.7426678538322449, Accuracy: 0.767578125\n",
      "Batch: 126, Loss: 0.7433541417121887, Accuracy: 0.7529296875\n",
      "Batch: 127, Loss: 0.6734024286270142, Accuracy: 0.7822265625\n",
      "Batch: 128, Loss: 0.8218958377838135, Accuracy: 0.7509765625\n",
      "Batch: 129, Loss: 0.6714402437210083, Accuracy: 0.7802734375\n",
      "Batch: 130, Loss: 0.816365122795105, Accuracy: 0.73046875\n",
      "Batch: 131, Loss: 0.7422424554824829, Accuracy: 0.7607421875\n",
      "Batch: 132, Loss: 0.748275101184845, Accuracy: 0.76953125\n",
      "Batch: 133, Loss: 0.6950703859329224, Accuracy: 0.7783203125\n",
      "Batch: 134, Loss: 0.7345269918441772, Accuracy: 0.7568359375\n",
      "Batch: 135, Loss: 0.6512019038200378, Accuracy: 0.78125\n",
      "Batch: 136, Loss: 0.7412671446800232, Accuracy: 0.7666015625\n",
      "Batch: 137, Loss: 0.7501147389411926, Accuracy: 0.7490234375\n",
      "Batch: 138, Loss: 0.6502128839492798, Accuracy: 0.7802734375\n",
      "Batch: 139, Loss: 0.7228829860687256, Accuracy: 0.755859375\n",
      "Batch: 140, Loss: 0.7121503353118896, Accuracy: 0.7646484375\n",
      "Batch: 141, Loss: 0.7855794429779053, Accuracy: 0.75390625\n",
      "Batch: 142, Loss: 0.7653580904006958, Accuracy: 0.744140625\n",
      "Batch: 143, Loss: 0.742725133895874, Accuracy: 0.763671875\n",
      "Batch: 144, Loss: 0.7224512100219727, Accuracy: 0.767578125\n",
      "Batch: 145, Loss: 0.6880450248718262, Accuracy: 0.7705078125\n",
      "Batch: 146, Loss: 0.7576465606689453, Accuracy: 0.75\n",
      "Batch: 147, Loss: 0.7462949752807617, Accuracy: 0.7666015625\n",
      "Batch: 148, Loss: 0.8724374771118164, Accuracy: 0.728515625\n",
      "Batch: 149, Loss: 0.717827320098877, Accuracy: 0.7607421875\n",
      "Batch: 150, Loss: 0.7179359197616577, Accuracy: 0.7724609375\n",
      "Batch: 151, Loss: 0.6592565774917603, Accuracy: 0.77734375\n",
      "Epoch 39/80\n",
      "Batch: 1, Loss: 0.9289745092391968, Accuracy: 0.705078125\n",
      "Batch: 2, Loss: 0.8335081934928894, Accuracy: 0.71484375\n",
      "Batch: 3, Loss: 0.6892450451850891, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.6457995772361755, Accuracy: 0.7958984375\n",
      "Batch: 5, Loss: 0.6815276741981506, Accuracy: 0.7880859375\n",
      "Batch: 6, Loss: 0.7240729331970215, Accuracy: 0.7529296875\n",
      "Batch: 7, Loss: 0.7301198244094849, Accuracy: 0.74609375\n",
      "Batch: 8, Loss: 0.6971852779388428, Accuracy: 0.7666015625\n",
      "Batch: 9, Loss: 0.6793587803840637, Accuracy: 0.794921875\n",
      "Batch: 10, Loss: 0.6691868305206299, Accuracy: 0.7724609375\n",
      "Batch: 11, Loss: 0.8015138506889343, Accuracy: 0.7392578125\n",
      "Batch: 12, Loss: 0.7750685214996338, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.5908011198043823, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.8000519275665283, Accuracy: 0.7578125\n",
      "Batch: 15, Loss: 0.669991135597229, Accuracy: 0.8037109375\n",
      "Batch: 16, Loss: 0.6841784715652466, Accuracy: 0.7919921875\n",
      "Batch: 17, Loss: 0.7498334646224976, Accuracy: 0.7568359375\n",
      "Batch: 18, Loss: 0.7794098854064941, Accuracy: 0.7587890625\n",
      "Batch: 19, Loss: 0.749130368232727, Accuracy: 0.759765625\n",
      "Batch: 20, Loss: 0.6500833034515381, Accuracy: 0.7919921875\n",
      "Batch: 21, Loss: 0.7002218961715698, Accuracy: 0.7626953125\n",
      "Batch: 22, Loss: 0.7896621227264404, Accuracy: 0.751953125\n",
      "Batch: 23, Loss: 0.7750599980354309, Accuracy: 0.7431640625\n",
      "Batch: 24, Loss: 0.7680255174636841, Accuracy: 0.7607421875\n",
      "Batch: 25, Loss: 0.715582013130188, Accuracy: 0.7734375\n",
      "Batch: 26, Loss: 0.6578539609909058, Accuracy: 0.7783203125\n",
      "Batch: 27, Loss: 0.6548284292221069, Accuracy: 0.7666015625\n",
      "Batch: 28, Loss: 0.7276467084884644, Accuracy: 0.7705078125\n",
      "Batch: 29, Loss: 0.7153765559196472, Accuracy: 0.7626953125\n",
      "Batch: 30, Loss: 0.6166912317276001, Accuracy: 0.80859375\n",
      "Batch: 31, Loss: 0.6392722129821777, Accuracy: 0.78515625\n",
      "Batch: 32, Loss: 0.6855186223983765, Accuracy: 0.7802734375\n",
      "Batch: 33, Loss: 0.7545116543769836, Accuracy: 0.7578125\n",
      "Batch: 34, Loss: 0.8514447212219238, Accuracy: 0.7353515625\n",
      "Batch: 35, Loss: 0.7555073499679565, Accuracy: 0.74609375\n",
      "Batch: 36, Loss: 0.7375010251998901, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.725629448890686, Accuracy: 0.759765625\n",
      "Batch: 38, Loss: 0.7716089487075806, Accuracy: 0.7294921875\n",
      "Batch: 39, Loss: 0.7445086240768433, Accuracy: 0.76953125\n",
      "Batch: 40, Loss: 0.7127029299736023, Accuracy: 0.7734375\n",
      "Batch: 41, Loss: 0.6723670959472656, Accuracy: 0.7880859375\n",
      "Batch: 42, Loss: 0.526279866695404, Accuracy: 0.822265625\n",
      "Batch: 43, Loss: 0.7089903950691223, Accuracy: 0.767578125\n",
      "Batch: 44, Loss: 0.7138991951942444, Accuracy: 0.7529296875\n",
      "Batch: 45, Loss: 0.6340186595916748, Accuracy: 0.7919921875\n",
      "Batch: 46, Loss: 0.6346312761306763, Accuracy: 0.7998046875\n",
      "Batch: 47, Loss: 0.6761602163314819, Accuracy: 0.7890625\n",
      "Batch: 48, Loss: 0.6343392729759216, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.7844234704971313, Accuracy: 0.75\n",
      "Batch: 50, Loss: 0.7695867419242859, Accuracy: 0.7626953125\n",
      "Batch: 51, Loss: 0.7690719366073608, Accuracy: 0.771484375\n",
      "Batch: 52, Loss: 0.7594809532165527, Accuracy: 0.759765625\n",
      "Batch: 53, Loss: 0.6706705689430237, Accuracy: 0.7744140625\n",
      "Batch: 54, Loss: 0.7021743059158325, Accuracy: 0.7734375\n",
      "Batch: 55, Loss: 0.798641562461853, Accuracy: 0.73046875\n",
      "Batch: 56, Loss: 0.8025164604187012, Accuracy: 0.736328125\n",
      "Batch: 57, Loss: 0.7551587820053101, Accuracy: 0.759765625\n",
      "Batch: 58, Loss: 0.8090483546257019, Accuracy: 0.74609375\n",
      "Batch: 59, Loss: 0.699184775352478, Accuracy: 0.7744140625\n",
      "Batch: 60, Loss: 0.6385339498519897, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.6979498863220215, Accuracy: 0.7607421875\n",
      "Batch: 62, Loss: 0.6486656665802002, Accuracy: 0.79296875\n",
      "Batch: 63, Loss: 0.7291604280471802, Accuracy: 0.76953125\n",
      "Batch: 64, Loss: 0.7272418141365051, Accuracy: 0.779296875\n",
      "Batch: 65, Loss: 0.7093876600265503, Accuracy: 0.7734375\n",
      "Batch: 66, Loss: 0.7016786336898804, Accuracy: 0.775390625\n",
      "Batch: 67, Loss: 0.7458509802818298, Accuracy: 0.7490234375\n",
      "Batch: 68, Loss: 0.7972657680511475, Accuracy: 0.7314453125\n",
      "Batch: 69, Loss: 0.7406713962554932, Accuracy: 0.7666015625\n",
      "Batch: 70, Loss: 0.7341150045394897, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.7510733604431152, Accuracy: 0.7421875\n",
      "Batch: 72, Loss: 0.6897813081741333, Accuracy: 0.7802734375\n",
      "Batch: 73, Loss: 0.6483806371688843, Accuracy: 0.7861328125\n",
      "Batch: 74, Loss: 0.6137215495109558, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.6071435809135437, Accuracy: 0.8056640625\n",
      "Batch: 76, Loss: 0.7507448196411133, Accuracy: 0.75390625\n",
      "Batch: 77, Loss: 0.6710932850837708, Accuracy: 0.7841796875\n",
      "Batch: 78, Loss: 0.6602286696434021, Accuracy: 0.7919921875\n",
      "Batch: 79, Loss: 0.6525652408599854, Accuracy: 0.7958984375\n",
      "Batch: 80, Loss: 0.6842365264892578, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.7347084283828735, Accuracy: 0.736328125\n",
      "Batch: 82, Loss: 0.7177000045776367, Accuracy: 0.7626953125\n",
      "Batch: 83, Loss: 0.6332039833068848, Accuracy: 0.802734375\n",
      "Batch: 84, Loss: 0.7187939286231995, Accuracy: 0.76953125\n",
      "Batch: 85, Loss: 0.662279486656189, Accuracy: 0.787109375\n",
      "Batch: 86, Loss: 0.8332135677337646, Accuracy: 0.734375\n",
      "Batch: 87, Loss: 0.6354902386665344, Accuracy: 0.8037109375\n",
      "Batch: 88, Loss: 0.7691414952278137, Accuracy: 0.7626953125\n",
      "Batch: 89, Loss: 0.7429581880569458, Accuracy: 0.7763671875\n",
      "Batch: 90, Loss: 0.7278602123260498, Accuracy: 0.7587890625\n",
      "Batch: 91, Loss: 0.7203077077865601, Accuracy: 0.76171875\n",
      "Batch: 92, Loss: 0.7677596211433411, Accuracy: 0.751953125\n",
      "Batch: 93, Loss: 0.7171370983123779, Accuracy: 0.771484375\n",
      "Batch: 94, Loss: 0.7179298400878906, Accuracy: 0.767578125\n",
      "Batch: 95, Loss: 0.721328854560852, Accuracy: 0.763671875\n",
      "Batch: 96, Loss: 0.7158068418502808, Accuracy: 0.765625\n",
      "Batch: 97, Loss: 0.5738401412963867, Accuracy: 0.8212890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 98, Loss: 0.6622142195701599, Accuracy: 0.7802734375\n",
      "Batch: 99, Loss: 0.6507763862609863, Accuracy: 0.7841796875\n",
      "Batch: 100, Loss: 0.7322554588317871, Accuracy: 0.7509765625\n",
      "Batch: 101, Loss: 0.752503514289856, Accuracy: 0.7412109375\n",
      "Batch: 102, Loss: 0.7119789123535156, Accuracy: 0.759765625\n",
      "Batch: 103, Loss: 0.699035108089447, Accuracy: 0.7802734375\n",
      "Batch: 104, Loss: 0.640334963798523, Accuracy: 0.7880859375\n",
      "Batch: 105, Loss: 0.7081884145736694, Accuracy: 0.755859375\n",
      "Batch: 106, Loss: 0.6585675477981567, Accuracy: 0.791015625\n",
      "Batch: 107, Loss: 0.7118314504623413, Accuracy: 0.771484375\n",
      "Batch: 108, Loss: 0.6769205331802368, Accuracy: 0.7744140625\n",
      "Batch: 109, Loss: 0.8036320209503174, Accuracy: 0.736328125\n",
      "Batch: 110, Loss: 0.6246086955070496, Accuracy: 0.78125\n",
      "Batch: 111, Loss: 0.7110129594802856, Accuracy: 0.7744140625\n",
      "Batch: 112, Loss: 0.7153710126876831, Accuracy: 0.7783203125\n",
      "Batch: 113, Loss: 0.7021093368530273, Accuracy: 0.779296875\n",
      "Batch: 114, Loss: 0.8098819255828857, Accuracy: 0.7548828125\n",
      "Batch: 115, Loss: 0.7908167243003845, Accuracy: 0.7431640625\n",
      "Batch: 116, Loss: 0.7391431331634521, Accuracy: 0.7568359375\n",
      "Batch: 117, Loss: 0.7462043762207031, Accuracy: 0.7646484375\n",
      "Batch: 118, Loss: 0.6769647598266602, Accuracy: 0.7958984375\n",
      "Batch: 119, Loss: 0.607319176197052, Accuracy: 0.802734375\n",
      "Batch: 120, Loss: 0.6997053623199463, Accuracy: 0.76953125\n",
      "Batch: 121, Loss: 0.7653205394744873, Accuracy: 0.7412109375\n",
      "Batch: 122, Loss: 0.6751434803009033, Accuracy: 0.7841796875\n",
      "Batch: 123, Loss: 0.666580080986023, Accuracy: 0.78515625\n",
      "Batch: 124, Loss: 0.7397092580795288, Accuracy: 0.7607421875\n",
      "Batch: 125, Loss: 0.7617505192756653, Accuracy: 0.73828125\n",
      "Batch: 126, Loss: 0.7442965507507324, Accuracy: 0.75\n",
      "Batch: 127, Loss: 0.6469988822937012, Accuracy: 0.7939453125\n",
      "Batch: 128, Loss: 0.7949503660202026, Accuracy: 0.7548828125\n",
      "Batch: 129, Loss: 0.6683202385902405, Accuracy: 0.7861328125\n",
      "Batch: 130, Loss: 0.8093178868293762, Accuracy: 0.728515625\n",
      "Batch: 131, Loss: 0.7190194725990295, Accuracy: 0.76953125\n",
      "Batch: 132, Loss: 0.7490358948707581, Accuracy: 0.7509765625\n",
      "Batch: 133, Loss: 0.6884967088699341, Accuracy: 0.7685546875\n",
      "Batch: 134, Loss: 0.7437692284584045, Accuracy: 0.744140625\n",
      "Batch: 135, Loss: 0.6675712466239929, Accuracy: 0.783203125\n",
      "Batch: 136, Loss: 0.747390627861023, Accuracy: 0.7646484375\n",
      "Batch: 137, Loss: 0.7446693181991577, Accuracy: 0.73828125\n",
      "Batch: 138, Loss: 0.6182333827018738, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.7002569437026978, Accuracy: 0.7607421875\n",
      "Batch: 140, Loss: 0.6928190588951111, Accuracy: 0.7822265625\n",
      "Batch: 141, Loss: 0.7743829488754272, Accuracy: 0.751953125\n",
      "Batch: 142, Loss: 0.7420868873596191, Accuracy: 0.7548828125\n",
      "Batch: 143, Loss: 0.7280652523040771, Accuracy: 0.76953125\n",
      "Batch: 144, Loss: 0.7334640026092529, Accuracy: 0.76171875\n",
      "Batch: 145, Loss: 0.6832281351089478, Accuracy: 0.75390625\n",
      "Batch: 146, Loss: 0.7314456701278687, Accuracy: 0.7578125\n",
      "Batch: 147, Loss: 0.7383578419685364, Accuracy: 0.7568359375\n",
      "Batch: 148, Loss: 0.8321492075920105, Accuracy: 0.7333984375\n",
      "Batch: 149, Loss: 0.6921136379241943, Accuracy: 0.78125\n",
      "Batch: 150, Loss: 0.7041704058647156, Accuracy: 0.7744140625\n",
      "Batch: 151, Loss: 0.63433438539505, Accuracy: 0.7939453125\n",
      "Epoch 40/80\n",
      "Batch: 1, Loss: 0.9459728002548218, Accuracy: 0.69921875\n",
      "Batch: 2, Loss: 0.8235453367233276, Accuracy: 0.7177734375\n",
      "Batch: 3, Loss: 0.7108132243156433, Accuracy: 0.7607421875\n",
      "Batch: 4, Loss: 0.6618423461914062, Accuracy: 0.7861328125\n",
      "Batch: 5, Loss: 0.6782655119895935, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.7206149101257324, Accuracy: 0.7548828125\n",
      "Batch: 7, Loss: 0.7214633226394653, Accuracy: 0.7607421875\n",
      "Batch: 8, Loss: 0.676175594329834, Accuracy: 0.77734375\n",
      "Batch: 9, Loss: 0.6734555959701538, Accuracy: 0.7919921875\n",
      "Batch: 10, Loss: 0.7162309885025024, Accuracy: 0.7529296875\n",
      "Batch: 11, Loss: 0.7864049077033997, Accuracy: 0.7333984375\n",
      "Batch: 12, Loss: 0.7525134086608887, Accuracy: 0.736328125\n",
      "Batch: 13, Loss: 0.5646300315856934, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.8033151626586914, Accuracy: 0.7490234375\n",
      "Batch: 15, Loss: 0.6538511514663696, Accuracy: 0.798828125\n",
      "Batch: 16, Loss: 0.6996856927871704, Accuracy: 0.78515625\n",
      "Batch: 17, Loss: 0.7447259426116943, Accuracy: 0.76171875\n",
      "Batch: 18, Loss: 0.7551521062850952, Accuracy: 0.7529296875\n",
      "Batch: 19, Loss: 0.7603938579559326, Accuracy: 0.75390625\n",
      "Batch: 20, Loss: 0.6481017470359802, Accuracy: 0.8046875\n",
      "Batch: 21, Loss: 0.699741780757904, Accuracy: 0.7705078125\n",
      "Batch: 22, Loss: 0.7802697420120239, Accuracy: 0.7470703125\n",
      "Batch: 23, Loss: 0.7410967350006104, Accuracy: 0.7607421875\n",
      "Batch: 24, Loss: 0.7597930431365967, Accuracy: 0.7568359375\n",
      "Batch: 25, Loss: 0.6853799819946289, Accuracy: 0.7890625\n",
      "Batch: 26, Loss: 0.6497200131416321, Accuracy: 0.7783203125\n",
      "Batch: 27, Loss: 0.6464020013809204, Accuracy: 0.7861328125\n",
      "Batch: 28, Loss: 0.7202147841453552, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.6972428560256958, Accuracy: 0.7724609375\n",
      "Batch: 30, Loss: 0.6192147135734558, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.633979320526123, Accuracy: 0.7939453125\n",
      "Batch: 32, Loss: 0.6388134956359863, Accuracy: 0.7900390625\n",
      "Batch: 33, Loss: 0.7511539459228516, Accuracy: 0.763671875\n",
      "Batch: 34, Loss: 0.7779340744018555, Accuracy: 0.7392578125\n",
      "Batch: 35, Loss: 0.7389066219329834, Accuracy: 0.7666015625\n",
      "Batch: 36, Loss: 0.7408636808395386, Accuracy: 0.791015625\n",
      "Batch: 37, Loss: 0.7061444520950317, Accuracy: 0.7705078125\n",
      "Batch: 38, Loss: 0.7024863362312317, Accuracy: 0.765625\n",
      "Batch: 39, Loss: 0.718627393245697, Accuracy: 0.7734375\n",
      "Batch: 40, Loss: 0.6983917355537415, Accuracy: 0.7822265625\n",
      "Batch: 41, Loss: 0.665103554725647, Accuracy: 0.7861328125\n",
      "Batch: 42, Loss: 0.5505193471908569, Accuracy: 0.8056640625\n",
      "Batch: 43, Loss: 0.6909927129745483, Accuracy: 0.767578125\n",
      "Batch: 44, Loss: 0.734991192817688, Accuracy: 0.7626953125\n",
      "Batch: 45, Loss: 0.6070695519447327, Accuracy: 0.8037109375\n",
      "Batch: 46, Loss: 0.6650351285934448, Accuracy: 0.7763671875\n",
      "Batch: 47, Loss: 0.6477851867675781, Accuracy: 0.7919921875\n",
      "Batch: 48, Loss: 0.6305718421936035, Accuracy: 0.7939453125\n",
      "Batch: 49, Loss: 0.7342526316642761, Accuracy: 0.7666015625\n",
      "Batch: 50, Loss: 0.7129400968551636, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.7863197326660156, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.7334119081497192, Accuracy: 0.775390625\n",
      "Batch: 53, Loss: 0.6461136937141418, Accuracy: 0.7841796875\n",
      "Batch: 54, Loss: 0.6771723031997681, Accuracy: 0.7734375\n",
      "Batch: 55, Loss: 0.7989253997802734, Accuracy: 0.7431640625\n",
      "Batch: 56, Loss: 0.7574982047080994, Accuracy: 0.7587890625\n",
      "Batch: 57, Loss: 0.7335090637207031, Accuracy: 0.771484375\n",
      "Batch: 58, Loss: 0.8034950494766235, Accuracy: 0.7451171875\n",
      "Batch: 59, Loss: 0.6846153736114502, Accuracy: 0.77734375\n",
      "Batch: 60, Loss: 0.6541597843170166, Accuracy: 0.77734375\n",
      "Batch: 61, Loss: 0.7225731611251831, Accuracy: 0.7724609375\n",
      "Batch: 62, Loss: 0.6831624507904053, Accuracy: 0.7685546875\n",
      "Batch: 63, Loss: 0.7215415835380554, Accuracy: 0.771484375\n",
      "Batch: 64, Loss: 0.7134513854980469, Accuracy: 0.7763671875\n",
      "Batch: 65, Loss: 0.682799220085144, Accuracy: 0.7763671875\n",
      "Batch: 66, Loss: 0.7082717418670654, Accuracy: 0.7705078125\n",
      "Batch: 67, Loss: 0.7601521015167236, Accuracy: 0.75390625\n",
      "Batch: 68, Loss: 0.8051732778549194, Accuracy: 0.73828125\n",
      "Batch: 69, Loss: 0.7609720230102539, Accuracy: 0.75390625\n",
      "Batch: 70, Loss: 0.6988037824630737, Accuracy: 0.7734375\n",
      "Batch: 71, Loss: 0.7596423625946045, Accuracy: 0.74609375\n",
      "Batch: 72, Loss: 0.6605821847915649, Accuracy: 0.7900390625\n",
      "Batch: 73, Loss: 0.671387791633606, Accuracy: 0.7822265625\n",
      "Batch: 74, Loss: 0.5911566019058228, Accuracy: 0.8154296875\n",
      "Batch: 75, Loss: 0.6300565600395203, Accuracy: 0.78515625\n",
      "Batch: 76, Loss: 0.7331314086914062, Accuracy: 0.76171875\n",
      "Batch: 77, Loss: 0.668913722038269, Accuracy: 0.794921875\n",
      "Batch: 78, Loss: 0.6512963771820068, Accuracy: 0.796875\n",
      "Batch: 79, Loss: 0.6294664144515991, Accuracy: 0.796875\n",
      "Batch: 80, Loss: 0.672425389289856, Accuracy: 0.7763671875\n",
      "Batch: 81, Loss: 0.7481685280799866, Accuracy: 0.7392578125\n",
      "Batch: 82, Loss: 0.7082104086875916, Accuracy: 0.759765625\n",
      "Batch: 83, Loss: 0.6061328649520874, Accuracy: 0.8095703125\n",
      "Batch: 84, Loss: 0.7113621234893799, Accuracy: 0.7744140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 0.6626268029212952, Accuracy: 0.79296875\n",
      "Batch: 86, Loss: 0.8384691476821899, Accuracy: 0.7373046875\n",
      "Batch: 87, Loss: 0.6369020342826843, Accuracy: 0.8076171875\n",
      "Batch: 88, Loss: 0.7712035775184631, Accuracy: 0.7568359375\n",
      "Batch: 89, Loss: 0.7270407676696777, Accuracy: 0.7705078125\n",
      "Batch: 90, Loss: 0.7224704027175903, Accuracy: 0.7783203125\n",
      "Batch: 91, Loss: 0.6978205442428589, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.7442328929901123, Accuracy: 0.7548828125\n",
      "Batch: 93, Loss: 0.6702620983123779, Accuracy: 0.783203125\n",
      "Batch: 94, Loss: 0.7245797514915466, Accuracy: 0.7724609375\n",
      "Batch: 95, Loss: 0.7337834239006042, Accuracy: 0.7451171875\n",
      "Batch: 96, Loss: 0.7074174284934998, Accuracy: 0.7802734375\n",
      "Batch: 97, Loss: 0.5897073745727539, Accuracy: 0.8046875\n",
      "Batch: 98, Loss: 0.6890017986297607, Accuracy: 0.763671875\n",
      "Batch: 99, Loss: 0.6952592134475708, Accuracy: 0.76171875\n",
      "Batch: 100, Loss: 0.7154438495635986, Accuracy: 0.7646484375\n",
      "Batch: 101, Loss: 0.7262556552886963, Accuracy: 0.7646484375\n",
      "Batch: 102, Loss: 0.670362651348114, Accuracy: 0.7802734375\n",
      "Batch: 103, Loss: 0.7182639837265015, Accuracy: 0.7783203125\n",
      "Batch: 104, Loss: 0.6370152235031128, Accuracy: 0.7890625\n",
      "Batch: 105, Loss: 0.7229560613632202, Accuracy: 0.7607421875\n",
      "Batch: 106, Loss: 0.6661182641983032, Accuracy: 0.7919921875\n",
      "Batch: 107, Loss: 0.706824779510498, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.6956069469451904, Accuracy: 0.7578125\n",
      "Batch: 109, Loss: 0.7929490804672241, Accuracy: 0.748046875\n",
      "Batch: 110, Loss: 0.6047117114067078, Accuracy: 0.7939453125\n",
      "Batch: 111, Loss: 0.6907668113708496, Accuracy: 0.765625\n",
      "Batch: 112, Loss: 0.7188887596130371, Accuracy: 0.7705078125\n",
      "Batch: 113, Loss: 0.6935621500015259, Accuracy: 0.7822265625\n",
      "Batch: 114, Loss: 0.7935820817947388, Accuracy: 0.7490234375\n",
      "Batch: 115, Loss: 0.7738465666770935, Accuracy: 0.73828125\n",
      "Batch: 116, Loss: 0.7490043640136719, Accuracy: 0.75390625\n",
      "Batch: 117, Loss: 0.7480056881904602, Accuracy: 0.759765625\n",
      "Batch: 118, Loss: 0.622047483921051, Accuracy: 0.7978515625\n",
      "Batch: 119, Loss: 0.6289618015289307, Accuracy: 0.796875\n",
      "Batch: 120, Loss: 0.7252293825149536, Accuracy: 0.759765625\n",
      "Batch: 121, Loss: 0.7437779307365417, Accuracy: 0.7529296875\n",
      "Batch: 122, Loss: 0.6716067790985107, Accuracy: 0.791015625\n",
      "Batch: 123, Loss: 0.6671018600463867, Accuracy: 0.787109375\n",
      "Batch: 124, Loss: 0.7048819065093994, Accuracy: 0.7783203125\n",
      "Batch: 125, Loss: 0.7459670305252075, Accuracy: 0.7578125\n",
      "Batch: 126, Loss: 0.7421929836273193, Accuracy: 0.7626953125\n",
      "Batch: 127, Loss: 0.6318299770355225, Accuracy: 0.7978515625\n",
      "Batch: 128, Loss: 0.7742881774902344, Accuracy: 0.7666015625\n",
      "Batch: 129, Loss: 0.65762859582901, Accuracy: 0.787109375\n",
      "Batch: 130, Loss: 0.827345609664917, Accuracy: 0.7373046875\n",
      "Batch: 131, Loss: 0.728391706943512, Accuracy: 0.75390625\n",
      "Batch: 132, Loss: 0.7405681610107422, Accuracy: 0.7685546875\n",
      "Batch: 133, Loss: 0.7115474939346313, Accuracy: 0.7626953125\n",
      "Batch: 134, Loss: 0.7287920713424683, Accuracy: 0.765625\n",
      "Batch: 135, Loss: 0.659982442855835, Accuracy: 0.7802734375\n",
      "Batch: 136, Loss: 0.7347744107246399, Accuracy: 0.7724609375\n",
      "Batch: 137, Loss: 0.6923128366470337, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.6311922073364258, Accuracy: 0.7744140625\n",
      "Batch: 139, Loss: 0.7174079418182373, Accuracy: 0.7568359375\n",
      "Batch: 140, Loss: 0.6681029796600342, Accuracy: 0.787109375\n",
      "Batch: 141, Loss: 0.7633761167526245, Accuracy: 0.759765625\n",
      "Batch: 142, Loss: 0.7277022004127502, Accuracy: 0.763671875\n",
      "Batch: 143, Loss: 0.7260517477989197, Accuracy: 0.7529296875\n",
      "Batch: 144, Loss: 0.7134847640991211, Accuracy: 0.783203125\n",
      "Batch: 145, Loss: 0.6635515689849854, Accuracy: 0.7783203125\n",
      "Batch: 146, Loss: 0.719265878200531, Accuracy: 0.755859375\n",
      "Batch: 147, Loss: 0.7344815731048584, Accuracy: 0.763671875\n",
      "Batch: 148, Loss: 0.8085669279098511, Accuracy: 0.7548828125\n",
      "Batch: 149, Loss: 0.688140332698822, Accuracy: 0.7734375\n",
      "Batch: 150, Loss: 0.6884182691574097, Accuracy: 0.7744140625\n",
      "Batch: 151, Loss: 0.6425226330757141, Accuracy: 0.798828125\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/80\n",
      "Batch: 1, Loss: 0.9043499827384949, Accuracy: 0.69921875\n",
      "Batch: 2, Loss: 0.8005279302597046, Accuracy: 0.7275390625\n",
      "Batch: 3, Loss: 0.6928207874298096, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.6573690176010132, Accuracy: 0.787109375\n",
      "Batch: 5, Loss: 0.6507249474525452, Accuracy: 0.7978515625\n",
      "Batch: 6, Loss: 0.6921052932739258, Accuracy: 0.7666015625\n",
      "Batch: 7, Loss: 0.707150936126709, Accuracy: 0.7431640625\n",
      "Batch: 8, Loss: 0.6864915490150452, Accuracy: 0.7626953125\n",
      "Batch: 9, Loss: 0.6997060179710388, Accuracy: 0.7822265625\n",
      "Batch: 10, Loss: 0.6683396100997925, Accuracy: 0.7705078125\n",
      "Batch: 11, Loss: 0.7672440409660339, Accuracy: 0.7421875\n",
      "Batch: 12, Loss: 0.7397246956825256, Accuracy: 0.75390625\n",
      "Batch: 13, Loss: 0.5684845447540283, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.7554166316986084, Accuracy: 0.751953125\n",
      "Batch: 15, Loss: 0.6543805599212646, Accuracy: 0.80078125\n",
      "Batch: 16, Loss: 0.667003870010376, Accuracy: 0.794921875\n",
      "Batch: 17, Loss: 0.7080087661743164, Accuracy: 0.78515625\n",
      "Batch: 18, Loss: 0.754509687423706, Accuracy: 0.7646484375\n",
      "Batch: 19, Loss: 0.7462701201438904, Accuracy: 0.7529296875\n",
      "Batch: 20, Loss: 0.6251329183578491, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.6908198595046997, Accuracy: 0.7587890625\n",
      "Batch: 22, Loss: 0.7585480213165283, Accuracy: 0.7626953125\n",
      "Batch: 23, Loss: 0.7365431785583496, Accuracy: 0.7724609375\n",
      "Batch: 24, Loss: 0.7487524151802063, Accuracy: 0.7578125\n",
      "Batch: 25, Loss: 0.6950443387031555, Accuracy: 0.765625\n",
      "Batch: 26, Loss: 0.6010968685150146, Accuracy: 0.798828125\n",
      "Batch: 27, Loss: 0.6697726249694824, Accuracy: 0.771484375\n",
      "Batch: 28, Loss: 0.7210236191749573, Accuracy: 0.7685546875\n",
      "Batch: 29, Loss: 0.7024016380310059, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.6241101026535034, Accuracy: 0.802734375\n",
      "Batch: 31, Loss: 0.6393022537231445, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.6424202919006348, Accuracy: 0.7890625\n",
      "Batch: 33, Loss: 0.7459907531738281, Accuracy: 0.763671875\n",
      "Batch: 34, Loss: 0.807672381401062, Accuracy: 0.736328125\n",
      "Batch: 35, Loss: 0.7207766771316528, Accuracy: 0.763671875\n",
      "Batch: 36, Loss: 0.7492292523384094, Accuracy: 0.767578125\n",
      "Batch: 37, Loss: 0.7264362573623657, Accuracy: 0.7666015625\n",
      "Batch: 38, Loss: 0.7124680280685425, Accuracy: 0.767578125\n",
      "Batch: 39, Loss: 0.7491019368171692, Accuracy: 0.7607421875\n",
      "Batch: 40, Loss: 0.7112451195716858, Accuracy: 0.775390625\n",
      "Batch: 41, Loss: 0.6660417318344116, Accuracy: 0.78515625\n",
      "Batch: 42, Loss: 0.541185736656189, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.6900757551193237, Accuracy: 0.7685546875\n",
      "Batch: 44, Loss: 0.7030649781227112, Accuracy: 0.7685546875\n",
      "Batch: 45, Loss: 0.6212384104728699, Accuracy: 0.7900390625\n",
      "Batch: 46, Loss: 0.6105260252952576, Accuracy: 0.7998046875\n",
      "Batch: 47, Loss: 0.6309564113616943, Accuracy: 0.80078125\n",
      "Batch: 48, Loss: 0.6329622268676758, Accuracy: 0.79296875\n",
      "Batch: 49, Loss: 0.7427197694778442, Accuracy: 0.7626953125\n",
      "Batch: 50, Loss: 0.7171629071235657, Accuracy: 0.763671875\n",
      "Batch: 51, Loss: 0.7496190667152405, Accuracy: 0.7578125\n",
      "Batch: 52, Loss: 0.6991236209869385, Accuracy: 0.78515625\n",
      "Batch: 53, Loss: 0.6383776068687439, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.6835278868675232, Accuracy: 0.78125\n",
      "Batch: 55, Loss: 0.7824835777282715, Accuracy: 0.7421875\n",
      "Batch: 56, Loss: 0.7415025234222412, Accuracy: 0.763671875\n",
      "Batch: 57, Loss: 0.7157666683197021, Accuracy: 0.7744140625\n",
      "Batch: 58, Loss: 0.7649693489074707, Accuracy: 0.763671875\n",
      "Batch: 59, Loss: 0.6504385471343994, Accuracy: 0.79296875\n",
      "Batch: 60, Loss: 0.6395983695983887, Accuracy: 0.7841796875\n",
      "Batch: 61, Loss: 0.7282241582870483, Accuracy: 0.771484375\n",
      "Batch: 62, Loss: 0.6599057912826538, Accuracy: 0.787109375\n",
      "Batch: 63, Loss: 0.6999977231025696, Accuracy: 0.7802734375\n",
      "Batch: 64, Loss: 0.6771199703216553, Accuracy: 0.7783203125\n",
      "Batch: 65, Loss: 0.720805287361145, Accuracy: 0.7568359375\n",
      "Batch: 66, Loss: 0.6976709365844727, Accuracy: 0.7724609375\n",
      "Batch: 67, Loss: 0.7468342185020447, Accuracy: 0.75\n",
      "Batch: 68, Loss: 0.779820442199707, Accuracy: 0.7490234375\n",
      "Batch: 69, Loss: 0.7413097023963928, Accuracy: 0.755859375\n",
      "Batch: 70, Loss: 0.7135577201843262, Accuracy: 0.775390625\n",
      "Batch: 71, Loss: 0.7667001485824585, Accuracy: 0.740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 0.6700620651245117, Accuracy: 0.77734375\n",
      "Batch: 73, Loss: 0.6229747533798218, Accuracy: 0.806640625\n",
      "Batch: 74, Loss: 0.5913971662521362, Accuracy: 0.8037109375\n",
      "Batch: 75, Loss: 0.6265767812728882, Accuracy: 0.8037109375\n",
      "Batch: 76, Loss: 0.7257721424102783, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.6577735543251038, Accuracy: 0.787109375\n",
      "Batch: 78, Loss: 0.6423368453979492, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.6195130348205566, Accuracy: 0.8046875\n",
      "Batch: 80, Loss: 0.6430448889732361, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.7326844930648804, Accuracy: 0.7529296875\n",
      "Batch: 82, Loss: 0.7872008085250854, Accuracy: 0.7421875\n",
      "Batch: 83, Loss: 0.6172244548797607, Accuracy: 0.8056640625\n",
      "Batch: 84, Loss: 0.7002519965171814, Accuracy: 0.7822265625\n",
      "Batch: 85, Loss: 0.6778637170791626, Accuracy: 0.794921875\n",
      "Batch: 86, Loss: 0.8479723930358887, Accuracy: 0.7275390625\n",
      "Batch: 87, Loss: 0.6536153554916382, Accuracy: 0.7890625\n",
      "Batch: 88, Loss: 0.7431116104125977, Accuracy: 0.7744140625\n",
      "Batch: 89, Loss: 0.7601234912872314, Accuracy: 0.7685546875\n",
      "Batch: 90, Loss: 0.7574819326400757, Accuracy: 0.775390625\n",
      "Batch: 91, Loss: 0.7332272529602051, Accuracy: 0.7568359375\n",
      "Batch: 92, Loss: 0.7779202461242676, Accuracy: 0.7509765625\n",
      "Batch: 93, Loss: 0.7317636609077454, Accuracy: 0.7685546875\n",
      "Batch: 94, Loss: 0.7432899475097656, Accuracy: 0.751953125\n",
      "Batch: 95, Loss: 0.7904067635536194, Accuracy: 0.7373046875\n",
      "Batch: 96, Loss: 0.6953423619270325, Accuracy: 0.7724609375\n",
      "Batch: 97, Loss: 0.6022869348526001, Accuracy: 0.8037109375\n",
      "Batch: 98, Loss: 0.676970362663269, Accuracy: 0.7666015625\n",
      "Batch: 99, Loss: 0.6396527290344238, Accuracy: 0.802734375\n",
      "Batch: 100, Loss: 0.704094409942627, Accuracy: 0.7763671875\n",
      "Batch: 101, Loss: 0.7150453329086304, Accuracy: 0.767578125\n",
      "Batch: 102, Loss: 0.6865859031677246, Accuracy: 0.767578125\n",
      "Batch: 103, Loss: 0.7036896347999573, Accuracy: 0.7763671875\n",
      "Batch: 104, Loss: 0.6528979539871216, Accuracy: 0.7705078125\n",
      "Batch: 105, Loss: 0.7305421233177185, Accuracy: 0.7626953125\n",
      "Batch: 106, Loss: 0.6605609059333801, Accuracy: 0.7958984375\n",
      "Batch: 107, Loss: 0.6926050186157227, Accuracy: 0.787109375\n",
      "Batch: 108, Loss: 0.6892430782318115, Accuracy: 0.77734375\n",
      "Batch: 109, Loss: 0.7861042022705078, Accuracy: 0.7470703125\n",
      "Batch: 110, Loss: 0.6197727918624878, Accuracy: 0.798828125\n",
      "Batch: 111, Loss: 0.7390768527984619, Accuracy: 0.748046875\n",
      "Batch: 112, Loss: 0.7000061869621277, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.7306556701660156, Accuracy: 0.7919921875\n",
      "Batch: 114, Loss: 0.7735519409179688, Accuracy: 0.7392578125\n",
      "Batch: 115, Loss: 0.8162678480148315, Accuracy: 0.736328125\n",
      "Batch: 116, Loss: 0.7357698678970337, Accuracy: 0.7509765625\n",
      "Batch: 117, Loss: 0.7109282612800598, Accuracy: 0.7880859375\n",
      "Batch: 118, Loss: 0.640363335609436, Accuracy: 0.8017578125\n",
      "Batch: 119, Loss: 0.5885049700737, Accuracy: 0.8095703125\n",
      "Batch: 120, Loss: 0.7057525515556335, Accuracy: 0.7587890625\n",
      "Batch: 121, Loss: 0.7539056539535522, Accuracy: 0.75\n",
      "Batch: 122, Loss: 0.6939820051193237, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.6306767463684082, Accuracy: 0.80078125\n",
      "Batch: 124, Loss: 0.7385597229003906, Accuracy: 0.76171875\n",
      "Batch: 125, Loss: 0.7313387393951416, Accuracy: 0.7685546875\n",
      "Batch: 126, Loss: 0.7154179811477661, Accuracy: 0.7685546875\n",
      "Batch: 127, Loss: 0.6165454387664795, Accuracy: 0.7978515625\n",
      "Batch: 128, Loss: 0.787341296672821, Accuracy: 0.755859375\n",
      "Batch: 129, Loss: 0.6553645730018616, Accuracy: 0.7705078125\n",
      "Batch: 130, Loss: 0.7646304965019226, Accuracy: 0.751953125\n",
      "Batch: 131, Loss: 0.7200400829315186, Accuracy: 0.765625\n",
      "Batch: 132, Loss: 0.696689248085022, Accuracy: 0.775390625\n",
      "Batch: 133, Loss: 0.6981945037841797, Accuracy: 0.7685546875\n",
      "Batch: 134, Loss: 0.745976984500885, Accuracy: 0.7529296875\n",
      "Batch: 135, Loss: 0.6394490599632263, Accuracy: 0.791015625\n",
      "Batch: 136, Loss: 0.7293890714645386, Accuracy: 0.767578125\n",
      "Batch: 137, Loss: 0.7403166890144348, Accuracy: 0.7529296875\n",
      "Batch: 138, Loss: 0.6346615552902222, Accuracy: 0.78125\n",
      "Batch: 139, Loss: 0.7279961109161377, Accuracy: 0.76171875\n",
      "Batch: 140, Loss: 0.6824518442153931, Accuracy: 0.7841796875\n",
      "Batch: 141, Loss: 0.7434696555137634, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.7373918294906616, Accuracy: 0.7490234375\n",
      "Batch: 143, Loss: 0.7177091836929321, Accuracy: 0.7666015625\n",
      "Batch: 144, Loss: 0.7256428599357605, Accuracy: 0.7685546875\n",
      "Batch: 145, Loss: 0.6323899030685425, Accuracy: 0.7841796875\n",
      "Batch: 146, Loss: 0.7259751558303833, Accuracy: 0.7685546875\n",
      "Batch: 147, Loss: 0.7206729650497437, Accuracy: 0.759765625\n",
      "Batch: 148, Loss: 0.8211729526519775, Accuracy: 0.7451171875\n",
      "Batch: 149, Loss: 0.6838294267654419, Accuracy: 0.7802734375\n",
      "Batch: 150, Loss: 0.6852664351463318, Accuracy: 0.771484375\n",
      "Batch: 151, Loss: 0.637189507484436, Accuracy: 0.779296875\n",
      "Epoch 42/80\n",
      "Batch: 1, Loss: 0.9428439140319824, Accuracy: 0.7099609375\n",
      "Batch: 2, Loss: 0.7741439342498779, Accuracy: 0.7412109375\n",
      "Batch: 3, Loss: 0.6774730682373047, Accuracy: 0.77734375\n",
      "Batch: 4, Loss: 0.6506975889205933, Accuracy: 0.791015625\n",
      "Batch: 5, Loss: 0.6499627828598022, Accuracy: 0.79296875\n",
      "Batch: 6, Loss: 0.6927022933959961, Accuracy: 0.7646484375\n",
      "Batch: 7, Loss: 0.7499316930770874, Accuracy: 0.7607421875\n",
      "Batch: 8, Loss: 0.6530584096908569, Accuracy: 0.7958984375\n",
      "Batch: 9, Loss: 0.6718498468399048, Accuracy: 0.7822265625\n",
      "Batch: 10, Loss: 0.6616584062576294, Accuracy: 0.78125\n",
      "Batch: 11, Loss: 0.7442793250083923, Accuracy: 0.765625\n",
      "Batch: 12, Loss: 0.7562215924263, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.5730584859848022, Accuracy: 0.8125\n",
      "Batch: 14, Loss: 0.7602769136428833, Accuracy: 0.7529296875\n",
      "Batch: 15, Loss: 0.6394975185394287, Accuracy: 0.80078125\n",
      "Batch: 16, Loss: 0.6659015417098999, Accuracy: 0.8017578125\n",
      "Batch: 17, Loss: 0.7231453657150269, Accuracy: 0.767578125\n",
      "Batch: 18, Loss: 0.723763108253479, Accuracy: 0.7587890625\n",
      "Batch: 19, Loss: 0.7180542945861816, Accuracy: 0.7763671875\n",
      "Batch: 20, Loss: 0.6163097620010376, Accuracy: 0.7861328125\n",
      "Batch: 21, Loss: 0.6918509006500244, Accuracy: 0.7890625\n",
      "Batch: 22, Loss: 0.7591144442558289, Accuracy: 0.75\n",
      "Batch: 23, Loss: 0.7492470741271973, Accuracy: 0.7587890625\n",
      "Batch: 24, Loss: 0.7129664421081543, Accuracy: 0.7734375\n",
      "Batch: 25, Loss: 0.6755883097648621, Accuracy: 0.7958984375\n",
      "Batch: 26, Loss: 0.6131038665771484, Accuracy: 0.8115234375\n",
      "Batch: 27, Loss: 0.6385377049446106, Accuracy: 0.7802734375\n",
      "Batch: 28, Loss: 0.6944029331207275, Accuracy: 0.7744140625\n",
      "Batch: 29, Loss: 0.6873514652252197, Accuracy: 0.775390625\n",
      "Batch: 30, Loss: 0.6001166105270386, Accuracy: 0.80859375\n",
      "Batch: 31, Loss: 0.6276838779449463, Accuracy: 0.8037109375\n",
      "Batch: 32, Loss: 0.6485699415206909, Accuracy: 0.783203125\n",
      "Batch: 33, Loss: 0.7348105907440186, Accuracy: 0.7705078125\n",
      "Batch: 34, Loss: 0.829230546951294, Accuracy: 0.720703125\n",
      "Batch: 35, Loss: 0.7160529494285583, Accuracy: 0.767578125\n",
      "Batch: 36, Loss: 0.7108429670333862, Accuracy: 0.78515625\n",
      "Batch: 37, Loss: 0.6941668391227722, Accuracy: 0.7763671875\n",
      "Batch: 38, Loss: 0.6901466250419617, Accuracy: 0.7724609375\n",
      "Batch: 39, Loss: 0.7193480730056763, Accuracy: 0.7724609375\n",
      "Batch: 40, Loss: 0.6594683527946472, Accuracy: 0.7841796875\n",
      "Batch: 41, Loss: 0.6332804560661316, Accuracy: 0.79296875\n",
      "Batch: 42, Loss: 0.5382788181304932, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.6948416233062744, Accuracy: 0.76953125\n",
      "Batch: 44, Loss: 0.6825436353683472, Accuracy: 0.7841796875\n",
      "Batch: 45, Loss: 0.6468163728713989, Accuracy: 0.791015625\n",
      "Batch: 46, Loss: 0.6159734129905701, Accuracy: 0.791015625\n",
      "Batch: 47, Loss: 0.6307545900344849, Accuracy: 0.8095703125\n",
      "Batch: 48, Loss: 0.6047502756118774, Accuracy: 0.7919921875\n",
      "Batch: 49, Loss: 0.7354153394699097, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.6977227926254272, Accuracy: 0.7919921875\n",
      "Batch: 51, Loss: 0.7261568307876587, Accuracy: 0.76953125\n",
      "Batch: 52, Loss: 0.7075345516204834, Accuracy: 0.767578125\n",
      "Batch: 53, Loss: 0.6263822913169861, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.6724454760551453, Accuracy: 0.78515625\n",
      "Batch: 55, Loss: 0.7807679176330566, Accuracy: 0.7451171875\n",
      "Batch: 56, Loss: 0.7515118718147278, Accuracy: 0.7626953125\n",
      "Batch: 57, Loss: 0.7251027226448059, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.789146363735199, Accuracy: 0.7412109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 0.6753008365631104, Accuracy: 0.783203125\n",
      "Batch: 60, Loss: 0.6613277196884155, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7027604579925537, Accuracy: 0.767578125\n",
      "Batch: 62, Loss: 0.6292795538902283, Accuracy: 0.794921875\n",
      "Batch: 63, Loss: 0.6887906789779663, Accuracy: 0.765625\n",
      "Batch: 64, Loss: 0.6664702892303467, Accuracy: 0.78125\n",
      "Batch: 65, Loss: 0.6825376749038696, Accuracy: 0.7890625\n",
      "Batch: 66, Loss: 0.6988732218742371, Accuracy: 0.7744140625\n",
      "Batch: 67, Loss: 0.7649343013763428, Accuracy: 0.7578125\n",
      "Batch: 68, Loss: 0.7710576057434082, Accuracy: 0.7509765625\n",
      "Batch: 69, Loss: 0.7396061420440674, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.6957540512084961, Accuracy: 0.76953125\n",
      "Batch: 71, Loss: 0.7276248335838318, Accuracy: 0.7431640625\n",
      "Batch: 72, Loss: 0.6248773336410522, Accuracy: 0.787109375\n",
      "Batch: 73, Loss: 0.638713002204895, Accuracy: 0.798828125\n",
      "Batch: 74, Loss: 0.591476321220398, Accuracy: 0.8173828125\n",
      "Batch: 75, Loss: 0.6105431318283081, Accuracy: 0.806640625\n",
      "Batch: 76, Loss: 0.6788859963417053, Accuracy: 0.77734375\n",
      "Batch: 77, Loss: 0.6424109935760498, Accuracy: 0.7861328125\n",
      "Batch: 78, Loss: 0.6316767930984497, Accuracy: 0.7958984375\n",
      "Batch: 79, Loss: 0.6257483959197998, Accuracy: 0.8017578125\n",
      "Batch: 80, Loss: 0.6609381437301636, Accuracy: 0.7802734375\n",
      "Batch: 81, Loss: 0.7414990663528442, Accuracy: 0.76171875\n",
      "Batch: 82, Loss: 0.7180841565132141, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.5785708427429199, Accuracy: 0.8173828125\n",
      "Batch: 84, Loss: 0.676047682762146, Accuracy: 0.79296875\n",
      "Batch: 85, Loss: 0.6493178009986877, Accuracy: 0.8115234375\n",
      "Batch: 86, Loss: 0.8182599544525146, Accuracy: 0.7412109375\n",
      "Batch: 87, Loss: 0.6224848031997681, Accuracy: 0.80078125\n",
      "Batch: 88, Loss: 0.745401918888092, Accuracy: 0.767578125\n",
      "Batch: 89, Loss: 0.7210243940353394, Accuracy: 0.77734375\n",
      "Batch: 90, Loss: 0.7111430168151855, Accuracy: 0.7822265625\n",
      "Batch: 91, Loss: 0.688796877861023, Accuracy: 0.7783203125\n",
      "Batch: 92, Loss: 0.713654637336731, Accuracy: 0.779296875\n",
      "Batch: 93, Loss: 0.6634330749511719, Accuracy: 0.79296875\n",
      "Batch: 94, Loss: 0.7045081257820129, Accuracy: 0.755859375\n",
      "Batch: 95, Loss: 0.7196557521820068, Accuracy: 0.7578125\n",
      "Batch: 96, Loss: 0.6847549676895142, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.5678738355636597, Accuracy: 0.80859375\n",
      "Batch: 98, Loss: 0.6628551483154297, Accuracy: 0.76953125\n",
      "Batch: 99, Loss: 0.6736166477203369, Accuracy: 0.7744140625\n",
      "Batch: 100, Loss: 0.692976176738739, Accuracy: 0.763671875\n",
      "Batch: 101, Loss: 0.7096929550170898, Accuracy: 0.7646484375\n",
      "Batch: 102, Loss: 0.6998897790908813, Accuracy: 0.7578125\n",
      "Batch: 103, Loss: 0.7015174627304077, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.6285051107406616, Accuracy: 0.794921875\n",
      "Batch: 105, Loss: 0.7192727327346802, Accuracy: 0.7744140625\n",
      "Batch: 106, Loss: 0.6015827655792236, Accuracy: 0.8115234375\n",
      "Batch: 107, Loss: 0.6635938286781311, Accuracy: 0.7978515625\n",
      "Batch: 108, Loss: 0.6742597818374634, Accuracy: 0.765625\n",
      "Batch: 109, Loss: 0.7413272857666016, Accuracy: 0.7548828125\n",
      "Batch: 110, Loss: 0.6068916320800781, Accuracy: 0.80078125\n",
      "Batch: 111, Loss: 0.7109731435775757, Accuracy: 0.7763671875\n",
      "Batch: 112, Loss: 0.6879096031188965, Accuracy: 0.7685546875\n",
      "Batch: 113, Loss: 0.7165442705154419, Accuracy: 0.7802734375\n",
      "Batch: 114, Loss: 0.7879688739776611, Accuracy: 0.7470703125\n",
      "Batch: 115, Loss: 0.7368372678756714, Accuracy: 0.763671875\n",
      "Batch: 116, Loss: 0.7032938003540039, Accuracy: 0.7734375\n",
      "Batch: 117, Loss: 0.731262743473053, Accuracy: 0.7548828125\n",
      "Batch: 118, Loss: 0.6439862251281738, Accuracy: 0.7978515625\n",
      "Batch: 119, Loss: 0.5694277286529541, Accuracy: 0.826171875\n",
      "Batch: 120, Loss: 0.6701099872589111, Accuracy: 0.7900390625\n",
      "Batch: 121, Loss: 0.7128369808197021, Accuracy: 0.7646484375\n",
      "Batch: 122, Loss: 0.6559780240058899, Accuracy: 0.7919921875\n",
      "Batch: 123, Loss: 0.6400014758110046, Accuracy: 0.7998046875\n",
      "Batch: 124, Loss: 0.7249674797058105, Accuracy: 0.7763671875\n",
      "Batch: 125, Loss: 0.733154296875, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.7000950574874878, Accuracy: 0.77734375\n",
      "Batch: 127, Loss: 0.636677086353302, Accuracy: 0.8046875\n",
      "Batch: 128, Loss: 0.7688105702400208, Accuracy: 0.75390625\n",
      "Batch: 129, Loss: 0.6572527885437012, Accuracy: 0.7841796875\n",
      "Batch: 130, Loss: 0.7624037265777588, Accuracy: 0.7509765625\n",
      "Batch: 131, Loss: 0.7032250165939331, Accuracy: 0.7607421875\n",
      "Batch: 132, Loss: 0.736330509185791, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.6580914258956909, Accuracy: 0.78125\n",
      "Batch: 134, Loss: 0.7067333459854126, Accuracy: 0.7529296875\n",
      "Batch: 135, Loss: 0.6263926029205322, Accuracy: 0.7939453125\n",
      "Batch: 136, Loss: 0.7180434465408325, Accuracy: 0.7646484375\n",
      "Batch: 137, Loss: 0.7033149003982544, Accuracy: 0.751953125\n",
      "Batch: 138, Loss: 0.6414151191711426, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.7096933722496033, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.6731959581375122, Accuracy: 0.7900390625\n",
      "Batch: 141, Loss: 0.7468296885490417, Accuracy: 0.7587890625\n",
      "Batch: 142, Loss: 0.7273814678192139, Accuracy: 0.7626953125\n",
      "Batch: 143, Loss: 0.6997025609016418, Accuracy: 0.7666015625\n",
      "Batch: 144, Loss: 0.7052127122879028, Accuracy: 0.767578125\n",
      "Batch: 145, Loss: 0.6321892142295837, Accuracy: 0.7841796875\n",
      "Batch: 146, Loss: 0.7293847799301147, Accuracy: 0.76953125\n",
      "Batch: 147, Loss: 0.6983184814453125, Accuracy: 0.7802734375\n",
      "Batch: 148, Loss: 0.7927054166793823, Accuracy: 0.7509765625\n",
      "Batch: 149, Loss: 0.690855085849762, Accuracy: 0.771484375\n",
      "Batch: 150, Loss: 0.6745996475219727, Accuracy: 0.76953125\n",
      "Batch: 151, Loss: 0.6206039786338806, Accuracy: 0.7998046875\n",
      "Epoch 43/80\n",
      "Batch: 1, Loss: 0.8988547325134277, Accuracy: 0.7236328125\n",
      "Batch: 2, Loss: 0.8183392882347107, Accuracy: 0.7119140625\n",
      "Batch: 3, Loss: 0.692359209060669, Accuracy: 0.7724609375\n",
      "Batch: 4, Loss: 0.6293760538101196, Accuracy: 0.796875\n",
      "Batch: 5, Loss: 0.6577197313308716, Accuracy: 0.7900390625\n",
      "Batch: 6, Loss: 0.6948485374450684, Accuracy: 0.7861328125\n",
      "Batch: 7, Loss: 0.7055985927581787, Accuracy: 0.771484375\n",
      "Batch: 8, Loss: 0.6588891744613647, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.6667347550392151, Accuracy: 0.7841796875\n",
      "Batch: 10, Loss: 0.6634813547134399, Accuracy: 0.7783203125\n",
      "Batch: 11, Loss: 0.7188842296600342, Accuracy: 0.7568359375\n",
      "Batch: 12, Loss: 0.7357569932937622, Accuracy: 0.7587890625\n",
      "Batch: 13, Loss: 0.5485247373580933, Accuracy: 0.8134765625\n",
      "Batch: 14, Loss: 0.7432335019111633, Accuracy: 0.765625\n",
      "Batch: 15, Loss: 0.6331039667129517, Accuracy: 0.810546875\n",
      "Batch: 16, Loss: 0.6382980346679688, Accuracy: 0.8046875\n",
      "Batch: 17, Loss: 0.7038795948028564, Accuracy: 0.7763671875\n",
      "Batch: 18, Loss: 0.7197458744049072, Accuracy: 0.7666015625\n",
      "Batch: 19, Loss: 0.72533118724823, Accuracy: 0.771484375\n",
      "Batch: 20, Loss: 0.5973089933395386, Accuracy: 0.8134765625\n",
      "Batch: 21, Loss: 0.6780985593795776, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.7585333585739136, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.723108172416687, Accuracy: 0.7578125\n",
      "Batch: 24, Loss: 0.7317218780517578, Accuracy: 0.7734375\n",
      "Batch: 25, Loss: 0.6922295689582825, Accuracy: 0.7880859375\n",
      "Batch: 26, Loss: 0.5956417322158813, Accuracy: 0.8115234375\n",
      "Batch: 27, Loss: 0.6206817030906677, Accuracy: 0.783203125\n",
      "Batch: 28, Loss: 0.6667295694351196, Accuracy: 0.7783203125\n",
      "Batch: 29, Loss: 0.639950156211853, Accuracy: 0.7841796875\n",
      "Batch: 30, Loss: 0.5885016918182373, Accuracy: 0.818359375\n",
      "Batch: 31, Loss: 0.6238667964935303, Accuracy: 0.8017578125\n",
      "Batch: 32, Loss: 0.6100492477416992, Accuracy: 0.7939453125\n",
      "Batch: 33, Loss: 0.7440661191940308, Accuracy: 0.76171875\n",
      "Batch: 34, Loss: 0.8013046383857727, Accuracy: 0.7421875\n",
      "Batch: 35, Loss: 0.69784015417099, Accuracy: 0.7685546875\n",
      "Batch: 36, Loss: 0.713279128074646, Accuracy: 0.7763671875\n",
      "Batch: 37, Loss: 0.6946976780891418, Accuracy: 0.7568359375\n",
      "Batch: 38, Loss: 0.6839718222618103, Accuracy: 0.763671875\n",
      "Batch: 39, Loss: 0.7174264788627625, Accuracy: 0.7646484375\n",
      "Batch: 40, Loss: 0.6646256446838379, Accuracy: 0.794921875\n",
      "Batch: 41, Loss: 0.6236073970794678, Accuracy: 0.7900390625\n",
      "Batch: 42, Loss: 0.5101103186607361, Accuracy: 0.818359375\n",
      "Batch: 43, Loss: 0.6786524057388306, Accuracy: 0.7646484375\n",
      "Batch: 44, Loss: 0.6750115752220154, Accuracy: 0.7890625\n",
      "Batch: 45, Loss: 0.6187576055526733, Accuracy: 0.794921875\n",
      "Batch: 46, Loss: 0.6011073589324951, Accuracy: 0.80859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 47, Loss: 0.625407338142395, Accuracy: 0.8017578125\n",
      "Batch: 48, Loss: 0.5939081907272339, Accuracy: 0.8154296875\n",
      "Batch: 49, Loss: 0.7159759998321533, Accuracy: 0.7685546875\n",
      "Batch: 50, Loss: 0.690795361995697, Accuracy: 0.7763671875\n",
      "Batch: 51, Loss: 0.7297316789627075, Accuracy: 0.7607421875\n",
      "Batch: 52, Loss: 0.702154278755188, Accuracy: 0.79296875\n",
      "Batch: 53, Loss: 0.6445733308792114, Accuracy: 0.7841796875\n",
      "Batch: 54, Loss: 0.6655707955360413, Accuracy: 0.7861328125\n",
      "Batch: 55, Loss: 0.7589818835258484, Accuracy: 0.7412109375\n",
      "Batch: 56, Loss: 0.7346044778823853, Accuracy: 0.763671875\n",
      "Batch: 57, Loss: 0.6996561884880066, Accuracy: 0.7685546875\n",
      "Batch: 58, Loss: 0.7752052545547485, Accuracy: 0.75390625\n",
      "Batch: 59, Loss: 0.6351243257522583, Accuracy: 0.7783203125\n",
      "Batch: 60, Loss: 0.6440024971961975, Accuracy: 0.7861328125\n",
      "Batch: 61, Loss: 0.7035888433456421, Accuracy: 0.77734375\n",
      "Batch: 62, Loss: 0.6467108726501465, Accuracy: 0.787109375\n",
      "Batch: 63, Loss: 0.6646570563316345, Accuracy: 0.7685546875\n",
      "Batch: 64, Loss: 0.6422500610351562, Accuracy: 0.7900390625\n",
      "Batch: 65, Loss: 0.6836689114570618, Accuracy: 0.779296875\n",
      "Batch: 66, Loss: 0.679650068283081, Accuracy: 0.78515625\n",
      "Batch: 67, Loss: 0.7300407290458679, Accuracy: 0.7568359375\n",
      "Batch: 68, Loss: 0.7500061988830566, Accuracy: 0.7509765625\n",
      "Batch: 69, Loss: 0.7269196510314941, Accuracy: 0.7646484375\n",
      "Batch: 70, Loss: 0.7029749155044556, Accuracy: 0.7802734375\n",
      "Batch: 71, Loss: 0.7426310777664185, Accuracy: 0.7412109375\n",
      "Batch: 72, Loss: 0.6403454542160034, Accuracy: 0.791015625\n",
      "Batch: 73, Loss: 0.621965229511261, Accuracy: 0.796875\n",
      "Batch: 74, Loss: 0.5786502957344055, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.5816594362258911, Accuracy: 0.8212890625\n",
      "Batch: 76, Loss: 0.6819358468055725, Accuracy: 0.783203125\n",
      "Batch: 77, Loss: 0.6333158016204834, Accuracy: 0.7861328125\n",
      "Batch: 78, Loss: 0.6243248581886292, Accuracy: 0.796875\n",
      "Batch: 79, Loss: 0.6092517375946045, Accuracy: 0.796875\n",
      "Batch: 80, Loss: 0.6487439870834351, Accuracy: 0.7822265625\n",
      "Batch: 81, Loss: 0.7499982118606567, Accuracy: 0.740234375\n",
      "Batch: 82, Loss: 0.6800283193588257, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.6080463528633118, Accuracy: 0.8212890625\n",
      "Batch: 84, Loss: 0.7099553942680359, Accuracy: 0.7626953125\n",
      "Batch: 85, Loss: 0.6743795871734619, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.8222793340682983, Accuracy: 0.74609375\n",
      "Batch: 87, Loss: 0.6290120482444763, Accuracy: 0.8017578125\n",
      "Batch: 88, Loss: 0.7363437414169312, Accuracy: 0.78125\n",
      "Batch: 89, Loss: 0.704609751701355, Accuracy: 0.76171875\n",
      "Batch: 90, Loss: 0.6784657835960388, Accuracy: 0.783203125\n",
      "Batch: 91, Loss: 0.6581370234489441, Accuracy: 0.783203125\n",
      "Batch: 92, Loss: 0.7346854209899902, Accuracy: 0.7705078125\n",
      "Batch: 93, Loss: 0.6368616223335266, Accuracy: 0.7919921875\n",
      "Batch: 94, Loss: 0.6794236898422241, Accuracy: 0.779296875\n",
      "Batch: 95, Loss: 0.717652440071106, Accuracy: 0.75\n",
      "Batch: 96, Loss: 0.687528133392334, Accuracy: 0.7802734375\n",
      "Batch: 97, Loss: 0.5499980449676514, Accuracy: 0.8232421875\n",
      "Batch: 98, Loss: 0.6412901878356934, Accuracy: 0.7919921875\n",
      "Batch: 99, Loss: 0.6446026563644409, Accuracy: 0.787109375\n",
      "Batch: 100, Loss: 0.706588864326477, Accuracy: 0.765625\n",
      "Batch: 101, Loss: 0.7266756296157837, Accuracy: 0.7587890625\n",
      "Batch: 102, Loss: 0.6735497713088989, Accuracy: 0.78125\n",
      "Batch: 103, Loss: 0.7111486196517944, Accuracy: 0.7841796875\n",
      "Batch: 104, Loss: 0.637442946434021, Accuracy: 0.78515625\n",
      "Batch: 105, Loss: 0.7013500332832336, Accuracy: 0.7666015625\n",
      "Batch: 106, Loss: 0.6159111261367798, Accuracy: 0.79296875\n",
      "Batch: 107, Loss: 0.6920012831687927, Accuracy: 0.7880859375\n",
      "Batch: 108, Loss: 0.6717305779457092, Accuracy: 0.7724609375\n",
      "Batch: 109, Loss: 0.7695862650871277, Accuracy: 0.7587890625\n",
      "Batch: 110, Loss: 0.5900549292564392, Accuracy: 0.8056640625\n",
      "Batch: 111, Loss: 0.6982532739639282, Accuracy: 0.7802734375\n",
      "Batch: 112, Loss: 0.6913031935691833, Accuracy: 0.76953125\n",
      "Batch: 113, Loss: 0.68572998046875, Accuracy: 0.779296875\n",
      "Batch: 114, Loss: 0.7770431041717529, Accuracy: 0.7607421875\n",
      "Batch: 115, Loss: 0.7824693918228149, Accuracy: 0.7685546875\n",
      "Batch: 116, Loss: 0.7031078338623047, Accuracy: 0.7587890625\n",
      "Batch: 117, Loss: 0.6946475505828857, Accuracy: 0.7705078125\n",
      "Batch: 118, Loss: 0.5853008031845093, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.596305251121521, Accuracy: 0.814453125\n",
      "Batch: 120, Loss: 0.6880162954330444, Accuracy: 0.783203125\n",
      "Batch: 121, Loss: 0.7127765417098999, Accuracy: 0.779296875\n",
      "Batch: 122, Loss: 0.6525094509124756, Accuracy: 0.7919921875\n",
      "Batch: 123, Loss: 0.650261640548706, Accuracy: 0.796875\n",
      "Batch: 124, Loss: 0.7179737687110901, Accuracy: 0.7646484375\n",
      "Batch: 125, Loss: 0.719340443611145, Accuracy: 0.7587890625\n",
      "Batch: 126, Loss: 0.7197476625442505, Accuracy: 0.7587890625\n",
      "Batch: 127, Loss: 0.6274973154067993, Accuracy: 0.80078125\n",
      "Batch: 128, Loss: 0.7591317892074585, Accuracy: 0.7734375\n",
      "Batch: 129, Loss: 0.6172404885292053, Accuracy: 0.8017578125\n",
      "Batch: 130, Loss: 0.7762457132339478, Accuracy: 0.7294921875\n",
      "Batch: 131, Loss: 0.684018611907959, Accuracy: 0.7705078125\n",
      "Batch: 132, Loss: 0.7104246020317078, Accuracy: 0.76953125\n",
      "Batch: 133, Loss: 0.6497194170951843, Accuracy: 0.7734375\n",
      "Batch: 134, Loss: 0.6948103308677673, Accuracy: 0.765625\n",
      "Batch: 135, Loss: 0.6577870845794678, Accuracy: 0.7880859375\n",
      "Batch: 136, Loss: 0.7025827765464783, Accuracy: 0.77734375\n",
      "Batch: 137, Loss: 0.6842426657676697, Accuracy: 0.759765625\n",
      "Batch: 138, Loss: 0.6434106826782227, Accuracy: 0.7861328125\n",
      "Batch: 139, Loss: 0.7046403884887695, Accuracy: 0.76171875\n",
      "Batch: 140, Loss: 0.6644037961959839, Accuracy: 0.7880859375\n",
      "Batch: 141, Loss: 0.7491385340690613, Accuracy: 0.7470703125\n",
      "Batch: 142, Loss: 0.7322180271148682, Accuracy: 0.759765625\n",
      "Batch: 143, Loss: 0.7171238660812378, Accuracy: 0.7705078125\n",
      "Batch: 144, Loss: 0.7117551565170288, Accuracy: 0.77734375\n",
      "Batch: 145, Loss: 0.6367952823638916, Accuracy: 0.7939453125\n",
      "Batch: 146, Loss: 0.7063570022583008, Accuracy: 0.771484375\n",
      "Batch: 147, Loss: 0.6898385882377625, Accuracy: 0.7763671875\n",
      "Batch: 148, Loss: 0.8091452121734619, Accuracy: 0.7373046875\n",
      "Batch: 149, Loss: 0.6326572895050049, Accuracy: 0.80078125\n",
      "Batch: 150, Loss: 0.6832249760627747, Accuracy: 0.765625\n",
      "Batch: 151, Loss: 0.5919926762580872, Accuracy: 0.80078125\n",
      "Epoch 44/80\n",
      "Batch: 1, Loss: 0.8796634674072266, Accuracy: 0.7138671875\n",
      "Batch: 2, Loss: 0.7934656739234924, Accuracy: 0.7314453125\n",
      "Batch: 3, Loss: 0.6864016056060791, Accuracy: 0.767578125\n",
      "Batch: 4, Loss: 0.6091815233230591, Accuracy: 0.802734375\n",
      "Batch: 5, Loss: 0.6545451283454895, Accuracy: 0.7919921875\n",
      "Batch: 6, Loss: 0.6659640669822693, Accuracy: 0.7724609375\n",
      "Batch: 7, Loss: 0.7142744064331055, Accuracy: 0.765625\n",
      "Batch: 8, Loss: 0.6459707021713257, Accuracy: 0.779296875\n",
      "Batch: 9, Loss: 0.6524619460105896, Accuracy: 0.7939453125\n",
      "Batch: 10, Loss: 0.6884609460830688, Accuracy: 0.7705078125\n",
      "Batch: 11, Loss: 0.7583526968955994, Accuracy: 0.7451171875\n",
      "Batch: 12, Loss: 0.7176265716552734, Accuracy: 0.755859375\n",
      "Batch: 13, Loss: 0.5649443864822388, Accuracy: 0.8193359375\n",
      "Batch: 14, Loss: 0.7637590169906616, Accuracy: 0.7578125\n",
      "Batch: 15, Loss: 0.6140539050102234, Accuracy: 0.8134765625\n",
      "Batch: 16, Loss: 0.6288272142410278, Accuracy: 0.814453125\n",
      "Batch: 17, Loss: 0.6957831382751465, Accuracy: 0.7587890625\n",
      "Batch: 18, Loss: 0.7059333324432373, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.7295573949813843, Accuracy: 0.7607421875\n",
      "Batch: 20, Loss: 0.5974318981170654, Accuracy: 0.8046875\n",
      "Batch: 21, Loss: 0.6734340786933899, Accuracy: 0.787109375\n",
      "Batch: 22, Loss: 0.7264207601547241, Accuracy: 0.7724609375\n",
      "Batch: 23, Loss: 0.7516242861747742, Accuracy: 0.7431640625\n",
      "Batch: 24, Loss: 0.7187213897705078, Accuracy: 0.775390625\n",
      "Batch: 25, Loss: 0.6942958831787109, Accuracy: 0.7783203125\n",
      "Batch: 26, Loss: 0.5953534841537476, Accuracy: 0.798828125\n",
      "Batch: 27, Loss: 0.6314879655838013, Accuracy: 0.7822265625\n",
      "Batch: 28, Loss: 0.671263575553894, Accuracy: 0.7802734375\n",
      "Batch: 29, Loss: 0.6402837038040161, Accuracy: 0.8017578125\n",
      "Batch: 30, Loss: 0.5908125638961792, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.6252182722091675, Accuracy: 0.8017578125\n",
      "Batch: 32, Loss: 0.5995742082595825, Accuracy: 0.8095703125\n",
      "Batch: 33, Loss: 0.729251503944397, Accuracy: 0.767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 0.7845248579978943, Accuracy: 0.763671875\n",
      "Batch: 35, Loss: 0.6775962710380554, Accuracy: 0.78515625\n",
      "Batch: 36, Loss: 0.7069007158279419, Accuracy: 0.7890625\n",
      "Batch: 37, Loss: 0.6640481352806091, Accuracy: 0.7822265625\n",
      "Batch: 38, Loss: 0.6846429705619812, Accuracy: 0.7822265625\n",
      "Batch: 39, Loss: 0.7365984320640564, Accuracy: 0.7509765625\n",
      "Batch: 40, Loss: 0.6672208905220032, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.6366056203842163, Accuracy: 0.7978515625\n",
      "Batch: 42, Loss: 0.5097491145133972, Accuracy: 0.8330078125\n",
      "Batch: 43, Loss: 0.6835625171661377, Accuracy: 0.7626953125\n",
      "Batch: 44, Loss: 0.6536273956298828, Accuracy: 0.775390625\n",
      "Batch: 45, Loss: 0.5936299562454224, Accuracy: 0.8017578125\n",
      "Batch: 46, Loss: 0.6223698854446411, Accuracy: 0.80859375\n",
      "Batch: 47, Loss: 0.6067246198654175, Accuracy: 0.80078125\n",
      "Batch: 48, Loss: 0.5990543365478516, Accuracy: 0.806640625\n",
      "Batch: 49, Loss: 0.6766035556793213, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.6770190596580505, Accuracy: 0.78515625\n",
      "Batch: 51, Loss: 0.7082986235618591, Accuracy: 0.771484375\n",
      "Batch: 52, Loss: 0.7010120153427124, Accuracy: 0.77734375\n",
      "Batch: 53, Loss: 0.6230963468551636, Accuracy: 0.7880859375\n",
      "Batch: 54, Loss: 0.6496670842170715, Accuracy: 0.7802734375\n",
      "Batch: 55, Loss: 0.7475544214248657, Accuracy: 0.7587890625\n",
      "Batch: 56, Loss: 0.7201488614082336, Accuracy: 0.7587890625\n",
      "Batch: 57, Loss: 0.7096608281135559, Accuracy: 0.771484375\n",
      "Batch: 58, Loss: 0.7630540132522583, Accuracy: 0.7607421875\n",
      "Batch: 59, Loss: 0.6574797630310059, Accuracy: 0.7900390625\n",
      "Batch: 60, Loss: 0.6418377161026001, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7091729640960693, Accuracy: 0.759765625\n",
      "Batch: 62, Loss: 0.6093928813934326, Accuracy: 0.7978515625\n",
      "Batch: 63, Loss: 0.6382179260253906, Accuracy: 0.794921875\n",
      "Batch: 64, Loss: 0.660192608833313, Accuracy: 0.787109375\n",
      "Batch: 65, Loss: 0.69413161277771, Accuracy: 0.759765625\n",
      "Batch: 66, Loss: 0.6861790418624878, Accuracy: 0.775390625\n",
      "Batch: 67, Loss: 0.7515866160392761, Accuracy: 0.7509765625\n",
      "Batch: 68, Loss: 0.7528277039527893, Accuracy: 0.7646484375\n",
      "Batch: 69, Loss: 0.7289127111434937, Accuracy: 0.77734375\n",
      "Batch: 70, Loss: 0.703910231590271, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.7321964502334595, Accuracy: 0.748046875\n",
      "Batch: 72, Loss: 0.6303521394729614, Accuracy: 0.78515625\n",
      "Batch: 73, Loss: 0.6195194125175476, Accuracy: 0.8076171875\n",
      "Batch: 74, Loss: 0.5666255950927734, Accuracy: 0.830078125\n",
      "Batch: 75, Loss: 0.5751746296882629, Accuracy: 0.7998046875\n",
      "Batch: 76, Loss: 0.685328483581543, Accuracy: 0.7724609375\n",
      "Batch: 77, Loss: 0.6413102149963379, Accuracy: 0.7861328125\n",
      "Batch: 78, Loss: 0.5983461141586304, Accuracy: 0.80859375\n",
      "Batch: 79, Loss: 0.605963945388794, Accuracy: 0.8076171875\n",
      "Batch: 80, Loss: 0.6615963578224182, Accuracy: 0.765625\n",
      "Batch: 81, Loss: 0.7184433341026306, Accuracy: 0.75390625\n",
      "Batch: 82, Loss: 0.6934803128242493, Accuracy: 0.763671875\n",
      "Batch: 83, Loss: 0.5868820548057556, Accuracy: 0.814453125\n",
      "Batch: 84, Loss: 0.6440281271934509, Accuracy: 0.8017578125\n",
      "Batch: 85, Loss: 0.6482822895050049, Accuracy: 0.7763671875\n",
      "Batch: 86, Loss: 0.8242216110229492, Accuracy: 0.7421875\n",
      "Batch: 87, Loss: 0.5935701131820679, Accuracy: 0.814453125\n",
      "Batch: 88, Loss: 0.7468338012695312, Accuracy: 0.7705078125\n",
      "Batch: 89, Loss: 0.6842869520187378, Accuracy: 0.7822265625\n",
      "Batch: 90, Loss: 0.6894339323043823, Accuracy: 0.7890625\n",
      "Batch: 91, Loss: 0.6466424465179443, Accuracy: 0.796875\n",
      "Batch: 92, Loss: 0.6931366920471191, Accuracy: 0.7890625\n",
      "Batch: 93, Loss: 0.6262919902801514, Accuracy: 0.80078125\n",
      "Batch: 94, Loss: 0.6756184101104736, Accuracy: 0.7734375\n",
      "Batch: 95, Loss: 0.690967857837677, Accuracy: 0.7744140625\n",
      "Batch: 96, Loss: 0.662618100643158, Accuracy: 0.796875\n",
      "Batch: 97, Loss: 0.5453546047210693, Accuracy: 0.818359375\n",
      "Batch: 98, Loss: 0.6357964873313904, Accuracy: 0.7978515625\n",
      "Batch: 99, Loss: 0.6233970522880554, Accuracy: 0.78125\n",
      "Batch: 100, Loss: 0.6923818588256836, Accuracy: 0.7802734375\n",
      "Batch: 101, Loss: 0.6954442262649536, Accuracy: 0.76953125\n",
      "Batch: 102, Loss: 0.6529038548469543, Accuracy: 0.7783203125\n",
      "Batch: 103, Loss: 0.6958349347114563, Accuracy: 0.7822265625\n",
      "Batch: 104, Loss: 0.613047182559967, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.7031397819519043, Accuracy: 0.771484375\n",
      "Batch: 106, Loss: 0.5753803849220276, Accuracy: 0.8125\n",
      "Batch: 107, Loss: 0.6346211433410645, Accuracy: 0.8046875\n",
      "Batch: 108, Loss: 0.656551718711853, Accuracy: 0.7802734375\n",
      "Batch: 109, Loss: 0.7708423137664795, Accuracy: 0.7470703125\n",
      "Batch: 110, Loss: 0.5719110369682312, Accuracy: 0.8125\n",
      "Batch: 111, Loss: 0.6626507639884949, Accuracy: 0.7919921875\n",
      "Batch: 112, Loss: 0.6608991026878357, Accuracy: 0.796875\n",
      "Batch: 113, Loss: 0.6634677648544312, Accuracy: 0.794921875\n",
      "Batch: 114, Loss: 0.7654330730438232, Accuracy: 0.751953125\n",
      "Batch: 115, Loss: 0.7198474407196045, Accuracy: 0.775390625\n",
      "Batch: 116, Loss: 0.7094342112541199, Accuracy: 0.7744140625\n",
      "Batch: 117, Loss: 0.6858217716217041, Accuracy: 0.771484375\n",
      "Batch: 118, Loss: 0.6157708168029785, Accuracy: 0.802734375\n",
      "Batch: 119, Loss: 0.5883277654647827, Accuracy: 0.806640625\n",
      "Batch: 120, Loss: 0.6478563547134399, Accuracy: 0.78515625\n",
      "Batch: 121, Loss: 0.7152326703071594, Accuracy: 0.7724609375\n",
      "Batch: 122, Loss: 0.6590258479118347, Accuracy: 0.7958984375\n",
      "Batch: 123, Loss: 0.6401282548904419, Accuracy: 0.7890625\n",
      "Batch: 124, Loss: 0.6792468428611755, Accuracy: 0.7841796875\n",
      "Batch: 125, Loss: 0.7107503414154053, Accuracy: 0.77734375\n",
      "Batch: 126, Loss: 0.7081218957901001, Accuracy: 0.7705078125\n",
      "Batch: 127, Loss: 0.6554728746414185, Accuracy: 0.79296875\n",
      "Batch: 128, Loss: 0.7427645921707153, Accuracy: 0.765625\n",
      "Batch: 129, Loss: 0.6217930912971497, Accuracy: 0.794921875\n",
      "Batch: 130, Loss: 0.7478010654449463, Accuracy: 0.7568359375\n",
      "Batch: 131, Loss: 0.7057076692581177, Accuracy: 0.7705078125\n",
      "Batch: 132, Loss: 0.70884108543396, Accuracy: 0.783203125\n",
      "Batch: 133, Loss: 0.6700183749198914, Accuracy: 0.7744140625\n",
      "Batch: 134, Loss: 0.6912710666656494, Accuracy: 0.767578125\n",
      "Batch: 135, Loss: 0.6265897750854492, Accuracy: 0.798828125\n",
      "Batch: 136, Loss: 0.6858307719230652, Accuracy: 0.775390625\n",
      "Batch: 137, Loss: 0.6868815422058105, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.6103521585464478, Accuracy: 0.8037109375\n",
      "Batch: 139, Loss: 0.6680250763893127, Accuracy: 0.7783203125\n",
      "Batch: 140, Loss: 0.6443414688110352, Accuracy: 0.7822265625\n",
      "Batch: 141, Loss: 0.7339910864830017, Accuracy: 0.7548828125\n",
      "Batch: 142, Loss: 0.6825470924377441, Accuracy: 0.7685546875\n",
      "Batch: 143, Loss: 0.6771214008331299, Accuracy: 0.7744140625\n",
      "Batch: 144, Loss: 0.7044990062713623, Accuracy: 0.783203125\n",
      "Batch: 145, Loss: 0.6145825386047363, Accuracy: 0.7919921875\n",
      "Batch: 146, Loss: 0.6979424357414246, Accuracy: 0.7763671875\n",
      "Batch: 147, Loss: 0.6667819619178772, Accuracy: 0.7841796875\n",
      "Batch: 148, Loss: 0.7900769710540771, Accuracy: 0.7431640625\n",
      "Batch: 149, Loss: 0.6695238351821899, Accuracy: 0.794921875\n",
      "Batch: 150, Loss: 0.6632393598556519, Accuracy: 0.7763671875\n",
      "Batch: 151, Loss: 0.6130836009979248, Accuracy: 0.802734375\n",
      "Epoch 45/80\n",
      "Batch: 1, Loss: 0.8988536596298218, Accuracy: 0.7080078125\n",
      "Batch: 2, Loss: 0.7245848178863525, Accuracy: 0.759765625\n",
      "Batch: 3, Loss: 0.676912784576416, Accuracy: 0.7724609375\n",
      "Batch: 4, Loss: 0.6305288672447205, Accuracy: 0.794921875\n",
      "Batch: 5, Loss: 0.6375306844711304, Accuracy: 0.798828125\n",
      "Batch: 6, Loss: 0.6774183511734009, Accuracy: 0.77734375\n",
      "Batch: 7, Loss: 0.6843789219856262, Accuracy: 0.763671875\n",
      "Batch: 8, Loss: 0.6577898263931274, Accuracy: 0.78125\n",
      "Batch: 9, Loss: 0.6410881280899048, Accuracy: 0.7998046875\n",
      "Batch: 10, Loss: 0.6617233753204346, Accuracy: 0.77734375\n",
      "Batch: 11, Loss: 0.7469143867492676, Accuracy: 0.73828125\n",
      "Batch: 12, Loss: 0.7097916007041931, Accuracy: 0.7626953125\n",
      "Batch: 13, Loss: 0.553743839263916, Accuracy: 0.814453125\n",
      "Batch: 14, Loss: 0.7582784295082092, Accuracy: 0.7490234375\n",
      "Batch: 15, Loss: 0.5993049144744873, Accuracy: 0.8154296875\n",
      "Batch: 16, Loss: 0.6217210292816162, Accuracy: 0.8095703125\n",
      "Batch: 17, Loss: 0.6984344720840454, Accuracy: 0.7841796875\n",
      "Batch: 18, Loss: 0.7068836688995361, Accuracy: 0.771484375\n",
      "Batch: 19, Loss: 0.7249724864959717, Accuracy: 0.7734375\n",
      "Batch: 20, Loss: 0.6066379547119141, Accuracy: 0.80859375\n",
      "Batch: 21, Loss: 0.6860771179199219, Accuracy: 0.759765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 0.768604040145874, Accuracy: 0.75\n",
      "Batch: 23, Loss: 0.7185595631599426, Accuracy: 0.767578125\n",
      "Batch: 24, Loss: 0.7114077806472778, Accuracy: 0.7744140625\n",
      "Batch: 25, Loss: 0.650665283203125, Accuracy: 0.7900390625\n",
      "Batch: 26, Loss: 0.602618932723999, Accuracy: 0.8125\n",
      "Batch: 27, Loss: 0.6203655004501343, Accuracy: 0.7890625\n",
      "Batch: 28, Loss: 0.690986156463623, Accuracy: 0.7763671875\n",
      "Batch: 29, Loss: 0.6387539505958557, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.5733556747436523, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.5827409029006958, Accuracy: 0.8134765625\n",
      "Batch: 32, Loss: 0.5960012078285217, Accuracy: 0.798828125\n",
      "Batch: 33, Loss: 0.7115962505340576, Accuracy: 0.775390625\n",
      "Batch: 34, Loss: 0.763559103012085, Accuracy: 0.75390625\n",
      "Batch: 35, Loss: 0.6656209230422974, Accuracy: 0.78125\n",
      "Batch: 36, Loss: 0.673339307308197, Accuracy: 0.796875\n",
      "Batch: 37, Loss: 0.6684008836746216, Accuracy: 0.78515625\n",
      "Batch: 38, Loss: 0.6891740560531616, Accuracy: 0.7607421875\n",
      "Batch: 39, Loss: 0.7205499410629272, Accuracy: 0.7568359375\n",
      "Batch: 40, Loss: 0.659020185470581, Accuracy: 0.7783203125\n",
      "Batch: 41, Loss: 0.623417854309082, Accuracy: 0.8017578125\n",
      "Batch: 42, Loss: 0.5129573941230774, Accuracy: 0.833984375\n",
      "Batch: 43, Loss: 0.6783266067504883, Accuracy: 0.779296875\n",
      "Batch: 44, Loss: 0.667920708656311, Accuracy: 0.7705078125\n",
      "Batch: 45, Loss: 0.6083095073699951, Accuracy: 0.80078125\n",
      "Batch: 46, Loss: 0.5943465232849121, Accuracy: 0.8017578125\n",
      "Batch: 47, Loss: 0.5924290418624878, Accuracy: 0.810546875\n",
      "Batch: 48, Loss: 0.5904650688171387, Accuracy: 0.8056640625\n",
      "Batch: 49, Loss: 0.7064003348350525, Accuracy: 0.765625\n",
      "Batch: 50, Loss: 0.6937955021858215, Accuracy: 0.7705078125\n",
      "Batch: 51, Loss: 0.6758100390434265, Accuracy: 0.796875\n",
      "Batch: 52, Loss: 0.6862950921058655, Accuracy: 0.7822265625\n",
      "Batch: 53, Loss: 0.6161512136459351, Accuracy: 0.7939453125\n",
      "Batch: 54, Loss: 0.6334235668182373, Accuracy: 0.7900390625\n",
      "Batch: 55, Loss: 0.7347003221511841, Accuracy: 0.748046875\n",
      "Batch: 56, Loss: 0.7311307191848755, Accuracy: 0.7509765625\n",
      "Batch: 57, Loss: 0.6953698396682739, Accuracy: 0.783203125\n",
      "Batch: 58, Loss: 0.7326650619506836, Accuracy: 0.755859375\n",
      "Batch: 59, Loss: 0.6424387693405151, Accuracy: 0.78515625\n",
      "Batch: 60, Loss: 0.6251980066299438, Accuracy: 0.7939453125\n",
      "Batch: 61, Loss: 0.7031106948852539, Accuracy: 0.7587890625\n",
      "Batch: 62, Loss: 0.5947016477584839, Accuracy: 0.802734375\n",
      "Batch: 63, Loss: 0.654937744140625, Accuracy: 0.78515625\n",
      "Batch: 64, Loss: 0.6518058180809021, Accuracy: 0.7978515625\n",
      "Batch: 65, Loss: 0.6739691495895386, Accuracy: 0.7880859375\n",
      "Batch: 66, Loss: 0.6759909391403198, Accuracy: 0.7890625\n",
      "Batch: 67, Loss: 0.6916794776916504, Accuracy: 0.7802734375\n",
      "Batch: 68, Loss: 0.7040571570396423, Accuracy: 0.76953125\n",
      "Batch: 69, Loss: 0.7062118053436279, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.6853055953979492, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.7211553454399109, Accuracy: 0.7626953125\n",
      "Batch: 72, Loss: 0.6163175702095032, Accuracy: 0.79296875\n",
      "Batch: 73, Loss: 0.5982600450515747, Accuracy: 0.8134765625\n",
      "Batch: 74, Loss: 0.5620261430740356, Accuracy: 0.828125\n",
      "Batch: 75, Loss: 0.5902469158172607, Accuracy: 0.8037109375\n",
      "Batch: 76, Loss: 0.6867465972900391, Accuracy: 0.767578125\n",
      "Batch: 77, Loss: 0.6301543116569519, Accuracy: 0.796875\n",
      "Batch: 78, Loss: 0.6102031469345093, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.6249629855155945, Accuracy: 0.7939453125\n",
      "Batch: 80, Loss: 0.6394369602203369, Accuracy: 0.7861328125\n",
      "Batch: 81, Loss: 0.7026900053024292, Accuracy: 0.7529296875\n",
      "Batch: 82, Loss: 0.6705970764160156, Accuracy: 0.7724609375\n",
      "Batch: 83, Loss: 0.5955508947372437, Accuracy: 0.810546875\n",
      "Batch: 84, Loss: 0.6666601896286011, Accuracy: 0.76953125\n",
      "Batch: 85, Loss: 0.6651602387428284, Accuracy: 0.798828125\n",
      "Batch: 86, Loss: 0.7829148769378662, Accuracy: 0.751953125\n",
      "Batch: 87, Loss: 0.6014118194580078, Accuracy: 0.8046875\n",
      "Batch: 88, Loss: 0.7090780735015869, Accuracy: 0.7763671875\n",
      "Batch: 89, Loss: 0.6913894414901733, Accuracy: 0.783203125\n",
      "Batch: 90, Loss: 0.6548335552215576, Accuracy: 0.7841796875\n",
      "Batch: 91, Loss: 0.6353250741958618, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.6648558378219604, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.6421593427658081, Accuracy: 0.79296875\n",
      "Batch: 94, Loss: 0.6604657173156738, Accuracy: 0.7861328125\n",
      "Batch: 95, Loss: 0.6865644454956055, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.6474353075027466, Accuracy: 0.7880859375\n",
      "Batch: 97, Loss: 0.549769401550293, Accuracy: 0.8232421875\n",
      "Batch: 98, Loss: 0.6277045607566833, Accuracy: 0.7958984375\n",
      "Batch: 99, Loss: 0.6136243939399719, Accuracy: 0.787109375\n",
      "Batch: 100, Loss: 0.698793351650238, Accuracy: 0.7734375\n",
      "Batch: 101, Loss: 0.704494059085846, Accuracy: 0.765625\n",
      "Batch: 102, Loss: 0.6484079957008362, Accuracy: 0.78515625\n",
      "Batch: 103, Loss: 0.6787092685699463, Accuracy: 0.7919921875\n",
      "Batch: 104, Loss: 0.6261920928955078, Accuracy: 0.791015625\n",
      "Batch: 105, Loss: 0.6815845370292664, Accuracy: 0.7685546875\n",
      "Batch: 106, Loss: 0.5928600430488586, Accuracy: 0.8056640625\n",
      "Batch: 107, Loss: 0.6516565084457397, Accuracy: 0.806640625\n",
      "Batch: 108, Loss: 0.6547691822052002, Accuracy: 0.76953125\n",
      "Batch: 109, Loss: 0.7725164890289307, Accuracy: 0.7529296875\n",
      "Batch: 110, Loss: 0.5641875267028809, Accuracy: 0.8037109375\n",
      "Batch: 111, Loss: 0.6353906393051147, Accuracy: 0.79296875\n",
      "Batch: 112, Loss: 0.6563071012496948, Accuracy: 0.791015625\n",
      "Batch: 113, Loss: 0.6958940029144287, Accuracy: 0.8017578125\n",
      "Batch: 114, Loss: 0.7462897896766663, Accuracy: 0.75390625\n",
      "Batch: 115, Loss: 0.7246547341346741, Accuracy: 0.779296875\n",
      "Batch: 116, Loss: 0.6635109186172485, Accuracy: 0.7890625\n",
      "Batch: 117, Loss: 0.6999014616012573, Accuracy: 0.7705078125\n",
      "Batch: 118, Loss: 0.6410949230194092, Accuracy: 0.7958984375\n",
      "Batch: 119, Loss: 0.5688155293464661, Accuracy: 0.8154296875\n",
      "Batch: 120, Loss: 0.6664829254150391, Accuracy: 0.7705078125\n",
      "Batch: 121, Loss: 0.712952733039856, Accuracy: 0.7744140625\n",
      "Batch: 122, Loss: 0.6199144124984741, Accuracy: 0.8115234375\n",
      "Batch: 123, Loss: 0.6110419034957886, Accuracy: 0.8095703125\n",
      "Batch: 124, Loss: 0.6926292181015015, Accuracy: 0.7685546875\n",
      "Batch: 125, Loss: 0.685844898223877, Accuracy: 0.7841796875\n",
      "Batch: 126, Loss: 0.731393575668335, Accuracy: 0.7529296875\n",
      "Batch: 127, Loss: 0.6086317300796509, Accuracy: 0.8017578125\n",
      "Batch: 128, Loss: 0.7307005524635315, Accuracy: 0.7646484375\n",
      "Batch: 129, Loss: 0.6375849843025208, Accuracy: 0.7890625\n",
      "Batch: 130, Loss: 0.7098813056945801, Accuracy: 0.7666015625\n",
      "Batch: 131, Loss: 0.650525689125061, Accuracy: 0.7880859375\n",
      "Batch: 132, Loss: 0.6758573055267334, Accuracy: 0.78125\n",
      "Batch: 133, Loss: 0.6756807565689087, Accuracy: 0.7685546875\n",
      "Batch: 134, Loss: 0.6825447082519531, Accuracy: 0.7705078125\n",
      "Batch: 135, Loss: 0.612987756729126, Accuracy: 0.806640625\n",
      "Batch: 136, Loss: 0.6807668209075928, Accuracy: 0.7744140625\n",
      "Batch: 137, Loss: 0.6716452836990356, Accuracy: 0.767578125\n",
      "Batch: 138, Loss: 0.5995821356773376, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.6844015121459961, Accuracy: 0.7548828125\n",
      "Batch: 140, Loss: 0.6532649993896484, Accuracy: 0.77734375\n",
      "Batch: 141, Loss: 0.7023525238037109, Accuracy: 0.7666015625\n",
      "Batch: 142, Loss: 0.7277835011482239, Accuracy: 0.7587890625\n",
      "Batch: 143, Loss: 0.6892552375793457, Accuracy: 0.7685546875\n",
      "Batch: 144, Loss: 0.6707208156585693, Accuracy: 0.7705078125\n",
      "Batch: 145, Loss: 0.6260683536529541, Accuracy: 0.79296875\n",
      "Batch: 146, Loss: 0.690436065196991, Accuracy: 0.7705078125\n",
      "Batch: 147, Loss: 0.693497896194458, Accuracy: 0.78125\n",
      "Batch: 148, Loss: 0.779181957244873, Accuracy: 0.755859375\n",
      "Batch: 149, Loss: 0.6421515345573425, Accuracy: 0.7861328125\n",
      "Batch: 150, Loss: 0.6334120631217957, Accuracy: 0.7822265625\n",
      "Batch: 151, Loss: 0.5891119241714478, Accuracy: 0.8037109375\n",
      "Epoch 46/80\n",
      "Batch: 1, Loss: 0.8453278541564941, Accuracy: 0.7333984375\n",
      "Batch: 2, Loss: 0.7483333945274353, Accuracy: 0.7392578125\n",
      "Batch: 3, Loss: 0.6919909715652466, Accuracy: 0.765625\n",
      "Batch: 4, Loss: 0.6194431781768799, Accuracy: 0.8115234375\n",
      "Batch: 5, Loss: 0.633065938949585, Accuracy: 0.8076171875\n",
      "Batch: 6, Loss: 0.6703872084617615, Accuracy: 0.7783203125\n",
      "Batch: 7, Loss: 0.668145477771759, Accuracy: 0.7705078125\n",
      "Batch: 8, Loss: 0.6478116512298584, Accuracy: 0.79296875\n",
      "Batch: 9, Loss: 0.6366239786148071, Accuracy: 0.798828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 0.6208693981170654, Accuracy: 0.7978515625\n",
      "Batch: 11, Loss: 0.7279360294342041, Accuracy: 0.7587890625\n",
      "Batch: 12, Loss: 0.7069458365440369, Accuracy: 0.7646484375\n",
      "Batch: 13, Loss: 0.5407272577285767, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.7224133014678955, Accuracy: 0.75390625\n",
      "Batch: 15, Loss: 0.6096926927566528, Accuracy: 0.8095703125\n",
      "Batch: 16, Loss: 0.6167236566543579, Accuracy: 0.8046875\n",
      "Batch: 17, Loss: 0.6785906553268433, Accuracy: 0.787109375\n",
      "Batch: 18, Loss: 0.6966221928596497, Accuracy: 0.783203125\n",
      "Batch: 19, Loss: 0.6988417506217957, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.5836917161941528, Accuracy: 0.8193359375\n",
      "Batch: 21, Loss: 0.6520877480506897, Accuracy: 0.7861328125\n",
      "Batch: 22, Loss: 0.7552521228790283, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.6929634809494019, Accuracy: 0.779296875\n",
      "Batch: 24, Loss: 0.6810125112533569, Accuracy: 0.794921875\n",
      "Batch: 25, Loss: 0.6465804576873779, Accuracy: 0.80859375\n",
      "Batch: 26, Loss: 0.5868809223175049, Accuracy: 0.80859375\n",
      "Batch: 27, Loss: 0.6355082988739014, Accuracy: 0.7783203125\n",
      "Batch: 28, Loss: 0.6611123085021973, Accuracy: 0.77734375\n",
      "Batch: 29, Loss: 0.6080053448677063, Accuracy: 0.7919921875\n",
      "Batch: 30, Loss: 0.5610795617103577, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.5742208957672119, Accuracy: 0.8095703125\n",
      "Batch: 32, Loss: 0.6016436815261841, Accuracy: 0.7939453125\n",
      "Batch: 33, Loss: 0.7014739513397217, Accuracy: 0.7939453125\n",
      "Batch: 34, Loss: 0.7735528945922852, Accuracy: 0.7509765625\n",
      "Batch: 35, Loss: 0.6488420963287354, Accuracy: 0.79296875\n",
      "Batch: 36, Loss: 0.6950416564941406, Accuracy: 0.7783203125\n",
      "Batch: 37, Loss: 0.6655747890472412, Accuracy: 0.7802734375\n",
      "Batch: 38, Loss: 0.6552743315696716, Accuracy: 0.783203125\n",
      "Batch: 39, Loss: 0.7008988261222839, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.6471938490867615, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.6191582679748535, Accuracy: 0.7998046875\n",
      "Batch: 42, Loss: 0.5196002721786499, Accuracy: 0.83203125\n",
      "Batch: 43, Loss: 0.6321184635162354, Accuracy: 0.783203125\n",
      "Batch: 44, Loss: 0.6501885056495667, Accuracy: 0.787109375\n",
      "Batch: 45, Loss: 0.5842447280883789, Accuracy: 0.8056640625\n",
      "Batch: 46, Loss: 0.5918595790863037, Accuracy: 0.7998046875\n",
      "Batch: 47, Loss: 0.6108766794204712, Accuracy: 0.8046875\n",
      "Batch: 48, Loss: 0.5888189077377319, Accuracy: 0.8134765625\n",
      "Batch: 49, Loss: 0.7029331922531128, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.7027207612991333, Accuracy: 0.7685546875\n",
      "Batch: 51, Loss: 0.6816484928131104, Accuracy: 0.7880859375\n",
      "Batch: 52, Loss: 0.6485194563865662, Accuracy: 0.7919921875\n",
      "Batch: 53, Loss: 0.6236968040466309, Accuracy: 0.7841796875\n",
      "Batch: 54, Loss: 0.6458364725112915, Accuracy: 0.7802734375\n",
      "Batch: 55, Loss: 0.6802774667739868, Accuracy: 0.779296875\n",
      "Batch: 56, Loss: 0.7008686065673828, Accuracy: 0.765625\n",
      "Batch: 57, Loss: 0.6895442008972168, Accuracy: 0.7744140625\n",
      "Batch: 58, Loss: 0.7331688404083252, Accuracy: 0.7734375\n",
      "Batch: 59, Loss: 0.6477632522583008, Accuracy: 0.7861328125\n",
      "Batch: 60, Loss: 0.602910041809082, Accuracy: 0.7900390625\n",
      "Batch: 61, Loss: 0.6470153331756592, Accuracy: 0.7802734375\n",
      "Batch: 62, Loss: 0.5857160091400146, Accuracy: 0.8134765625\n",
      "Batch: 63, Loss: 0.6427268981933594, Accuracy: 0.79296875\n",
      "Batch: 64, Loss: 0.6267886161804199, Accuracy: 0.8056640625\n",
      "Batch: 65, Loss: 0.6581953763961792, Accuracy: 0.7890625\n",
      "Batch: 66, Loss: 0.6605507135391235, Accuracy: 0.79296875\n",
      "Batch: 67, Loss: 0.6977996230125427, Accuracy: 0.763671875\n",
      "Batch: 68, Loss: 0.7666829824447632, Accuracy: 0.7587890625\n",
      "Batch: 69, Loss: 0.7177541255950928, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.6684372425079346, Accuracy: 0.79296875\n",
      "Batch: 71, Loss: 0.6944615840911865, Accuracy: 0.7666015625\n",
      "Batch: 72, Loss: 0.6196277141571045, Accuracy: 0.7998046875\n",
      "Batch: 73, Loss: 0.5916919112205505, Accuracy: 0.8115234375\n",
      "Batch: 74, Loss: 0.5561600923538208, Accuracy: 0.833984375\n",
      "Batch: 75, Loss: 0.5789594650268555, Accuracy: 0.8125\n",
      "Batch: 76, Loss: 0.6760805249214172, Accuracy: 0.76171875\n",
      "Batch: 77, Loss: 0.606540322303772, Accuracy: 0.7998046875\n",
      "Batch: 78, Loss: 0.6075526475906372, Accuracy: 0.802734375\n",
      "Batch: 79, Loss: 0.5920833349227905, Accuracy: 0.806640625\n",
      "Batch: 80, Loss: 0.6436896324157715, Accuracy: 0.7841796875\n",
      "Batch: 81, Loss: 0.728294849395752, Accuracy: 0.748046875\n",
      "Batch: 82, Loss: 0.6524239778518677, Accuracy: 0.7880859375\n",
      "Batch: 83, Loss: 0.5707944631576538, Accuracy: 0.8232421875\n",
      "Batch: 84, Loss: 0.6625217795372009, Accuracy: 0.7919921875\n",
      "Batch: 85, Loss: 0.6031869649887085, Accuracy: 0.8154296875\n",
      "Batch: 86, Loss: 0.794221043586731, Accuracy: 0.7314453125\n",
      "Batch: 87, Loss: 0.57564377784729, Accuracy: 0.814453125\n",
      "Batch: 88, Loss: 0.706519603729248, Accuracy: 0.78125\n",
      "Batch: 89, Loss: 0.6633322238922119, Accuracy: 0.7919921875\n",
      "Batch: 90, Loss: 0.6408131718635559, Accuracy: 0.7880859375\n",
      "Batch: 91, Loss: 0.6428873538970947, Accuracy: 0.7939453125\n",
      "Batch: 92, Loss: 0.6654788255691528, Accuracy: 0.7900390625\n",
      "Batch: 93, Loss: 0.6493607759475708, Accuracy: 0.78515625\n",
      "Batch: 94, Loss: 0.6779427528381348, Accuracy: 0.787109375\n",
      "Batch: 95, Loss: 0.6926525831222534, Accuracy: 0.765625\n",
      "Batch: 96, Loss: 0.6422443389892578, Accuracy: 0.7861328125\n",
      "Batch: 97, Loss: 0.5265036821365356, Accuracy: 0.826171875\n",
      "Batch: 98, Loss: 0.6286709308624268, Accuracy: 0.802734375\n",
      "Batch: 99, Loss: 0.6091257333755493, Accuracy: 0.7890625\n",
      "Batch: 100, Loss: 0.6699063777923584, Accuracy: 0.7724609375\n",
      "Batch: 101, Loss: 0.6821344494819641, Accuracy: 0.76953125\n",
      "Batch: 102, Loss: 0.6445432901382446, Accuracy: 0.796875\n",
      "Batch: 103, Loss: 0.6780478954315186, Accuracy: 0.7861328125\n",
      "Batch: 104, Loss: 0.6185241937637329, Accuracy: 0.802734375\n",
      "Batch: 105, Loss: 0.703243613243103, Accuracy: 0.7646484375\n",
      "Batch: 106, Loss: 0.5876865386962891, Accuracy: 0.8212890625\n",
      "Batch: 107, Loss: 0.6337661147117615, Accuracy: 0.7900390625\n",
      "Batch: 108, Loss: 0.6322091817855835, Accuracy: 0.796875\n",
      "Batch: 109, Loss: 0.7290226817131042, Accuracy: 0.76953125\n",
      "Batch: 110, Loss: 0.5625981092453003, Accuracy: 0.82421875\n",
      "Batch: 111, Loss: 0.6479475498199463, Accuracy: 0.79296875\n",
      "Batch: 112, Loss: 0.6760076284408569, Accuracy: 0.7763671875\n",
      "Batch: 113, Loss: 0.6201610565185547, Accuracy: 0.80078125\n",
      "Batch: 114, Loss: 0.7031811475753784, Accuracy: 0.7802734375\n",
      "Batch: 115, Loss: 0.7097058296203613, Accuracy: 0.76171875\n",
      "Batch: 116, Loss: 0.646820068359375, Accuracy: 0.7841796875\n",
      "Batch: 117, Loss: 0.7062427997589111, Accuracy: 0.7822265625\n",
      "Batch: 118, Loss: 0.5882484316825867, Accuracy: 0.8251953125\n",
      "Batch: 119, Loss: 0.5373583436012268, Accuracy: 0.8232421875\n",
      "Batch: 120, Loss: 0.6515336036682129, Accuracy: 0.7890625\n",
      "Batch: 121, Loss: 0.7005085945129395, Accuracy: 0.76171875\n",
      "Batch: 122, Loss: 0.6136454343795776, Accuracy: 0.79296875\n",
      "Batch: 123, Loss: 0.5735195279121399, Accuracy: 0.8232421875\n",
      "Batch: 124, Loss: 0.7065550088882446, Accuracy: 0.775390625\n",
      "Batch: 125, Loss: 0.6850137710571289, Accuracy: 0.78125\n",
      "Batch: 126, Loss: 0.6826556324958801, Accuracy: 0.7763671875\n",
      "Batch: 127, Loss: 0.5663610696792603, Accuracy: 0.82421875\n",
      "Batch: 128, Loss: 0.7314519882202148, Accuracy: 0.7705078125\n",
      "Batch: 129, Loss: 0.6143093109130859, Accuracy: 0.7998046875\n",
      "Batch: 130, Loss: 0.7189823389053345, Accuracy: 0.759765625\n",
      "Batch: 131, Loss: 0.6596482992172241, Accuracy: 0.7998046875\n",
      "Batch: 132, Loss: 0.6605870723724365, Accuracy: 0.7890625\n",
      "Batch: 133, Loss: 0.6348670721054077, Accuracy: 0.7998046875\n",
      "Batch: 134, Loss: 0.6630353331565857, Accuracy: 0.7705078125\n",
      "Batch: 135, Loss: 0.6169861555099487, Accuracy: 0.80859375\n",
      "Batch: 136, Loss: 0.6932456493377686, Accuracy: 0.783203125\n",
      "Batch: 137, Loss: 0.6517093181610107, Accuracy: 0.78515625\n",
      "Batch: 138, Loss: 0.5871661901473999, Accuracy: 0.814453125\n",
      "Batch: 139, Loss: 0.677046537399292, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.6328146457672119, Accuracy: 0.798828125\n",
      "Batch: 141, Loss: 0.6878536939620972, Accuracy: 0.7744140625\n",
      "Batch: 142, Loss: 0.6949894428253174, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.676652729511261, Accuracy: 0.787109375\n",
      "Batch: 144, Loss: 0.6794834136962891, Accuracy: 0.7783203125\n",
      "Batch: 145, Loss: 0.602851390838623, Accuracy: 0.806640625\n",
      "Batch: 146, Loss: 0.6603509783744812, Accuracy: 0.7724609375\n",
      "Batch: 147, Loss: 0.6374419927597046, Accuracy: 0.7939453125\n",
      "Batch: 148, Loss: 0.7564010620117188, Accuracy: 0.7626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 0.6292831301689148, Accuracy: 0.7939453125\n",
      "Batch: 150, Loss: 0.6300651431083679, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.573400616645813, Accuracy: 0.806640625\n",
      "Epoch 47/80\n",
      "Batch: 1, Loss: 0.8328296542167664, Accuracy: 0.736328125\n",
      "Batch: 2, Loss: 0.7377389669418335, Accuracy: 0.7392578125\n",
      "Batch: 3, Loss: 0.6646139025688171, Accuracy: 0.7705078125\n",
      "Batch: 4, Loss: 0.5962342023849487, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6043318510055542, Accuracy: 0.8017578125\n",
      "Batch: 6, Loss: 0.6434193849563599, Accuracy: 0.7890625\n",
      "Batch: 7, Loss: 0.6777404546737671, Accuracy: 0.763671875\n",
      "Batch: 8, Loss: 0.6347666382789612, Accuracy: 0.791015625\n",
      "Batch: 9, Loss: 0.6310319900512695, Accuracy: 0.798828125\n",
      "Batch: 10, Loss: 0.6497286558151245, Accuracy: 0.7880859375\n",
      "Batch: 11, Loss: 0.6959065198898315, Accuracy: 0.767578125\n",
      "Batch: 12, Loss: 0.6646829843521118, Accuracy: 0.76953125\n",
      "Batch: 13, Loss: 0.5341305732727051, Accuracy: 0.83203125\n",
      "Batch: 14, Loss: 0.7513623237609863, Accuracy: 0.751953125\n",
      "Batch: 15, Loss: 0.5992240905761719, Accuracy: 0.8115234375\n",
      "Batch: 16, Loss: 0.6002095937728882, Accuracy: 0.8232421875\n",
      "Batch: 17, Loss: 0.658247709274292, Accuracy: 0.7890625\n",
      "Batch: 18, Loss: 0.6911917328834534, Accuracy: 0.775390625\n",
      "Batch: 19, Loss: 0.6873791217803955, Accuracy: 0.7763671875\n",
      "Batch: 20, Loss: 0.5779194831848145, Accuracy: 0.8193359375\n",
      "Batch: 21, Loss: 0.6567012071609497, Accuracy: 0.7783203125\n",
      "Batch: 22, Loss: 0.7434628009796143, Accuracy: 0.771484375\n",
      "Batch: 23, Loss: 0.6885430216789246, Accuracy: 0.7861328125\n",
      "Batch: 24, Loss: 0.6889083385467529, Accuracy: 0.7822265625\n",
      "Batch: 25, Loss: 0.6512142419815063, Accuracy: 0.7939453125\n",
      "Batch: 26, Loss: 0.5541472434997559, Accuracy: 0.8291015625\n",
      "Batch: 27, Loss: 0.6174447536468506, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.6457353830337524, Accuracy: 0.7744140625\n",
      "Batch: 29, Loss: 0.6091957688331604, Accuracy: 0.8056640625\n",
      "Batch: 30, Loss: 0.5263427495956421, Accuracy: 0.8310546875\n",
      "Batch: 31, Loss: 0.5869497656822205, Accuracy: 0.8095703125\n",
      "Batch: 32, Loss: 0.588721513748169, Accuracy: 0.80859375\n",
      "Batch: 33, Loss: 0.6698786020278931, Accuracy: 0.7822265625\n",
      "Batch: 34, Loss: 0.7377103567123413, Accuracy: 0.7666015625\n",
      "Batch: 35, Loss: 0.6638163328170776, Accuracy: 0.7822265625\n",
      "Batch: 36, Loss: 0.6702642440795898, Accuracy: 0.791015625\n",
      "Batch: 37, Loss: 0.6537189483642578, Accuracy: 0.7841796875\n",
      "Batch: 38, Loss: 0.63727867603302, Accuracy: 0.78515625\n",
      "Batch: 39, Loss: 0.6725557446479797, Accuracy: 0.7763671875\n",
      "Batch: 40, Loss: 0.643074095249176, Accuracy: 0.7978515625\n",
      "Batch: 41, Loss: 0.6024567484855652, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.5008081197738647, Accuracy: 0.826171875\n",
      "Batch: 43, Loss: 0.6094688177108765, Accuracy: 0.7939453125\n",
      "Batch: 44, Loss: 0.6421647071838379, Accuracy: 0.7783203125\n",
      "Batch: 45, Loss: 0.5512781739234924, Accuracy: 0.814453125\n",
      "Batch: 46, Loss: 0.5660262107849121, Accuracy: 0.826171875\n",
      "Batch: 47, Loss: 0.5994839072227478, Accuracy: 0.8134765625\n",
      "Batch: 48, Loss: 0.5721590518951416, Accuracy: 0.81640625\n",
      "Batch: 49, Loss: 0.6839373707771301, Accuracy: 0.7646484375\n",
      "Batch: 50, Loss: 0.6767733097076416, Accuracy: 0.78515625\n",
      "Batch: 51, Loss: 0.6524423956871033, Accuracy: 0.7841796875\n",
      "Batch: 52, Loss: 0.6483165621757507, Accuracy: 0.7880859375\n",
      "Batch: 53, Loss: 0.5706284046173096, Accuracy: 0.810546875\n",
      "Batch: 54, Loss: 0.6236352920532227, Accuracy: 0.7978515625\n",
      "Batch: 55, Loss: 0.724162220954895, Accuracy: 0.7724609375\n",
      "Batch: 56, Loss: 0.7182523608207703, Accuracy: 0.767578125\n",
      "Batch: 57, Loss: 0.682851254940033, Accuracy: 0.7763671875\n",
      "Batch: 58, Loss: 0.7193121910095215, Accuracy: 0.7705078125\n",
      "Batch: 59, Loss: 0.6066076755523682, Accuracy: 0.8095703125\n",
      "Batch: 60, Loss: 0.5782917737960815, Accuracy: 0.8076171875\n",
      "Batch: 61, Loss: 0.6450810432434082, Accuracy: 0.775390625\n",
      "Batch: 62, Loss: 0.5731456279754639, Accuracy: 0.8203125\n",
      "Batch: 63, Loss: 0.6354536414146423, Accuracy: 0.796875\n",
      "Batch: 64, Loss: 0.629370391368866, Accuracy: 0.791015625\n",
      "Batch: 65, Loss: 0.6519911289215088, Accuracy: 0.802734375\n",
      "Batch: 66, Loss: 0.6552670001983643, Accuracy: 0.7890625\n",
      "Batch: 67, Loss: 0.6997939348220825, Accuracy: 0.7763671875\n",
      "Batch: 68, Loss: 0.7600690126419067, Accuracy: 0.7548828125\n",
      "Batch: 69, Loss: 0.688683807849884, Accuracy: 0.7763671875\n",
      "Batch: 70, Loss: 0.6848325729370117, Accuracy: 0.783203125\n",
      "Batch: 71, Loss: 0.6669064164161682, Accuracy: 0.7822265625\n",
      "Batch: 72, Loss: 0.6182359457015991, Accuracy: 0.7998046875\n",
      "Batch: 73, Loss: 0.5999035835266113, Accuracy: 0.7998046875\n",
      "Batch: 74, Loss: 0.5522966980934143, Accuracy: 0.828125\n",
      "Batch: 75, Loss: 0.577198326587677, Accuracy: 0.8017578125\n",
      "Batch: 76, Loss: 0.6399356126785278, Accuracy: 0.7841796875\n",
      "Batch: 77, Loss: 0.603451132774353, Accuracy: 0.802734375\n",
      "Batch: 78, Loss: 0.584705650806427, Accuracy: 0.8193359375\n",
      "Batch: 79, Loss: 0.5485629439353943, Accuracy: 0.8369140625\n",
      "Batch: 80, Loss: 0.606491208076477, Accuracy: 0.796875\n",
      "Batch: 81, Loss: 0.6828611493110657, Accuracy: 0.7724609375\n",
      "Batch: 82, Loss: 0.645859956741333, Accuracy: 0.7958984375\n",
      "Batch: 83, Loss: 0.5610542893409729, Accuracy: 0.8125\n",
      "Batch: 84, Loss: 0.6598889827728271, Accuracy: 0.7880859375\n",
      "Batch: 85, Loss: 0.6025546193122864, Accuracy: 0.80859375\n",
      "Batch: 86, Loss: 0.7802602052688599, Accuracy: 0.763671875\n",
      "Batch: 87, Loss: 0.5429624915122986, Accuracy: 0.8330078125\n",
      "Batch: 88, Loss: 0.6808959245681763, Accuracy: 0.802734375\n",
      "Batch: 89, Loss: 0.6636030077934265, Accuracy: 0.80078125\n",
      "Batch: 90, Loss: 0.6542230844497681, Accuracy: 0.7998046875\n",
      "Batch: 91, Loss: 0.6435031294822693, Accuracy: 0.80078125\n",
      "Batch: 92, Loss: 0.6613118052482605, Accuracy: 0.7822265625\n",
      "Batch: 93, Loss: 0.6113426685333252, Accuracy: 0.802734375\n",
      "Batch: 94, Loss: 0.6338824033737183, Accuracy: 0.7998046875\n",
      "Batch: 95, Loss: 0.650545060634613, Accuracy: 0.7841796875\n",
      "Batch: 96, Loss: 0.6171222925186157, Accuracy: 0.8037109375\n",
      "Batch: 97, Loss: 0.520936131477356, Accuracy: 0.8349609375\n",
      "Batch: 98, Loss: 0.6297980546951294, Accuracy: 0.7880859375\n",
      "Batch: 99, Loss: 0.6115004420280457, Accuracy: 0.791015625\n",
      "Batch: 100, Loss: 0.6669601202011108, Accuracy: 0.779296875\n",
      "Batch: 101, Loss: 0.651050329208374, Accuracy: 0.767578125\n",
      "Batch: 102, Loss: 0.6442114114761353, Accuracy: 0.7841796875\n",
      "Batch: 103, Loss: 0.6753758788108826, Accuracy: 0.7705078125\n",
      "Batch: 104, Loss: 0.6266636848449707, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.666875958442688, Accuracy: 0.7744140625\n",
      "Batch: 106, Loss: 0.5712723731994629, Accuracy: 0.8212890625\n",
      "Batch: 107, Loss: 0.6009389162063599, Accuracy: 0.814453125\n",
      "Batch: 108, Loss: 0.626054048538208, Accuracy: 0.7958984375\n",
      "Batch: 109, Loss: 0.7173466086387634, Accuracy: 0.7626953125\n",
      "Batch: 110, Loss: 0.5486355423927307, Accuracy: 0.822265625\n",
      "Batch: 111, Loss: 0.6676344871520996, Accuracy: 0.783203125\n",
      "Batch: 112, Loss: 0.6459699869155884, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6309592127799988, Accuracy: 0.8037109375\n",
      "Batch: 114, Loss: 0.6899804472923279, Accuracy: 0.7783203125\n",
      "Batch: 115, Loss: 0.6895476579666138, Accuracy: 0.78515625\n",
      "Batch: 116, Loss: 0.6469711661338806, Accuracy: 0.7890625\n",
      "Batch: 117, Loss: 0.6743960380554199, Accuracy: 0.7822265625\n",
      "Batch: 118, Loss: 0.5946129560470581, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5379095673561096, Accuracy: 0.8359375\n",
      "Batch: 120, Loss: 0.632659375667572, Accuracy: 0.798828125\n",
      "Batch: 121, Loss: 0.6714353561401367, Accuracy: 0.7900390625\n",
      "Batch: 122, Loss: 0.6309418678283691, Accuracy: 0.794921875\n",
      "Batch: 123, Loss: 0.5999587774276733, Accuracy: 0.8056640625\n",
      "Batch: 124, Loss: 0.6615419387817383, Accuracy: 0.7822265625\n",
      "Batch: 125, Loss: 0.6846091151237488, Accuracy: 0.7666015625\n",
      "Batch: 126, Loss: 0.6783187389373779, Accuracy: 0.787109375\n",
      "Batch: 127, Loss: 0.6004369258880615, Accuracy: 0.810546875\n",
      "Batch: 128, Loss: 0.6939741373062134, Accuracy: 0.7861328125\n",
      "Batch: 129, Loss: 0.6334401369094849, Accuracy: 0.796875\n",
      "Batch: 130, Loss: 0.7006075978279114, Accuracy: 0.767578125\n",
      "Batch: 131, Loss: 0.6590142250061035, Accuracy: 0.7841796875\n",
      "Batch: 132, Loss: 0.6744021773338318, Accuracy: 0.7890625\n",
      "Batch: 133, Loss: 0.6622887849807739, Accuracy: 0.771484375\n",
      "Batch: 134, Loss: 0.6699867248535156, Accuracy: 0.7763671875\n",
      "Batch: 135, Loss: 0.5978944897651672, Accuracy: 0.8046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 0.6429736018180847, Accuracy: 0.798828125\n",
      "Batch: 137, Loss: 0.6733049750328064, Accuracy: 0.7724609375\n",
      "Batch: 138, Loss: 0.5605146884918213, Accuracy: 0.818359375\n",
      "Batch: 139, Loss: 0.6723555326461792, Accuracy: 0.7880859375\n",
      "Batch: 140, Loss: 0.618902325630188, Accuracy: 0.802734375\n",
      "Batch: 141, Loss: 0.6954734325408936, Accuracy: 0.775390625\n",
      "Batch: 142, Loss: 0.6994525194168091, Accuracy: 0.7705078125\n",
      "Batch: 143, Loss: 0.6880612373352051, Accuracy: 0.7744140625\n",
      "Batch: 144, Loss: 0.6623245477676392, Accuracy: 0.779296875\n",
      "Batch: 145, Loss: 0.597785234451294, Accuracy: 0.7998046875\n",
      "Batch: 146, Loss: 0.6830431818962097, Accuracy: 0.7705078125\n",
      "Batch: 147, Loss: 0.6566377878189087, Accuracy: 0.78515625\n",
      "Batch: 148, Loss: 0.7284872531890869, Accuracy: 0.748046875\n",
      "Batch: 149, Loss: 0.6031457185745239, Accuracy: 0.8115234375\n",
      "Batch: 150, Loss: 0.6399271488189697, Accuracy: 0.7802734375\n",
      "Batch: 151, Loss: 0.5769287347793579, Accuracy: 0.8046875\n",
      "Epoch 48/80\n",
      "Batch: 1, Loss: 0.82480788230896, Accuracy: 0.7333984375\n",
      "Batch: 2, Loss: 0.7454186081886292, Accuracy: 0.7587890625\n",
      "Batch: 3, Loss: 0.6529475450515747, Accuracy: 0.783203125\n",
      "Batch: 4, Loss: 0.6206023693084717, Accuracy: 0.7919921875\n",
      "Batch: 5, Loss: 0.604698896408081, Accuracy: 0.8095703125\n",
      "Batch: 6, Loss: 0.6721800565719604, Accuracy: 0.775390625\n",
      "Batch: 7, Loss: 0.6684241890907288, Accuracy: 0.7763671875\n",
      "Batch: 8, Loss: 0.6008841395378113, Accuracy: 0.8017578125\n",
      "Batch: 9, Loss: 0.6420739889144897, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.6243973970413208, Accuracy: 0.7880859375\n",
      "Batch: 11, Loss: 0.6884041428565979, Accuracy: 0.76953125\n",
      "Batch: 12, Loss: 0.6534060835838318, Accuracy: 0.787109375\n",
      "Batch: 13, Loss: 0.5282261371612549, Accuracy: 0.8349609375\n",
      "Batch: 14, Loss: 0.728059709072113, Accuracy: 0.7587890625\n",
      "Batch: 15, Loss: 0.5820842981338501, Accuracy: 0.8271484375\n",
      "Batch: 16, Loss: 0.5939372777938843, Accuracy: 0.8271484375\n",
      "Batch: 17, Loss: 0.6711038947105408, Accuracy: 0.79296875\n",
      "Batch: 18, Loss: 0.669806957244873, Accuracy: 0.79296875\n",
      "Batch: 19, Loss: 0.6945170164108276, Accuracy: 0.7783203125\n",
      "Batch: 20, Loss: 0.5648725032806396, Accuracy: 0.8291015625\n",
      "Batch: 21, Loss: 0.6465264558792114, Accuracy: 0.7763671875\n",
      "Batch: 22, Loss: 0.7211365699768066, Accuracy: 0.77734375\n",
      "Batch: 23, Loss: 0.6630100607872009, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.6759225726127625, Accuracy: 0.78515625\n",
      "Batch: 25, Loss: 0.649059534072876, Accuracy: 0.798828125\n",
      "Batch: 26, Loss: 0.5804600119590759, Accuracy: 0.80859375\n",
      "Batch: 27, Loss: 0.6121302843093872, Accuracy: 0.8037109375\n",
      "Batch: 28, Loss: 0.6190643906593323, Accuracy: 0.8134765625\n",
      "Batch: 29, Loss: 0.616426944732666, Accuracy: 0.8115234375\n",
      "Batch: 30, Loss: 0.5359532237052917, Accuracy: 0.8359375\n",
      "Batch: 31, Loss: 0.5508135557174683, Accuracy: 0.822265625\n",
      "Batch: 32, Loss: 0.5784696340560913, Accuracy: 0.8056640625\n",
      "Batch: 33, Loss: 0.6836217641830444, Accuracy: 0.7841796875\n",
      "Batch: 34, Loss: 0.7262064814567566, Accuracy: 0.7626953125\n",
      "Batch: 35, Loss: 0.6291744709014893, Accuracy: 0.8076171875\n",
      "Batch: 36, Loss: 0.6603429317474365, Accuracy: 0.814453125\n",
      "Batch: 37, Loss: 0.6501944065093994, Accuracy: 0.783203125\n",
      "Batch: 38, Loss: 0.6452181935310364, Accuracy: 0.78125\n",
      "Batch: 39, Loss: 0.664365291595459, Accuracy: 0.78125\n",
      "Batch: 40, Loss: 0.6364845037460327, Accuracy: 0.7978515625\n",
      "Batch: 41, Loss: 0.5887324810028076, Accuracy: 0.8037109375\n",
      "Batch: 42, Loss: 0.47524529695510864, Accuracy: 0.837890625\n",
      "Batch: 43, Loss: 0.6061826944351196, Accuracy: 0.7890625\n",
      "Batch: 44, Loss: 0.6127492785453796, Accuracy: 0.7919921875\n",
      "Batch: 45, Loss: 0.5559046268463135, Accuracy: 0.81640625\n",
      "Batch: 46, Loss: 0.5567281246185303, Accuracy: 0.822265625\n",
      "Batch: 47, Loss: 0.5952222347259521, Accuracy: 0.8125\n",
      "Batch: 48, Loss: 0.5510562658309937, Accuracy: 0.8115234375\n",
      "Batch: 49, Loss: 0.688164234161377, Accuracy: 0.775390625\n",
      "Batch: 50, Loss: 0.6493020057678223, Accuracy: 0.7890625\n",
      "Batch: 51, Loss: 0.6361604332923889, Accuracy: 0.798828125\n",
      "Batch: 52, Loss: 0.635572075843811, Accuracy: 0.80859375\n",
      "Batch: 53, Loss: 0.5800225734710693, Accuracy: 0.79296875\n",
      "Batch: 54, Loss: 0.6413094997406006, Accuracy: 0.79296875\n",
      "Batch: 55, Loss: 0.6820886731147766, Accuracy: 0.765625\n",
      "Batch: 56, Loss: 0.6800365447998047, Accuracy: 0.7783203125\n",
      "Batch: 57, Loss: 0.664431095123291, Accuracy: 0.7841796875\n",
      "Batch: 58, Loss: 0.7480831146240234, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.6154335737228394, Accuracy: 0.8017578125\n",
      "Batch: 60, Loss: 0.5795377492904663, Accuracy: 0.8037109375\n",
      "Batch: 61, Loss: 0.6092236042022705, Accuracy: 0.79296875\n",
      "Batch: 62, Loss: 0.5907450914382935, Accuracy: 0.8037109375\n",
      "Batch: 63, Loss: 0.6296290159225464, Accuracy: 0.7998046875\n",
      "Batch: 64, Loss: 0.6096435785293579, Accuracy: 0.810546875\n",
      "Batch: 65, Loss: 0.6355979442596436, Accuracy: 0.798828125\n",
      "Batch: 66, Loss: 0.6716611385345459, Accuracy: 0.7900390625\n",
      "Batch: 67, Loss: 0.6935300230979919, Accuracy: 0.787109375\n",
      "Batch: 68, Loss: 0.7034350633621216, Accuracy: 0.7734375\n",
      "Batch: 69, Loss: 0.6751366853713989, Accuracy: 0.78515625\n",
      "Batch: 70, Loss: 0.6856578588485718, Accuracy: 0.7822265625\n",
      "Batch: 71, Loss: 0.6648446321487427, Accuracy: 0.7783203125\n",
      "Batch: 72, Loss: 0.6389716863632202, Accuracy: 0.7880859375\n",
      "Batch: 73, Loss: 0.5968288779258728, Accuracy: 0.8134765625\n",
      "Batch: 74, Loss: 0.5754899978637695, Accuracy: 0.81640625\n",
      "Batch: 75, Loss: 0.5505119562149048, Accuracy: 0.814453125\n",
      "Batch: 76, Loss: 0.659622073173523, Accuracy: 0.783203125\n",
      "Batch: 77, Loss: 0.6069092154502869, Accuracy: 0.80078125\n",
      "Batch: 78, Loss: 0.5720783472061157, Accuracy: 0.814453125\n",
      "Batch: 79, Loss: 0.5555742979049683, Accuracy: 0.8291015625\n",
      "Batch: 80, Loss: 0.5795434713363647, Accuracy: 0.80859375\n",
      "Batch: 81, Loss: 0.6718306541442871, Accuracy: 0.7734375\n",
      "Batch: 82, Loss: 0.6129530668258667, Accuracy: 0.8017578125\n",
      "Batch: 83, Loss: 0.5661436319351196, Accuracy: 0.8095703125\n",
      "Batch: 84, Loss: 0.6523112058639526, Accuracy: 0.77734375\n",
      "Batch: 85, Loss: 0.6051716804504395, Accuracy: 0.8212890625\n",
      "Batch: 86, Loss: 0.7622403502464294, Accuracy: 0.7568359375\n",
      "Batch: 87, Loss: 0.5751771330833435, Accuracy: 0.8125\n",
      "Batch: 88, Loss: 0.6692917943000793, Accuracy: 0.7978515625\n",
      "Batch: 89, Loss: 0.6458820700645447, Accuracy: 0.8056640625\n",
      "Batch: 90, Loss: 0.6208456754684448, Accuracy: 0.787109375\n",
      "Batch: 91, Loss: 0.6171461939811707, Accuracy: 0.791015625\n",
      "Batch: 92, Loss: 0.6621354818344116, Accuracy: 0.783203125\n",
      "Batch: 93, Loss: 0.6191130876541138, Accuracy: 0.7958984375\n",
      "Batch: 94, Loss: 0.6613845825195312, Accuracy: 0.7880859375\n",
      "Batch: 95, Loss: 0.6546815037727356, Accuracy: 0.7685546875\n",
      "Batch: 96, Loss: 0.6122556328773499, Accuracy: 0.798828125\n",
      "Batch: 97, Loss: 0.5135939121246338, Accuracy: 0.8349609375\n",
      "Batch: 98, Loss: 0.5959960222244263, Accuracy: 0.796875\n",
      "Batch: 99, Loss: 0.577418327331543, Accuracy: 0.8056640625\n",
      "Batch: 100, Loss: 0.6477882266044617, Accuracy: 0.78515625\n",
      "Batch: 101, Loss: 0.6628727912902832, Accuracy: 0.78515625\n",
      "Batch: 102, Loss: 0.6285327672958374, Accuracy: 0.7978515625\n",
      "Batch: 103, Loss: 0.6370772123336792, Accuracy: 0.787109375\n",
      "Batch: 104, Loss: 0.5788983106613159, Accuracy: 0.806640625\n",
      "Batch: 105, Loss: 0.6261134147644043, Accuracy: 0.7822265625\n",
      "Batch: 106, Loss: 0.5763952732086182, Accuracy: 0.814453125\n",
      "Batch: 107, Loss: 0.632705569267273, Accuracy: 0.798828125\n",
      "Batch: 108, Loss: 0.6394960880279541, Accuracy: 0.80078125\n",
      "Batch: 109, Loss: 0.7073892951011658, Accuracy: 0.76953125\n",
      "Batch: 110, Loss: 0.5471946001052856, Accuracy: 0.8095703125\n",
      "Batch: 111, Loss: 0.6449472904205322, Accuracy: 0.77734375\n",
      "Batch: 112, Loss: 0.6297401785850525, Accuracy: 0.7919921875\n",
      "Batch: 113, Loss: 0.6638103723526001, Accuracy: 0.7900390625\n",
      "Batch: 114, Loss: 0.711675763130188, Accuracy: 0.775390625\n",
      "Batch: 115, Loss: 0.6969035863876343, Accuracy: 0.78125\n",
      "Batch: 116, Loss: 0.6561193466186523, Accuracy: 0.7705078125\n",
      "Batch: 117, Loss: 0.6243704557418823, Accuracy: 0.79296875\n",
      "Batch: 118, Loss: 0.6002507209777832, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.5425694584846497, Accuracy: 0.828125\n",
      "Batch: 120, Loss: 0.6368471384048462, Accuracy: 0.7763671875\n",
      "Batch: 121, Loss: 0.6516257524490356, Accuracy: 0.7919921875\n",
      "Batch: 122, Loss: 0.5710881352424622, Accuracy: 0.8154296875\n",
      "Batch: 123, Loss: 0.5973607897758484, Accuracy: 0.8017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 0.6714451313018799, Accuracy: 0.7802734375\n",
      "Batch: 125, Loss: 0.6465886831283569, Accuracy: 0.7763671875\n",
      "Batch: 126, Loss: 0.6746727824211121, Accuracy: 0.7861328125\n",
      "Batch: 127, Loss: 0.5847075581550598, Accuracy: 0.826171875\n",
      "Batch: 128, Loss: 0.7097853422164917, Accuracy: 0.771484375\n",
      "Batch: 129, Loss: 0.6073578000068665, Accuracy: 0.7978515625\n",
      "Batch: 130, Loss: 0.6998282670974731, Accuracy: 0.79296875\n",
      "Batch: 131, Loss: 0.647109866142273, Accuracy: 0.7861328125\n",
      "Batch: 132, Loss: 0.6277410984039307, Accuracy: 0.79296875\n",
      "Batch: 133, Loss: 0.6465117335319519, Accuracy: 0.7822265625\n",
      "Batch: 134, Loss: 0.6336952447891235, Accuracy: 0.7841796875\n",
      "Batch: 135, Loss: 0.5755820274353027, Accuracy: 0.8056640625\n",
      "Batch: 136, Loss: 0.6711007952690125, Accuracy: 0.7822265625\n",
      "Batch: 137, Loss: 0.6739884614944458, Accuracy: 0.7666015625\n",
      "Batch: 138, Loss: 0.591641902923584, Accuracy: 0.796875\n",
      "Batch: 139, Loss: 0.6730038523674011, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.6228599548339844, Accuracy: 0.7861328125\n",
      "Batch: 141, Loss: 0.6915373802185059, Accuracy: 0.7763671875\n",
      "Batch: 142, Loss: 0.6943546533584595, Accuracy: 0.7724609375\n",
      "Batch: 143, Loss: 0.667017936706543, Accuracy: 0.7822265625\n",
      "Batch: 144, Loss: 0.6781889200210571, Accuracy: 0.7734375\n",
      "Batch: 145, Loss: 0.5803178548812866, Accuracy: 0.8046875\n",
      "Batch: 146, Loss: 0.6612110137939453, Accuracy: 0.77734375\n",
      "Batch: 147, Loss: 0.6320520639419556, Accuracy: 0.7900390625\n",
      "Batch: 148, Loss: 0.7311649322509766, Accuracy: 0.7451171875\n",
      "Batch: 149, Loss: 0.6050837635993958, Accuracy: 0.8046875\n",
      "Batch: 150, Loss: 0.6374452114105225, Accuracy: 0.787109375\n",
      "Batch: 151, Loss: 0.5826483964920044, Accuracy: 0.80859375\n",
      "Epoch 49/80\n",
      "Batch: 1, Loss: 0.8251603841781616, Accuracy: 0.7392578125\n",
      "Batch: 2, Loss: 0.7621786594390869, Accuracy: 0.740234375\n",
      "Batch: 3, Loss: 0.6155952215194702, Accuracy: 0.798828125\n",
      "Batch: 4, Loss: 0.5761311054229736, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6176460981369019, Accuracy: 0.8037109375\n",
      "Batch: 6, Loss: 0.6490703821182251, Accuracy: 0.77734375\n",
      "Batch: 7, Loss: 0.6608688831329346, Accuracy: 0.775390625\n",
      "Batch: 8, Loss: 0.6371636986732483, Accuracy: 0.7861328125\n",
      "Batch: 9, Loss: 0.6330254673957825, Accuracy: 0.7880859375\n",
      "Batch: 10, Loss: 0.6295459270477295, Accuracy: 0.7958984375\n",
      "Batch: 11, Loss: 0.6999464631080627, Accuracy: 0.7763671875\n",
      "Batch: 12, Loss: 0.653792142868042, Accuracy: 0.787109375\n",
      "Batch: 13, Loss: 0.5166553854942322, Accuracy: 0.8310546875\n",
      "Batch: 14, Loss: 0.7248499393463135, Accuracy: 0.7607421875\n",
      "Batch: 15, Loss: 0.5870038270950317, Accuracy: 0.8212890625\n",
      "Batch: 16, Loss: 0.5961631536483765, Accuracy: 0.8134765625\n",
      "Batch: 17, Loss: 0.6604170799255371, Accuracy: 0.78515625\n",
      "Batch: 18, Loss: 0.6637260913848877, Accuracy: 0.787109375\n",
      "Batch: 19, Loss: 0.6784343123435974, Accuracy: 0.7802734375\n",
      "Batch: 20, Loss: 0.557336688041687, Accuracy: 0.8203125\n",
      "Batch: 21, Loss: 0.6441857814788818, Accuracy: 0.783203125\n",
      "Batch: 22, Loss: 0.725142240524292, Accuracy: 0.7705078125\n",
      "Batch: 23, Loss: 0.7129895687103271, Accuracy: 0.7724609375\n",
      "Batch: 24, Loss: 0.6950101852416992, Accuracy: 0.7685546875\n",
      "Batch: 25, Loss: 0.611136794090271, Accuracy: 0.818359375\n",
      "Batch: 26, Loss: 0.5444368720054626, Accuracy: 0.8134765625\n",
      "Batch: 27, Loss: 0.5822343230247498, Accuracy: 0.798828125\n",
      "Batch: 28, Loss: 0.6388524174690247, Accuracy: 0.796875\n",
      "Batch: 29, Loss: 0.5917314887046814, Accuracy: 0.8056640625\n",
      "Batch: 30, Loss: 0.5453121662139893, Accuracy: 0.830078125\n",
      "Batch: 31, Loss: 0.5603578090667725, Accuracy: 0.81640625\n",
      "Batch: 32, Loss: 0.5774388313293457, Accuracy: 0.8134765625\n",
      "Batch: 33, Loss: 0.6339226961135864, Accuracy: 0.8076171875\n",
      "Batch: 34, Loss: 0.7424726486206055, Accuracy: 0.7607421875\n",
      "Batch: 35, Loss: 0.6277023553848267, Accuracy: 0.796875\n",
      "Batch: 36, Loss: 0.6478233337402344, Accuracy: 0.8017578125\n",
      "Batch: 37, Loss: 0.6443946361541748, Accuracy: 0.7890625\n",
      "Batch: 38, Loss: 0.6256529688835144, Accuracy: 0.8046875\n",
      "Batch: 39, Loss: 0.6383411884307861, Accuracy: 0.7958984375\n",
      "Batch: 40, Loss: 0.5940473079681396, Accuracy: 0.7958984375\n",
      "Batch: 41, Loss: 0.5936957001686096, Accuracy: 0.810546875\n",
      "Batch: 42, Loss: 0.4926930069923401, Accuracy: 0.82421875\n",
      "Batch: 43, Loss: 0.62176913022995, Accuracy: 0.7939453125\n",
      "Batch: 44, Loss: 0.575336217880249, Accuracy: 0.8037109375\n",
      "Batch: 45, Loss: 0.5171900987625122, Accuracy: 0.818359375\n",
      "Batch: 46, Loss: 0.5591312646865845, Accuracy: 0.818359375\n",
      "Batch: 47, Loss: 0.5726248621940613, Accuracy: 0.81640625\n",
      "Batch: 48, Loss: 0.5665714740753174, Accuracy: 0.828125\n",
      "Batch: 49, Loss: 0.6369581818580627, Accuracy: 0.7958984375\n",
      "Batch: 50, Loss: 0.6194174885749817, Accuracy: 0.802734375\n",
      "Batch: 51, Loss: 0.6153585314750671, Accuracy: 0.7998046875\n",
      "Batch: 52, Loss: 0.6228433847427368, Accuracy: 0.802734375\n",
      "Batch: 53, Loss: 0.5537960529327393, Accuracy: 0.814453125\n",
      "Batch: 54, Loss: 0.6217617392539978, Accuracy: 0.7919921875\n",
      "Batch: 55, Loss: 0.692456841468811, Accuracy: 0.77734375\n",
      "Batch: 56, Loss: 0.6927567720413208, Accuracy: 0.7705078125\n",
      "Batch: 57, Loss: 0.6376672983169556, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.6976453065872192, Accuracy: 0.771484375\n",
      "Batch: 59, Loss: 0.6192973256111145, Accuracy: 0.7998046875\n",
      "Batch: 60, Loss: 0.5665336847305298, Accuracy: 0.8076171875\n",
      "Batch: 61, Loss: 0.6243453025817871, Accuracy: 0.787109375\n",
      "Batch: 62, Loss: 0.56010901927948, Accuracy: 0.8134765625\n",
      "Batch: 63, Loss: 0.589047372341156, Accuracy: 0.7998046875\n",
      "Batch: 64, Loss: 0.6233950853347778, Accuracy: 0.7919921875\n",
      "Batch: 65, Loss: 0.6195721626281738, Accuracy: 0.798828125\n",
      "Batch: 66, Loss: 0.6295972466468811, Accuracy: 0.8056640625\n",
      "Batch: 67, Loss: 0.6659879684448242, Accuracy: 0.765625\n",
      "Batch: 68, Loss: 0.6950741410255432, Accuracy: 0.7919921875\n",
      "Batch: 69, Loss: 0.6616348028182983, Accuracy: 0.78125\n",
      "Batch: 70, Loss: 0.6586633920669556, Accuracy: 0.7890625\n",
      "Batch: 71, Loss: 0.6624757051467896, Accuracy: 0.783203125\n",
      "Batch: 72, Loss: 0.5932641625404358, Accuracy: 0.8037109375\n",
      "Batch: 73, Loss: 0.5602808594703674, Accuracy: 0.82421875\n",
      "Batch: 74, Loss: 0.5328348278999329, Accuracy: 0.82421875\n",
      "Batch: 75, Loss: 0.5239120721817017, Accuracy: 0.830078125\n",
      "Batch: 76, Loss: 0.6588432788848877, Accuracy: 0.775390625\n",
      "Batch: 77, Loss: 0.6049365997314453, Accuracy: 0.8017578125\n",
      "Batch: 78, Loss: 0.5745431184768677, Accuracy: 0.826171875\n",
      "Batch: 79, Loss: 0.5682109594345093, Accuracy: 0.8193359375\n",
      "Batch: 80, Loss: 0.5852669477462769, Accuracy: 0.81640625\n",
      "Batch: 81, Loss: 0.6903717517852783, Accuracy: 0.7529296875\n",
      "Batch: 82, Loss: 0.6337058544158936, Accuracy: 0.7978515625\n",
      "Batch: 83, Loss: 0.5617170929908752, Accuracy: 0.8193359375\n",
      "Batch: 84, Loss: 0.643565833568573, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.6235421895980835, Accuracy: 0.798828125\n",
      "Batch: 86, Loss: 0.7284586429595947, Accuracy: 0.771484375\n",
      "Batch: 87, Loss: 0.5852484703063965, Accuracy: 0.8212890625\n",
      "Batch: 88, Loss: 0.6779268383979797, Accuracy: 0.794921875\n",
      "Batch: 89, Loss: 0.6562442779541016, Accuracy: 0.80859375\n",
      "Batch: 90, Loss: 0.621062695980072, Accuracy: 0.8076171875\n",
      "Batch: 91, Loss: 0.6099517345428467, Accuracy: 0.79296875\n",
      "Batch: 92, Loss: 0.6297858953475952, Accuracy: 0.8125\n",
      "Batch: 93, Loss: 0.6094403266906738, Accuracy: 0.8037109375\n",
      "Batch: 94, Loss: 0.6420495510101318, Accuracy: 0.78515625\n",
      "Batch: 95, Loss: 0.6398046016693115, Accuracy: 0.7978515625\n",
      "Batch: 96, Loss: 0.5998960733413696, Accuracy: 0.8125\n",
      "Batch: 97, Loss: 0.5110676884651184, Accuracy: 0.833984375\n",
      "Batch: 98, Loss: 0.5899502635002136, Accuracy: 0.8037109375\n",
      "Batch: 99, Loss: 0.5702941417694092, Accuracy: 0.806640625\n",
      "Batch: 100, Loss: 0.6291401386260986, Accuracy: 0.794921875\n",
      "Batch: 101, Loss: 0.6727721691131592, Accuracy: 0.7783203125\n",
      "Batch: 102, Loss: 0.619512677192688, Accuracy: 0.80859375\n",
      "Batch: 103, Loss: 0.6634407043457031, Accuracy: 0.7890625\n",
      "Batch: 104, Loss: 0.6029545068740845, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.6530552506446838, Accuracy: 0.7734375\n",
      "Batch: 106, Loss: 0.5481569170951843, Accuracy: 0.8173828125\n",
      "Batch: 107, Loss: 0.5614213347434998, Accuracy: 0.8310546875\n",
      "Batch: 108, Loss: 0.6082005500793457, Accuracy: 0.7978515625\n",
      "Batch: 109, Loss: 0.6685431003570557, Accuracy: 0.787109375\n",
      "Batch: 110, Loss: 0.5532569885253906, Accuracy: 0.80078125\n",
      "Batch: 111, Loss: 0.6289668083190918, Accuracy: 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 0.6314648389816284, Accuracy: 0.8056640625\n",
      "Batch: 113, Loss: 0.6232489347457886, Accuracy: 0.796875\n",
      "Batch: 114, Loss: 0.7179849147796631, Accuracy: 0.765625\n",
      "Batch: 115, Loss: 0.68321692943573, Accuracy: 0.7802734375\n",
      "Batch: 116, Loss: 0.6206095814704895, Accuracy: 0.7978515625\n",
      "Batch: 117, Loss: 0.6633907556533813, Accuracy: 0.7880859375\n",
      "Batch: 118, Loss: 0.5687602758407593, Accuracy: 0.818359375\n",
      "Batch: 119, Loss: 0.5486335754394531, Accuracy: 0.81640625\n",
      "Batch: 120, Loss: 0.591398298740387, Accuracy: 0.8037109375\n",
      "Batch: 121, Loss: 0.6851980686187744, Accuracy: 0.7880859375\n",
      "Batch: 122, Loss: 0.614265501499176, Accuracy: 0.80078125\n",
      "Batch: 123, Loss: 0.5635335445404053, Accuracy: 0.818359375\n",
      "Batch: 124, Loss: 0.6535212993621826, Accuracy: 0.7861328125\n",
      "Batch: 125, Loss: 0.6484241485595703, Accuracy: 0.7900390625\n",
      "Batch: 126, Loss: 0.6677799224853516, Accuracy: 0.7880859375\n",
      "Batch: 127, Loss: 0.5878793597221375, Accuracy: 0.806640625\n",
      "Batch: 128, Loss: 0.6700611710548401, Accuracy: 0.7900390625\n",
      "Batch: 129, Loss: 0.5773183107376099, Accuracy: 0.8076171875\n",
      "Batch: 130, Loss: 0.6749213337898254, Accuracy: 0.7880859375\n",
      "Batch: 131, Loss: 0.6247040033340454, Accuracy: 0.796875\n",
      "Batch: 132, Loss: 0.6673269867897034, Accuracy: 0.7880859375\n",
      "Batch: 133, Loss: 0.6194604635238647, Accuracy: 0.7890625\n",
      "Batch: 134, Loss: 0.6501230001449585, Accuracy: 0.7705078125\n",
      "Batch: 135, Loss: 0.5795178413391113, Accuracy: 0.8095703125\n",
      "Batch: 136, Loss: 0.6484568119049072, Accuracy: 0.794921875\n",
      "Batch: 137, Loss: 0.6586862802505493, Accuracy: 0.7685546875\n",
      "Batch: 138, Loss: 0.5450814366340637, Accuracy: 0.8203125\n",
      "Batch: 139, Loss: 0.6521705389022827, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.6442274451255798, Accuracy: 0.787109375\n",
      "Batch: 141, Loss: 0.692810595035553, Accuracy: 0.7724609375\n",
      "Batch: 142, Loss: 0.6694163084030151, Accuracy: 0.765625\n",
      "Batch: 143, Loss: 0.6620610952377319, Accuracy: 0.787109375\n",
      "Batch: 144, Loss: 0.6787468194961548, Accuracy: 0.78515625\n",
      "Batch: 145, Loss: 0.6151180267333984, Accuracy: 0.79296875\n",
      "Batch: 146, Loss: 0.6347964406013489, Accuracy: 0.7939453125\n",
      "Batch: 147, Loss: 0.6046462059020996, Accuracy: 0.8115234375\n",
      "Batch: 148, Loss: 0.7416646480560303, Accuracy: 0.74609375\n",
      "Batch: 149, Loss: 0.6002564430236816, Accuracy: 0.8134765625\n",
      "Batch: 150, Loss: 0.6198386549949646, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.5699362754821777, Accuracy: 0.814453125\n",
      "Epoch 50/80\n",
      "Batch: 1, Loss: 0.8195598125457764, Accuracy: 0.7353515625\n",
      "Batch: 2, Loss: 0.6956959366798401, Accuracy: 0.7685546875\n",
      "Batch: 3, Loss: 0.6242760419845581, Accuracy: 0.798828125\n",
      "Batch: 4, Loss: 0.5610849857330322, Accuracy: 0.8125\n",
      "Batch: 5, Loss: 0.6066314578056335, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.6053242087364197, Accuracy: 0.8056640625\n",
      "Batch: 7, Loss: 0.6187963485717773, Accuracy: 0.7958984375\n",
      "Batch: 8, Loss: 0.6082451343536377, Accuracy: 0.7880859375\n",
      "Batch: 9, Loss: 0.6275037527084351, Accuracy: 0.796875\n",
      "Batch: 10, Loss: 0.636330246925354, Accuracy: 0.78515625\n",
      "Batch: 11, Loss: 0.6938439011573792, Accuracy: 0.7724609375\n",
      "Batch: 12, Loss: 0.6910319328308105, Accuracy: 0.767578125\n",
      "Batch: 13, Loss: 0.5179418325424194, Accuracy: 0.8359375\n",
      "Batch: 14, Loss: 0.6712354421615601, Accuracy: 0.7802734375\n",
      "Batch: 15, Loss: 0.5531930923461914, Accuracy: 0.8232421875\n",
      "Batch: 16, Loss: 0.5882207155227661, Accuracy: 0.833984375\n",
      "Batch: 17, Loss: 0.646327018737793, Accuracy: 0.7919921875\n",
      "Batch: 18, Loss: 0.6648352146148682, Accuracy: 0.7890625\n",
      "Batch: 19, Loss: 0.6646318435668945, Accuracy: 0.7958984375\n",
      "Batch: 20, Loss: 0.5640332698822021, Accuracy: 0.818359375\n",
      "Batch: 21, Loss: 0.6012764573097229, Accuracy: 0.8154296875\n",
      "Batch: 22, Loss: 0.7267118692398071, Accuracy: 0.787109375\n",
      "Batch: 23, Loss: 0.6949610710144043, Accuracy: 0.7685546875\n",
      "Batch: 24, Loss: 0.6712722182273865, Accuracy: 0.7880859375\n",
      "Batch: 25, Loss: 0.6289211511611938, Accuracy: 0.7998046875\n",
      "Batch: 26, Loss: 0.5502344369888306, Accuracy: 0.8193359375\n",
      "Batch: 27, Loss: 0.597116231918335, Accuracy: 0.7958984375\n",
      "Batch: 28, Loss: 0.6248361468315125, Accuracy: 0.791015625\n",
      "Batch: 29, Loss: 0.5829155445098877, Accuracy: 0.80859375\n",
      "Batch: 30, Loss: 0.5257527232170105, Accuracy: 0.833984375\n",
      "Batch: 31, Loss: 0.5396660566329956, Accuracy: 0.8095703125\n",
      "Batch: 32, Loss: 0.5724644660949707, Accuracy: 0.822265625\n",
      "Batch: 33, Loss: 0.6692932844161987, Accuracy: 0.7822265625\n",
      "Batch: 34, Loss: 0.6817020177841187, Accuracy: 0.7783203125\n",
      "Batch: 35, Loss: 0.6301544904708862, Accuracy: 0.7822265625\n",
      "Batch: 36, Loss: 0.6101165413856506, Accuracy: 0.8046875\n",
      "Batch: 37, Loss: 0.6264685988426208, Accuracy: 0.7880859375\n",
      "Batch: 38, Loss: 0.6156506538391113, Accuracy: 0.796875\n",
      "Batch: 39, Loss: 0.6595412492752075, Accuracy: 0.7822265625\n",
      "Batch: 40, Loss: 0.60819411277771, Accuracy: 0.8056640625\n",
      "Batch: 41, Loss: 0.5648291110992432, Accuracy: 0.82421875\n",
      "Batch: 42, Loss: 0.48054587841033936, Accuracy: 0.830078125\n",
      "Batch: 43, Loss: 0.5931016206741333, Accuracy: 0.80078125\n",
      "Batch: 44, Loss: 0.6109249591827393, Accuracy: 0.7998046875\n",
      "Batch: 45, Loss: 0.5568660497665405, Accuracy: 0.8154296875\n",
      "Batch: 46, Loss: 0.5803366899490356, Accuracy: 0.8212890625\n",
      "Batch: 47, Loss: 0.5643438696861267, Accuracy: 0.822265625\n",
      "Batch: 48, Loss: 0.542889416217804, Accuracy: 0.8251953125\n",
      "Batch: 49, Loss: 0.5975728631019592, Accuracy: 0.8291015625\n",
      "Batch: 50, Loss: 0.6151313781738281, Accuracy: 0.802734375\n",
      "Batch: 51, Loss: 0.6058728694915771, Accuracy: 0.8037109375\n",
      "Batch: 52, Loss: 0.6242849230766296, Accuracy: 0.8017578125\n",
      "Batch: 53, Loss: 0.5499429702758789, Accuracy: 0.8212890625\n",
      "Batch: 54, Loss: 0.6120879650115967, Accuracy: 0.7978515625\n",
      "Batch: 55, Loss: 0.674102783203125, Accuracy: 0.7666015625\n",
      "Batch: 56, Loss: 0.6390243172645569, Accuracy: 0.8017578125\n",
      "Batch: 57, Loss: 0.6225986480712891, Accuracy: 0.814453125\n",
      "Batch: 58, Loss: 0.6896829605102539, Accuracy: 0.7900390625\n",
      "Batch: 59, Loss: 0.5774881839752197, Accuracy: 0.8017578125\n",
      "Batch: 60, Loss: 0.5801734328269958, Accuracy: 0.8076171875\n",
      "Batch: 61, Loss: 0.6316234469413757, Accuracy: 0.7880859375\n",
      "Batch: 62, Loss: 0.5521629452705383, Accuracy: 0.8154296875\n",
      "Batch: 63, Loss: 0.6148698925971985, Accuracy: 0.7958984375\n",
      "Batch: 64, Loss: 0.5851920247077942, Accuracy: 0.8095703125\n",
      "Batch: 65, Loss: 0.6179295182228088, Accuracy: 0.798828125\n",
      "Batch: 66, Loss: 0.6196980476379395, Accuracy: 0.7900390625\n",
      "Batch: 67, Loss: 0.6863060593605042, Accuracy: 0.78515625\n",
      "Batch: 68, Loss: 0.7057872414588928, Accuracy: 0.7724609375\n",
      "Batch: 69, Loss: 0.6671205759048462, Accuracy: 0.78125\n",
      "Batch: 70, Loss: 0.6331238150596619, Accuracy: 0.8056640625\n",
      "Batch: 71, Loss: 0.6546090841293335, Accuracy: 0.775390625\n",
      "Batch: 72, Loss: 0.576048731803894, Accuracy: 0.810546875\n",
      "Batch: 73, Loss: 0.5660364627838135, Accuracy: 0.8203125\n",
      "Batch: 74, Loss: 0.5001682043075562, Accuracy: 0.837890625\n",
      "Batch: 75, Loss: 0.5460373163223267, Accuracy: 0.826171875\n",
      "Batch: 76, Loss: 0.6201332807540894, Accuracy: 0.791015625\n",
      "Batch: 77, Loss: 0.5655865669250488, Accuracy: 0.8173828125\n",
      "Batch: 78, Loss: 0.5688591003417969, Accuracy: 0.8134765625\n",
      "Batch: 79, Loss: 0.5360966920852661, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.5799627304077148, Accuracy: 0.802734375\n",
      "Batch: 81, Loss: 0.6707876920700073, Accuracy: 0.763671875\n",
      "Batch: 82, Loss: 0.620165228843689, Accuracy: 0.794921875\n",
      "Batch: 83, Loss: 0.5342941284179688, Accuracy: 0.818359375\n",
      "Batch: 84, Loss: 0.602230966091156, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.6259219646453857, Accuracy: 0.7958984375\n",
      "Batch: 86, Loss: 0.7304961681365967, Accuracy: 0.779296875\n",
      "Batch: 87, Loss: 0.5597172379493713, Accuracy: 0.828125\n",
      "Batch: 88, Loss: 0.6377542018890381, Accuracy: 0.810546875\n",
      "Batch: 89, Loss: 0.6541689038276672, Accuracy: 0.794921875\n",
      "Batch: 90, Loss: 0.6284984350204468, Accuracy: 0.80859375\n",
      "Batch: 91, Loss: 0.6008031964302063, Accuracy: 0.802734375\n",
      "Batch: 92, Loss: 0.645514726638794, Accuracy: 0.7880859375\n",
      "Batch: 93, Loss: 0.5785854458808899, Accuracy: 0.8056640625\n",
      "Batch: 94, Loss: 0.6230701208114624, Accuracy: 0.7919921875\n",
      "Batch: 95, Loss: 0.6241509914398193, Accuracy: 0.787109375\n",
      "Batch: 96, Loss: 0.5799890756607056, Accuracy: 0.814453125\n",
      "Batch: 97, Loss: 0.4931427836418152, Accuracy: 0.833984375\n",
      "Batch: 98, Loss: 0.585564374923706, Accuracy: 0.7939453125\n",
      "Batch: 99, Loss: 0.5677505731582642, Accuracy: 0.80859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.6266031861305237, Accuracy: 0.7890625\n",
      "Batch: 101, Loss: 0.6275969743728638, Accuracy: 0.7841796875\n",
      "Batch: 102, Loss: 0.6157554388046265, Accuracy: 0.8017578125\n",
      "Batch: 103, Loss: 0.6299539804458618, Accuracy: 0.8037109375\n",
      "Batch: 104, Loss: 0.571358323097229, Accuracy: 0.8134765625\n",
      "Batch: 105, Loss: 0.6523251533508301, Accuracy: 0.7919921875\n",
      "Batch: 106, Loss: 0.5525486469268799, Accuracy: 0.8251953125\n",
      "Batch: 107, Loss: 0.6086905598640442, Accuracy: 0.80078125\n",
      "Batch: 108, Loss: 0.5996708869934082, Accuracy: 0.794921875\n",
      "Batch: 109, Loss: 0.7021799683570862, Accuracy: 0.78515625\n",
      "Batch: 110, Loss: 0.5616058111190796, Accuracy: 0.8173828125\n",
      "Batch: 111, Loss: 0.594417929649353, Accuracy: 0.80078125\n",
      "Batch: 112, Loss: 0.6473509669303894, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6212306022644043, Accuracy: 0.8056640625\n",
      "Batch: 114, Loss: 0.6877556443214417, Accuracy: 0.775390625\n",
      "Batch: 115, Loss: 0.6653433442115784, Accuracy: 0.791015625\n",
      "Batch: 116, Loss: 0.6445966362953186, Accuracy: 0.783203125\n",
      "Batch: 117, Loss: 0.6240791082382202, Accuracy: 0.8125\n",
      "Batch: 118, Loss: 0.5594112873077393, Accuracy: 0.8291015625\n",
      "Batch: 119, Loss: 0.5157130360603333, Accuracy: 0.8359375\n",
      "Batch: 120, Loss: 0.5934505462646484, Accuracy: 0.8037109375\n",
      "Batch: 121, Loss: 0.6514161825180054, Accuracy: 0.798828125\n",
      "Batch: 122, Loss: 0.5393601655960083, Accuracy: 0.82421875\n",
      "Batch: 123, Loss: 0.5345074534416199, Accuracy: 0.8388671875\n",
      "Batch: 124, Loss: 0.6320778131484985, Accuracy: 0.7939453125\n",
      "Batch: 125, Loss: 0.644450306892395, Accuracy: 0.7880859375\n",
      "Batch: 126, Loss: 0.635076642036438, Accuracy: 0.8076171875\n",
      "Batch: 127, Loss: 0.5748557448387146, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.7017539143562317, Accuracy: 0.775390625\n",
      "Batch: 129, Loss: 0.6040387153625488, Accuracy: 0.798828125\n",
      "Batch: 130, Loss: 0.6602113246917725, Accuracy: 0.79296875\n",
      "Batch: 131, Loss: 0.6180791854858398, Accuracy: 0.7919921875\n",
      "Batch: 132, Loss: 0.6223247051239014, Accuracy: 0.80859375\n",
      "Batch: 133, Loss: 0.5896657109260559, Accuracy: 0.79296875\n",
      "Batch: 134, Loss: 0.6350349187850952, Accuracy: 0.7880859375\n",
      "Batch: 135, Loss: 0.5480440855026245, Accuracy: 0.8193359375\n",
      "Batch: 136, Loss: 0.641320526599884, Accuracy: 0.7861328125\n",
      "Batch: 137, Loss: 0.6566510200500488, Accuracy: 0.771484375\n",
      "Batch: 138, Loss: 0.5491916537284851, Accuracy: 0.8154296875\n",
      "Batch: 139, Loss: 0.6732665300369263, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.6062105894088745, Accuracy: 0.8017578125\n",
      "Batch: 141, Loss: 0.6785385012626648, Accuracy: 0.779296875\n",
      "Batch: 142, Loss: 0.6724228858947754, Accuracy: 0.7783203125\n",
      "Batch: 143, Loss: 0.6215284466743469, Accuracy: 0.794921875\n",
      "Batch: 144, Loss: 0.6423845291137695, Accuracy: 0.7939453125\n",
      "Batch: 145, Loss: 0.5753593444824219, Accuracy: 0.8056640625\n",
      "Batch: 146, Loss: 0.6271269917488098, Accuracy: 0.798828125\n",
      "Batch: 147, Loss: 0.5993059873580933, Accuracy: 0.806640625\n",
      "Batch: 148, Loss: 0.7148308157920837, Accuracy: 0.7705078125\n",
      "Batch: 149, Loss: 0.5899274349212646, Accuracy: 0.8193359375\n",
      "Batch: 150, Loss: 0.6006909608840942, Accuracy: 0.80078125\n",
      "Batch: 151, Loss: 0.5668033361434937, Accuracy: 0.8115234375\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/80\n",
      "Batch: 1, Loss: 0.7943309545516968, Accuracy: 0.7509765625\n",
      "Batch: 2, Loss: 0.7077493667602539, Accuracy: 0.7685546875\n",
      "Batch: 3, Loss: 0.616875410079956, Accuracy: 0.796875\n",
      "Batch: 4, Loss: 0.5582828521728516, Accuracy: 0.8330078125\n",
      "Batch: 5, Loss: 0.5849272012710571, Accuracy: 0.8173828125\n",
      "Batch: 6, Loss: 0.6147034168243408, Accuracy: 0.7978515625\n",
      "Batch: 7, Loss: 0.6146740913391113, Accuracy: 0.79296875\n",
      "Batch: 8, Loss: 0.6149342060089111, Accuracy: 0.7958984375\n",
      "Batch: 9, Loss: 0.5890843868255615, Accuracy: 0.8095703125\n",
      "Batch: 10, Loss: 0.58365797996521, Accuracy: 0.7978515625\n",
      "Batch: 11, Loss: 0.6930186152458191, Accuracy: 0.775390625\n",
      "Batch: 12, Loss: 0.6361045837402344, Accuracy: 0.7978515625\n",
      "Batch: 13, Loss: 0.4920305609703064, Accuracy: 0.84375\n",
      "Batch: 14, Loss: 0.6836007833480835, Accuracy: 0.7802734375\n",
      "Batch: 15, Loss: 0.5357002019882202, Accuracy: 0.826171875\n",
      "Batch: 16, Loss: 0.5981090068817139, Accuracy: 0.82421875\n",
      "Batch: 17, Loss: 0.5931925773620605, Accuracy: 0.8203125\n",
      "Batch: 18, Loss: 0.6724329590797424, Accuracy: 0.796875\n",
      "Batch: 19, Loss: 0.6779301762580872, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.5902310609817505, Accuracy: 0.8095703125\n",
      "Batch: 21, Loss: 0.6330242156982422, Accuracy: 0.78125\n",
      "Batch: 22, Loss: 0.700263500213623, Accuracy: 0.77734375\n",
      "Batch: 23, Loss: 0.6656111478805542, Accuracy: 0.771484375\n",
      "Batch: 24, Loss: 0.6698558330535889, Accuracy: 0.7841796875\n",
      "Batch: 25, Loss: 0.6137343049049377, Accuracy: 0.7978515625\n",
      "Batch: 26, Loss: 0.538684606552124, Accuracy: 0.81640625\n",
      "Batch: 27, Loss: 0.5717900395393372, Accuracy: 0.8017578125\n",
      "Batch: 28, Loss: 0.6187849640846252, Accuracy: 0.8037109375\n",
      "Batch: 29, Loss: 0.5697686672210693, Accuracy: 0.82421875\n",
      "Batch: 30, Loss: 0.5253181457519531, Accuracy: 0.828125\n",
      "Batch: 31, Loss: 0.5534759163856506, Accuracy: 0.8193359375\n",
      "Batch: 32, Loss: 0.5622419714927673, Accuracy: 0.814453125\n",
      "Batch: 33, Loss: 0.645679235458374, Accuracy: 0.79296875\n",
      "Batch: 34, Loss: 0.732176661491394, Accuracy: 0.771484375\n",
      "Batch: 35, Loss: 0.6314634680747986, Accuracy: 0.7861328125\n",
      "Batch: 36, Loss: 0.6199553608894348, Accuracy: 0.8115234375\n",
      "Batch: 37, Loss: 0.6394447088241577, Accuracy: 0.7861328125\n",
      "Batch: 38, Loss: 0.6493504047393799, Accuracy: 0.7880859375\n",
      "Batch: 39, Loss: 0.6557084321975708, Accuracy: 0.78515625\n",
      "Batch: 40, Loss: 0.6028933525085449, Accuracy: 0.80078125\n",
      "Batch: 41, Loss: 0.5701041221618652, Accuracy: 0.818359375\n",
      "Batch: 42, Loss: 0.48636358976364136, Accuracy: 0.8203125\n",
      "Batch: 43, Loss: 0.6057966351509094, Accuracy: 0.7919921875\n",
      "Batch: 44, Loss: 0.6027340888977051, Accuracy: 0.80859375\n",
      "Batch: 45, Loss: 0.5060125589370728, Accuracy: 0.822265625\n",
      "Batch: 46, Loss: 0.5753375291824341, Accuracy: 0.814453125\n",
      "Batch: 47, Loss: 0.5446513891220093, Accuracy: 0.83203125\n",
      "Batch: 48, Loss: 0.5362250804901123, Accuracy: 0.8251953125\n",
      "Batch: 49, Loss: 0.6154340505599976, Accuracy: 0.8095703125\n",
      "Batch: 50, Loss: 0.6297523975372314, Accuracy: 0.7841796875\n",
      "Batch: 51, Loss: 0.6026932597160339, Accuracy: 0.80859375\n",
      "Batch: 52, Loss: 0.5921010971069336, Accuracy: 0.814453125\n",
      "Batch: 53, Loss: 0.5635096430778503, Accuracy: 0.806640625\n",
      "Batch: 54, Loss: 0.6043161749839783, Accuracy: 0.80078125\n",
      "Batch: 55, Loss: 0.6737172603607178, Accuracy: 0.7841796875\n",
      "Batch: 56, Loss: 0.6639747023582458, Accuracy: 0.787109375\n",
      "Batch: 57, Loss: 0.6337646245956421, Accuracy: 0.77734375\n",
      "Batch: 58, Loss: 0.651700496673584, Accuracy: 0.791015625\n",
      "Batch: 59, Loss: 0.5837123394012451, Accuracy: 0.8046875\n",
      "Batch: 60, Loss: 0.5594195127487183, Accuracy: 0.80078125\n",
      "Batch: 61, Loss: 0.6500459313392639, Accuracy: 0.78125\n",
      "Batch: 62, Loss: 0.5402726531028748, Accuracy: 0.8193359375\n",
      "Batch: 63, Loss: 0.607541024684906, Accuracy: 0.8056640625\n",
      "Batch: 64, Loss: 0.5990302562713623, Accuracy: 0.8037109375\n",
      "Batch: 65, Loss: 0.6491843461990356, Accuracy: 0.7939453125\n",
      "Batch: 66, Loss: 0.6164314150810242, Accuracy: 0.8056640625\n",
      "Batch: 67, Loss: 0.6685557961463928, Accuracy: 0.7900390625\n",
      "Batch: 68, Loss: 0.712245762348175, Accuracy: 0.7666015625\n",
      "Batch: 69, Loss: 0.6314078569412231, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.6276660561561584, Accuracy: 0.8095703125\n",
      "Batch: 71, Loss: 0.6608842611312866, Accuracy: 0.765625\n",
      "Batch: 72, Loss: 0.5615330934524536, Accuracy: 0.814453125\n",
      "Batch: 73, Loss: 0.5307379961013794, Accuracy: 0.8203125\n",
      "Batch: 74, Loss: 0.5292301177978516, Accuracy: 0.82421875\n",
      "Batch: 75, Loss: 0.5228132605552673, Accuracy: 0.8349609375\n",
      "Batch: 76, Loss: 0.6296771168708801, Accuracy: 0.7880859375\n",
      "Batch: 77, Loss: 0.5847039222717285, Accuracy: 0.81640625\n",
      "Batch: 78, Loss: 0.5412126779556274, Accuracy: 0.8251953125\n",
      "Batch: 79, Loss: 0.5364238023757935, Accuracy: 0.82421875\n",
      "Batch: 80, Loss: 0.6152088642120361, Accuracy: 0.7919921875\n",
      "Batch: 81, Loss: 0.6568844318389893, Accuracy: 0.767578125\n",
      "Batch: 82, Loss: 0.5967774391174316, Accuracy: 0.80078125\n",
      "Batch: 83, Loss: 0.4722534418106079, Accuracy: 0.8388671875\n",
      "Batch: 84, Loss: 0.6343193054199219, Accuracy: 0.79296875\n",
      "Batch: 85, Loss: 0.6017563343048096, Accuracy: 0.826171875\n",
      "Batch: 86, Loss: 0.7038718461990356, Accuracy: 0.7822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 87, Loss: 0.5656802654266357, Accuracy: 0.818359375\n",
      "Batch: 88, Loss: 0.6798450350761414, Accuracy: 0.78515625\n",
      "Batch: 89, Loss: 0.649479866027832, Accuracy: 0.7978515625\n",
      "Batch: 90, Loss: 0.6155015230178833, Accuracy: 0.8076171875\n",
      "Batch: 91, Loss: 0.5775591135025024, Accuracy: 0.814453125\n",
      "Batch: 92, Loss: 0.6230682134628296, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.5749305486679077, Accuracy: 0.814453125\n",
      "Batch: 94, Loss: 0.5894489288330078, Accuracy: 0.8125\n",
      "Batch: 95, Loss: 0.6234798431396484, Accuracy: 0.7880859375\n",
      "Batch: 96, Loss: 0.6207599639892578, Accuracy: 0.796875\n",
      "Batch: 97, Loss: 0.48561370372772217, Accuracy: 0.83984375\n",
      "Batch: 98, Loss: 0.6206878423690796, Accuracy: 0.79296875\n",
      "Batch: 99, Loss: 0.5602207183837891, Accuracy: 0.8125\n",
      "Batch: 100, Loss: 0.6148306131362915, Accuracy: 0.79296875\n",
      "Batch: 101, Loss: 0.648282527923584, Accuracy: 0.7900390625\n",
      "Batch: 102, Loss: 0.6115165948867798, Accuracy: 0.7978515625\n",
      "Batch: 103, Loss: 0.6240036487579346, Accuracy: 0.7958984375\n",
      "Batch: 104, Loss: 0.57364821434021, Accuracy: 0.80078125\n",
      "Batch: 105, Loss: 0.6410796642303467, Accuracy: 0.7939453125\n",
      "Batch: 106, Loss: 0.5750853419303894, Accuracy: 0.826171875\n",
      "Batch: 107, Loss: 0.6079373359680176, Accuracy: 0.8134765625\n",
      "Batch: 108, Loss: 0.5973701477050781, Accuracy: 0.796875\n",
      "Batch: 109, Loss: 0.6781496405601501, Accuracy: 0.7861328125\n",
      "Batch: 110, Loss: 0.5298066139221191, Accuracy: 0.828125\n",
      "Batch: 111, Loss: 0.6137503981590271, Accuracy: 0.7998046875\n",
      "Batch: 112, Loss: 0.612572431564331, Accuracy: 0.8076171875\n",
      "Batch: 113, Loss: 0.6125097274780273, Accuracy: 0.8134765625\n",
      "Batch: 114, Loss: 0.6836506128311157, Accuracy: 0.775390625\n",
      "Batch: 115, Loss: 0.6688867807388306, Accuracy: 0.7890625\n",
      "Batch: 116, Loss: 0.6032266020774841, Accuracy: 0.8212890625\n",
      "Batch: 117, Loss: 0.6414863467216492, Accuracy: 0.7919921875\n",
      "Batch: 118, Loss: 0.5722872018814087, Accuracy: 0.8212890625\n",
      "Batch: 119, Loss: 0.539327085018158, Accuracy: 0.83203125\n",
      "Batch: 120, Loss: 0.6278842687606812, Accuracy: 0.7763671875\n",
      "Batch: 121, Loss: 0.6619430780410767, Accuracy: 0.79296875\n",
      "Batch: 122, Loss: 0.5747710466384888, Accuracy: 0.806640625\n",
      "Batch: 123, Loss: 0.5544701814651489, Accuracy: 0.8076171875\n",
      "Batch: 124, Loss: 0.6367360949516296, Accuracy: 0.796875\n",
      "Batch: 125, Loss: 0.6450495719909668, Accuracy: 0.7861328125\n",
      "Batch: 126, Loss: 0.6505047082901001, Accuracy: 0.7978515625\n",
      "Batch: 127, Loss: 0.5612167119979858, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.7003328800201416, Accuracy: 0.7763671875\n",
      "Batch: 129, Loss: 0.5700911283493042, Accuracy: 0.8095703125\n",
      "Batch: 130, Loss: 0.6539560556411743, Accuracy: 0.7841796875\n",
      "Batch: 131, Loss: 0.6294533610343933, Accuracy: 0.7900390625\n",
      "Batch: 132, Loss: 0.6304059028625488, Accuracy: 0.7822265625\n",
      "Batch: 133, Loss: 0.6109731197357178, Accuracy: 0.8017578125\n",
      "Batch: 134, Loss: 0.6060415506362915, Accuracy: 0.8037109375\n",
      "Batch: 135, Loss: 0.5953365564346313, Accuracy: 0.806640625\n",
      "Batch: 136, Loss: 0.6510398983955383, Accuracy: 0.7861328125\n",
      "Batch: 137, Loss: 0.6156362295150757, Accuracy: 0.7919921875\n",
      "Batch: 138, Loss: 0.5689023733139038, Accuracy: 0.8212890625\n",
      "Batch: 139, Loss: 0.6234159469604492, Accuracy: 0.8076171875\n",
      "Batch: 140, Loss: 0.5991936326026917, Accuracy: 0.8056640625\n",
      "Batch: 141, Loss: 0.6779183149337769, Accuracy: 0.7822265625\n",
      "Batch: 142, Loss: 0.6554578542709351, Accuracy: 0.7841796875\n",
      "Batch: 143, Loss: 0.6292146444320679, Accuracy: 0.7958984375\n",
      "Batch: 144, Loss: 0.626692533493042, Accuracy: 0.79296875\n",
      "Batch: 145, Loss: 0.5565603971481323, Accuracy: 0.8046875\n",
      "Batch: 146, Loss: 0.6199851036071777, Accuracy: 0.796875\n",
      "Batch: 147, Loss: 0.6255074739456177, Accuracy: 0.802734375\n",
      "Batch: 148, Loss: 0.716995358467102, Accuracy: 0.7685546875\n",
      "Batch: 149, Loss: 0.5695909857749939, Accuracy: 0.8154296875\n",
      "Batch: 150, Loss: 0.6144325137138367, Accuracy: 0.7978515625\n",
      "Batch: 151, Loss: 0.5374009013175964, Accuracy: 0.8212890625\n",
      "Epoch 52/80\n",
      "Batch: 1, Loss: 0.8050307035446167, Accuracy: 0.7490234375\n",
      "Batch: 2, Loss: 0.7423401474952698, Accuracy: 0.75\n",
      "Batch: 3, Loss: 0.6194512248039246, Accuracy: 0.787109375\n",
      "Batch: 4, Loss: 0.5909093022346497, Accuracy: 0.8115234375\n",
      "Batch: 5, Loss: 0.598426342010498, Accuracy: 0.798828125\n",
      "Batch: 6, Loss: 0.605516791343689, Accuracy: 0.8017578125\n",
      "Batch: 7, Loss: 0.6288700103759766, Accuracy: 0.78515625\n",
      "Batch: 8, Loss: 0.5816149711608887, Accuracy: 0.802734375\n",
      "Batch: 9, Loss: 0.5927168726921082, Accuracy: 0.8037109375\n",
      "Batch: 10, Loss: 0.5942608118057251, Accuracy: 0.8056640625\n",
      "Batch: 11, Loss: 0.645403265953064, Accuracy: 0.7734375\n",
      "Batch: 12, Loss: 0.6222138404846191, Accuracy: 0.80078125\n",
      "Batch: 13, Loss: 0.5055989623069763, Accuracy: 0.8388671875\n",
      "Batch: 14, Loss: 0.651168704032898, Accuracy: 0.78515625\n",
      "Batch: 15, Loss: 0.530086874961853, Accuracy: 0.8369140625\n",
      "Batch: 16, Loss: 0.5719233155250549, Accuracy: 0.8310546875\n",
      "Batch: 17, Loss: 0.585432767868042, Accuracy: 0.8154296875\n",
      "Batch: 18, Loss: 0.6467674970626831, Accuracy: 0.783203125\n",
      "Batch: 19, Loss: 0.6615234613418579, Accuracy: 0.7890625\n",
      "Batch: 20, Loss: 0.5563480854034424, Accuracy: 0.8125\n",
      "Batch: 21, Loss: 0.6022480130195618, Accuracy: 0.8037109375\n",
      "Batch: 22, Loss: 0.6964552998542786, Accuracy: 0.7802734375\n",
      "Batch: 23, Loss: 0.6418312788009644, Accuracy: 0.796875\n",
      "Batch: 24, Loss: 0.6585983037948608, Accuracy: 0.798828125\n",
      "Batch: 25, Loss: 0.6104778051376343, Accuracy: 0.802734375\n",
      "Batch: 26, Loss: 0.5595588684082031, Accuracy: 0.826171875\n",
      "Batch: 27, Loss: 0.5901640057563782, Accuracy: 0.8037109375\n",
      "Batch: 28, Loss: 0.6131046414375305, Accuracy: 0.796875\n",
      "Batch: 29, Loss: 0.596899151802063, Accuracy: 0.8115234375\n",
      "Batch: 30, Loss: 0.5112717747688293, Accuracy: 0.83203125\n",
      "Batch: 31, Loss: 0.5389784574508667, Accuracy: 0.8203125\n",
      "Batch: 32, Loss: 0.5564682483673096, Accuracy: 0.80859375\n",
      "Batch: 33, Loss: 0.6440209150314331, Accuracy: 0.7939453125\n",
      "Batch: 34, Loss: 0.7176732420921326, Accuracy: 0.76171875\n",
      "Batch: 35, Loss: 0.6298462152481079, Accuracy: 0.8017578125\n",
      "Batch: 36, Loss: 0.6139910221099854, Accuracy: 0.8095703125\n",
      "Batch: 37, Loss: 0.6184178590774536, Accuracy: 0.8037109375\n",
      "Batch: 38, Loss: 0.5910463333129883, Accuracy: 0.794921875\n",
      "Batch: 39, Loss: 0.6184661388397217, Accuracy: 0.796875\n",
      "Batch: 40, Loss: 0.5948812961578369, Accuracy: 0.7998046875\n",
      "Batch: 41, Loss: 0.5677400231361389, Accuracy: 0.8115234375\n",
      "Batch: 42, Loss: 0.46103769540786743, Accuracy: 0.837890625\n",
      "Batch: 43, Loss: 0.6074550747871399, Accuracy: 0.7978515625\n",
      "Batch: 44, Loss: 0.5599129796028137, Accuracy: 0.814453125\n",
      "Batch: 45, Loss: 0.5239348411560059, Accuracy: 0.83984375\n",
      "Batch: 46, Loss: 0.5392118096351624, Accuracy: 0.83203125\n",
      "Batch: 47, Loss: 0.5332597494125366, Accuracy: 0.830078125\n",
      "Batch: 48, Loss: 0.5152193307876587, Accuracy: 0.8359375\n",
      "Batch: 49, Loss: 0.6026970148086548, Accuracy: 0.8017578125\n",
      "Batch: 50, Loss: 0.6260435581207275, Accuracy: 0.7958984375\n",
      "Batch: 51, Loss: 0.6042200922966003, Accuracy: 0.7978515625\n",
      "Batch: 52, Loss: 0.5967518091201782, Accuracy: 0.8056640625\n",
      "Batch: 53, Loss: 0.5559177398681641, Accuracy: 0.8173828125\n",
      "Batch: 54, Loss: 0.5763270854949951, Accuracy: 0.8076171875\n",
      "Batch: 55, Loss: 0.653134822845459, Accuracy: 0.7900390625\n",
      "Batch: 56, Loss: 0.6534044742584229, Accuracy: 0.783203125\n",
      "Batch: 57, Loss: 0.5955649614334106, Accuracy: 0.8095703125\n",
      "Batch: 58, Loss: 0.6564983129501343, Accuracy: 0.78515625\n",
      "Batch: 59, Loss: 0.5672060251235962, Accuracy: 0.8115234375\n",
      "Batch: 60, Loss: 0.5441850423812866, Accuracy: 0.8193359375\n",
      "Batch: 61, Loss: 0.6124633550643921, Accuracy: 0.7890625\n",
      "Batch: 62, Loss: 0.5479949712753296, Accuracy: 0.81640625\n",
      "Batch: 63, Loss: 0.5946227312088013, Accuracy: 0.8115234375\n",
      "Batch: 64, Loss: 0.5891672968864441, Accuracy: 0.8046875\n",
      "Batch: 65, Loss: 0.5856785774230957, Accuracy: 0.80859375\n",
      "Batch: 66, Loss: 0.5974522829055786, Accuracy: 0.818359375\n",
      "Batch: 67, Loss: 0.6402319669723511, Accuracy: 0.787109375\n",
      "Batch: 68, Loss: 0.6757196187973022, Accuracy: 0.7763671875\n",
      "Batch: 69, Loss: 0.6496562361717224, Accuracy: 0.80078125\n",
      "Batch: 70, Loss: 0.6257745027542114, Accuracy: 0.8076171875\n",
      "Batch: 71, Loss: 0.6241594552993774, Accuracy: 0.7724609375\n",
      "Batch: 72, Loss: 0.542723536491394, Accuracy: 0.81640625\n",
      "Batch: 73, Loss: 0.5698710680007935, Accuracy: 0.8193359375\n",
      "Batch: 74, Loss: 0.523790180683136, Accuracy: 0.8349609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 75, Loss: 0.5336475968360901, Accuracy: 0.828125\n",
      "Batch: 76, Loss: 0.6163299083709717, Accuracy: 0.7978515625\n",
      "Batch: 77, Loss: 0.5853427648544312, Accuracy: 0.8134765625\n",
      "Batch: 78, Loss: 0.5600626468658447, Accuracy: 0.8154296875\n",
      "Batch: 79, Loss: 0.5311480760574341, Accuracy: 0.8291015625\n",
      "Batch: 80, Loss: 0.5704841017723083, Accuracy: 0.794921875\n",
      "Batch: 81, Loss: 0.6274914145469666, Accuracy: 0.794921875\n",
      "Batch: 82, Loss: 0.5935404896736145, Accuracy: 0.80078125\n",
      "Batch: 83, Loss: 0.49003028869628906, Accuracy: 0.83984375\n",
      "Batch: 84, Loss: 0.5917218923568726, Accuracy: 0.8095703125\n",
      "Batch: 85, Loss: 0.548050045967102, Accuracy: 0.830078125\n",
      "Batch: 86, Loss: 0.7226591110229492, Accuracy: 0.7724609375\n",
      "Batch: 87, Loss: 0.5370818972587585, Accuracy: 0.8251953125\n",
      "Batch: 88, Loss: 0.6505415439605713, Accuracy: 0.7998046875\n",
      "Batch: 89, Loss: 0.5942581295967102, Accuracy: 0.810546875\n",
      "Batch: 90, Loss: 0.6047803163528442, Accuracy: 0.806640625\n",
      "Batch: 91, Loss: 0.5857982635498047, Accuracy: 0.7978515625\n",
      "Batch: 92, Loss: 0.6486564874649048, Accuracy: 0.80078125\n",
      "Batch: 93, Loss: 0.5684676170349121, Accuracy: 0.8232421875\n",
      "Batch: 94, Loss: 0.5828256607055664, Accuracy: 0.802734375\n",
      "Batch: 95, Loss: 0.6111836433410645, Accuracy: 0.78125\n",
      "Batch: 96, Loss: 0.5865983963012695, Accuracy: 0.8056640625\n",
      "Batch: 97, Loss: 0.49787431955337524, Accuracy: 0.8408203125\n",
      "Batch: 98, Loss: 0.556056559085846, Accuracy: 0.8095703125\n",
      "Batch: 99, Loss: 0.5776735544204712, Accuracy: 0.80859375\n",
      "Batch: 100, Loss: 0.6066783666610718, Accuracy: 0.8056640625\n",
      "Batch: 101, Loss: 0.6063250303268433, Accuracy: 0.796875\n",
      "Batch: 102, Loss: 0.5895413756370544, Accuracy: 0.8046875\n",
      "Batch: 103, Loss: 0.6281949877738953, Accuracy: 0.8046875\n",
      "Batch: 104, Loss: 0.5454556941986084, Accuracy: 0.81640625\n",
      "Batch: 105, Loss: 0.6029285788536072, Accuracy: 0.80859375\n",
      "Batch: 106, Loss: 0.5291857123374939, Accuracy: 0.8291015625\n",
      "Batch: 107, Loss: 0.5650261640548706, Accuracy: 0.81640625\n",
      "Batch: 108, Loss: 0.5820837616920471, Accuracy: 0.8017578125\n",
      "Batch: 109, Loss: 0.64885014295578, Accuracy: 0.7724609375\n",
      "Batch: 110, Loss: 0.5250139236450195, Accuracy: 0.8251953125\n",
      "Batch: 111, Loss: 0.5920861959457397, Accuracy: 0.8134765625\n",
      "Batch: 112, Loss: 0.5852988958358765, Accuracy: 0.8193359375\n",
      "Batch: 113, Loss: 0.5946065187454224, Accuracy: 0.814453125\n",
      "Batch: 114, Loss: 0.6760635375976562, Accuracy: 0.7783203125\n",
      "Batch: 115, Loss: 0.6407738327980042, Accuracy: 0.7861328125\n",
      "Batch: 116, Loss: 0.6184444427490234, Accuracy: 0.7890625\n",
      "Batch: 117, Loss: 0.6437757015228271, Accuracy: 0.7861328125\n",
      "Batch: 118, Loss: 0.5568755865097046, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.512275218963623, Accuracy: 0.8369140625\n",
      "Batch: 120, Loss: 0.5978509187698364, Accuracy: 0.7978515625\n",
      "Batch: 121, Loss: 0.6433413028717041, Accuracy: 0.79296875\n",
      "Batch: 122, Loss: 0.5479782819747925, Accuracy: 0.822265625\n",
      "Batch: 123, Loss: 0.5710630416870117, Accuracy: 0.814453125\n",
      "Batch: 124, Loss: 0.5798555612564087, Accuracy: 0.8095703125\n",
      "Batch: 125, Loss: 0.6371739506721497, Accuracy: 0.77734375\n",
      "Batch: 126, Loss: 0.6071904301643372, Accuracy: 0.80859375\n",
      "Batch: 127, Loss: 0.5249748229980469, Accuracy: 0.8310546875\n",
      "Batch: 128, Loss: 0.690773606300354, Accuracy: 0.76953125\n",
      "Batch: 129, Loss: 0.5617426633834839, Accuracy: 0.802734375\n",
      "Batch: 130, Loss: 0.650910496711731, Accuracy: 0.796875\n",
      "Batch: 131, Loss: 0.6025680899620056, Accuracy: 0.806640625\n",
      "Batch: 132, Loss: 0.6173456907272339, Accuracy: 0.7861328125\n",
      "Batch: 133, Loss: 0.5876224040985107, Accuracy: 0.80078125\n",
      "Batch: 134, Loss: 0.5914991497993469, Accuracy: 0.8095703125\n",
      "Batch: 135, Loss: 0.5652502775192261, Accuracy: 0.8134765625\n",
      "Batch: 136, Loss: 0.6150134801864624, Accuracy: 0.7919921875\n",
      "Batch: 137, Loss: 0.6329089999198914, Accuracy: 0.7724609375\n",
      "Batch: 138, Loss: 0.5470472574234009, Accuracy: 0.8125\n",
      "Batch: 139, Loss: 0.6234947443008423, Accuracy: 0.7900390625\n",
      "Batch: 140, Loss: 0.5599094033241272, Accuracy: 0.8134765625\n",
      "Batch: 141, Loss: 0.6671581268310547, Accuracy: 0.79296875\n",
      "Batch: 142, Loss: 0.644453763961792, Accuracy: 0.78515625\n",
      "Batch: 143, Loss: 0.6350767016410828, Accuracy: 0.7958984375\n",
      "Batch: 144, Loss: 0.670682430267334, Accuracy: 0.7763671875\n",
      "Batch: 145, Loss: 0.5604739785194397, Accuracy: 0.8056640625\n",
      "Batch: 146, Loss: 0.6138569116592407, Accuracy: 0.80078125\n",
      "Batch: 147, Loss: 0.576830267906189, Accuracy: 0.8125\n",
      "Batch: 148, Loss: 0.6971094608306885, Accuracy: 0.765625\n",
      "Batch: 149, Loss: 0.5874841213226318, Accuracy: 0.8017578125\n",
      "Batch: 150, Loss: 0.5937772989273071, Accuracy: 0.7978515625\n",
      "Batch: 151, Loss: 0.5467951893806458, Accuracy: 0.8251953125\n",
      "Epoch 53/80\n",
      "Batch: 1, Loss: 0.7875978946685791, Accuracy: 0.73828125\n",
      "Batch: 2, Loss: 0.6816153526306152, Accuracy: 0.7734375\n",
      "Batch: 3, Loss: 0.5977100133895874, Accuracy: 0.787109375\n",
      "Batch: 4, Loss: 0.5531030297279358, Accuracy: 0.8134765625\n",
      "Batch: 5, Loss: 0.5675375461578369, Accuracy: 0.8134765625\n",
      "Batch: 6, Loss: 0.6094082593917847, Accuracy: 0.7958984375\n",
      "Batch: 7, Loss: 0.6418849229812622, Accuracy: 0.78515625\n",
      "Batch: 8, Loss: 0.5837007164955139, Accuracy: 0.80859375\n",
      "Batch: 9, Loss: 0.5856218338012695, Accuracy: 0.8134765625\n",
      "Batch: 10, Loss: 0.5777133703231812, Accuracy: 0.80078125\n",
      "Batch: 11, Loss: 0.6302734613418579, Accuracy: 0.794921875\n",
      "Batch: 12, Loss: 0.5951075553894043, Accuracy: 0.8046875\n",
      "Batch: 13, Loss: 0.4779817461967468, Accuracy: 0.8447265625\n",
      "Batch: 14, Loss: 0.678787112236023, Accuracy: 0.7744140625\n",
      "Batch: 15, Loss: 0.5427534580230713, Accuracy: 0.8173828125\n",
      "Batch: 16, Loss: 0.5642990469932556, Accuracy: 0.826171875\n",
      "Batch: 17, Loss: 0.6192864179611206, Accuracy: 0.80859375\n",
      "Batch: 18, Loss: 0.6269735097885132, Accuracy: 0.8046875\n",
      "Batch: 19, Loss: 0.6534444093704224, Accuracy: 0.7880859375\n",
      "Batch: 20, Loss: 0.5503329038619995, Accuracy: 0.8349609375\n",
      "Batch: 21, Loss: 0.5806740522384644, Accuracy: 0.8095703125\n",
      "Batch: 22, Loss: 0.6977616548538208, Accuracy: 0.7841796875\n",
      "Batch: 23, Loss: 0.6704863905906677, Accuracy: 0.77734375\n",
      "Batch: 24, Loss: 0.6778255701065063, Accuracy: 0.7802734375\n",
      "Batch: 25, Loss: 0.6072790026664734, Accuracy: 0.8115234375\n",
      "Batch: 26, Loss: 0.5245690941810608, Accuracy: 0.82421875\n",
      "Batch: 27, Loss: 0.58411705493927, Accuracy: 0.8046875\n",
      "Batch: 28, Loss: 0.5718180537223816, Accuracy: 0.8095703125\n",
      "Batch: 29, Loss: 0.569451630115509, Accuracy: 0.8203125\n",
      "Batch: 30, Loss: 0.49648886919021606, Accuracy: 0.833984375\n",
      "Batch: 31, Loss: 0.5392899513244629, Accuracy: 0.8193359375\n",
      "Batch: 32, Loss: 0.5195024013519287, Accuracy: 0.822265625\n",
      "Batch: 33, Loss: 0.6646907925605774, Accuracy: 0.7900390625\n",
      "Batch: 34, Loss: 0.6889442205429077, Accuracy: 0.7666015625\n",
      "Batch: 35, Loss: 0.632366955280304, Accuracy: 0.791015625\n",
      "Batch: 36, Loss: 0.6232913732528687, Accuracy: 0.80859375\n",
      "Batch: 37, Loss: 0.6019786596298218, Accuracy: 0.7890625\n",
      "Batch: 38, Loss: 0.5666038393974304, Accuracy: 0.8154296875\n",
      "Batch: 39, Loss: 0.6114500761032104, Accuracy: 0.794921875\n",
      "Batch: 40, Loss: 0.5881369709968567, Accuracy: 0.818359375\n",
      "Batch: 41, Loss: 0.5594265460968018, Accuracy: 0.8173828125\n",
      "Batch: 42, Loss: 0.4345799386501312, Accuracy: 0.857421875\n",
      "Batch: 43, Loss: 0.599298357963562, Accuracy: 0.7978515625\n",
      "Batch: 44, Loss: 0.5696237087249756, Accuracy: 0.8154296875\n",
      "Batch: 45, Loss: 0.4920423924922943, Accuracy: 0.8369140625\n",
      "Batch: 46, Loss: 0.5298252105712891, Accuracy: 0.818359375\n",
      "Batch: 47, Loss: 0.5148228406906128, Accuracy: 0.833984375\n",
      "Batch: 48, Loss: 0.5213505029678345, Accuracy: 0.8310546875\n",
      "Batch: 49, Loss: 0.5760834217071533, Accuracy: 0.818359375\n",
      "Batch: 50, Loss: 0.607647716999054, Accuracy: 0.8056640625\n",
      "Batch: 51, Loss: 0.6024529337882996, Accuracy: 0.806640625\n",
      "Batch: 52, Loss: 0.5972568988800049, Accuracy: 0.810546875\n",
      "Batch: 53, Loss: 0.5331186652183533, Accuracy: 0.822265625\n",
      "Batch: 54, Loss: 0.549554705619812, Accuracy: 0.8095703125\n",
      "Batch: 55, Loss: 0.6789988279342651, Accuracy: 0.787109375\n",
      "Batch: 56, Loss: 0.626808762550354, Accuracy: 0.79296875\n",
      "Batch: 57, Loss: 0.6201335191726685, Accuracy: 0.8037109375\n",
      "Batch: 58, Loss: 0.6611422300338745, Accuracy: 0.791015625\n",
      "Batch: 59, Loss: 0.5832679867744446, Accuracy: 0.8076171875\n",
      "Batch: 60, Loss: 0.559965968132019, Accuracy: 0.81640625\n",
      "Batch: 61, Loss: 0.607467532157898, Accuracy: 0.794921875\n",
      "Batch: 62, Loss: 0.5374554395675659, Accuracy: 0.8271484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 63, Loss: 0.5688767433166504, Accuracy: 0.8173828125\n",
      "Batch: 64, Loss: 0.5707470178604126, Accuracy: 0.810546875\n",
      "Batch: 65, Loss: 0.6071902513504028, Accuracy: 0.8056640625\n",
      "Batch: 66, Loss: 0.5698511600494385, Accuracy: 0.8212890625\n",
      "Batch: 67, Loss: 0.6449722051620483, Accuracy: 0.7880859375\n",
      "Batch: 68, Loss: 0.6823877096176147, Accuracy: 0.7705078125\n",
      "Batch: 69, Loss: 0.6230982542037964, Accuracy: 0.7919921875\n",
      "Batch: 70, Loss: 0.6172756552696228, Accuracy: 0.8037109375\n",
      "Batch: 71, Loss: 0.6240125298500061, Accuracy: 0.7744140625\n",
      "Batch: 72, Loss: 0.5320589542388916, Accuracy: 0.8251953125\n",
      "Batch: 73, Loss: 0.5431860685348511, Accuracy: 0.822265625\n",
      "Batch: 74, Loss: 0.5090672969818115, Accuracy: 0.8388671875\n",
      "Batch: 75, Loss: 0.5153017640113831, Accuracy: 0.83984375\n",
      "Batch: 76, Loss: 0.5951583981513977, Accuracy: 0.7880859375\n",
      "Batch: 77, Loss: 0.5723979473114014, Accuracy: 0.81640625\n",
      "Batch: 78, Loss: 0.5537852048873901, Accuracy: 0.82421875\n",
      "Batch: 79, Loss: 0.5366764664649963, Accuracy: 0.8388671875\n",
      "Batch: 80, Loss: 0.5548674464225769, Accuracy: 0.8125\n",
      "Batch: 81, Loss: 0.6149797439575195, Accuracy: 0.8017578125\n",
      "Batch: 82, Loss: 0.5793583393096924, Accuracy: 0.8193359375\n",
      "Batch: 83, Loss: 0.5278371572494507, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.6039550304412842, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.5702857971191406, Accuracy: 0.81640625\n",
      "Batch: 86, Loss: 0.6780028343200684, Accuracy: 0.7978515625\n",
      "Batch: 87, Loss: 0.5215958952903748, Accuracy: 0.8310546875\n",
      "Batch: 88, Loss: 0.6564610004425049, Accuracy: 0.7861328125\n",
      "Batch: 89, Loss: 0.5986322164535522, Accuracy: 0.8115234375\n",
      "Batch: 90, Loss: 0.6193689107894897, Accuracy: 0.796875\n",
      "Batch: 91, Loss: 0.569606363773346, Accuracy: 0.818359375\n",
      "Batch: 92, Loss: 0.6009378433227539, Accuracy: 0.7958984375\n",
      "Batch: 93, Loss: 0.5602294206619263, Accuracy: 0.8017578125\n",
      "Batch: 94, Loss: 0.6187887191772461, Accuracy: 0.7763671875\n",
      "Batch: 95, Loss: 0.5975508093833923, Accuracy: 0.7958984375\n",
      "Batch: 96, Loss: 0.5689934492111206, Accuracy: 0.814453125\n",
      "Batch: 97, Loss: 0.4995781183242798, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.5698264241218567, Accuracy: 0.810546875\n",
      "Batch: 99, Loss: 0.5385739803314209, Accuracy: 0.8115234375\n",
      "Batch: 100, Loss: 0.587402880191803, Accuracy: 0.8134765625\n",
      "Batch: 101, Loss: 0.6093945503234863, Accuracy: 0.7998046875\n",
      "Batch: 102, Loss: 0.5773667097091675, Accuracy: 0.8134765625\n",
      "Batch: 103, Loss: 0.6174370050430298, Accuracy: 0.802734375\n",
      "Batch: 104, Loss: 0.5811111927032471, Accuracy: 0.814453125\n",
      "Batch: 105, Loss: 0.6153439283370972, Accuracy: 0.7958984375\n",
      "Batch: 106, Loss: 0.5561761856079102, Accuracy: 0.818359375\n",
      "Batch: 107, Loss: 0.5610454082489014, Accuracy: 0.80859375\n",
      "Batch: 108, Loss: 0.5871826410293579, Accuracy: 0.8076171875\n",
      "Batch: 109, Loss: 0.6554081439971924, Accuracy: 0.7666015625\n",
      "Batch: 110, Loss: 0.5003339052200317, Accuracy: 0.828125\n",
      "Batch: 111, Loss: 0.5991110801696777, Accuracy: 0.806640625\n",
      "Batch: 112, Loss: 0.5907945036888123, Accuracy: 0.80859375\n",
      "Batch: 113, Loss: 0.5708034038543701, Accuracy: 0.8232421875\n",
      "Batch: 114, Loss: 0.6199853420257568, Accuracy: 0.8017578125\n",
      "Batch: 115, Loss: 0.641060471534729, Accuracy: 0.79296875\n",
      "Batch: 116, Loss: 0.6130880117416382, Accuracy: 0.7900390625\n",
      "Batch: 117, Loss: 0.597064733505249, Accuracy: 0.79296875\n",
      "Batch: 118, Loss: 0.5718432068824768, Accuracy: 0.8203125\n",
      "Batch: 119, Loss: 0.5073555707931519, Accuracy: 0.8408203125\n",
      "Batch: 120, Loss: 0.600193977355957, Accuracy: 0.806640625\n",
      "Batch: 121, Loss: 0.6456552743911743, Accuracy: 0.7890625\n",
      "Batch: 122, Loss: 0.5428924560546875, Accuracy: 0.822265625\n",
      "Batch: 123, Loss: 0.5740101933479309, Accuracy: 0.8154296875\n",
      "Batch: 124, Loss: 0.6133875846862793, Accuracy: 0.796875\n",
      "Batch: 125, Loss: 0.603507399559021, Accuracy: 0.7958984375\n",
      "Batch: 126, Loss: 0.6220909357070923, Accuracy: 0.8076171875\n",
      "Batch: 127, Loss: 0.5514236688613892, Accuracy: 0.828125\n",
      "Batch: 128, Loss: 0.668305516242981, Accuracy: 0.7900390625\n",
      "Batch: 129, Loss: 0.5475980639457703, Accuracy: 0.8271484375\n",
      "Batch: 130, Loss: 0.6744567155838013, Accuracy: 0.787109375\n",
      "Batch: 131, Loss: 0.6475656628608704, Accuracy: 0.7763671875\n",
      "Batch: 132, Loss: 0.6122281551361084, Accuracy: 0.8154296875\n",
      "Batch: 133, Loss: 0.6048357486724854, Accuracy: 0.7900390625\n",
      "Batch: 134, Loss: 0.6212606430053711, Accuracy: 0.7861328125\n",
      "Batch: 135, Loss: 0.5450326204299927, Accuracy: 0.830078125\n",
      "Batch: 136, Loss: 0.6269374489784241, Accuracy: 0.8056640625\n",
      "Batch: 137, Loss: 0.6152765154838562, Accuracy: 0.779296875\n",
      "Batch: 138, Loss: 0.5458000898361206, Accuracy: 0.814453125\n",
      "Batch: 139, Loss: 0.6265122890472412, Accuracy: 0.8017578125\n",
      "Batch: 140, Loss: 0.5831234455108643, Accuracy: 0.8115234375\n",
      "Batch: 141, Loss: 0.6408147215843201, Accuracy: 0.7783203125\n",
      "Batch: 142, Loss: 0.6541584730148315, Accuracy: 0.783203125\n",
      "Batch: 143, Loss: 0.6152647733688354, Accuracy: 0.8056640625\n",
      "Batch: 144, Loss: 0.6212542057037354, Accuracy: 0.798828125\n",
      "Batch: 145, Loss: 0.5775724053382874, Accuracy: 0.80078125\n",
      "Batch: 146, Loss: 0.6215063333511353, Accuracy: 0.8037109375\n",
      "Batch: 147, Loss: 0.5855520367622375, Accuracy: 0.8046875\n",
      "Batch: 148, Loss: 0.6901527643203735, Accuracy: 0.7841796875\n",
      "Batch: 149, Loss: 0.5742533206939697, Accuracy: 0.8203125\n",
      "Batch: 150, Loss: 0.5747140049934387, Accuracy: 0.8017578125\n",
      "Batch: 151, Loss: 0.5458906888961792, Accuracy: 0.8154296875\n",
      "Epoch 54/80\n",
      "Batch: 1, Loss: 0.804064154624939, Accuracy: 0.7470703125\n",
      "Batch: 2, Loss: 0.6778935790061951, Accuracy: 0.7744140625\n",
      "Batch: 3, Loss: 0.6278420686721802, Accuracy: 0.79296875\n",
      "Batch: 4, Loss: 0.546837329864502, Accuracy: 0.822265625\n",
      "Batch: 5, Loss: 0.5623235106468201, Accuracy: 0.8095703125\n",
      "Batch: 6, Loss: 0.6480592489242554, Accuracy: 0.7841796875\n",
      "Batch: 7, Loss: 0.6892186999320984, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.6342774033546448, Accuracy: 0.80078125\n",
      "Batch: 9, Loss: 0.5978245139122009, Accuracy: 0.8115234375\n",
      "Batch: 10, Loss: 0.6048425436019897, Accuracy: 0.80078125\n",
      "Batch: 11, Loss: 0.641110360622406, Accuracy: 0.77734375\n",
      "Batch: 12, Loss: 0.6345987319946289, Accuracy: 0.7958984375\n",
      "Batch: 13, Loss: 0.49434012174606323, Accuracy: 0.8359375\n",
      "Batch: 14, Loss: 0.6622353196144104, Accuracy: 0.7841796875\n",
      "Batch: 15, Loss: 0.5203065276145935, Accuracy: 0.833984375\n",
      "Batch: 16, Loss: 0.5498279333114624, Accuracy: 0.8310546875\n",
      "Batch: 17, Loss: 0.5989439487457275, Accuracy: 0.8046875\n",
      "Batch: 18, Loss: 0.6365371942520142, Accuracy: 0.78515625\n",
      "Batch: 19, Loss: 0.6922675371170044, Accuracy: 0.767578125\n",
      "Batch: 20, Loss: 0.5494534969329834, Accuracy: 0.8291015625\n",
      "Batch: 21, Loss: 0.6230266094207764, Accuracy: 0.7939453125\n",
      "Batch: 22, Loss: 0.6818549633026123, Accuracy: 0.7734375\n",
      "Batch: 23, Loss: 0.6662232875823975, Accuracy: 0.7724609375\n",
      "Batch: 24, Loss: 0.6456658840179443, Accuracy: 0.7919921875\n",
      "Batch: 25, Loss: 0.5982542037963867, Accuracy: 0.81640625\n",
      "Batch: 26, Loss: 0.5073651075363159, Accuracy: 0.8330078125\n",
      "Batch: 27, Loss: 0.5791069269180298, Accuracy: 0.7880859375\n",
      "Batch: 28, Loss: 0.618806004524231, Accuracy: 0.798828125\n",
      "Batch: 29, Loss: 0.5646559000015259, Accuracy: 0.806640625\n",
      "Batch: 30, Loss: 0.5319210290908813, Accuracy: 0.82421875\n",
      "Batch: 31, Loss: 0.5425102114677429, Accuracy: 0.818359375\n",
      "Batch: 32, Loss: 0.5333974361419678, Accuracy: 0.8271484375\n",
      "Batch: 33, Loss: 0.6649143099784851, Accuracy: 0.7841796875\n",
      "Batch: 34, Loss: 0.6991137266159058, Accuracy: 0.76953125\n",
      "Batch: 35, Loss: 0.5987941026687622, Accuracy: 0.7998046875\n",
      "Batch: 36, Loss: 0.625089168548584, Accuracy: 0.7958984375\n",
      "Batch: 37, Loss: 0.625870943069458, Accuracy: 0.7841796875\n",
      "Batch: 38, Loss: 0.5845791101455688, Accuracy: 0.8056640625\n",
      "Batch: 39, Loss: 0.6123461723327637, Accuracy: 0.8056640625\n",
      "Batch: 40, Loss: 0.5845409631729126, Accuracy: 0.8076171875\n",
      "Batch: 41, Loss: 0.5565342903137207, Accuracy: 0.8203125\n",
      "Batch: 42, Loss: 0.4321453273296356, Accuracy: 0.8544921875\n",
      "Batch: 43, Loss: 0.6021803617477417, Accuracy: 0.7861328125\n",
      "Batch: 44, Loss: 0.5367188453674316, Accuracy: 0.8173828125\n",
      "Batch: 45, Loss: 0.49898281693458557, Accuracy: 0.83203125\n",
      "Batch: 46, Loss: 0.5224282145500183, Accuracy: 0.82421875\n",
      "Batch: 47, Loss: 0.5129091739654541, Accuracy: 0.8427734375\n",
      "Batch: 48, Loss: 0.5210237503051758, Accuracy: 0.8349609375\n",
      "Batch: 49, Loss: 0.617353081703186, Accuracy: 0.78515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.5924847722053528, Accuracy: 0.8056640625\n",
      "Batch: 51, Loss: 0.5918892621994019, Accuracy: 0.810546875\n",
      "Batch: 52, Loss: 0.5815269947052002, Accuracy: 0.8154296875\n",
      "Batch: 53, Loss: 0.5128246545791626, Accuracy: 0.82421875\n",
      "Batch: 54, Loss: 0.5682947635650635, Accuracy: 0.802734375\n",
      "Batch: 55, Loss: 0.6579124927520752, Accuracy: 0.791015625\n",
      "Batch: 56, Loss: 0.6313283443450928, Accuracy: 0.7900390625\n",
      "Batch: 57, Loss: 0.5808364152908325, Accuracy: 0.7998046875\n",
      "Batch: 58, Loss: 0.6635207533836365, Accuracy: 0.794921875\n",
      "Batch: 59, Loss: 0.5870386362075806, Accuracy: 0.8125\n",
      "Batch: 60, Loss: 0.5414993762969971, Accuracy: 0.822265625\n",
      "Batch: 61, Loss: 0.6058711409568787, Accuracy: 0.7900390625\n",
      "Batch: 62, Loss: 0.5329945683479309, Accuracy: 0.83203125\n",
      "Batch: 63, Loss: 0.5712260007858276, Accuracy: 0.81640625\n",
      "Batch: 64, Loss: 0.5559288859367371, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.5856722593307495, Accuracy: 0.8125\n",
      "Batch: 66, Loss: 0.5669358968734741, Accuracy: 0.8193359375\n",
      "Batch: 67, Loss: 0.6511015892028809, Accuracy: 0.79296875\n",
      "Batch: 68, Loss: 0.6879726648330688, Accuracy: 0.7646484375\n",
      "Batch: 69, Loss: 0.6400114297866821, Accuracy: 0.7919921875\n",
      "Batch: 70, Loss: 0.6105793714523315, Accuracy: 0.7998046875\n",
      "Batch: 71, Loss: 0.6349148750305176, Accuracy: 0.783203125\n",
      "Batch: 72, Loss: 0.544526219367981, Accuracy: 0.8232421875\n",
      "Batch: 73, Loss: 0.5339664220809937, Accuracy: 0.828125\n",
      "Batch: 74, Loss: 0.5106323957443237, Accuracy: 0.8427734375\n",
      "Batch: 75, Loss: 0.5131928324699402, Accuracy: 0.828125\n",
      "Batch: 76, Loss: 0.5944764614105225, Accuracy: 0.802734375\n",
      "Batch: 77, Loss: 0.5214933753013611, Accuracy: 0.8330078125\n",
      "Batch: 78, Loss: 0.5158432722091675, Accuracy: 0.8310546875\n",
      "Batch: 79, Loss: 0.5081313848495483, Accuracy: 0.8359375\n",
      "Batch: 80, Loss: 0.5580321550369263, Accuracy: 0.8076171875\n",
      "Batch: 81, Loss: 0.6233548521995544, Accuracy: 0.7783203125\n",
      "Batch: 82, Loss: 0.57685387134552, Accuracy: 0.8056640625\n",
      "Batch: 83, Loss: 0.4989691376686096, Accuracy: 0.8427734375\n",
      "Batch: 84, Loss: 0.6033452749252319, Accuracy: 0.802734375\n",
      "Batch: 85, Loss: 0.5379881858825684, Accuracy: 0.828125\n",
      "Batch: 86, Loss: 0.6753203272819519, Accuracy: 0.7890625\n",
      "Batch: 87, Loss: 0.5371776819229126, Accuracy: 0.8232421875\n",
      "Batch: 88, Loss: 0.6222008466720581, Accuracy: 0.8115234375\n",
      "Batch: 89, Loss: 0.6168336868286133, Accuracy: 0.8017578125\n",
      "Batch: 90, Loss: 0.588961124420166, Accuracy: 0.814453125\n",
      "Batch: 91, Loss: 0.5351152420043945, Accuracy: 0.8349609375\n",
      "Batch: 92, Loss: 0.6143900156021118, Accuracy: 0.796875\n",
      "Batch: 93, Loss: 0.5748574733734131, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.6119397878646851, Accuracy: 0.796875\n",
      "Batch: 95, Loss: 0.6229662895202637, Accuracy: 0.7880859375\n",
      "Batch: 96, Loss: 0.5563780069351196, Accuracy: 0.810546875\n",
      "Batch: 97, Loss: 0.4659537076950073, Accuracy: 0.837890625\n",
      "Batch: 98, Loss: 0.5650947093963623, Accuracy: 0.8173828125\n",
      "Batch: 99, Loss: 0.5538018345832825, Accuracy: 0.8095703125\n",
      "Batch: 100, Loss: 0.5873618125915527, Accuracy: 0.8037109375\n",
      "Batch: 101, Loss: 0.6095045804977417, Accuracy: 0.78515625\n",
      "Batch: 102, Loss: 0.5937703847885132, Accuracy: 0.7978515625\n",
      "Batch: 103, Loss: 0.5733661651611328, Accuracy: 0.814453125\n",
      "Batch: 104, Loss: 0.5796709060668945, Accuracy: 0.7900390625\n",
      "Batch: 105, Loss: 0.6214418411254883, Accuracy: 0.8037109375\n",
      "Batch: 106, Loss: 0.5196104049682617, Accuracy: 0.833984375\n",
      "Batch: 107, Loss: 0.5740411281585693, Accuracy: 0.8154296875\n",
      "Batch: 108, Loss: 0.5920079350471497, Accuracy: 0.7919921875\n",
      "Batch: 109, Loss: 0.6477184295654297, Accuracy: 0.7802734375\n",
      "Batch: 110, Loss: 0.5251811742782593, Accuracy: 0.8310546875\n",
      "Batch: 111, Loss: 0.5914785861968994, Accuracy: 0.8076171875\n",
      "Batch: 112, Loss: 0.5811893939971924, Accuracy: 0.8095703125\n",
      "Batch: 113, Loss: 0.5976948142051697, Accuracy: 0.8232421875\n",
      "Batch: 114, Loss: 0.6246903538703918, Accuracy: 0.8056640625\n",
      "Batch: 115, Loss: 0.6421145796775818, Accuracy: 0.783203125\n",
      "Batch: 116, Loss: 0.5781670212745667, Accuracy: 0.8056640625\n",
      "Batch: 117, Loss: 0.6070478558540344, Accuracy: 0.8125\n",
      "Batch: 118, Loss: 0.5660864114761353, Accuracy: 0.8232421875\n",
      "Batch: 119, Loss: 0.5131791830062866, Accuracy: 0.8388671875\n",
      "Batch: 120, Loss: 0.5616127848625183, Accuracy: 0.8115234375\n",
      "Batch: 121, Loss: 0.6502753496170044, Accuracy: 0.787109375\n",
      "Batch: 122, Loss: 0.5684699416160583, Accuracy: 0.81640625\n",
      "Batch: 123, Loss: 0.5444536209106445, Accuracy: 0.826171875\n",
      "Batch: 124, Loss: 0.5741098523139954, Accuracy: 0.8046875\n",
      "Batch: 125, Loss: 0.573375403881073, Accuracy: 0.8115234375\n",
      "Batch: 126, Loss: 0.5792843103408813, Accuracy: 0.80859375\n",
      "Batch: 127, Loss: 0.5198041200637817, Accuracy: 0.8310546875\n",
      "Batch: 128, Loss: 0.6395177245140076, Accuracy: 0.7978515625\n",
      "Batch: 129, Loss: 0.5565966963768005, Accuracy: 0.8125\n",
      "Batch: 130, Loss: 0.6239345073699951, Accuracy: 0.8056640625\n",
      "Batch: 131, Loss: 0.5794815421104431, Accuracy: 0.8046875\n",
      "Batch: 132, Loss: 0.5886492729187012, Accuracy: 0.810546875\n",
      "Batch: 133, Loss: 0.5742068290710449, Accuracy: 0.814453125\n",
      "Batch: 134, Loss: 0.5917247533798218, Accuracy: 0.79296875\n",
      "Batch: 135, Loss: 0.5392707586288452, Accuracy: 0.8251953125\n",
      "Batch: 136, Loss: 0.5877689719200134, Accuracy: 0.822265625\n",
      "Batch: 137, Loss: 0.6057443618774414, Accuracy: 0.7939453125\n",
      "Batch: 138, Loss: 0.5440215468406677, Accuracy: 0.8056640625\n",
      "Batch: 139, Loss: 0.6321843862533569, Accuracy: 0.794921875\n",
      "Batch: 140, Loss: 0.5681966543197632, Accuracy: 0.810546875\n",
      "Batch: 141, Loss: 0.6577144861221313, Accuracy: 0.7919921875\n",
      "Batch: 142, Loss: 0.6462662816047668, Accuracy: 0.7890625\n",
      "Batch: 143, Loss: 0.6076637506484985, Accuracy: 0.810546875\n",
      "Batch: 144, Loss: 0.6016243696212769, Accuracy: 0.7998046875\n",
      "Batch: 145, Loss: 0.5556114912033081, Accuracy: 0.8017578125\n",
      "Batch: 146, Loss: 0.6185623407363892, Accuracy: 0.7958984375\n",
      "Batch: 147, Loss: 0.5713738799095154, Accuracy: 0.822265625\n",
      "Batch: 148, Loss: 0.6972373723983765, Accuracy: 0.7783203125\n",
      "Batch: 149, Loss: 0.5483385324478149, Accuracy: 0.822265625\n",
      "Batch: 150, Loss: 0.5764029622077942, Accuracy: 0.8056640625\n",
      "Batch: 151, Loss: 0.519619345664978, Accuracy: 0.8115234375\n",
      "Epoch 55/80\n",
      "Batch: 1, Loss: 0.7846956253051758, Accuracy: 0.7490234375\n",
      "Batch: 2, Loss: 0.6535800695419312, Accuracy: 0.7841796875\n",
      "Batch: 3, Loss: 0.6010705828666687, Accuracy: 0.8017578125\n",
      "Batch: 4, Loss: 0.5390982627868652, Accuracy: 0.8330078125\n",
      "Batch: 5, Loss: 0.5539366006851196, Accuracy: 0.8212890625\n",
      "Batch: 6, Loss: 0.6012734174728394, Accuracy: 0.802734375\n",
      "Batch: 7, Loss: 0.6051802635192871, Accuracy: 0.791015625\n",
      "Batch: 8, Loss: 0.5773075819015503, Accuracy: 0.8037109375\n",
      "Batch: 9, Loss: 0.5977504849433899, Accuracy: 0.8017578125\n",
      "Batch: 10, Loss: 0.5854789614677429, Accuracy: 0.796875\n",
      "Batch: 11, Loss: 0.642436683177948, Accuracy: 0.791015625\n",
      "Batch: 12, Loss: 0.6214377880096436, Accuracy: 0.7919921875\n",
      "Batch: 13, Loss: 0.49556493759155273, Accuracy: 0.8349609375\n",
      "Batch: 14, Loss: 0.6311168074607849, Accuracy: 0.802734375\n",
      "Batch: 15, Loss: 0.5198044180870056, Accuracy: 0.8447265625\n",
      "Batch: 16, Loss: 0.5448455810546875, Accuracy: 0.822265625\n",
      "Batch: 17, Loss: 0.6028415560722351, Accuracy: 0.8076171875\n",
      "Batch: 18, Loss: 0.6366166472434998, Accuracy: 0.7978515625\n",
      "Batch: 19, Loss: 0.6434630155563354, Accuracy: 0.8095703125\n",
      "Batch: 20, Loss: 0.501070499420166, Accuracy: 0.8359375\n",
      "Batch: 21, Loss: 0.5644034147262573, Accuracy: 0.814453125\n",
      "Batch: 22, Loss: 0.6680284738540649, Accuracy: 0.7822265625\n",
      "Batch: 23, Loss: 0.6394268870353699, Accuracy: 0.7822265625\n",
      "Batch: 24, Loss: 0.6562756299972534, Accuracy: 0.7958984375\n",
      "Batch: 25, Loss: 0.5708754062652588, Accuracy: 0.80859375\n",
      "Batch: 26, Loss: 0.523484468460083, Accuracy: 0.830078125\n",
      "Batch: 27, Loss: 0.5641820430755615, Accuracy: 0.8017578125\n",
      "Batch: 28, Loss: 0.5743904113769531, Accuracy: 0.810546875\n",
      "Batch: 29, Loss: 0.5737790465354919, Accuracy: 0.81640625\n",
      "Batch: 30, Loss: 0.5365234017372131, Accuracy: 0.8271484375\n",
      "Batch: 31, Loss: 0.5236905813217163, Accuracy: 0.8291015625\n",
      "Batch: 32, Loss: 0.5378333330154419, Accuracy: 0.826171875\n",
      "Batch: 33, Loss: 0.6190011501312256, Accuracy: 0.806640625\n",
      "Batch: 34, Loss: 0.6628516912460327, Accuracy: 0.7763671875\n",
      "Batch: 35, Loss: 0.6124307513237, Accuracy: 0.7919921875\n",
      "Batch: 36, Loss: 0.6188287138938904, Accuracy: 0.798828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 37, Loss: 0.6448317170143127, Accuracy: 0.7861328125\n",
      "Batch: 38, Loss: 0.5819323062896729, Accuracy: 0.796875\n",
      "Batch: 39, Loss: 0.5860651731491089, Accuracy: 0.818359375\n",
      "Batch: 40, Loss: 0.5694739818572998, Accuracy: 0.8017578125\n",
      "Batch: 41, Loss: 0.505603551864624, Accuracy: 0.833984375\n",
      "Batch: 42, Loss: 0.4403154253959656, Accuracy: 0.8515625\n",
      "Batch: 43, Loss: 0.5774536728858948, Accuracy: 0.7998046875\n",
      "Batch: 44, Loss: 0.5302591323852539, Accuracy: 0.8046875\n",
      "Batch: 45, Loss: 0.4872482717037201, Accuracy: 0.8408203125\n",
      "Batch: 46, Loss: 0.527509331703186, Accuracy: 0.8388671875\n",
      "Batch: 47, Loss: 0.5014086961746216, Accuracy: 0.8388671875\n",
      "Batch: 48, Loss: 0.5422515869140625, Accuracy: 0.8271484375\n",
      "Batch: 49, Loss: 0.5857540369033813, Accuracy: 0.798828125\n",
      "Batch: 50, Loss: 0.6063365340232849, Accuracy: 0.8056640625\n",
      "Batch: 51, Loss: 0.6156991720199585, Accuracy: 0.81640625\n",
      "Batch: 52, Loss: 0.6036381125450134, Accuracy: 0.8076171875\n",
      "Batch: 53, Loss: 0.5195619463920593, Accuracy: 0.818359375\n",
      "Batch: 54, Loss: 0.5609509348869324, Accuracy: 0.8134765625\n",
      "Batch: 55, Loss: 0.604396641254425, Accuracy: 0.7978515625\n",
      "Batch: 56, Loss: 0.6364021897315979, Accuracy: 0.7880859375\n",
      "Batch: 57, Loss: 0.5914309620857239, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.6557275056838989, Accuracy: 0.7763671875\n",
      "Batch: 59, Loss: 0.5406259298324585, Accuracy: 0.8212890625\n",
      "Batch: 60, Loss: 0.5322055220603943, Accuracy: 0.8193359375\n",
      "Batch: 61, Loss: 0.5839705467224121, Accuracy: 0.802734375\n",
      "Batch: 62, Loss: 0.5097212791442871, Accuracy: 0.837890625\n",
      "Batch: 63, Loss: 0.5444554090499878, Accuracy: 0.8154296875\n",
      "Batch: 64, Loss: 0.5282861590385437, Accuracy: 0.830078125\n",
      "Batch: 65, Loss: 0.5993420481681824, Accuracy: 0.8037109375\n",
      "Batch: 66, Loss: 0.5729719400405884, Accuracy: 0.810546875\n",
      "Batch: 67, Loss: 0.6213788390159607, Accuracy: 0.7958984375\n",
      "Batch: 68, Loss: 0.6789996027946472, Accuracy: 0.759765625\n",
      "Batch: 69, Loss: 0.6389251947402954, Accuracy: 0.7900390625\n",
      "Batch: 70, Loss: 0.5913635492324829, Accuracy: 0.8193359375\n",
      "Batch: 71, Loss: 0.610129177570343, Accuracy: 0.7880859375\n",
      "Batch: 72, Loss: 0.5528717637062073, Accuracy: 0.8134765625\n",
      "Batch: 73, Loss: 0.528552234172821, Accuracy: 0.8408203125\n",
      "Batch: 74, Loss: 0.48366403579711914, Accuracy: 0.849609375\n",
      "Batch: 75, Loss: 0.4844440221786499, Accuracy: 0.8388671875\n",
      "Batch: 76, Loss: 0.5873041152954102, Accuracy: 0.8046875\n",
      "Batch: 77, Loss: 0.5542917847633362, Accuracy: 0.822265625\n",
      "Batch: 78, Loss: 0.5376365184783936, Accuracy: 0.830078125\n",
      "Batch: 79, Loss: 0.5312988758087158, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.555310070514679, Accuracy: 0.8154296875\n",
      "Batch: 81, Loss: 0.6423200368881226, Accuracy: 0.78125\n",
      "Batch: 82, Loss: 0.5561177134513855, Accuracy: 0.8125\n",
      "Batch: 83, Loss: 0.49487584829330444, Accuracy: 0.83984375\n",
      "Batch: 84, Loss: 0.5604158043861389, Accuracy: 0.814453125\n",
      "Batch: 85, Loss: 0.5716693997383118, Accuracy: 0.822265625\n",
      "Batch: 86, Loss: 0.6761725544929504, Accuracy: 0.783203125\n",
      "Batch: 87, Loss: 0.5118205547332764, Accuracy: 0.8388671875\n",
      "Batch: 88, Loss: 0.6171431541442871, Accuracy: 0.80859375\n",
      "Batch: 89, Loss: 0.5953487157821655, Accuracy: 0.81640625\n",
      "Batch: 90, Loss: 0.5535625219345093, Accuracy: 0.826171875\n",
      "Batch: 91, Loss: 0.5533884763717651, Accuracy: 0.81640625\n",
      "Batch: 92, Loss: 0.5990850925445557, Accuracy: 0.8076171875\n",
      "Batch: 93, Loss: 0.5602929592132568, Accuracy: 0.8095703125\n",
      "Batch: 94, Loss: 0.6059121489524841, Accuracy: 0.7998046875\n",
      "Batch: 95, Loss: 0.5939067006111145, Accuracy: 0.8056640625\n",
      "Batch: 96, Loss: 0.5892089605331421, Accuracy: 0.8134765625\n",
      "Batch: 97, Loss: 0.47278857231140137, Accuracy: 0.849609375\n",
      "Batch: 98, Loss: 0.5354664325714111, Accuracy: 0.8203125\n",
      "Batch: 99, Loss: 0.5165307521820068, Accuracy: 0.8330078125\n",
      "Batch: 100, Loss: 0.5991421937942505, Accuracy: 0.794921875\n",
      "Batch: 101, Loss: 0.6006772518157959, Accuracy: 0.7880859375\n",
      "Batch: 102, Loss: 0.5457039475440979, Accuracy: 0.8203125\n",
      "Batch: 103, Loss: 0.6105544567108154, Accuracy: 0.8125\n",
      "Batch: 104, Loss: 0.571962296962738, Accuracy: 0.80859375\n",
      "Batch: 105, Loss: 0.6221879124641418, Accuracy: 0.794921875\n",
      "Batch: 106, Loss: 0.5045741200447083, Accuracy: 0.8369140625\n",
      "Batch: 107, Loss: 0.5647308826446533, Accuracy: 0.82421875\n",
      "Batch: 108, Loss: 0.5628995895385742, Accuracy: 0.818359375\n",
      "Batch: 109, Loss: 0.6199734210968018, Accuracy: 0.8037109375\n",
      "Batch: 110, Loss: 0.5099012851715088, Accuracy: 0.8232421875\n",
      "Batch: 111, Loss: 0.5881073474884033, Accuracy: 0.8095703125\n",
      "Batch: 112, Loss: 0.5587160587310791, Accuracy: 0.810546875\n",
      "Batch: 113, Loss: 0.570130467414856, Accuracy: 0.822265625\n",
      "Batch: 114, Loss: 0.6401029229164124, Accuracy: 0.7978515625\n",
      "Batch: 115, Loss: 0.6066344976425171, Accuracy: 0.7919921875\n",
      "Batch: 116, Loss: 0.5977786183357239, Accuracy: 0.8125\n",
      "Batch: 117, Loss: 0.580172061920166, Accuracy: 0.80859375\n",
      "Batch: 118, Loss: 0.543212890625, Accuracy: 0.8369140625\n",
      "Batch: 119, Loss: 0.5114787817001343, Accuracy: 0.8486328125\n",
      "Batch: 120, Loss: 0.5423467755317688, Accuracy: 0.8115234375\n",
      "Batch: 121, Loss: 0.6196800470352173, Accuracy: 0.80078125\n",
      "Batch: 122, Loss: 0.5748227834701538, Accuracy: 0.8095703125\n",
      "Batch: 123, Loss: 0.5257370471954346, Accuracy: 0.8349609375\n",
      "Batch: 124, Loss: 0.5777879953384399, Accuracy: 0.8134765625\n",
      "Batch: 125, Loss: 0.6006401777267456, Accuracy: 0.80078125\n",
      "Batch: 126, Loss: 0.6053588390350342, Accuracy: 0.8115234375\n",
      "Batch: 127, Loss: 0.5020812749862671, Accuracy: 0.8408203125\n",
      "Batch: 128, Loss: 0.6264839172363281, Accuracy: 0.8125\n",
      "Batch: 129, Loss: 0.5140347480773926, Accuracy: 0.830078125\n",
      "Batch: 130, Loss: 0.6483391523361206, Accuracy: 0.787109375\n",
      "Batch: 131, Loss: 0.5742899179458618, Accuracy: 0.8125\n",
      "Batch: 132, Loss: 0.6037023067474365, Accuracy: 0.806640625\n",
      "Batch: 133, Loss: 0.5699523091316223, Accuracy: 0.802734375\n",
      "Batch: 134, Loss: 0.5796303749084473, Accuracy: 0.8046875\n",
      "Batch: 135, Loss: 0.533446729183197, Accuracy: 0.8203125\n",
      "Batch: 136, Loss: 0.6100590229034424, Accuracy: 0.796875\n",
      "Batch: 137, Loss: 0.5921764373779297, Accuracy: 0.7998046875\n",
      "Batch: 138, Loss: 0.5563732385635376, Accuracy: 0.81640625\n",
      "Batch: 139, Loss: 0.6284621357917786, Accuracy: 0.8017578125\n",
      "Batch: 140, Loss: 0.5744949579238892, Accuracy: 0.8056640625\n",
      "Batch: 141, Loss: 0.6257162094116211, Accuracy: 0.791015625\n",
      "Batch: 142, Loss: 0.582172155380249, Accuracy: 0.8203125\n",
      "Batch: 143, Loss: 0.5970220565795898, Accuracy: 0.810546875\n",
      "Batch: 144, Loss: 0.6088098883628845, Accuracy: 0.796875\n",
      "Batch: 145, Loss: 0.5508278608322144, Accuracy: 0.8125\n",
      "Batch: 146, Loss: 0.5956783294677734, Accuracy: 0.7880859375\n",
      "Batch: 147, Loss: 0.6097703576087952, Accuracy: 0.8125\n",
      "Batch: 148, Loss: 0.6552308797836304, Accuracy: 0.791015625\n",
      "Batch: 149, Loss: 0.5534559488296509, Accuracy: 0.828125\n",
      "Batch: 150, Loss: 0.5655925273895264, Accuracy: 0.80859375\n",
      "Batch: 151, Loss: 0.5034999251365662, Accuracy: 0.8369140625\n",
      "Epoch 56/80\n",
      "Batch: 1, Loss: 0.7730090618133545, Accuracy: 0.7626953125\n",
      "Batch: 2, Loss: 0.6689375638961792, Accuracy: 0.771484375\n",
      "Batch: 3, Loss: 0.5650798082351685, Accuracy: 0.8193359375\n",
      "Batch: 4, Loss: 0.5485658049583435, Accuracy: 0.8291015625\n",
      "Batch: 5, Loss: 0.5736141204833984, Accuracy: 0.828125\n",
      "Batch: 6, Loss: 0.581702470779419, Accuracy: 0.8076171875\n",
      "Batch: 7, Loss: 0.5891304016113281, Accuracy: 0.796875\n",
      "Batch: 8, Loss: 0.5644548535346985, Accuracy: 0.8134765625\n",
      "Batch: 9, Loss: 0.5688915252685547, Accuracy: 0.8134765625\n",
      "Batch: 10, Loss: 0.5729961395263672, Accuracy: 0.7998046875\n",
      "Batch: 11, Loss: 0.6270621418952942, Accuracy: 0.794921875\n",
      "Batch: 12, Loss: 0.5790148973464966, Accuracy: 0.8154296875\n",
      "Batch: 13, Loss: 0.47185564041137695, Accuracy: 0.845703125\n",
      "Batch: 14, Loss: 0.645750880241394, Accuracy: 0.7822265625\n",
      "Batch: 15, Loss: 0.5347194671630859, Accuracy: 0.8310546875\n",
      "Batch: 16, Loss: 0.5479643940925598, Accuracy: 0.833984375\n",
      "Batch: 17, Loss: 0.5723038911819458, Accuracy: 0.8193359375\n",
      "Batch: 18, Loss: 0.6022859811782837, Accuracy: 0.8017578125\n",
      "Batch: 19, Loss: 0.6060509085655212, Accuracy: 0.8134765625\n",
      "Batch: 20, Loss: 0.5225404500961304, Accuracy: 0.8369140625\n",
      "Batch: 21, Loss: 0.5612407922744751, Accuracy: 0.8212890625\n",
      "Batch: 22, Loss: 0.6599577069282532, Accuracy: 0.7900390625\n",
      "Batch: 23, Loss: 0.6324754953384399, Accuracy: 0.798828125\n",
      "Batch: 24, Loss: 0.6179572343826294, Accuracy: 0.8017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 25, Loss: 0.6060894727706909, Accuracy: 0.81640625\n",
      "Batch: 26, Loss: 0.4869333505630493, Accuracy: 0.841796875\n",
      "Batch: 27, Loss: 0.5627899169921875, Accuracy: 0.8017578125\n",
      "Batch: 28, Loss: 0.5895731449127197, Accuracy: 0.81640625\n",
      "Batch: 29, Loss: 0.5722259283065796, Accuracy: 0.80859375\n",
      "Batch: 30, Loss: 0.5051692724227905, Accuracy: 0.8330078125\n",
      "Batch: 31, Loss: 0.508827805519104, Accuracy: 0.8427734375\n",
      "Batch: 32, Loss: 0.5153179168701172, Accuracy: 0.830078125\n",
      "Batch: 33, Loss: 0.5988407135009766, Accuracy: 0.81640625\n",
      "Batch: 34, Loss: 0.6863503456115723, Accuracy: 0.7763671875\n",
      "Batch: 35, Loss: 0.6122174263000488, Accuracy: 0.7880859375\n",
      "Batch: 36, Loss: 0.6016227006912231, Accuracy: 0.81640625\n",
      "Batch: 37, Loss: 0.5905187129974365, Accuracy: 0.8076171875\n",
      "Batch: 38, Loss: 0.5783629417419434, Accuracy: 0.8017578125\n",
      "Batch: 39, Loss: 0.6030921936035156, Accuracy: 0.7998046875\n",
      "Batch: 40, Loss: 0.6063339710235596, Accuracy: 0.8056640625\n",
      "Batch: 41, Loss: 0.5109248161315918, Accuracy: 0.8330078125\n",
      "Batch: 42, Loss: 0.44800716638565063, Accuracy: 0.8515625\n",
      "Batch: 43, Loss: 0.5803350210189819, Accuracy: 0.8056640625\n",
      "Batch: 44, Loss: 0.5463191270828247, Accuracy: 0.798828125\n",
      "Batch: 45, Loss: 0.4886208772659302, Accuracy: 0.841796875\n",
      "Batch: 46, Loss: 0.5032581686973572, Accuracy: 0.83984375\n",
      "Batch: 47, Loss: 0.5074977874755859, Accuracy: 0.8466796875\n",
      "Batch: 48, Loss: 0.5424156188964844, Accuracy: 0.814453125\n",
      "Batch: 49, Loss: 0.5584506392478943, Accuracy: 0.818359375\n",
      "Batch: 50, Loss: 0.5912025570869446, Accuracy: 0.802734375\n",
      "Batch: 51, Loss: 0.5643407106399536, Accuracy: 0.830078125\n",
      "Batch: 52, Loss: 0.5515826940536499, Accuracy: 0.8251953125\n",
      "Batch: 53, Loss: 0.519690215587616, Accuracy: 0.8173828125\n",
      "Batch: 54, Loss: 0.5428922176361084, Accuracy: 0.828125\n",
      "Batch: 55, Loss: 0.6263055801391602, Accuracy: 0.796875\n",
      "Batch: 56, Loss: 0.6133102178573608, Accuracy: 0.80078125\n",
      "Batch: 57, Loss: 0.6062130928039551, Accuracy: 0.8134765625\n",
      "Batch: 58, Loss: 0.6387662887573242, Accuracy: 0.7880859375\n",
      "Batch: 59, Loss: 0.5460987091064453, Accuracy: 0.814453125\n",
      "Batch: 60, Loss: 0.5526247024536133, Accuracy: 0.8125\n",
      "Batch: 61, Loss: 0.5642340183258057, Accuracy: 0.8125\n",
      "Batch: 62, Loss: 0.5282303690910339, Accuracy: 0.822265625\n",
      "Batch: 63, Loss: 0.5648429989814758, Accuracy: 0.82421875\n",
      "Batch: 64, Loss: 0.5184389352798462, Accuracy: 0.83203125\n",
      "Batch: 65, Loss: 0.5603426694869995, Accuracy: 0.8134765625\n",
      "Batch: 66, Loss: 0.572655439376831, Accuracy: 0.802734375\n",
      "Batch: 67, Loss: 0.6076524257659912, Accuracy: 0.81640625\n",
      "Batch: 68, Loss: 0.6832190752029419, Accuracy: 0.7734375\n",
      "Batch: 69, Loss: 0.6167660355567932, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.5882647037506104, Accuracy: 0.80859375\n",
      "Batch: 71, Loss: 0.6214874386787415, Accuracy: 0.7841796875\n",
      "Batch: 72, Loss: 0.5464106798171997, Accuracy: 0.81640625\n",
      "Batch: 73, Loss: 0.5353686809539795, Accuracy: 0.8408203125\n",
      "Batch: 74, Loss: 0.48147058486938477, Accuracy: 0.849609375\n",
      "Batch: 75, Loss: 0.5204201340675354, Accuracy: 0.8271484375\n",
      "Batch: 76, Loss: 0.5641614198684692, Accuracy: 0.8154296875\n",
      "Batch: 77, Loss: 0.5503747463226318, Accuracy: 0.8310546875\n",
      "Batch: 78, Loss: 0.5485202074050903, Accuracy: 0.814453125\n",
      "Batch: 79, Loss: 0.5065997242927551, Accuracy: 0.845703125\n",
      "Batch: 80, Loss: 0.5291926264762878, Accuracy: 0.8212890625\n",
      "Batch: 81, Loss: 0.6086556911468506, Accuracy: 0.796875\n",
      "Batch: 82, Loss: 0.5692907571792603, Accuracy: 0.81640625\n",
      "Batch: 83, Loss: 0.5097314119338989, Accuracy: 0.8310546875\n",
      "Batch: 84, Loss: 0.5954145193099976, Accuracy: 0.7958984375\n",
      "Batch: 85, Loss: 0.5383518934249878, Accuracy: 0.8291015625\n",
      "Batch: 86, Loss: 0.7015880346298218, Accuracy: 0.76171875\n",
      "Batch: 87, Loss: 0.5202488899230957, Accuracy: 0.8349609375\n",
      "Batch: 88, Loss: 0.5978872179985046, Accuracy: 0.81640625\n",
      "Batch: 89, Loss: 0.5670502781867981, Accuracy: 0.82421875\n",
      "Batch: 90, Loss: 0.5652607679367065, Accuracy: 0.8271484375\n",
      "Batch: 91, Loss: 0.5389817953109741, Accuracy: 0.8232421875\n",
      "Batch: 92, Loss: 0.59389328956604, Accuracy: 0.798828125\n",
      "Batch: 93, Loss: 0.5546889901161194, Accuracy: 0.8037109375\n",
      "Batch: 94, Loss: 0.5720973014831543, Accuracy: 0.8095703125\n",
      "Batch: 95, Loss: 0.5890564322471619, Accuracy: 0.796875\n",
      "Batch: 96, Loss: 0.5529236793518066, Accuracy: 0.814453125\n",
      "Batch: 97, Loss: 0.4610711932182312, Accuracy: 0.83984375\n",
      "Batch: 98, Loss: 0.5616040825843811, Accuracy: 0.7958984375\n",
      "Batch: 99, Loss: 0.5506705045700073, Accuracy: 0.8115234375\n",
      "Batch: 100, Loss: 0.5729004740715027, Accuracy: 0.8251953125\n",
      "Batch: 101, Loss: 0.5990341901779175, Accuracy: 0.7939453125\n",
      "Batch: 102, Loss: 0.5955194234848022, Accuracy: 0.814453125\n",
      "Batch: 103, Loss: 0.587529182434082, Accuracy: 0.8095703125\n",
      "Batch: 104, Loss: 0.5238046646118164, Accuracy: 0.8271484375\n",
      "Batch: 105, Loss: 0.6017004251480103, Accuracy: 0.796875\n",
      "Batch: 106, Loss: 0.49928346276283264, Accuracy: 0.8427734375\n",
      "Batch: 107, Loss: 0.5186541676521301, Accuracy: 0.8408203125\n",
      "Batch: 108, Loss: 0.5970966815948486, Accuracy: 0.814453125\n",
      "Batch: 109, Loss: 0.6363339424133301, Accuracy: 0.79296875\n",
      "Batch: 110, Loss: 0.523169994354248, Accuracy: 0.8212890625\n",
      "Batch: 111, Loss: 0.5854827761650085, Accuracy: 0.8095703125\n",
      "Batch: 112, Loss: 0.5732816457748413, Accuracy: 0.814453125\n",
      "Batch: 113, Loss: 0.5920395851135254, Accuracy: 0.8125\n",
      "Batch: 114, Loss: 0.6176310181617737, Accuracy: 0.7998046875\n",
      "Batch: 115, Loss: 0.6074714660644531, Accuracy: 0.8037109375\n",
      "Batch: 116, Loss: 0.6048309803009033, Accuracy: 0.8076171875\n",
      "Batch: 117, Loss: 0.6162070035934448, Accuracy: 0.80078125\n",
      "Batch: 118, Loss: 0.5227182507514954, Accuracy: 0.8369140625\n",
      "Batch: 119, Loss: 0.5144351720809937, Accuracy: 0.8427734375\n",
      "Batch: 120, Loss: 0.5488413572311401, Accuracy: 0.8203125\n",
      "Batch: 121, Loss: 0.6325754523277283, Accuracy: 0.8046875\n",
      "Batch: 122, Loss: 0.5454229712486267, Accuracy: 0.8251953125\n",
      "Batch: 123, Loss: 0.5186580419540405, Accuracy: 0.830078125\n",
      "Batch: 124, Loss: 0.5684293508529663, Accuracy: 0.8232421875\n",
      "Batch: 125, Loss: 0.6003290414810181, Accuracy: 0.8134765625\n",
      "Batch: 126, Loss: 0.6042494773864746, Accuracy: 0.8134765625\n",
      "Batch: 127, Loss: 0.5154445171356201, Accuracy: 0.830078125\n",
      "Batch: 128, Loss: 0.5916075706481934, Accuracy: 0.81640625\n",
      "Batch: 129, Loss: 0.5396103858947754, Accuracy: 0.833984375\n",
      "Batch: 130, Loss: 0.6094886064529419, Accuracy: 0.8037109375\n",
      "Batch: 131, Loss: 0.5669431686401367, Accuracy: 0.806640625\n",
      "Batch: 132, Loss: 0.5973069667816162, Accuracy: 0.806640625\n",
      "Batch: 133, Loss: 0.5659765601158142, Accuracy: 0.8046875\n",
      "Batch: 134, Loss: 0.5956284999847412, Accuracy: 0.798828125\n",
      "Batch: 135, Loss: 0.5449587106704712, Accuracy: 0.8310546875\n",
      "Batch: 136, Loss: 0.5565834641456604, Accuracy: 0.822265625\n",
      "Batch: 137, Loss: 0.5993306040763855, Accuracy: 0.7900390625\n",
      "Batch: 138, Loss: 0.5379661321640015, Accuracy: 0.826171875\n",
      "Batch: 139, Loss: 0.5952746868133545, Accuracy: 0.8017578125\n",
      "Batch: 140, Loss: 0.5685746669769287, Accuracy: 0.8125\n",
      "Batch: 141, Loss: 0.6205582618713379, Accuracy: 0.7978515625\n",
      "Batch: 142, Loss: 0.5928312540054321, Accuracy: 0.80859375\n",
      "Batch: 143, Loss: 0.6285239458084106, Accuracy: 0.7880859375\n",
      "Batch: 144, Loss: 0.612849235534668, Accuracy: 0.8037109375\n",
      "Batch: 145, Loss: 0.5382377505302429, Accuracy: 0.833984375\n",
      "Batch: 146, Loss: 0.6010815501213074, Accuracy: 0.802734375\n",
      "Batch: 147, Loss: 0.5618559718132019, Accuracy: 0.818359375\n",
      "Batch: 148, Loss: 0.6590692400932312, Accuracy: 0.7900390625\n",
      "Batch: 149, Loss: 0.583399772644043, Accuracy: 0.8115234375\n",
      "Batch: 150, Loss: 0.5421780347824097, Accuracy: 0.8125\n",
      "Batch: 151, Loss: 0.5295701026916504, Accuracy: 0.8173828125\n",
      "Epoch 57/80\n",
      "Batch: 1, Loss: 0.7241538166999817, Accuracy: 0.75390625\n",
      "Batch: 2, Loss: 0.6464376449584961, Accuracy: 0.7724609375\n",
      "Batch: 3, Loss: 0.5856121182441711, Accuracy: 0.80859375\n",
      "Batch: 4, Loss: 0.5386012196540833, Accuracy: 0.830078125\n",
      "Batch: 5, Loss: 0.5524969100952148, Accuracy: 0.826171875\n",
      "Batch: 6, Loss: 0.5835276246070862, Accuracy: 0.8046875\n",
      "Batch: 7, Loss: 0.6250709295272827, Accuracy: 0.78515625\n",
      "Batch: 8, Loss: 0.5550553202629089, Accuracy: 0.818359375\n",
      "Batch: 9, Loss: 0.5435432195663452, Accuracy: 0.8251953125\n",
      "Batch: 10, Loss: 0.5393749475479126, Accuracy: 0.826171875\n",
      "Batch: 11, Loss: 0.6277226209640503, Accuracy: 0.7900390625\n",
      "Batch: 12, Loss: 0.5766026973724365, Accuracy: 0.802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 13, Loss: 0.45734864473342896, Accuracy: 0.8544921875\n",
      "Batch: 14, Loss: 0.6250712275505066, Accuracy: 0.802734375\n",
      "Batch: 15, Loss: 0.4965208172798157, Accuracy: 0.8388671875\n",
      "Batch: 16, Loss: 0.5504825115203857, Accuracy: 0.8193359375\n",
      "Batch: 17, Loss: 0.5697442889213562, Accuracy: 0.81640625\n",
      "Batch: 18, Loss: 0.5901472568511963, Accuracy: 0.8212890625\n",
      "Batch: 19, Loss: 0.6125765442848206, Accuracy: 0.8134765625\n",
      "Batch: 20, Loss: 0.5379499197006226, Accuracy: 0.818359375\n",
      "Batch: 21, Loss: 0.5767850875854492, Accuracy: 0.8056640625\n",
      "Batch: 22, Loss: 0.6538860201835632, Accuracy: 0.78125\n",
      "Batch: 23, Loss: 0.6247574687004089, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.6515730619430542, Accuracy: 0.7841796875\n",
      "Batch: 25, Loss: 0.5626837015151978, Accuracy: 0.814453125\n",
      "Batch: 26, Loss: 0.4869194030761719, Accuracy: 0.8408203125\n",
      "Batch: 27, Loss: 0.5111052989959717, Accuracy: 0.8232421875\n",
      "Batch: 28, Loss: 0.5521848797798157, Accuracy: 0.818359375\n",
      "Batch: 29, Loss: 0.5073642730712891, Accuracy: 0.833984375\n",
      "Batch: 30, Loss: 0.4804181456565857, Accuracy: 0.8466796875\n",
      "Batch: 31, Loss: 0.5170098543167114, Accuracy: 0.8349609375\n",
      "Batch: 32, Loss: 0.5198538899421692, Accuracy: 0.8349609375\n",
      "Batch: 33, Loss: 0.614271879196167, Accuracy: 0.806640625\n",
      "Batch: 34, Loss: 0.6626949906349182, Accuracy: 0.78125\n",
      "Batch: 35, Loss: 0.5782532095909119, Accuracy: 0.8125\n",
      "Batch: 36, Loss: 0.5778593420982361, Accuracy: 0.830078125\n",
      "Batch: 37, Loss: 0.584474503993988, Accuracy: 0.8125\n",
      "Batch: 38, Loss: 0.5677852630615234, Accuracy: 0.8115234375\n",
      "Batch: 39, Loss: 0.6091563701629639, Accuracy: 0.806640625\n",
      "Batch: 40, Loss: 0.5584345459938049, Accuracy: 0.8232421875\n",
      "Batch: 41, Loss: 0.5482537150382996, Accuracy: 0.8212890625\n",
      "Batch: 42, Loss: 0.4100745916366577, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.5591294169425964, Accuracy: 0.802734375\n",
      "Batch: 44, Loss: 0.5424731373786926, Accuracy: 0.8330078125\n",
      "Batch: 45, Loss: 0.4873550236225128, Accuracy: 0.845703125\n",
      "Batch: 46, Loss: 0.4921610355377197, Accuracy: 0.84375\n",
      "Batch: 47, Loss: 0.5464282035827637, Accuracy: 0.83984375\n",
      "Batch: 48, Loss: 0.49357736110687256, Accuracy: 0.833984375\n",
      "Batch: 49, Loss: 0.5771389603614807, Accuracy: 0.8154296875\n",
      "Batch: 50, Loss: 0.5526168346405029, Accuracy: 0.8232421875\n",
      "Batch: 51, Loss: 0.5552315711975098, Accuracy: 0.8232421875\n",
      "Batch: 52, Loss: 0.5581605434417725, Accuracy: 0.806640625\n",
      "Batch: 53, Loss: 0.5056668519973755, Accuracy: 0.83203125\n",
      "Batch: 54, Loss: 0.5565246343612671, Accuracy: 0.818359375\n",
      "Batch: 55, Loss: 0.5997020602226257, Accuracy: 0.8017578125\n",
      "Batch: 56, Loss: 0.599091649055481, Accuracy: 0.8017578125\n",
      "Batch: 57, Loss: 0.5931098461151123, Accuracy: 0.798828125\n",
      "Batch: 58, Loss: 0.6634728908538818, Accuracy: 0.791015625\n",
      "Batch: 59, Loss: 0.5587294697761536, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.5277344584465027, Accuracy: 0.8212890625\n",
      "Batch: 61, Loss: 0.5784311890602112, Accuracy: 0.7998046875\n",
      "Batch: 62, Loss: 0.5167302489280701, Accuracy: 0.8251953125\n",
      "Batch: 63, Loss: 0.5629237294197083, Accuracy: 0.8125\n",
      "Batch: 64, Loss: 0.5554994344711304, Accuracy: 0.8193359375\n",
      "Batch: 65, Loss: 0.5679128170013428, Accuracy: 0.8232421875\n",
      "Batch: 66, Loss: 0.5672152638435364, Accuracy: 0.826171875\n",
      "Batch: 67, Loss: 0.6028903722763062, Accuracy: 0.8017578125\n",
      "Batch: 68, Loss: 0.6535542011260986, Accuracy: 0.791015625\n",
      "Batch: 69, Loss: 0.605063796043396, Accuracy: 0.8046875\n",
      "Batch: 70, Loss: 0.6344776153564453, Accuracy: 0.802734375\n",
      "Batch: 71, Loss: 0.64605712890625, Accuracy: 0.767578125\n",
      "Batch: 72, Loss: 0.5583513975143433, Accuracy: 0.822265625\n",
      "Batch: 73, Loss: 0.518054723739624, Accuracy: 0.837890625\n",
      "Batch: 74, Loss: 0.4695613980293274, Accuracy: 0.865234375\n",
      "Batch: 75, Loss: 0.48256927728652954, Accuracy: 0.841796875\n",
      "Batch: 76, Loss: 0.5518270134925842, Accuracy: 0.8125\n",
      "Batch: 77, Loss: 0.5349562168121338, Accuracy: 0.8251953125\n",
      "Batch: 78, Loss: 0.5126336812973022, Accuracy: 0.8349609375\n",
      "Batch: 79, Loss: 0.5230152606964111, Accuracy: 0.8271484375\n",
      "Batch: 80, Loss: 0.5268827080726624, Accuracy: 0.8203125\n",
      "Batch: 81, Loss: 0.6076645851135254, Accuracy: 0.7919921875\n",
      "Batch: 82, Loss: 0.5584608912467957, Accuracy: 0.802734375\n",
      "Batch: 83, Loss: 0.5129854679107666, Accuracy: 0.833984375\n",
      "Batch: 84, Loss: 0.6019641160964966, Accuracy: 0.8037109375\n",
      "Batch: 85, Loss: 0.5623888969421387, Accuracy: 0.8193359375\n",
      "Batch: 86, Loss: 0.6535598039627075, Accuracy: 0.7919921875\n",
      "Batch: 87, Loss: 0.5067523717880249, Accuracy: 0.826171875\n",
      "Batch: 88, Loss: 0.5882518291473389, Accuracy: 0.810546875\n",
      "Batch: 89, Loss: 0.5851616859436035, Accuracy: 0.8056640625\n",
      "Batch: 90, Loss: 0.6015629768371582, Accuracy: 0.7978515625\n",
      "Batch: 91, Loss: 0.5231350660324097, Accuracy: 0.81640625\n",
      "Batch: 92, Loss: 0.5918971300125122, Accuracy: 0.8056640625\n",
      "Batch: 93, Loss: 0.5464842915534973, Accuracy: 0.81640625\n",
      "Batch: 94, Loss: 0.6118134260177612, Accuracy: 0.7978515625\n",
      "Batch: 95, Loss: 0.5918974280357361, Accuracy: 0.80859375\n",
      "Batch: 96, Loss: 0.5686315298080444, Accuracy: 0.814453125\n",
      "Batch: 97, Loss: 0.4311157464981079, Accuracy: 0.8671875\n",
      "Batch: 98, Loss: 0.5217387080192566, Accuracy: 0.81640625\n",
      "Batch: 99, Loss: 0.5299732685089111, Accuracy: 0.8173828125\n",
      "Batch: 100, Loss: 0.5435629487037659, Accuracy: 0.8251953125\n",
      "Batch: 101, Loss: 0.588543176651001, Accuracy: 0.7998046875\n",
      "Batch: 102, Loss: 0.5617802143096924, Accuracy: 0.8203125\n",
      "Batch: 103, Loss: 0.5874518156051636, Accuracy: 0.8046875\n",
      "Batch: 104, Loss: 0.5388911962509155, Accuracy: 0.818359375\n",
      "Batch: 105, Loss: 0.5932189226150513, Accuracy: 0.7900390625\n",
      "Batch: 106, Loss: 0.5217310786247253, Accuracy: 0.830078125\n",
      "Batch: 107, Loss: 0.51605224609375, Accuracy: 0.8310546875\n",
      "Batch: 108, Loss: 0.5737062692642212, Accuracy: 0.80078125\n",
      "Batch: 109, Loss: 0.6290320158004761, Accuracy: 0.7978515625\n",
      "Batch: 110, Loss: 0.5142647624015808, Accuracy: 0.818359375\n",
      "Batch: 111, Loss: 0.5971819162368774, Accuracy: 0.8056640625\n",
      "Batch: 112, Loss: 0.5365708470344543, Accuracy: 0.8349609375\n",
      "Batch: 113, Loss: 0.5712223052978516, Accuracy: 0.810546875\n",
      "Batch: 114, Loss: 0.6496459245681763, Accuracy: 0.802734375\n",
      "Batch: 115, Loss: 0.5763945579528809, Accuracy: 0.8076171875\n",
      "Batch: 116, Loss: 0.5623212456703186, Accuracy: 0.8173828125\n",
      "Batch: 117, Loss: 0.6024205684661865, Accuracy: 0.787109375\n",
      "Batch: 118, Loss: 0.5370664596557617, Accuracy: 0.837890625\n",
      "Batch: 119, Loss: 0.4896424114704132, Accuracy: 0.8486328125\n",
      "Batch: 120, Loss: 0.5512313842773438, Accuracy: 0.8203125\n",
      "Batch: 121, Loss: 0.5995451211929321, Accuracy: 0.8037109375\n",
      "Batch: 122, Loss: 0.5394882559776306, Accuracy: 0.8173828125\n",
      "Batch: 123, Loss: 0.5372483730316162, Accuracy: 0.8193359375\n",
      "Batch: 124, Loss: 0.5792574882507324, Accuracy: 0.80859375\n",
      "Batch: 125, Loss: 0.5920383930206299, Accuracy: 0.802734375\n",
      "Batch: 126, Loss: 0.563701868057251, Accuracy: 0.822265625\n",
      "Batch: 127, Loss: 0.5243662595748901, Accuracy: 0.8349609375\n",
      "Batch: 128, Loss: 0.6378939151763916, Accuracy: 0.810546875\n",
      "Batch: 129, Loss: 0.486671507358551, Accuracy: 0.8310546875\n",
      "Batch: 130, Loss: 0.5843678116798401, Accuracy: 0.8134765625\n",
      "Batch: 131, Loss: 0.5897606611251831, Accuracy: 0.7880859375\n",
      "Batch: 132, Loss: 0.5835529565811157, Accuracy: 0.80859375\n",
      "Batch: 133, Loss: 0.5949591398239136, Accuracy: 0.814453125\n",
      "Batch: 134, Loss: 0.5730433464050293, Accuracy: 0.8115234375\n",
      "Batch: 135, Loss: 0.5374127626419067, Accuracy: 0.8271484375\n",
      "Batch: 136, Loss: 0.6348413825035095, Accuracy: 0.7861328125\n",
      "Batch: 137, Loss: 0.6137444972991943, Accuracy: 0.7890625\n",
      "Batch: 138, Loss: 0.5182784795761108, Accuracy: 0.830078125\n",
      "Batch: 139, Loss: 0.6306827068328857, Accuracy: 0.806640625\n",
      "Batch: 140, Loss: 0.5618731379508972, Accuracy: 0.826171875\n",
      "Batch: 141, Loss: 0.6133615970611572, Accuracy: 0.8017578125\n",
      "Batch: 142, Loss: 0.5983888506889343, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.5817694664001465, Accuracy: 0.814453125\n",
      "Batch: 144, Loss: 0.6100319623947144, Accuracy: 0.7978515625\n",
      "Batch: 145, Loss: 0.5527817010879517, Accuracy: 0.810546875\n",
      "Batch: 146, Loss: 0.598156213760376, Accuracy: 0.8076171875\n",
      "Batch: 147, Loss: 0.5435671806335449, Accuracy: 0.828125\n",
      "Batch: 148, Loss: 0.6492059826850891, Accuracy: 0.7890625\n",
      "Batch: 149, Loss: 0.555137038230896, Accuracy: 0.806640625\n",
      "Batch: 150, Loss: 0.5551380515098572, Accuracy: 0.8203125\n",
      "Batch: 151, Loss: 0.5060680508613586, Accuracy: 0.826171875\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 0.7541702389717102, Accuracy: 0.7666015625\n",
      "Batch: 2, Loss: 0.6661482453346252, Accuracy: 0.7822265625\n",
      "Batch: 3, Loss: 0.5878249406814575, Accuracy: 0.8095703125\n",
      "Batch: 4, Loss: 0.49306803941726685, Accuracy: 0.8564453125\n",
      "Batch: 5, Loss: 0.5643110871315002, Accuracy: 0.8251953125\n",
      "Batch: 6, Loss: 0.5761920809745789, Accuracy: 0.796875\n",
      "Batch: 7, Loss: 0.6372287273406982, Accuracy: 0.7880859375\n",
      "Batch: 8, Loss: 0.554135262966156, Accuracy: 0.8212890625\n",
      "Batch: 9, Loss: 0.5446213483810425, Accuracy: 0.837890625\n",
      "Batch: 10, Loss: 0.5503397583961487, Accuracy: 0.8037109375\n",
      "Batch: 11, Loss: 0.6168267726898193, Accuracy: 0.7861328125\n",
      "Batch: 12, Loss: 0.536793053150177, Accuracy: 0.83203125\n",
      "Batch: 13, Loss: 0.47444432973861694, Accuracy: 0.8505859375\n",
      "Batch: 14, Loss: 0.6338306665420532, Accuracy: 0.78515625\n",
      "Batch: 15, Loss: 0.4954836964607239, Accuracy: 0.8359375\n",
      "Batch: 16, Loss: 0.5432937145233154, Accuracy: 0.826171875\n",
      "Batch: 17, Loss: 0.5579324960708618, Accuracy: 0.814453125\n",
      "Batch: 18, Loss: 0.5731441974639893, Accuracy: 0.8173828125\n",
      "Batch: 19, Loss: 0.6007547974586487, Accuracy: 0.7998046875\n",
      "Batch: 20, Loss: 0.4928879737854004, Accuracy: 0.8427734375\n",
      "Batch: 21, Loss: 0.5710996985435486, Accuracy: 0.8125\n",
      "Batch: 22, Loss: 0.6445108652114868, Accuracy: 0.79296875\n",
      "Batch: 23, Loss: 0.6048043966293335, Accuracy: 0.8017578125\n",
      "Batch: 24, Loss: 0.5868046283721924, Accuracy: 0.80859375\n",
      "Batch: 25, Loss: 0.541873037815094, Accuracy: 0.8271484375\n",
      "Batch: 26, Loss: 0.5054904818534851, Accuracy: 0.83203125\n",
      "Batch: 27, Loss: 0.5299044847488403, Accuracy: 0.818359375\n",
      "Batch: 28, Loss: 0.5669412612915039, Accuracy: 0.8134765625\n",
      "Batch: 29, Loss: 0.5514142513275146, Accuracy: 0.8115234375\n",
      "Batch: 30, Loss: 0.4818211793899536, Accuracy: 0.84375\n",
      "Batch: 31, Loss: 0.5025866031646729, Accuracy: 0.8310546875\n",
      "Batch: 32, Loss: 0.5079909563064575, Accuracy: 0.8310546875\n",
      "Batch: 33, Loss: 0.5957074165344238, Accuracy: 0.822265625\n",
      "Batch: 34, Loss: 0.6415485143661499, Accuracy: 0.7919921875\n",
      "Batch: 35, Loss: 0.5840985774993896, Accuracy: 0.8134765625\n",
      "Batch: 36, Loss: 0.5660374760627747, Accuracy: 0.814453125\n",
      "Batch: 37, Loss: 0.5793470144271851, Accuracy: 0.80859375\n",
      "Batch: 38, Loss: 0.5531875491142273, Accuracy: 0.8203125\n",
      "Batch: 39, Loss: 0.564473569393158, Accuracy: 0.81640625\n",
      "Batch: 40, Loss: 0.5842058658599854, Accuracy: 0.8037109375\n",
      "Batch: 41, Loss: 0.526179313659668, Accuracy: 0.82421875\n",
      "Batch: 42, Loss: 0.44351041316986084, Accuracy: 0.8466796875\n",
      "Batch: 43, Loss: 0.5406550168991089, Accuracy: 0.8125\n",
      "Batch: 44, Loss: 0.5349792838096619, Accuracy: 0.8203125\n",
      "Batch: 45, Loss: 0.4970088601112366, Accuracy: 0.845703125\n",
      "Batch: 46, Loss: 0.4941890239715576, Accuracy: 0.845703125\n",
      "Batch: 47, Loss: 0.5099231004714966, Accuracy: 0.833984375\n",
      "Batch: 48, Loss: 0.5152305364608765, Accuracy: 0.83203125\n",
      "Batch: 49, Loss: 0.5488407611846924, Accuracy: 0.8251953125\n",
      "Batch: 50, Loss: 0.6019505262374878, Accuracy: 0.806640625\n",
      "Batch: 51, Loss: 0.5765860080718994, Accuracy: 0.8134765625\n",
      "Batch: 52, Loss: 0.5338951349258423, Accuracy: 0.818359375\n",
      "Batch: 53, Loss: 0.4748097360134125, Accuracy: 0.822265625\n",
      "Batch: 54, Loss: 0.540463924407959, Accuracy: 0.8271484375\n",
      "Batch: 55, Loss: 0.6007161140441895, Accuracy: 0.7998046875\n",
      "Batch: 56, Loss: 0.6276925802230835, Accuracy: 0.791015625\n",
      "Batch: 57, Loss: 0.5722382664680481, Accuracy: 0.806640625\n",
      "Batch: 58, Loss: 0.6229422092437744, Accuracy: 0.802734375\n",
      "Batch: 59, Loss: 0.5438946485519409, Accuracy: 0.8232421875\n",
      "Batch: 60, Loss: 0.5249881744384766, Accuracy: 0.8291015625\n",
      "Batch: 61, Loss: 0.5611468553543091, Accuracy: 0.802734375\n",
      "Batch: 62, Loss: 0.4866527318954468, Accuracy: 0.8388671875\n",
      "Batch: 63, Loss: 0.5336169004440308, Accuracy: 0.826171875\n",
      "Batch: 64, Loss: 0.5451992154121399, Accuracy: 0.8212890625\n",
      "Batch: 65, Loss: 0.5625318288803101, Accuracy: 0.8203125\n",
      "Batch: 66, Loss: 0.5689029693603516, Accuracy: 0.8154296875\n",
      "Batch: 67, Loss: 0.5851849913597107, Accuracy: 0.810546875\n",
      "Batch: 68, Loss: 0.6700659990310669, Accuracy: 0.7734375\n",
      "Batch: 69, Loss: 0.6030648946762085, Accuracy: 0.79296875\n",
      "Batch: 70, Loss: 0.6100337505340576, Accuracy: 0.8095703125\n",
      "Batch: 71, Loss: 0.6172632575035095, Accuracy: 0.787109375\n",
      "Batch: 72, Loss: 0.5321224927902222, Accuracy: 0.822265625\n",
      "Batch: 73, Loss: 0.4908892810344696, Accuracy: 0.8466796875\n",
      "Batch: 74, Loss: 0.46220454573631287, Accuracy: 0.8671875\n",
      "Batch: 75, Loss: 0.47165095806121826, Accuracy: 0.8408203125\n",
      "Batch: 76, Loss: 0.5512534379959106, Accuracy: 0.8095703125\n",
      "Batch: 77, Loss: 0.5283029675483704, Accuracy: 0.8203125\n",
      "Batch: 78, Loss: 0.5116309523582458, Accuracy: 0.837890625\n",
      "Batch: 79, Loss: 0.5103675127029419, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.5186712741851807, Accuracy: 0.8310546875\n",
      "Batch: 81, Loss: 0.5975155830383301, Accuracy: 0.8046875\n",
      "Batch: 82, Loss: 0.5291974544525146, Accuracy: 0.8212890625\n",
      "Batch: 83, Loss: 0.4888548254966736, Accuracy: 0.837890625\n",
      "Batch: 84, Loss: 0.5801800489425659, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.5452018976211548, Accuracy: 0.837890625\n",
      "Batch: 86, Loss: 0.6462072134017944, Accuracy: 0.8046875\n",
      "Batch: 87, Loss: 0.49202626943588257, Accuracy: 0.833984375\n",
      "Batch: 88, Loss: 0.6209585070610046, Accuracy: 0.7978515625\n",
      "Batch: 89, Loss: 0.578778862953186, Accuracy: 0.8271484375\n",
      "Batch: 90, Loss: 0.540084958076477, Accuracy: 0.818359375\n",
      "Batch: 91, Loss: 0.5069758892059326, Accuracy: 0.8330078125\n",
      "Batch: 92, Loss: 0.600098729133606, Accuracy: 0.80859375\n",
      "Batch: 93, Loss: 0.4992617964744568, Accuracy: 0.845703125\n",
      "Batch: 94, Loss: 0.5402933955192566, Accuracy: 0.8271484375\n",
      "Batch: 95, Loss: 0.5835877656936646, Accuracy: 0.8134765625\n",
      "Batch: 96, Loss: 0.5397598743438721, Accuracy: 0.826171875\n",
      "Batch: 97, Loss: 0.43621063232421875, Accuracy: 0.853515625\n",
      "Batch: 98, Loss: 0.5458534955978394, Accuracy: 0.814453125\n",
      "Batch: 99, Loss: 0.5472049713134766, Accuracy: 0.833984375\n",
      "Batch: 100, Loss: 0.577332615852356, Accuracy: 0.818359375\n",
      "Batch: 101, Loss: 0.5523560047149658, Accuracy: 0.8125\n",
      "Batch: 102, Loss: 0.5768142938613892, Accuracy: 0.802734375\n",
      "Batch: 103, Loss: 0.5615822672843933, Accuracy: 0.82421875\n",
      "Batch: 104, Loss: 0.5147502422332764, Accuracy: 0.84375\n",
      "Batch: 105, Loss: 0.5760034322738647, Accuracy: 0.80859375\n",
      "Batch: 106, Loss: 0.5107619762420654, Accuracy: 0.833984375\n",
      "Batch: 107, Loss: 0.517603874206543, Accuracy: 0.828125\n",
      "Batch: 108, Loss: 0.5431315898895264, Accuracy: 0.81640625\n",
      "Batch: 109, Loss: 0.6149019598960876, Accuracy: 0.7978515625\n",
      "Batch: 110, Loss: 0.49960067868232727, Accuracy: 0.833984375\n",
      "Batch: 111, Loss: 0.5670727491378784, Accuracy: 0.8115234375\n",
      "Batch: 112, Loss: 0.5539162755012512, Accuracy: 0.810546875\n",
      "Batch: 113, Loss: 0.5549267530441284, Accuracy: 0.81640625\n",
      "Batch: 114, Loss: 0.6163957118988037, Accuracy: 0.7939453125\n",
      "Batch: 115, Loss: 0.6115621328353882, Accuracy: 0.806640625\n",
      "Batch: 116, Loss: 0.5445749759674072, Accuracy: 0.8310546875\n",
      "Batch: 117, Loss: 0.5692095160484314, Accuracy: 0.8095703125\n",
      "Batch: 118, Loss: 0.5240710973739624, Accuracy: 0.833984375\n",
      "Batch: 119, Loss: 0.4744580090045929, Accuracy: 0.841796875\n",
      "Batch: 120, Loss: 0.5309418439865112, Accuracy: 0.822265625\n",
      "Batch: 121, Loss: 0.623982310295105, Accuracy: 0.8037109375\n",
      "Batch: 122, Loss: 0.5407522320747375, Accuracy: 0.81640625\n",
      "Batch: 123, Loss: 0.4994008243083954, Accuracy: 0.8359375\n",
      "Batch: 124, Loss: 0.5632731914520264, Accuracy: 0.818359375\n",
      "Batch: 125, Loss: 0.576935350894928, Accuracy: 0.8134765625\n",
      "Batch: 126, Loss: 0.6172809600830078, Accuracy: 0.8046875\n",
      "Batch: 127, Loss: 0.5209575295448303, Accuracy: 0.830078125\n",
      "Batch: 128, Loss: 0.6002377271652222, Accuracy: 0.818359375\n",
      "Batch: 129, Loss: 0.49582433700561523, Accuracy: 0.8388671875\n",
      "Batch: 130, Loss: 0.6117900609970093, Accuracy: 0.7998046875\n",
      "Batch: 131, Loss: 0.5842642784118652, Accuracy: 0.798828125\n",
      "Batch: 132, Loss: 0.6007736921310425, Accuracy: 0.8115234375\n",
      "Batch: 133, Loss: 0.5684665441513062, Accuracy: 0.80078125\n",
      "Batch: 134, Loss: 0.5804886817932129, Accuracy: 0.802734375\n",
      "Batch: 135, Loss: 0.577797532081604, Accuracy: 0.79296875\n",
      "Batch: 136, Loss: 0.5717258453369141, Accuracy: 0.7978515625\n",
      "Batch: 137, Loss: 0.6000988483428955, Accuracy: 0.7998046875\n",
      "Batch: 138, Loss: 0.5234113931655884, Accuracy: 0.8154296875\n",
      "Batch: 139, Loss: 0.5982502102851868, Accuracy: 0.810546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 0.5513585805892944, Accuracy: 0.814453125\n",
      "Batch: 141, Loss: 0.6128858327865601, Accuracy: 0.8037109375\n",
      "Batch: 142, Loss: 0.6164810657501221, Accuracy: 0.796875\n",
      "Batch: 143, Loss: 0.5793325901031494, Accuracy: 0.8154296875\n",
      "Batch: 144, Loss: 0.5822231769561768, Accuracy: 0.8154296875\n",
      "Batch: 145, Loss: 0.49800148606300354, Accuracy: 0.828125\n",
      "Batch: 146, Loss: 0.5855258107185364, Accuracy: 0.798828125\n",
      "Batch: 147, Loss: 0.565422534942627, Accuracy: 0.818359375\n",
      "Batch: 148, Loss: 0.6270867586135864, Accuracy: 0.7998046875\n",
      "Batch: 149, Loss: 0.5767768621444702, Accuracy: 0.80859375\n",
      "Batch: 150, Loss: 0.5648659467697144, Accuracy: 0.822265625\n",
      "Batch: 151, Loss: 0.5143240094184875, Accuracy: 0.8359375\n",
      "Epoch 59/80\n",
      "Batch: 1, Loss: 0.7680525183677673, Accuracy: 0.748046875\n",
      "Batch: 2, Loss: 0.6592761874198914, Accuracy: 0.7744140625\n",
      "Batch: 3, Loss: 0.5861892700195312, Accuracy: 0.8154296875\n",
      "Batch: 4, Loss: 0.5379809141159058, Accuracy: 0.8095703125\n",
      "Batch: 5, Loss: 0.5436467528343201, Accuracy: 0.8203125\n",
      "Batch: 6, Loss: 0.5965311527252197, Accuracy: 0.8037109375\n",
      "Batch: 7, Loss: 0.5737942457199097, Accuracy: 0.8076171875\n",
      "Batch: 8, Loss: 0.5497452020645142, Accuracy: 0.8251953125\n",
      "Batch: 9, Loss: 0.5617767572402954, Accuracy: 0.8203125\n",
      "Batch: 10, Loss: 0.5594123601913452, Accuracy: 0.8115234375\n",
      "Batch: 11, Loss: 0.5976880192756653, Accuracy: 0.8154296875\n",
      "Batch: 12, Loss: 0.6194559335708618, Accuracy: 0.78515625\n",
      "Batch: 13, Loss: 0.4463171362876892, Accuracy: 0.84765625\n",
      "Batch: 14, Loss: 0.6210606694221497, Accuracy: 0.79296875\n",
      "Batch: 15, Loss: 0.5009415149688721, Accuracy: 0.8466796875\n",
      "Batch: 16, Loss: 0.5123138427734375, Accuracy: 0.8388671875\n",
      "Batch: 17, Loss: 0.5554623603820801, Accuracy: 0.818359375\n",
      "Batch: 18, Loss: 0.5954170227050781, Accuracy: 0.8134765625\n",
      "Batch: 19, Loss: 0.6184086799621582, Accuracy: 0.8076171875\n",
      "Batch: 20, Loss: 0.4939848780632019, Accuracy: 0.8515625\n",
      "Batch: 21, Loss: 0.5522387027740479, Accuracy: 0.830078125\n",
      "Batch: 22, Loss: 0.6299570202827454, Accuracy: 0.79296875\n",
      "Batch: 23, Loss: 0.5850971937179565, Accuracy: 0.8017578125\n",
      "Batch: 24, Loss: 0.5851813554763794, Accuracy: 0.8076171875\n",
      "Batch: 25, Loss: 0.5711926221847534, Accuracy: 0.81640625\n",
      "Batch: 26, Loss: 0.4566555917263031, Accuracy: 0.8466796875\n",
      "Batch: 27, Loss: 0.5322479605674744, Accuracy: 0.83203125\n",
      "Batch: 28, Loss: 0.5316183567047119, Accuracy: 0.8251953125\n",
      "Batch: 29, Loss: 0.5308120846748352, Accuracy: 0.8271484375\n",
      "Batch: 30, Loss: 0.4971521198749542, Accuracy: 0.830078125\n",
      "Batch: 31, Loss: 0.5071967840194702, Accuracy: 0.8349609375\n",
      "Batch: 32, Loss: 0.5012742280960083, Accuracy: 0.837890625\n",
      "Batch: 33, Loss: 0.6180648803710938, Accuracy: 0.8056640625\n",
      "Batch: 34, Loss: 0.6500764489173889, Accuracy: 0.7880859375\n",
      "Batch: 35, Loss: 0.5811148881912231, Accuracy: 0.8134765625\n",
      "Batch: 36, Loss: 0.5935218930244446, Accuracy: 0.8115234375\n",
      "Batch: 37, Loss: 0.5448602437973022, Accuracy: 0.83203125\n",
      "Batch: 38, Loss: 0.5345994830131531, Accuracy: 0.8193359375\n",
      "Batch: 39, Loss: 0.5833844542503357, Accuracy: 0.8076171875\n",
      "Batch: 40, Loss: 0.5395433902740479, Accuracy: 0.80859375\n",
      "Batch: 41, Loss: 0.5086731910705566, Accuracy: 0.8349609375\n",
      "Batch: 42, Loss: 0.43832194805145264, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.5220234990119934, Accuracy: 0.8173828125\n",
      "Batch: 44, Loss: 0.5254122614860535, Accuracy: 0.8388671875\n",
      "Batch: 45, Loss: 0.4621468186378479, Accuracy: 0.8515625\n",
      "Batch: 46, Loss: 0.4681723713874817, Accuracy: 0.8525390625\n",
      "Batch: 47, Loss: 0.5111730098724365, Accuracy: 0.8515625\n",
      "Batch: 48, Loss: 0.46158966422080994, Accuracy: 0.8564453125\n",
      "Batch: 49, Loss: 0.5797667503356934, Accuracy: 0.82421875\n",
      "Batch: 50, Loss: 0.5615693926811218, Accuracy: 0.810546875\n",
      "Batch: 51, Loss: 0.5464142560958862, Accuracy: 0.83203125\n",
      "Batch: 52, Loss: 0.5416109561920166, Accuracy: 0.8251953125\n",
      "Batch: 53, Loss: 0.4904111623764038, Accuracy: 0.84375\n",
      "Batch: 54, Loss: 0.5295235514640808, Accuracy: 0.8359375\n",
      "Batch: 55, Loss: 0.6274592280387878, Accuracy: 0.7890625\n",
      "Batch: 56, Loss: 0.6308244466781616, Accuracy: 0.7900390625\n",
      "Batch: 57, Loss: 0.5591171979904175, Accuracy: 0.8076171875\n",
      "Batch: 58, Loss: 0.6060019731521606, Accuracy: 0.7958984375\n",
      "Batch: 59, Loss: 0.5432968139648438, Accuracy: 0.8193359375\n",
      "Batch: 60, Loss: 0.5000885128974915, Accuracy: 0.828125\n",
      "Batch: 61, Loss: 0.5328814387321472, Accuracy: 0.828125\n",
      "Batch: 62, Loss: 0.47421085834503174, Accuracy: 0.849609375\n",
      "Batch: 63, Loss: 0.5512805581092834, Accuracy: 0.81640625\n",
      "Batch: 64, Loss: 0.5356776714324951, Accuracy: 0.8251953125\n",
      "Batch: 65, Loss: 0.5737396478652954, Accuracy: 0.8203125\n",
      "Batch: 66, Loss: 0.5776588320732117, Accuracy: 0.8212890625\n",
      "Batch: 67, Loss: 0.617781937122345, Accuracy: 0.8037109375\n",
      "Batch: 68, Loss: 0.6640049815177917, Accuracy: 0.7783203125\n",
      "Batch: 69, Loss: 0.5999183058738708, Accuracy: 0.7939453125\n",
      "Batch: 70, Loss: 0.5423959493637085, Accuracy: 0.83203125\n",
      "Batch: 71, Loss: 0.6032512784004211, Accuracy: 0.79296875\n",
      "Batch: 72, Loss: 0.501833975315094, Accuracy: 0.8330078125\n",
      "Batch: 73, Loss: 0.5092727541923523, Accuracy: 0.8349609375\n",
      "Batch: 74, Loss: 0.46412068605422974, Accuracy: 0.8623046875\n",
      "Batch: 75, Loss: 0.47904056310653687, Accuracy: 0.8486328125\n",
      "Batch: 76, Loss: 0.5801407098770142, Accuracy: 0.8037109375\n",
      "Batch: 77, Loss: 0.5148113965988159, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.516959011554718, Accuracy: 0.837890625\n",
      "Batch: 79, Loss: 0.5039751529693604, Accuracy: 0.8388671875\n",
      "Batch: 80, Loss: 0.5204065442085266, Accuracy: 0.81640625\n",
      "Batch: 81, Loss: 0.5725589990615845, Accuracy: 0.8095703125\n",
      "Batch: 82, Loss: 0.5299263000488281, Accuracy: 0.822265625\n",
      "Batch: 83, Loss: 0.4665101170539856, Accuracy: 0.853515625\n",
      "Batch: 84, Loss: 0.561203122138977, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.5389751195907593, Accuracy: 0.8251953125\n",
      "Batch: 86, Loss: 0.6456266641616821, Accuracy: 0.798828125\n",
      "Batch: 87, Loss: 0.5127024054527283, Accuracy: 0.8349609375\n",
      "Batch: 88, Loss: 0.6075727939605713, Accuracy: 0.8046875\n",
      "Batch: 89, Loss: 0.5883961915969849, Accuracy: 0.81640625\n",
      "Batch: 90, Loss: 0.5413849353790283, Accuracy: 0.828125\n",
      "Batch: 91, Loss: 0.5560181140899658, Accuracy: 0.8115234375\n",
      "Batch: 92, Loss: 0.539641261100769, Accuracy: 0.818359375\n",
      "Batch: 93, Loss: 0.5184531211853027, Accuracy: 0.8251953125\n",
      "Batch: 94, Loss: 0.5499846935272217, Accuracy: 0.8271484375\n",
      "Batch: 95, Loss: 0.6214832663536072, Accuracy: 0.8046875\n",
      "Batch: 96, Loss: 0.5094494819641113, Accuracy: 0.83984375\n",
      "Batch: 97, Loss: 0.4427286982536316, Accuracy: 0.8486328125\n",
      "Batch: 98, Loss: 0.5282662510871887, Accuracy: 0.8203125\n",
      "Batch: 99, Loss: 0.5139649510383606, Accuracy: 0.8193359375\n",
      "Batch: 100, Loss: 0.5610181093215942, Accuracy: 0.8193359375\n",
      "Batch: 101, Loss: 0.5759108662605286, Accuracy: 0.810546875\n",
      "Batch: 102, Loss: 0.5551474094390869, Accuracy: 0.8271484375\n",
      "Batch: 103, Loss: 0.5641179084777832, Accuracy: 0.826171875\n",
      "Batch: 104, Loss: 0.5107700824737549, Accuracy: 0.8310546875\n",
      "Batch: 105, Loss: 0.6108294725418091, Accuracy: 0.8046875\n",
      "Batch: 106, Loss: 0.5080821514129639, Accuracy: 0.8310546875\n",
      "Batch: 107, Loss: 0.535087525844574, Accuracy: 0.8369140625\n",
      "Batch: 108, Loss: 0.5375243425369263, Accuracy: 0.8125\n",
      "Batch: 109, Loss: 0.6313284635543823, Accuracy: 0.80078125\n",
      "Batch: 110, Loss: 0.4881640076637268, Accuracy: 0.8369140625\n",
      "Batch: 111, Loss: 0.5478758215904236, Accuracy: 0.814453125\n",
      "Batch: 112, Loss: 0.5420806407928467, Accuracy: 0.8349609375\n",
      "Batch: 113, Loss: 0.5524515509605408, Accuracy: 0.8154296875\n",
      "Batch: 114, Loss: 0.6456552147865295, Accuracy: 0.7978515625\n",
      "Batch: 115, Loss: 0.618291974067688, Accuracy: 0.798828125\n",
      "Batch: 116, Loss: 0.5674534440040588, Accuracy: 0.810546875\n",
      "Batch: 117, Loss: 0.598747968673706, Accuracy: 0.802734375\n",
      "Batch: 118, Loss: 0.5136114358901978, Accuracy: 0.826171875\n",
      "Batch: 119, Loss: 0.4706273674964905, Accuracy: 0.8447265625\n",
      "Batch: 120, Loss: 0.4913097620010376, Accuracy: 0.83203125\n",
      "Batch: 121, Loss: 0.5947239398956299, Accuracy: 0.8046875\n",
      "Batch: 122, Loss: 0.5297502875328064, Accuracy: 0.828125\n",
      "Batch: 123, Loss: 0.5262725353240967, Accuracy: 0.84375\n",
      "Batch: 124, Loss: 0.5548383593559265, Accuracy: 0.8095703125\n",
      "Batch: 125, Loss: 0.5711416006088257, Accuracy: 0.81640625\n",
      "Batch: 126, Loss: 0.5943296551704407, Accuracy: 0.8037109375\n",
      "Batch: 127, Loss: 0.4950181841850281, Accuracy: 0.833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 128, Loss: 0.6228101253509521, Accuracy: 0.8017578125\n",
      "Batch: 129, Loss: 0.49915462732315063, Accuracy: 0.8310546875\n",
      "Batch: 130, Loss: 0.6466571688652039, Accuracy: 0.794921875\n",
      "Batch: 131, Loss: 0.5315067768096924, Accuracy: 0.8291015625\n",
      "Batch: 132, Loss: 0.576482892036438, Accuracy: 0.8076171875\n",
      "Batch: 133, Loss: 0.5666819214820862, Accuracy: 0.806640625\n",
      "Batch: 134, Loss: 0.5951371788978577, Accuracy: 0.8017578125\n",
      "Batch: 135, Loss: 0.49939507246017456, Accuracy: 0.8427734375\n",
      "Batch: 136, Loss: 0.5674085021018982, Accuracy: 0.8125\n",
      "Batch: 137, Loss: 0.6068960428237915, Accuracy: 0.7939453125\n",
      "Batch: 138, Loss: 0.5261666774749756, Accuracy: 0.8271484375\n",
      "Batch: 139, Loss: 0.6079223155975342, Accuracy: 0.806640625\n",
      "Batch: 140, Loss: 0.5416536331176758, Accuracy: 0.8203125\n",
      "Batch: 141, Loss: 0.6130433678627014, Accuracy: 0.787109375\n",
      "Batch: 142, Loss: 0.5996968746185303, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.5914284586906433, Accuracy: 0.8095703125\n",
      "Batch: 144, Loss: 0.5845332145690918, Accuracy: 0.8173828125\n",
      "Batch: 145, Loss: 0.5192974209785461, Accuracy: 0.8193359375\n",
      "Batch: 146, Loss: 0.5949143171310425, Accuracy: 0.8115234375\n",
      "Batch: 147, Loss: 0.5381588935852051, Accuracy: 0.8212890625\n",
      "Batch: 148, Loss: 0.6559994220733643, Accuracy: 0.7978515625\n",
      "Batch: 149, Loss: 0.5405787229537964, Accuracy: 0.822265625\n",
      "Batch: 150, Loss: 0.5326310992240906, Accuracy: 0.826171875\n",
      "Batch: 151, Loss: 0.5185975432395935, Accuracy: 0.828125\n",
      "Epoch 60/80\n",
      "Batch: 1, Loss: 0.7310602068901062, Accuracy: 0.7529296875\n",
      "Batch: 2, Loss: 0.6428472995758057, Accuracy: 0.7841796875\n",
      "Batch: 3, Loss: 0.5421831607818604, Accuracy: 0.814453125\n",
      "Batch: 4, Loss: 0.5268413424491882, Accuracy: 0.833984375\n",
      "Batch: 5, Loss: 0.5370829105377197, Accuracy: 0.8359375\n",
      "Batch: 6, Loss: 0.549175500869751, Accuracy: 0.814453125\n",
      "Batch: 7, Loss: 0.5908583402633667, Accuracy: 0.8046875\n",
      "Batch: 8, Loss: 0.5566284656524658, Accuracy: 0.814453125\n",
      "Batch: 9, Loss: 0.5362606048583984, Accuracy: 0.826171875\n",
      "Batch: 10, Loss: 0.5498645305633545, Accuracy: 0.8134765625\n",
      "Batch: 11, Loss: 0.5991232395172119, Accuracy: 0.794921875\n",
      "Batch: 12, Loss: 0.6189372539520264, Accuracy: 0.779296875\n",
      "Batch: 13, Loss: 0.45321327447891235, Accuracy: 0.8623046875\n",
      "Batch: 14, Loss: 0.5878372192382812, Accuracy: 0.7978515625\n",
      "Batch: 15, Loss: 0.4847854971885681, Accuracy: 0.8486328125\n",
      "Batch: 16, Loss: 0.5241673588752747, Accuracy: 0.8349609375\n",
      "Batch: 17, Loss: 0.546354353427887, Accuracy: 0.8212890625\n",
      "Batch: 18, Loss: 0.593269407749176, Accuracy: 0.80859375\n",
      "Batch: 19, Loss: 0.6231873035430908, Accuracy: 0.80078125\n",
      "Batch: 20, Loss: 0.4857574701309204, Accuracy: 0.853515625\n",
      "Batch: 21, Loss: 0.5601950883865356, Accuracy: 0.8154296875\n",
      "Batch: 22, Loss: 0.6528365015983582, Accuracy: 0.7900390625\n",
      "Batch: 23, Loss: 0.5935479998588562, Accuracy: 0.791015625\n",
      "Batch: 24, Loss: 0.6057195663452148, Accuracy: 0.8017578125\n",
      "Batch: 25, Loss: 0.5371483564376831, Accuracy: 0.8203125\n",
      "Batch: 26, Loss: 0.48276081681251526, Accuracy: 0.8349609375\n",
      "Batch: 27, Loss: 0.5373696088790894, Accuracy: 0.81640625\n",
      "Batch: 28, Loss: 0.5611509084701538, Accuracy: 0.8046875\n",
      "Batch: 29, Loss: 0.5370059013366699, Accuracy: 0.814453125\n",
      "Batch: 30, Loss: 0.4914339482784271, Accuracy: 0.8349609375\n",
      "Batch: 31, Loss: 0.47976475954055786, Accuracy: 0.8427734375\n",
      "Batch: 32, Loss: 0.5269153714179993, Accuracy: 0.82421875\n",
      "Batch: 33, Loss: 0.5736837983131409, Accuracy: 0.83203125\n",
      "Batch: 34, Loss: 0.604464590549469, Accuracy: 0.8037109375\n",
      "Batch: 35, Loss: 0.530911922454834, Accuracy: 0.8369140625\n",
      "Batch: 36, Loss: 0.5366782546043396, Accuracy: 0.837890625\n",
      "Batch: 37, Loss: 0.5856918096542358, Accuracy: 0.7939453125\n",
      "Batch: 38, Loss: 0.524806559085846, Accuracy: 0.837890625\n",
      "Batch: 39, Loss: 0.5581490993499756, Accuracy: 0.8203125\n",
      "Batch: 40, Loss: 0.5444157123565674, Accuracy: 0.8232421875\n",
      "Batch: 41, Loss: 0.5156968832015991, Accuracy: 0.8251953125\n",
      "Batch: 42, Loss: 0.4268239140510559, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.5263049602508545, Accuracy: 0.828125\n",
      "Batch: 44, Loss: 0.5599509477615356, Accuracy: 0.818359375\n",
      "Batch: 45, Loss: 0.48103439807891846, Accuracy: 0.8466796875\n",
      "Batch: 46, Loss: 0.4850713610649109, Accuracy: 0.84375\n",
      "Batch: 47, Loss: 0.4994012713432312, Accuracy: 0.8388671875\n",
      "Batch: 48, Loss: 0.4828955829143524, Accuracy: 0.8525390625\n",
      "Batch: 49, Loss: 0.5513899326324463, Accuracy: 0.83203125\n",
      "Batch: 50, Loss: 0.5870451927185059, Accuracy: 0.8125\n",
      "Batch: 51, Loss: 0.5462722182273865, Accuracy: 0.8310546875\n",
      "Batch: 52, Loss: 0.5559062361717224, Accuracy: 0.8173828125\n",
      "Batch: 53, Loss: 0.5006182193756104, Accuracy: 0.8359375\n",
      "Batch: 54, Loss: 0.5162531137466431, Accuracy: 0.8291015625\n",
      "Batch: 55, Loss: 0.6133735179901123, Accuracy: 0.806640625\n",
      "Batch: 56, Loss: 0.5498480200767517, Accuracy: 0.81640625\n",
      "Batch: 57, Loss: 0.5737841129302979, Accuracy: 0.8173828125\n",
      "Batch: 58, Loss: 0.6199194192886353, Accuracy: 0.81640625\n",
      "Batch: 59, Loss: 0.5525838732719421, Accuracy: 0.8212890625\n",
      "Batch: 60, Loss: 0.5364360213279724, Accuracy: 0.822265625\n",
      "Batch: 61, Loss: 0.5461744070053101, Accuracy: 0.8173828125\n",
      "Batch: 62, Loss: 0.4697211682796478, Accuracy: 0.8369140625\n",
      "Batch: 63, Loss: 0.5595359802246094, Accuracy: 0.8134765625\n",
      "Batch: 64, Loss: 0.5226560831069946, Accuracy: 0.8271484375\n",
      "Batch: 65, Loss: 0.5396414995193481, Accuracy: 0.82421875\n",
      "Batch: 66, Loss: 0.5640823841094971, Accuracy: 0.8134765625\n",
      "Batch: 67, Loss: 0.567990243434906, Accuracy: 0.810546875\n",
      "Batch: 68, Loss: 0.6399524211883545, Accuracy: 0.7958984375\n",
      "Batch: 69, Loss: 0.6150323152542114, Accuracy: 0.802734375\n",
      "Batch: 70, Loss: 0.5559948682785034, Accuracy: 0.8251953125\n",
      "Batch: 71, Loss: 0.6123437881469727, Accuracy: 0.779296875\n",
      "Batch: 72, Loss: 0.5144250392913818, Accuracy: 0.8193359375\n",
      "Batch: 73, Loss: 0.5093717575073242, Accuracy: 0.8447265625\n",
      "Batch: 74, Loss: 0.4491490125656128, Accuracy: 0.865234375\n",
      "Batch: 75, Loss: 0.4623301923274994, Accuracy: 0.8564453125\n",
      "Batch: 76, Loss: 0.540632963180542, Accuracy: 0.822265625\n",
      "Batch: 77, Loss: 0.5361396074295044, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.513440728187561, Accuracy: 0.84375\n",
      "Batch: 79, Loss: 0.49487459659576416, Accuracy: 0.83984375\n",
      "Batch: 80, Loss: 0.5245654582977295, Accuracy: 0.83203125\n",
      "Batch: 81, Loss: 0.5558624267578125, Accuracy: 0.8125\n",
      "Batch: 82, Loss: 0.5235856771469116, Accuracy: 0.818359375\n",
      "Batch: 83, Loss: 0.46258288621902466, Accuracy: 0.841796875\n",
      "Batch: 84, Loss: 0.5633851289749146, Accuracy: 0.814453125\n",
      "Batch: 85, Loss: 0.5409424901008606, Accuracy: 0.828125\n",
      "Batch: 86, Loss: 0.6353664994239807, Accuracy: 0.791015625\n",
      "Batch: 87, Loss: 0.48812273144721985, Accuracy: 0.8564453125\n",
      "Batch: 88, Loss: 0.5929685831069946, Accuracy: 0.818359375\n",
      "Batch: 89, Loss: 0.5474042892456055, Accuracy: 0.830078125\n",
      "Batch: 90, Loss: 0.5540525913238525, Accuracy: 0.8154296875\n",
      "Batch: 91, Loss: 0.4922589659690857, Accuracy: 0.8408203125\n",
      "Batch: 92, Loss: 0.5505068302154541, Accuracy: 0.828125\n",
      "Batch: 93, Loss: 0.5000184774398804, Accuracy: 0.8330078125\n",
      "Batch: 94, Loss: 0.5485529899597168, Accuracy: 0.828125\n",
      "Batch: 95, Loss: 0.5587608218193054, Accuracy: 0.818359375\n",
      "Batch: 96, Loss: 0.546188235282898, Accuracy: 0.8232421875\n",
      "Batch: 97, Loss: 0.4342968761920929, Accuracy: 0.865234375\n",
      "Batch: 98, Loss: 0.5389652252197266, Accuracy: 0.8203125\n",
      "Batch: 99, Loss: 0.5048911571502686, Accuracy: 0.8330078125\n",
      "Batch: 100, Loss: 0.5381500124931335, Accuracy: 0.8232421875\n",
      "Batch: 101, Loss: 0.5537087321281433, Accuracy: 0.810546875\n",
      "Batch: 102, Loss: 0.5439680814743042, Accuracy: 0.826171875\n",
      "Batch: 103, Loss: 0.5621723532676697, Accuracy: 0.8232421875\n",
      "Batch: 104, Loss: 0.4970776438713074, Accuracy: 0.8330078125\n",
      "Batch: 105, Loss: 0.5926488637924194, Accuracy: 0.7978515625\n",
      "Batch: 106, Loss: 0.49598586559295654, Accuracy: 0.8466796875\n",
      "Batch: 107, Loss: 0.5127880573272705, Accuracy: 0.8369140625\n",
      "Batch: 108, Loss: 0.546952486038208, Accuracy: 0.81640625\n",
      "Batch: 109, Loss: 0.5626890659332275, Accuracy: 0.82421875\n",
      "Batch: 110, Loss: 0.47247886657714844, Accuracy: 0.8369140625\n",
      "Batch: 111, Loss: 0.5674304366111755, Accuracy: 0.818359375\n",
      "Batch: 112, Loss: 0.5495823621749878, Accuracy: 0.8173828125\n",
      "Batch: 113, Loss: 0.5474894046783447, Accuracy: 0.830078125\n",
      "Batch: 114, Loss: 0.6018736958503723, Accuracy: 0.798828125\n",
      "Batch: 115, Loss: 0.6158490777015686, Accuracy: 0.7861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 116, Loss: 0.5869102478027344, Accuracy: 0.814453125\n",
      "Batch: 117, Loss: 0.5842261910438538, Accuracy: 0.8154296875\n",
      "Batch: 118, Loss: 0.5027015209197998, Accuracy: 0.8388671875\n",
      "Batch: 119, Loss: 0.45353400707244873, Accuracy: 0.8642578125\n",
      "Batch: 120, Loss: 0.5098819732666016, Accuracy: 0.8212890625\n",
      "Batch: 121, Loss: 0.5977790355682373, Accuracy: 0.8125\n",
      "Batch: 122, Loss: 0.4800105094909668, Accuracy: 0.849609375\n",
      "Batch: 123, Loss: 0.49029725790023804, Accuracy: 0.8359375\n",
      "Batch: 124, Loss: 0.5600200891494751, Accuracy: 0.8173828125\n",
      "Batch: 125, Loss: 0.5586878657341003, Accuracy: 0.8173828125\n",
      "Batch: 126, Loss: 0.5615753531455994, Accuracy: 0.8154296875\n",
      "Batch: 127, Loss: 0.4916575253009796, Accuracy: 0.8310546875\n",
      "Batch: 128, Loss: 0.6075580716133118, Accuracy: 0.796875\n",
      "Batch: 129, Loss: 0.5173009634017944, Accuracy: 0.8330078125\n",
      "Batch: 130, Loss: 0.575371503829956, Accuracy: 0.80859375\n",
      "Batch: 131, Loss: 0.5260154008865356, Accuracy: 0.830078125\n",
      "Batch: 132, Loss: 0.5578927397727966, Accuracy: 0.814453125\n",
      "Batch: 133, Loss: 0.5667961835861206, Accuracy: 0.8017578125\n",
      "Batch: 134, Loss: 0.5783528089523315, Accuracy: 0.796875\n",
      "Batch: 135, Loss: 0.5469334125518799, Accuracy: 0.8232421875\n",
      "Batch: 136, Loss: 0.5871039032936096, Accuracy: 0.80859375\n",
      "Batch: 137, Loss: 0.5931538939476013, Accuracy: 0.7900390625\n",
      "Batch: 138, Loss: 0.5184550285339355, Accuracy: 0.8232421875\n",
      "Batch: 139, Loss: 0.5865978002548218, Accuracy: 0.8173828125\n",
      "Batch: 140, Loss: 0.5585112571716309, Accuracy: 0.814453125\n",
      "Batch: 141, Loss: 0.631836473941803, Accuracy: 0.78125\n",
      "Batch: 142, Loss: 0.5632535219192505, Accuracy: 0.8193359375\n",
      "Batch: 143, Loss: 0.5648267865180969, Accuracy: 0.8154296875\n",
      "Batch: 144, Loss: 0.581570565700531, Accuracy: 0.8095703125\n",
      "Batch: 145, Loss: 0.5155550241470337, Accuracy: 0.8203125\n",
      "Batch: 146, Loss: 0.5587091445922852, Accuracy: 0.814453125\n",
      "Batch: 147, Loss: 0.5210986137390137, Accuracy: 0.8212890625\n",
      "Batch: 148, Loss: 0.6236844062805176, Accuracy: 0.7978515625\n",
      "Batch: 149, Loss: 0.5257153511047363, Accuracy: 0.8291015625\n",
      "Batch: 150, Loss: 0.5474758744239807, Accuracy: 0.8193359375\n",
      "Batch: 151, Loss: 0.48966535925865173, Accuracy: 0.837890625\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/80\n",
      "Batch: 1, Loss: 0.7148996591567993, Accuracy: 0.767578125\n",
      "Batch: 2, Loss: 0.6291343569755554, Accuracy: 0.7802734375\n",
      "Batch: 3, Loss: 0.5467795133590698, Accuracy: 0.8115234375\n",
      "Batch: 4, Loss: 0.5360845327377319, Accuracy: 0.830078125\n",
      "Batch: 5, Loss: 0.5363588333129883, Accuracy: 0.8203125\n",
      "Batch: 6, Loss: 0.5628986358642578, Accuracy: 0.8134765625\n",
      "Batch: 7, Loss: 0.5586184859275818, Accuracy: 0.814453125\n",
      "Batch: 8, Loss: 0.5241177678108215, Accuracy: 0.8310546875\n",
      "Batch: 9, Loss: 0.545966386795044, Accuracy: 0.81640625\n",
      "Batch: 10, Loss: 0.5227874517440796, Accuracy: 0.8251953125\n",
      "Batch: 11, Loss: 0.5923737287521362, Accuracy: 0.8076171875\n",
      "Batch: 12, Loss: 0.5828914046287537, Accuracy: 0.810546875\n",
      "Batch: 13, Loss: 0.47475045919418335, Accuracy: 0.8388671875\n",
      "Batch: 14, Loss: 0.5860673785209656, Accuracy: 0.8193359375\n",
      "Batch: 15, Loss: 0.49143487215042114, Accuracy: 0.849609375\n",
      "Batch: 16, Loss: 0.5127027630805969, Accuracy: 0.828125\n",
      "Batch: 17, Loss: 0.5423786044120789, Accuracy: 0.8408203125\n",
      "Batch: 18, Loss: 0.5603801012039185, Accuracy: 0.8271484375\n",
      "Batch: 19, Loss: 0.5868436098098755, Accuracy: 0.8125\n",
      "Batch: 20, Loss: 0.5019376277923584, Accuracy: 0.83984375\n",
      "Batch: 21, Loss: 0.5536192655563354, Accuracy: 0.814453125\n",
      "Batch: 22, Loss: 0.6373803615570068, Accuracy: 0.7861328125\n",
      "Batch: 23, Loss: 0.5801005363464355, Accuracy: 0.8017578125\n",
      "Batch: 24, Loss: 0.6030991077423096, Accuracy: 0.794921875\n",
      "Batch: 25, Loss: 0.5241701602935791, Accuracy: 0.8369140625\n",
      "Batch: 26, Loss: 0.4693114757537842, Accuracy: 0.83984375\n",
      "Batch: 27, Loss: 0.5186625123023987, Accuracy: 0.8232421875\n",
      "Batch: 28, Loss: 0.5210959911346436, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.5217071771621704, Accuracy: 0.830078125\n",
      "Batch: 30, Loss: 0.48956233263015747, Accuracy: 0.837890625\n",
      "Batch: 31, Loss: 0.5056473612785339, Accuracy: 0.830078125\n",
      "Batch: 32, Loss: 0.5197161436080933, Accuracy: 0.828125\n",
      "Batch: 33, Loss: 0.561893880367279, Accuracy: 0.8291015625\n",
      "Batch: 34, Loss: 0.6484482288360596, Accuracy: 0.7978515625\n",
      "Batch: 35, Loss: 0.5689951181411743, Accuracy: 0.798828125\n",
      "Batch: 36, Loss: 0.5418139696121216, Accuracy: 0.8330078125\n",
      "Batch: 37, Loss: 0.5791486501693726, Accuracy: 0.810546875\n",
      "Batch: 38, Loss: 0.533865213394165, Accuracy: 0.8154296875\n",
      "Batch: 39, Loss: 0.5689167976379395, Accuracy: 0.8134765625\n",
      "Batch: 40, Loss: 0.5558538436889648, Accuracy: 0.8095703125\n",
      "Batch: 41, Loss: 0.5348267555236816, Accuracy: 0.8193359375\n",
      "Batch: 42, Loss: 0.42772579193115234, Accuracy: 0.8681640625\n",
      "Batch: 43, Loss: 0.5274190902709961, Accuracy: 0.8251953125\n",
      "Batch: 44, Loss: 0.5113889575004578, Accuracy: 0.8271484375\n",
      "Batch: 45, Loss: 0.44718897342681885, Accuracy: 0.8603515625\n",
      "Batch: 46, Loss: 0.4785999059677124, Accuracy: 0.8310546875\n",
      "Batch: 47, Loss: 0.5051969289779663, Accuracy: 0.8408203125\n",
      "Batch: 48, Loss: 0.47632214426994324, Accuracy: 0.853515625\n",
      "Batch: 49, Loss: 0.5300192832946777, Accuracy: 0.8291015625\n",
      "Batch: 50, Loss: 0.5722441673278809, Accuracy: 0.81640625\n",
      "Batch: 51, Loss: 0.545085072517395, Accuracy: 0.8232421875\n",
      "Batch: 52, Loss: 0.53397536277771, Accuracy: 0.8291015625\n",
      "Batch: 53, Loss: 0.4955567419528961, Accuracy: 0.8388671875\n",
      "Batch: 54, Loss: 0.5343393087387085, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.5875667333602905, Accuracy: 0.80859375\n",
      "Batch: 56, Loss: 0.6289629936218262, Accuracy: 0.7998046875\n",
      "Batch: 57, Loss: 0.5766558647155762, Accuracy: 0.8095703125\n",
      "Batch: 58, Loss: 0.6074897050857544, Accuracy: 0.810546875\n",
      "Batch: 59, Loss: 0.5513213872909546, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.5182479619979858, Accuracy: 0.826171875\n",
      "Batch: 61, Loss: 0.5588972568511963, Accuracy: 0.8095703125\n",
      "Batch: 62, Loss: 0.48723095655441284, Accuracy: 0.837890625\n",
      "Batch: 63, Loss: 0.5331445932388306, Accuracy: 0.8203125\n",
      "Batch: 64, Loss: 0.5284203290939331, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.5760658383369446, Accuracy: 0.814453125\n",
      "Batch: 66, Loss: 0.5529952049255371, Accuracy: 0.8125\n",
      "Batch: 67, Loss: 0.6087027192115784, Accuracy: 0.796875\n",
      "Batch: 68, Loss: 0.632686972618103, Accuracy: 0.7900390625\n",
      "Batch: 69, Loss: 0.587899386882782, Accuracy: 0.7978515625\n",
      "Batch: 70, Loss: 0.5847204923629761, Accuracy: 0.8125\n",
      "Batch: 71, Loss: 0.6231369972229004, Accuracy: 0.7822265625\n",
      "Batch: 72, Loss: 0.5106803774833679, Accuracy: 0.8388671875\n",
      "Batch: 73, Loss: 0.49107086658477783, Accuracy: 0.83984375\n",
      "Batch: 74, Loss: 0.46897706389427185, Accuracy: 0.8505859375\n",
      "Batch: 75, Loss: 0.47443100810050964, Accuracy: 0.83984375\n",
      "Batch: 76, Loss: 0.5249391794204712, Accuracy: 0.8193359375\n",
      "Batch: 77, Loss: 0.5178995728492737, Accuracy: 0.8349609375\n",
      "Batch: 78, Loss: 0.5122953653335571, Accuracy: 0.8369140625\n",
      "Batch: 79, Loss: 0.5008191466331482, Accuracy: 0.8427734375\n",
      "Batch: 80, Loss: 0.5481981635093689, Accuracy: 0.8232421875\n",
      "Batch: 81, Loss: 0.5358670949935913, Accuracy: 0.810546875\n",
      "Batch: 82, Loss: 0.5488673448562622, Accuracy: 0.8095703125\n",
      "Batch: 83, Loss: 0.4702940583229065, Accuracy: 0.8564453125\n",
      "Batch: 84, Loss: 0.538422703742981, Accuracy: 0.814453125\n",
      "Batch: 85, Loss: 0.5125738978385925, Accuracy: 0.8369140625\n",
      "Batch: 86, Loss: 0.6651183366775513, Accuracy: 0.798828125\n",
      "Batch: 87, Loss: 0.4954456686973572, Accuracy: 0.8408203125\n",
      "Batch: 88, Loss: 0.5792809724807739, Accuracy: 0.8125\n",
      "Batch: 89, Loss: 0.5586334466934204, Accuracy: 0.8134765625\n",
      "Batch: 90, Loss: 0.5274618268013, Accuracy: 0.8310546875\n",
      "Batch: 91, Loss: 0.5037403702735901, Accuracy: 0.8388671875\n",
      "Batch: 92, Loss: 0.5396541357040405, Accuracy: 0.822265625\n",
      "Batch: 93, Loss: 0.5015822052955627, Accuracy: 0.826171875\n",
      "Batch: 94, Loss: 0.5418078899383545, Accuracy: 0.8154296875\n",
      "Batch: 95, Loss: 0.5760053992271423, Accuracy: 0.8154296875\n",
      "Batch: 96, Loss: 0.5221246480941772, Accuracy: 0.84375\n",
      "Batch: 97, Loss: 0.4394608438014984, Accuracy: 0.8544921875\n",
      "Batch: 98, Loss: 0.5236065983772278, Accuracy: 0.8251953125\n",
      "Batch: 99, Loss: 0.5187631845474243, Accuracy: 0.8369140625\n",
      "Batch: 100, Loss: 0.5589311122894287, Accuracy: 0.8173828125\n",
      "Batch: 101, Loss: 0.5230189561843872, Accuracy: 0.8154296875\n",
      "Batch: 102, Loss: 0.5081937313079834, Accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 0.5401707887649536, Accuracy: 0.8349609375\n",
      "Batch: 104, Loss: 0.4778735637664795, Accuracy: 0.8349609375\n",
      "Batch: 105, Loss: 0.5552254915237427, Accuracy: 0.8125\n",
      "Batch: 106, Loss: 0.4881904423236847, Accuracy: 0.828125\n",
      "Batch: 107, Loss: 0.5315978527069092, Accuracy: 0.8251953125\n",
      "Batch: 108, Loss: 0.5358637571334839, Accuracy: 0.8193359375\n",
      "Batch: 109, Loss: 0.5984284281730652, Accuracy: 0.8115234375\n",
      "Batch: 110, Loss: 0.47456982731819153, Accuracy: 0.8388671875\n",
      "Batch: 111, Loss: 0.5486128330230713, Accuracy: 0.8330078125\n",
      "Batch: 112, Loss: 0.5275743007659912, Accuracy: 0.8271484375\n",
      "Batch: 113, Loss: 0.5319123864173889, Accuracy: 0.833984375\n",
      "Batch: 114, Loss: 0.6037952899932861, Accuracy: 0.8017578125\n",
      "Batch: 115, Loss: 0.6043775081634521, Accuracy: 0.8046875\n",
      "Batch: 116, Loss: 0.5542715191841125, Accuracy: 0.8095703125\n",
      "Batch: 117, Loss: 0.5578364133834839, Accuracy: 0.8125\n",
      "Batch: 118, Loss: 0.4864095449447632, Accuracy: 0.8515625\n",
      "Batch: 119, Loss: 0.4536641836166382, Accuracy: 0.8515625\n",
      "Batch: 120, Loss: 0.5314856767654419, Accuracy: 0.8203125\n",
      "Batch: 121, Loss: 0.6048479080200195, Accuracy: 0.8056640625\n",
      "Batch: 122, Loss: 0.49153441190719604, Accuracy: 0.8349609375\n",
      "Batch: 123, Loss: 0.523705244064331, Accuracy: 0.8193359375\n",
      "Batch: 124, Loss: 0.5074909925460815, Accuracy: 0.83984375\n",
      "Batch: 125, Loss: 0.5563212633132935, Accuracy: 0.818359375\n",
      "Batch: 126, Loss: 0.574181079864502, Accuracy: 0.8212890625\n",
      "Batch: 127, Loss: 0.48035115003585815, Accuracy: 0.84375\n",
      "Batch: 128, Loss: 0.6033138036727905, Accuracy: 0.8115234375\n",
      "Batch: 129, Loss: 0.48804396390914917, Accuracy: 0.83203125\n",
      "Batch: 130, Loss: 0.560239315032959, Accuracy: 0.826171875\n",
      "Batch: 131, Loss: 0.5279358625411987, Accuracy: 0.8251953125\n",
      "Batch: 132, Loss: 0.5765236020088196, Accuracy: 0.8115234375\n",
      "Batch: 133, Loss: 0.5731650590896606, Accuracy: 0.7939453125\n",
      "Batch: 134, Loss: 0.5287594795227051, Accuracy: 0.822265625\n",
      "Batch: 135, Loss: 0.5250917673110962, Accuracy: 0.8251953125\n",
      "Batch: 136, Loss: 0.548958420753479, Accuracy: 0.8203125\n",
      "Batch: 137, Loss: 0.5725239515304565, Accuracy: 0.8115234375\n",
      "Batch: 138, Loss: 0.5155913829803467, Accuracy: 0.826171875\n",
      "Batch: 139, Loss: 0.6037017107009888, Accuracy: 0.8056640625\n",
      "Batch: 140, Loss: 0.595404863357544, Accuracy: 0.8037109375\n",
      "Batch: 141, Loss: 0.6369203329086304, Accuracy: 0.7958984375\n",
      "Batch: 142, Loss: 0.577940821647644, Accuracy: 0.8125\n",
      "Batch: 143, Loss: 0.5767544507980347, Accuracy: 0.802734375\n",
      "Batch: 144, Loss: 0.5625508427619934, Accuracy: 0.8134765625\n",
      "Batch: 145, Loss: 0.49131086468696594, Accuracy: 0.84375\n",
      "Batch: 146, Loss: 0.6027377247810364, Accuracy: 0.7919921875\n",
      "Batch: 147, Loss: 0.5471177101135254, Accuracy: 0.8154296875\n",
      "Batch: 148, Loss: 0.5949034690856934, Accuracy: 0.8095703125\n",
      "Batch: 149, Loss: 0.5185732841491699, Accuracy: 0.826171875\n",
      "Batch: 150, Loss: 0.5204442739486694, Accuracy: 0.81640625\n",
      "Batch: 151, Loss: 0.5219740271568298, Accuracy: 0.826171875\n",
      "Epoch 62/80\n",
      "Batch: 1, Loss: 0.7215352654457092, Accuracy: 0.7724609375\n",
      "Batch: 2, Loss: 0.6177965402603149, Accuracy: 0.78125\n",
      "Batch: 3, Loss: 0.5416560173034668, Accuracy: 0.81640625\n",
      "Batch: 4, Loss: 0.5168471932411194, Accuracy: 0.8203125\n",
      "Batch: 5, Loss: 0.5207924842834473, Accuracy: 0.8251953125\n",
      "Batch: 6, Loss: 0.5568454265594482, Accuracy: 0.8095703125\n",
      "Batch: 7, Loss: 0.5863133668899536, Accuracy: 0.791015625\n",
      "Batch: 8, Loss: 0.5213979482650757, Accuracy: 0.822265625\n",
      "Batch: 9, Loss: 0.548290491104126, Accuracy: 0.8203125\n",
      "Batch: 10, Loss: 0.5247387290000916, Accuracy: 0.82421875\n",
      "Batch: 11, Loss: 0.5861319303512573, Accuracy: 0.8056640625\n",
      "Batch: 12, Loss: 0.5403438806533813, Accuracy: 0.82421875\n",
      "Batch: 13, Loss: 0.40638941526412964, Accuracy: 0.8583984375\n",
      "Batch: 14, Loss: 0.5815434455871582, Accuracy: 0.806640625\n",
      "Batch: 15, Loss: 0.47660237550735474, Accuracy: 0.8447265625\n",
      "Batch: 16, Loss: 0.4963485598564148, Accuracy: 0.84765625\n",
      "Batch: 17, Loss: 0.5447781085968018, Accuracy: 0.828125\n",
      "Batch: 18, Loss: 0.5665770769119263, Accuracy: 0.8193359375\n",
      "Batch: 19, Loss: 0.5650622844696045, Accuracy: 0.8193359375\n",
      "Batch: 20, Loss: 0.4958690404891968, Accuracy: 0.8349609375\n",
      "Batch: 21, Loss: 0.5284844636917114, Accuracy: 0.8330078125\n",
      "Batch: 22, Loss: 0.6506475210189819, Accuracy: 0.78515625\n",
      "Batch: 23, Loss: 0.5921112895011902, Accuracy: 0.8056640625\n",
      "Batch: 24, Loss: 0.5788511037826538, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5328754782676697, Accuracy: 0.8330078125\n",
      "Batch: 26, Loss: 0.45167458057403564, Accuracy: 0.84765625\n",
      "Batch: 27, Loss: 0.5010029077529907, Accuracy: 0.8291015625\n",
      "Batch: 28, Loss: 0.5517088174819946, Accuracy: 0.8134765625\n",
      "Batch: 29, Loss: 0.5241599678993225, Accuracy: 0.8203125\n",
      "Batch: 30, Loss: 0.454866886138916, Accuracy: 0.861328125\n",
      "Batch: 31, Loss: 0.47558218240737915, Accuracy: 0.8427734375\n",
      "Batch: 32, Loss: 0.5027579069137573, Accuracy: 0.8310546875\n",
      "Batch: 33, Loss: 0.5552645921707153, Accuracy: 0.8193359375\n",
      "Batch: 34, Loss: 0.656915545463562, Accuracy: 0.794921875\n",
      "Batch: 35, Loss: 0.5717778205871582, Accuracy: 0.8251953125\n",
      "Batch: 36, Loss: 0.5657644271850586, Accuracy: 0.8310546875\n",
      "Batch: 37, Loss: 0.557681143283844, Accuracy: 0.80859375\n",
      "Batch: 38, Loss: 0.5319299101829529, Accuracy: 0.8271484375\n",
      "Batch: 39, Loss: 0.5452688932418823, Accuracy: 0.8251953125\n",
      "Batch: 40, Loss: 0.5226689577102661, Accuracy: 0.83203125\n",
      "Batch: 41, Loss: 0.5278577208518982, Accuracy: 0.82421875\n",
      "Batch: 42, Loss: 0.4097924828529358, Accuracy: 0.8544921875\n",
      "Batch: 43, Loss: 0.5164191722869873, Accuracy: 0.830078125\n",
      "Batch: 44, Loss: 0.5435733199119568, Accuracy: 0.818359375\n",
      "Batch: 45, Loss: 0.46719709038734436, Accuracy: 0.853515625\n",
      "Batch: 46, Loss: 0.48361796140670776, Accuracy: 0.8359375\n",
      "Batch: 47, Loss: 0.4495828151702881, Accuracy: 0.8642578125\n",
      "Batch: 48, Loss: 0.5066021084785461, Accuracy: 0.826171875\n",
      "Batch: 49, Loss: 0.5338007211685181, Accuracy: 0.82421875\n",
      "Batch: 50, Loss: 0.5412769913673401, Accuracy: 0.8291015625\n",
      "Batch: 51, Loss: 0.5412886142730713, Accuracy: 0.826171875\n",
      "Batch: 52, Loss: 0.5209481716156006, Accuracy: 0.8330078125\n",
      "Batch: 53, Loss: 0.49768704175949097, Accuracy: 0.8203125\n",
      "Batch: 54, Loss: 0.5397261381149292, Accuracy: 0.826171875\n",
      "Batch: 55, Loss: 0.5794377326965332, Accuracy: 0.796875\n",
      "Batch: 56, Loss: 0.5859735012054443, Accuracy: 0.80078125\n",
      "Batch: 57, Loss: 0.5579034090042114, Accuracy: 0.8212890625\n",
      "Batch: 58, Loss: 0.5907534956932068, Accuracy: 0.8056640625\n",
      "Batch: 59, Loss: 0.5329779386520386, Accuracy: 0.8232421875\n",
      "Batch: 60, Loss: 0.5367083549499512, Accuracy: 0.8232421875\n",
      "Batch: 61, Loss: 0.5522980690002441, Accuracy: 0.826171875\n",
      "Batch: 62, Loss: 0.46961283683776855, Accuracy: 0.8427734375\n",
      "Batch: 63, Loss: 0.5294322967529297, Accuracy: 0.8349609375\n",
      "Batch: 64, Loss: 0.5133006572723389, Accuracy: 0.8369140625\n",
      "Batch: 65, Loss: 0.5335978269577026, Accuracy: 0.8203125\n",
      "Batch: 66, Loss: 0.5430593490600586, Accuracy: 0.8271484375\n",
      "Batch: 67, Loss: 0.5757819414138794, Accuracy: 0.814453125\n",
      "Batch: 68, Loss: 0.6187173128128052, Accuracy: 0.7978515625\n",
      "Batch: 69, Loss: 0.5803896188735962, Accuracy: 0.8115234375\n",
      "Batch: 70, Loss: 0.5953863859176636, Accuracy: 0.818359375\n",
      "Batch: 71, Loss: 0.6137268543243408, Accuracy: 0.7978515625\n",
      "Batch: 72, Loss: 0.506523072719574, Accuracy: 0.8359375\n",
      "Batch: 73, Loss: 0.4784414768218994, Accuracy: 0.8447265625\n",
      "Batch: 74, Loss: 0.47617989778518677, Accuracy: 0.837890625\n",
      "Batch: 75, Loss: 0.47836631536483765, Accuracy: 0.83984375\n",
      "Batch: 76, Loss: 0.5495408773422241, Accuracy: 0.8193359375\n",
      "Batch: 77, Loss: 0.5241820812225342, Accuracy: 0.8251953125\n",
      "Batch: 78, Loss: 0.4996819794178009, Accuracy: 0.833984375\n",
      "Batch: 79, Loss: 0.5228133201599121, Accuracy: 0.83203125\n",
      "Batch: 80, Loss: 0.5009959936141968, Accuracy: 0.8310546875\n",
      "Batch: 81, Loss: 0.5860940217971802, Accuracy: 0.798828125\n",
      "Batch: 82, Loss: 0.5636255741119385, Accuracy: 0.8291015625\n",
      "Batch: 83, Loss: 0.4896172881126404, Accuracy: 0.84375\n",
      "Batch: 84, Loss: 0.5603439211845398, Accuracy: 0.8203125\n",
      "Batch: 85, Loss: 0.5489054918289185, Accuracy: 0.833984375\n",
      "Batch: 86, Loss: 0.668969988822937, Accuracy: 0.7958984375\n",
      "Batch: 87, Loss: 0.4842946231365204, Accuracy: 0.8544921875\n",
      "Batch: 88, Loss: 0.5456552505493164, Accuracy: 0.8212890625\n",
      "Batch: 89, Loss: 0.5560197234153748, Accuracy: 0.8154296875\n",
      "Batch: 90, Loss: 0.5362952351570129, Accuracy: 0.833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 91, Loss: 0.5265101790428162, Accuracy: 0.81640625\n",
      "Batch: 92, Loss: 0.5794837474822998, Accuracy: 0.8076171875\n",
      "Batch: 93, Loss: 0.5618096590042114, Accuracy: 0.8056640625\n",
      "Batch: 94, Loss: 0.5233651399612427, Accuracy: 0.8349609375\n",
      "Batch: 95, Loss: 0.5686826705932617, Accuracy: 0.810546875\n",
      "Batch: 96, Loss: 0.5398848652839661, Accuracy: 0.82421875\n",
      "Batch: 97, Loss: 0.41391003131866455, Accuracy: 0.8681640625\n",
      "Batch: 98, Loss: 0.550426721572876, Accuracy: 0.8125\n",
      "Batch: 99, Loss: 0.49250489473342896, Accuracy: 0.828125\n",
      "Batch: 100, Loss: 0.5379843711853027, Accuracy: 0.837890625\n",
      "Batch: 101, Loss: 0.5619393587112427, Accuracy: 0.8046875\n",
      "Batch: 102, Loss: 0.5380833148956299, Accuracy: 0.8232421875\n",
      "Batch: 103, Loss: 0.5440027713775635, Accuracy: 0.8251953125\n",
      "Batch: 104, Loss: 0.4993993639945984, Accuracy: 0.830078125\n",
      "Batch: 105, Loss: 0.5733810663223267, Accuracy: 0.81640625\n",
      "Batch: 106, Loss: 0.5104365348815918, Accuracy: 0.8369140625\n",
      "Batch: 107, Loss: 0.5234478712081909, Accuracy: 0.84375\n",
      "Batch: 108, Loss: 0.5390881299972534, Accuracy: 0.8193359375\n",
      "Batch: 109, Loss: 0.5994608402252197, Accuracy: 0.7958984375\n",
      "Batch: 110, Loss: 0.452720046043396, Accuracy: 0.84375\n",
      "Batch: 111, Loss: 0.5410215854644775, Accuracy: 0.826171875\n",
      "Batch: 112, Loss: 0.5281078219413757, Accuracy: 0.8173828125\n",
      "Batch: 113, Loss: 0.5956546068191528, Accuracy: 0.810546875\n",
      "Batch: 114, Loss: 0.5922362804412842, Accuracy: 0.8134765625\n",
      "Batch: 115, Loss: 0.5711891651153564, Accuracy: 0.8076171875\n",
      "Batch: 116, Loss: 0.5555779933929443, Accuracy: 0.8291015625\n",
      "Batch: 117, Loss: 0.5829941034317017, Accuracy: 0.8037109375\n",
      "Batch: 118, Loss: 0.4849090576171875, Accuracy: 0.84765625\n",
      "Batch: 119, Loss: 0.4546647071838379, Accuracy: 0.84765625\n",
      "Batch: 120, Loss: 0.5180057883262634, Accuracy: 0.818359375\n",
      "Batch: 121, Loss: 0.60390305519104, Accuracy: 0.798828125\n",
      "Batch: 122, Loss: 0.4967688024044037, Accuracy: 0.841796875\n",
      "Batch: 123, Loss: 0.4926801919937134, Accuracy: 0.8447265625\n",
      "Batch: 124, Loss: 0.5548941493034363, Accuracy: 0.8125\n",
      "Batch: 125, Loss: 0.5773742198944092, Accuracy: 0.8115234375\n",
      "Batch: 126, Loss: 0.546617865562439, Accuracy: 0.8271484375\n",
      "Batch: 127, Loss: 0.47985002398490906, Accuracy: 0.841796875\n",
      "Batch: 128, Loss: 0.5981214046478271, Accuracy: 0.8017578125\n",
      "Batch: 129, Loss: 0.4807172119617462, Accuracy: 0.8359375\n",
      "Batch: 130, Loss: 0.6009281873703003, Accuracy: 0.806640625\n",
      "Batch: 131, Loss: 0.49193698167800903, Accuracy: 0.8408203125\n",
      "Batch: 132, Loss: 0.5641002058982849, Accuracy: 0.830078125\n",
      "Batch: 133, Loss: 0.5487536191940308, Accuracy: 0.8154296875\n",
      "Batch: 134, Loss: 0.5452972650527954, Accuracy: 0.8056640625\n",
      "Batch: 135, Loss: 0.5045849084854126, Accuracy: 0.833984375\n",
      "Batch: 136, Loss: 0.5505848526954651, Accuracy: 0.82421875\n",
      "Batch: 137, Loss: 0.58946692943573, Accuracy: 0.7998046875\n",
      "Batch: 138, Loss: 0.5386185646057129, Accuracy: 0.8193359375\n",
      "Batch: 139, Loss: 0.5962986350059509, Accuracy: 0.8046875\n",
      "Batch: 140, Loss: 0.529516339302063, Accuracy: 0.8251953125\n",
      "Batch: 141, Loss: 0.6404039263725281, Accuracy: 0.79296875\n",
      "Batch: 142, Loss: 0.5679899454116821, Accuracy: 0.8134765625\n",
      "Batch: 143, Loss: 0.5577894449234009, Accuracy: 0.818359375\n",
      "Batch: 144, Loss: 0.5530238747596741, Accuracy: 0.82421875\n",
      "Batch: 145, Loss: 0.5339443683624268, Accuracy: 0.8203125\n",
      "Batch: 146, Loss: 0.5640316605567932, Accuracy: 0.8095703125\n",
      "Batch: 147, Loss: 0.5609757304191589, Accuracy: 0.8251953125\n",
      "Batch: 148, Loss: 0.6253117322921753, Accuracy: 0.80078125\n",
      "Batch: 149, Loss: 0.5179286003112793, Accuracy: 0.8359375\n",
      "Batch: 150, Loss: 0.5518708229064941, Accuracy: 0.8095703125\n",
      "Batch: 151, Loss: 0.511231541633606, Accuracy: 0.83203125\n",
      "Epoch 63/80\n",
      "Batch: 1, Loss: 0.7350123524665833, Accuracy: 0.7578125\n",
      "Batch: 2, Loss: 0.5800433158874512, Accuracy: 0.796875\n",
      "Batch: 3, Loss: 0.5457375049591064, Accuracy: 0.8134765625\n",
      "Batch: 4, Loss: 0.5251142978668213, Accuracy: 0.837890625\n",
      "Batch: 5, Loss: 0.518008291721344, Accuracy: 0.826171875\n",
      "Batch: 6, Loss: 0.5902374982833862, Accuracy: 0.8095703125\n",
      "Batch: 7, Loss: 0.5785359144210815, Accuracy: 0.8095703125\n",
      "Batch: 8, Loss: 0.5283247232437134, Accuracy: 0.8271484375\n",
      "Batch: 9, Loss: 0.53975510597229, Accuracy: 0.828125\n",
      "Batch: 10, Loss: 0.5726422071456909, Accuracy: 0.8076171875\n",
      "Batch: 11, Loss: 0.6105825901031494, Accuracy: 0.7900390625\n",
      "Batch: 12, Loss: 0.5671180486679077, Accuracy: 0.7978515625\n",
      "Batch: 13, Loss: 0.4366748332977295, Accuracy: 0.8505859375\n",
      "Batch: 14, Loss: 0.6112591028213501, Accuracy: 0.791015625\n",
      "Batch: 15, Loss: 0.5416934490203857, Accuracy: 0.810546875\n",
      "Batch: 16, Loss: 0.5390324592590332, Accuracy: 0.818359375\n",
      "Batch: 17, Loss: 0.5662638545036316, Accuracy: 0.80078125\n",
      "Batch: 18, Loss: 0.5567986965179443, Accuracy: 0.8271484375\n",
      "Batch: 19, Loss: 0.5784616470336914, Accuracy: 0.81640625\n",
      "Batch: 20, Loss: 0.47462397813796997, Accuracy: 0.8515625\n",
      "Batch: 21, Loss: 0.5800207257270813, Accuracy: 0.8134765625\n",
      "Batch: 22, Loss: 0.6310379505157471, Accuracy: 0.7880859375\n",
      "Batch: 23, Loss: 0.5730984210968018, Accuracy: 0.8037109375\n",
      "Batch: 24, Loss: 0.5992881655693054, Accuracy: 0.7998046875\n",
      "Batch: 25, Loss: 0.5421893000602722, Accuracy: 0.8271484375\n",
      "Batch: 26, Loss: 0.45909950137138367, Accuracy: 0.8427734375\n",
      "Batch: 27, Loss: 0.5362014174461365, Accuracy: 0.8212890625\n",
      "Batch: 28, Loss: 0.5177211761474609, Accuracy: 0.8271484375\n",
      "Batch: 29, Loss: 0.5076225399971008, Accuracy: 0.8212890625\n",
      "Batch: 30, Loss: 0.4695199728012085, Accuracy: 0.85546875\n",
      "Batch: 31, Loss: 0.5034062266349792, Accuracy: 0.8369140625\n",
      "Batch: 32, Loss: 0.49945640563964844, Accuracy: 0.8330078125\n",
      "Batch: 33, Loss: 0.5794936418533325, Accuracy: 0.8193359375\n",
      "Batch: 34, Loss: 0.6290303468704224, Accuracy: 0.8056640625\n",
      "Batch: 35, Loss: 0.532611608505249, Accuracy: 0.8212890625\n",
      "Batch: 36, Loss: 0.5478345155715942, Accuracy: 0.82421875\n",
      "Batch: 37, Loss: 0.5385886430740356, Accuracy: 0.8193359375\n",
      "Batch: 38, Loss: 0.5020397901535034, Accuracy: 0.841796875\n",
      "Batch: 39, Loss: 0.5731049180030823, Accuracy: 0.8134765625\n",
      "Batch: 40, Loss: 0.5295017957687378, Accuracy: 0.82421875\n",
      "Batch: 41, Loss: 0.5343261361122131, Accuracy: 0.8330078125\n",
      "Batch: 42, Loss: 0.38864967226982117, Accuracy: 0.8662109375\n",
      "Batch: 43, Loss: 0.49346256256103516, Accuracy: 0.826171875\n",
      "Batch: 44, Loss: 0.4955734610557556, Accuracy: 0.8271484375\n",
      "Batch: 45, Loss: 0.4577929973602295, Accuracy: 0.853515625\n",
      "Batch: 46, Loss: 0.4879626929759979, Accuracy: 0.845703125\n",
      "Batch: 47, Loss: 0.4785076081752777, Accuracy: 0.849609375\n",
      "Batch: 48, Loss: 0.47741836309432983, Accuracy: 0.83984375\n",
      "Batch: 49, Loss: 0.5361905694007874, Accuracy: 0.841796875\n",
      "Batch: 50, Loss: 0.5438226461410522, Accuracy: 0.8251953125\n",
      "Batch: 51, Loss: 0.5388438701629639, Accuracy: 0.8310546875\n",
      "Batch: 52, Loss: 0.5369390845298767, Accuracy: 0.8232421875\n",
      "Batch: 53, Loss: 0.4646404981613159, Accuracy: 0.849609375\n",
      "Batch: 54, Loss: 0.49849700927734375, Accuracy: 0.8330078125\n",
      "Batch: 55, Loss: 0.5464464426040649, Accuracy: 0.82421875\n",
      "Batch: 56, Loss: 0.6075487732887268, Accuracy: 0.796875\n",
      "Batch: 57, Loss: 0.539562463760376, Accuracy: 0.8271484375\n",
      "Batch: 58, Loss: 0.6066910028457642, Accuracy: 0.8154296875\n",
      "Batch: 59, Loss: 0.523202121257782, Accuracy: 0.8232421875\n",
      "Batch: 60, Loss: 0.5111929178237915, Accuracy: 0.826171875\n",
      "Batch: 61, Loss: 0.5530685186386108, Accuracy: 0.80078125\n",
      "Batch: 62, Loss: 0.4808693826198578, Accuracy: 0.8427734375\n",
      "Batch: 63, Loss: 0.5386990904808044, Accuracy: 0.818359375\n",
      "Batch: 64, Loss: 0.5165332555770874, Accuracy: 0.826171875\n",
      "Batch: 65, Loss: 0.5532625317573547, Accuracy: 0.806640625\n",
      "Batch: 66, Loss: 0.5576092004776001, Accuracy: 0.8095703125\n",
      "Batch: 67, Loss: 0.5894416570663452, Accuracy: 0.814453125\n",
      "Batch: 68, Loss: 0.6208566427230835, Accuracy: 0.7958984375\n",
      "Batch: 69, Loss: 0.5568650960922241, Accuracy: 0.814453125\n",
      "Batch: 70, Loss: 0.5397971868515015, Accuracy: 0.841796875\n",
      "Batch: 71, Loss: 0.5677162408828735, Accuracy: 0.798828125\n",
      "Batch: 72, Loss: 0.49504798650741577, Accuracy: 0.83203125\n",
      "Batch: 73, Loss: 0.5084964036941528, Accuracy: 0.8349609375\n",
      "Batch: 74, Loss: 0.44741901755332947, Accuracy: 0.8564453125\n",
      "Batch: 75, Loss: 0.4566432535648346, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.5123263597488403, Accuracy: 0.8349609375\n",
      "Batch: 77, Loss: 0.5074827671051025, Accuracy: 0.837890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 78, Loss: 0.5477960109710693, Accuracy: 0.822265625\n",
      "Batch: 79, Loss: 0.4921530485153198, Accuracy: 0.83984375\n",
      "Batch: 80, Loss: 0.5404987335205078, Accuracy: 0.826171875\n",
      "Batch: 81, Loss: 0.5431689023971558, Accuracy: 0.8095703125\n",
      "Batch: 82, Loss: 0.5108610987663269, Accuracy: 0.8369140625\n",
      "Batch: 83, Loss: 0.45863157510757446, Accuracy: 0.8564453125\n",
      "Batch: 84, Loss: 0.5461891293525696, Accuracy: 0.8193359375\n",
      "Batch: 85, Loss: 0.48423874378204346, Accuracy: 0.8466796875\n",
      "Batch: 86, Loss: 0.6417208909988403, Accuracy: 0.7900390625\n",
      "Batch: 87, Loss: 0.45772600173950195, Accuracy: 0.845703125\n",
      "Batch: 88, Loss: 0.5716098546981812, Accuracy: 0.8251953125\n",
      "Batch: 89, Loss: 0.5271081924438477, Accuracy: 0.8408203125\n",
      "Batch: 90, Loss: 0.5261303186416626, Accuracy: 0.83203125\n",
      "Batch: 91, Loss: 0.5258126854896545, Accuracy: 0.83203125\n",
      "Batch: 92, Loss: 0.5562399625778198, Accuracy: 0.8134765625\n",
      "Batch: 93, Loss: 0.49610209465026855, Accuracy: 0.8291015625\n",
      "Batch: 94, Loss: 0.5193420648574829, Accuracy: 0.830078125\n",
      "Batch: 95, Loss: 0.554741621017456, Accuracy: 0.818359375\n",
      "Batch: 96, Loss: 0.5421991944313049, Accuracy: 0.8203125\n",
      "Batch: 97, Loss: 0.40957438945770264, Accuracy: 0.87109375\n",
      "Batch: 98, Loss: 0.5272263884544373, Accuracy: 0.8203125\n",
      "Batch: 99, Loss: 0.49983054399490356, Accuracy: 0.8251953125\n",
      "Batch: 100, Loss: 0.5444098711013794, Accuracy: 0.814453125\n",
      "Batch: 101, Loss: 0.5759273171424866, Accuracy: 0.8095703125\n",
      "Batch: 102, Loss: 0.5171185731887817, Accuracy: 0.83984375\n",
      "Batch: 103, Loss: 0.5685796737670898, Accuracy: 0.828125\n",
      "Batch: 104, Loss: 0.48806118965148926, Accuracy: 0.8291015625\n",
      "Batch: 105, Loss: 0.5773265361785889, Accuracy: 0.806640625\n",
      "Batch: 106, Loss: 0.49925798177719116, Accuracy: 0.830078125\n",
      "Batch: 107, Loss: 0.5235897302627563, Accuracy: 0.822265625\n",
      "Batch: 108, Loss: 0.5574243068695068, Accuracy: 0.81640625\n",
      "Batch: 109, Loss: 0.5867711305618286, Accuracy: 0.802734375\n",
      "Batch: 110, Loss: 0.485612690448761, Accuracy: 0.837890625\n",
      "Batch: 111, Loss: 0.5031439661979675, Accuracy: 0.837890625\n",
      "Batch: 112, Loss: 0.5239315032958984, Accuracy: 0.828125\n",
      "Batch: 113, Loss: 0.5619134902954102, Accuracy: 0.8291015625\n",
      "Batch: 114, Loss: 0.5971333980560303, Accuracy: 0.8017578125\n",
      "Batch: 115, Loss: 0.5467556715011597, Accuracy: 0.82421875\n",
      "Batch: 116, Loss: 0.5456192493438721, Accuracy: 0.8154296875\n",
      "Batch: 117, Loss: 0.5508118867874146, Accuracy: 0.8232421875\n",
      "Batch: 118, Loss: 0.491020143032074, Accuracy: 0.84375\n",
      "Batch: 119, Loss: 0.4803779721260071, Accuracy: 0.8466796875\n",
      "Batch: 120, Loss: 0.5337321758270264, Accuracy: 0.8251953125\n",
      "Batch: 121, Loss: 0.5932556390762329, Accuracy: 0.8017578125\n",
      "Batch: 122, Loss: 0.489141583442688, Accuracy: 0.8447265625\n",
      "Batch: 123, Loss: 0.4675855040550232, Accuracy: 0.8466796875\n",
      "Batch: 124, Loss: 0.535605251789093, Accuracy: 0.8359375\n",
      "Batch: 125, Loss: 0.5181499719619751, Accuracy: 0.830078125\n",
      "Batch: 126, Loss: 0.6034529805183411, Accuracy: 0.798828125\n",
      "Batch: 127, Loss: 0.4766221046447754, Accuracy: 0.830078125\n",
      "Batch: 128, Loss: 0.540195882320404, Accuracy: 0.8193359375\n",
      "Batch: 129, Loss: 0.49649885296821594, Accuracy: 0.8369140625\n",
      "Batch: 130, Loss: 0.5476408004760742, Accuracy: 0.8232421875\n",
      "Batch: 131, Loss: 0.532785177230835, Accuracy: 0.8271484375\n",
      "Batch: 132, Loss: 0.5605591535568237, Accuracy: 0.822265625\n",
      "Batch: 133, Loss: 0.5244969129562378, Accuracy: 0.837890625\n",
      "Batch: 134, Loss: 0.5201512575149536, Accuracy: 0.81640625\n",
      "Batch: 135, Loss: 0.47487348318099976, Accuracy: 0.8408203125\n",
      "Batch: 136, Loss: 0.5575535297393799, Accuracy: 0.81640625\n",
      "Batch: 137, Loss: 0.5756013989448547, Accuracy: 0.8017578125\n",
      "Batch: 138, Loss: 0.503659188747406, Accuracy: 0.8251953125\n",
      "Batch: 139, Loss: 0.5942190885543823, Accuracy: 0.8134765625\n",
      "Batch: 140, Loss: 0.5425512790679932, Accuracy: 0.8173828125\n",
      "Batch: 141, Loss: 0.6040835380554199, Accuracy: 0.8056640625\n",
      "Batch: 142, Loss: 0.6107582449913025, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.5423837900161743, Accuracy: 0.82421875\n",
      "Batch: 144, Loss: 0.5529580116271973, Accuracy: 0.8056640625\n",
      "Batch: 145, Loss: 0.5105611681938171, Accuracy: 0.8212890625\n",
      "Batch: 146, Loss: 0.5404041409492493, Accuracy: 0.8076171875\n",
      "Batch: 147, Loss: 0.5338245630264282, Accuracy: 0.8291015625\n",
      "Batch: 148, Loss: 0.6172018051147461, Accuracy: 0.7890625\n",
      "Batch: 149, Loss: 0.5212432146072388, Accuracy: 0.8349609375\n",
      "Batch: 150, Loss: 0.5271441340446472, Accuracy: 0.828125\n",
      "Batch: 151, Loss: 0.46044284105300903, Accuracy: 0.8515625\n",
      "Epoch 64/80\n",
      "Batch: 1, Loss: 0.7096914052963257, Accuracy: 0.775390625\n",
      "Batch: 2, Loss: 0.623917818069458, Accuracy: 0.7763671875\n",
      "Batch: 3, Loss: 0.549710750579834, Accuracy: 0.8203125\n",
      "Batch: 4, Loss: 0.5257040858268738, Accuracy: 0.8193359375\n",
      "Batch: 5, Loss: 0.5396775603294373, Accuracy: 0.8291015625\n",
      "Batch: 6, Loss: 0.5483121871948242, Accuracy: 0.8193359375\n",
      "Batch: 7, Loss: 0.5398986339569092, Accuracy: 0.8173828125\n",
      "Batch: 8, Loss: 0.5343400239944458, Accuracy: 0.8095703125\n",
      "Batch: 9, Loss: 0.5409306883811951, Accuracy: 0.8291015625\n",
      "Batch: 10, Loss: 0.5184913873672485, Accuracy: 0.826171875\n",
      "Batch: 11, Loss: 0.6085708737373352, Accuracy: 0.7998046875\n",
      "Batch: 12, Loss: 0.5673387050628662, Accuracy: 0.814453125\n",
      "Batch: 13, Loss: 0.4570672810077667, Accuracy: 0.8447265625\n",
      "Batch: 14, Loss: 0.5774568319320679, Accuracy: 0.822265625\n",
      "Batch: 15, Loss: 0.5032669305801392, Accuracy: 0.837890625\n",
      "Batch: 16, Loss: 0.5019681453704834, Accuracy: 0.8408203125\n",
      "Batch: 17, Loss: 0.5590589046478271, Accuracy: 0.8203125\n",
      "Batch: 18, Loss: 0.558892548084259, Accuracy: 0.8291015625\n",
      "Batch: 19, Loss: 0.5947791934013367, Accuracy: 0.8173828125\n",
      "Batch: 20, Loss: 0.4612472951412201, Accuracy: 0.8525390625\n",
      "Batch: 21, Loss: 0.5411809682846069, Accuracy: 0.8173828125\n",
      "Batch: 22, Loss: 0.6038910150527954, Accuracy: 0.806640625\n",
      "Batch: 23, Loss: 0.5823134183883667, Accuracy: 0.80859375\n",
      "Batch: 24, Loss: 0.5896703004837036, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5082575082778931, Accuracy: 0.8447265625\n",
      "Batch: 26, Loss: 0.5025622844696045, Accuracy: 0.826171875\n",
      "Batch: 27, Loss: 0.4883740544319153, Accuracy: 0.8349609375\n",
      "Batch: 28, Loss: 0.5481258630752563, Accuracy: 0.818359375\n",
      "Batch: 29, Loss: 0.5270190834999084, Accuracy: 0.822265625\n",
      "Batch: 30, Loss: 0.4640199542045593, Accuracy: 0.849609375\n",
      "Batch: 31, Loss: 0.4899196922779083, Accuracy: 0.8408203125\n",
      "Batch: 32, Loss: 0.47091490030288696, Accuracy: 0.83984375\n",
      "Batch: 33, Loss: 0.5759035348892212, Accuracy: 0.8095703125\n",
      "Batch: 34, Loss: 0.6380801796913147, Accuracy: 0.7958984375\n",
      "Batch: 35, Loss: 0.5274845361709595, Accuracy: 0.8310546875\n",
      "Batch: 36, Loss: 0.5509812235832214, Accuracy: 0.8330078125\n",
      "Batch: 37, Loss: 0.5415537357330322, Accuracy: 0.814453125\n",
      "Batch: 38, Loss: 0.5278670787811279, Accuracy: 0.83203125\n",
      "Batch: 39, Loss: 0.5587108135223389, Accuracy: 0.8154296875\n",
      "Batch: 40, Loss: 0.5223397016525269, Accuracy: 0.8212890625\n",
      "Batch: 41, Loss: 0.5272426605224609, Accuracy: 0.81640625\n",
      "Batch: 42, Loss: 0.4097544550895691, Accuracy: 0.8642578125\n",
      "Batch: 43, Loss: 0.5131487250328064, Accuracy: 0.818359375\n",
      "Batch: 44, Loss: 0.5266793966293335, Accuracy: 0.8203125\n",
      "Batch: 45, Loss: 0.4890884757041931, Accuracy: 0.8330078125\n",
      "Batch: 46, Loss: 0.459747850894928, Accuracy: 0.8515625\n",
      "Batch: 47, Loss: 0.49092939496040344, Accuracy: 0.8466796875\n",
      "Batch: 48, Loss: 0.49468162655830383, Accuracy: 0.833984375\n",
      "Batch: 49, Loss: 0.542210578918457, Accuracy: 0.833984375\n",
      "Batch: 50, Loss: 0.5392805933952332, Accuracy: 0.8232421875\n",
      "Batch: 51, Loss: 0.5025786757469177, Accuracy: 0.8447265625\n",
      "Batch: 52, Loss: 0.5553638935089111, Accuracy: 0.826171875\n",
      "Batch: 53, Loss: 0.4992811679840088, Accuracy: 0.8203125\n",
      "Batch: 54, Loss: 0.5147514343261719, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.5533384084701538, Accuracy: 0.82421875\n",
      "Batch: 56, Loss: 0.5798801779747009, Accuracy: 0.8125\n",
      "Batch: 57, Loss: 0.535223126411438, Accuracy: 0.82421875\n",
      "Batch: 58, Loss: 0.5911613702774048, Accuracy: 0.80859375\n",
      "Batch: 59, Loss: 0.4956192374229431, Accuracy: 0.8408203125\n",
      "Batch: 60, Loss: 0.5369971990585327, Accuracy: 0.81640625\n",
      "Batch: 61, Loss: 0.5571964979171753, Accuracy: 0.81640625\n",
      "Batch: 62, Loss: 0.4611222743988037, Accuracy: 0.845703125\n",
      "Batch: 63, Loss: 0.5268747806549072, Accuracy: 0.8369140625\n",
      "Batch: 64, Loss: 0.5317952632904053, Accuracy: 0.822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 65, Loss: 0.5173559784889221, Accuracy: 0.8251953125\n",
      "Batch: 66, Loss: 0.5353429913520813, Accuracy: 0.8359375\n",
      "Batch: 67, Loss: 0.5889027118682861, Accuracy: 0.8095703125\n",
      "Batch: 68, Loss: 0.631222665309906, Accuracy: 0.796875\n",
      "Batch: 69, Loss: 0.5398670434951782, Accuracy: 0.8203125\n",
      "Batch: 70, Loss: 0.5597594976425171, Accuracy: 0.818359375\n",
      "Batch: 71, Loss: 0.5768982172012329, Accuracy: 0.8017578125\n",
      "Batch: 72, Loss: 0.48779234290122986, Accuracy: 0.8271484375\n",
      "Batch: 73, Loss: 0.5205883979797363, Accuracy: 0.8291015625\n",
      "Batch: 74, Loss: 0.44280362129211426, Accuracy: 0.86328125\n",
      "Batch: 75, Loss: 0.4738459587097168, Accuracy: 0.84375\n",
      "Batch: 76, Loss: 0.5576395988464355, Accuracy: 0.8232421875\n",
      "Batch: 77, Loss: 0.5097109079360962, Accuracy: 0.8408203125\n",
      "Batch: 78, Loss: 0.49667757749557495, Accuracy: 0.8447265625\n",
      "Batch: 79, Loss: 0.4672461152076721, Accuracy: 0.8544921875\n",
      "Batch: 80, Loss: 0.4904126822948456, Accuracy: 0.8388671875\n",
      "Batch: 81, Loss: 0.5438347458839417, Accuracy: 0.8095703125\n",
      "Batch: 82, Loss: 0.5092328786849976, Accuracy: 0.8369140625\n",
      "Batch: 83, Loss: 0.45659884810447693, Accuracy: 0.8427734375\n",
      "Batch: 84, Loss: 0.5361149907112122, Accuracy: 0.81640625\n",
      "Batch: 85, Loss: 0.5023996233940125, Accuracy: 0.841796875\n",
      "Batch: 86, Loss: 0.6144810914993286, Accuracy: 0.796875\n",
      "Batch: 87, Loss: 0.48477253317832947, Accuracy: 0.845703125\n",
      "Batch: 88, Loss: 0.582854688167572, Accuracy: 0.814453125\n",
      "Batch: 89, Loss: 0.5472583174705505, Accuracy: 0.8251953125\n",
      "Batch: 90, Loss: 0.541113018989563, Accuracy: 0.826171875\n",
      "Batch: 91, Loss: 0.5167132616043091, Accuracy: 0.8173828125\n",
      "Batch: 92, Loss: 0.5324063301086426, Accuracy: 0.82421875\n",
      "Batch: 93, Loss: 0.4953378438949585, Accuracy: 0.8349609375\n",
      "Batch: 94, Loss: 0.5107995867729187, Accuracy: 0.830078125\n",
      "Batch: 95, Loss: 0.5793160200119019, Accuracy: 0.8095703125\n",
      "Batch: 96, Loss: 0.5116559863090515, Accuracy: 0.8291015625\n",
      "Batch: 97, Loss: 0.41906964778900146, Accuracy: 0.8671875\n",
      "Batch: 98, Loss: 0.5139508843421936, Accuracy: 0.8271484375\n",
      "Batch: 99, Loss: 0.4886482357978821, Accuracy: 0.8271484375\n",
      "Batch: 100, Loss: 0.5447708368301392, Accuracy: 0.822265625\n",
      "Batch: 101, Loss: 0.5428455471992493, Accuracy: 0.80859375\n",
      "Batch: 102, Loss: 0.5208737850189209, Accuracy: 0.8193359375\n",
      "Batch: 103, Loss: 0.5279322266578674, Accuracy: 0.833984375\n",
      "Batch: 104, Loss: 0.5009229183197021, Accuracy: 0.8310546875\n",
      "Batch: 105, Loss: 0.5380650162696838, Accuracy: 0.8134765625\n",
      "Batch: 106, Loss: 0.4512280821800232, Accuracy: 0.8486328125\n",
      "Batch: 107, Loss: 0.5044803619384766, Accuracy: 0.8369140625\n",
      "Batch: 108, Loss: 0.5363379120826721, Accuracy: 0.8203125\n",
      "Batch: 109, Loss: 0.5942107439041138, Accuracy: 0.80859375\n",
      "Batch: 110, Loss: 0.4729933738708496, Accuracy: 0.8447265625\n",
      "Batch: 111, Loss: 0.5185191631317139, Accuracy: 0.822265625\n",
      "Batch: 112, Loss: 0.5114028453826904, Accuracy: 0.8232421875\n",
      "Batch: 113, Loss: 0.5384687781333923, Accuracy: 0.8330078125\n",
      "Batch: 114, Loss: 0.5543161034584045, Accuracy: 0.8193359375\n",
      "Batch: 115, Loss: 0.5798020362854004, Accuracy: 0.8125\n",
      "Batch: 116, Loss: 0.5415927171707153, Accuracy: 0.8173828125\n",
      "Batch: 117, Loss: 0.5386041402816772, Accuracy: 0.8193359375\n",
      "Batch: 118, Loss: 0.5148203372955322, Accuracy: 0.8291015625\n",
      "Batch: 119, Loss: 0.41315796971321106, Accuracy: 0.8564453125\n",
      "Batch: 120, Loss: 0.5128326416015625, Accuracy: 0.8369140625\n",
      "Batch: 121, Loss: 0.5894860029220581, Accuracy: 0.8076171875\n",
      "Batch: 122, Loss: 0.48901113867759705, Accuracy: 0.8359375\n",
      "Batch: 123, Loss: 0.4876275062561035, Accuracy: 0.83984375\n",
      "Batch: 124, Loss: 0.519690990447998, Accuracy: 0.8310546875\n",
      "Batch: 125, Loss: 0.5722247362136841, Accuracy: 0.8154296875\n",
      "Batch: 126, Loss: 0.5333802700042725, Accuracy: 0.83203125\n",
      "Batch: 127, Loss: 0.4885396361351013, Accuracy: 0.8408203125\n",
      "Batch: 128, Loss: 0.5934123992919922, Accuracy: 0.8095703125\n",
      "Batch: 129, Loss: 0.4870617687702179, Accuracy: 0.8466796875\n",
      "Batch: 130, Loss: 0.5641448497772217, Accuracy: 0.814453125\n",
      "Batch: 131, Loss: 0.5131668448448181, Accuracy: 0.8291015625\n",
      "Batch: 132, Loss: 0.5565651059150696, Accuracy: 0.8115234375\n",
      "Batch: 133, Loss: 0.5416072607040405, Accuracy: 0.8251953125\n",
      "Batch: 134, Loss: 0.541275143623352, Accuracy: 0.8115234375\n",
      "Batch: 135, Loss: 0.49531692266464233, Accuracy: 0.837890625\n",
      "Batch: 136, Loss: 0.5352399349212646, Accuracy: 0.8251953125\n",
      "Batch: 137, Loss: 0.5532857179641724, Accuracy: 0.8115234375\n",
      "Batch: 138, Loss: 0.5054156184196472, Accuracy: 0.8408203125\n",
      "Batch: 139, Loss: 0.5830321311950684, Accuracy: 0.8203125\n",
      "Batch: 140, Loss: 0.5455230474472046, Accuracy: 0.8173828125\n",
      "Batch: 141, Loss: 0.562147319316864, Accuracy: 0.8212890625\n",
      "Batch: 142, Loss: 0.5536920428276062, Accuracy: 0.8134765625\n",
      "Batch: 143, Loss: 0.5655664801597595, Accuracy: 0.828125\n",
      "Batch: 144, Loss: 0.5535091757774353, Accuracy: 0.8212890625\n",
      "Batch: 145, Loss: 0.4781002402305603, Accuracy: 0.8427734375\n",
      "Batch: 146, Loss: 0.5529292821884155, Accuracy: 0.8193359375\n",
      "Batch: 147, Loss: 0.5465964078903198, Accuracy: 0.8095703125\n",
      "Batch: 148, Loss: 0.6179263591766357, Accuracy: 0.796875\n",
      "Batch: 149, Loss: 0.49009498953819275, Accuracy: 0.8408203125\n",
      "Batch: 150, Loss: 0.5334310531616211, Accuracy: 0.8271484375\n",
      "Batch: 151, Loss: 0.5002983808517456, Accuracy: 0.8291015625\n",
      "Epoch 65/80\n",
      "Batch: 1, Loss: 0.6980619430541992, Accuracy: 0.771484375\n",
      "Batch: 2, Loss: 0.6130461692810059, Accuracy: 0.7880859375\n",
      "Batch: 3, Loss: 0.5661572217941284, Accuracy: 0.8134765625\n",
      "Batch: 4, Loss: 0.5176035165786743, Accuracy: 0.8330078125\n",
      "Batch: 5, Loss: 0.5041307210922241, Accuracy: 0.83203125\n",
      "Batch: 6, Loss: 0.5836225748062134, Accuracy: 0.7978515625\n",
      "Batch: 7, Loss: 0.5652673244476318, Accuracy: 0.7978515625\n",
      "Batch: 8, Loss: 0.5140151977539062, Accuracy: 0.83203125\n",
      "Batch: 9, Loss: 0.5421310663223267, Accuracy: 0.82421875\n",
      "Batch: 10, Loss: 0.5011601448059082, Accuracy: 0.8271484375\n",
      "Batch: 11, Loss: 0.5567812919616699, Accuracy: 0.8251953125\n",
      "Batch: 12, Loss: 0.5448911786079407, Accuracy: 0.8134765625\n",
      "Batch: 13, Loss: 0.43284863233566284, Accuracy: 0.8564453125\n",
      "Batch: 14, Loss: 0.5598009824752808, Accuracy: 0.828125\n",
      "Batch: 15, Loss: 0.4714447557926178, Accuracy: 0.8544921875\n",
      "Batch: 16, Loss: 0.4933227300643921, Accuracy: 0.84375\n",
      "Batch: 17, Loss: 0.5336406826972961, Accuracy: 0.8388671875\n",
      "Batch: 18, Loss: 0.5553215742111206, Accuracy: 0.8173828125\n",
      "Batch: 19, Loss: 0.5823755264282227, Accuracy: 0.814453125\n",
      "Batch: 20, Loss: 0.46738171577453613, Accuracy: 0.845703125\n",
      "Batch: 21, Loss: 0.5261915922164917, Accuracy: 0.822265625\n",
      "Batch: 22, Loss: 0.5833777785301208, Accuracy: 0.814453125\n",
      "Batch: 23, Loss: 0.5620100498199463, Accuracy: 0.8037109375\n",
      "Batch: 24, Loss: 0.5934768915176392, Accuracy: 0.80859375\n",
      "Batch: 25, Loss: 0.5476921796798706, Accuracy: 0.830078125\n",
      "Batch: 26, Loss: 0.4470331072807312, Accuracy: 0.85546875\n",
      "Batch: 27, Loss: 0.48596227169036865, Accuracy: 0.8388671875\n",
      "Batch: 28, Loss: 0.5124523639678955, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.4862695634365082, Accuracy: 0.8388671875\n",
      "Batch: 30, Loss: 0.4545535743236542, Accuracy: 0.8505859375\n",
      "Batch: 31, Loss: 0.4735177159309387, Accuracy: 0.8408203125\n",
      "Batch: 32, Loss: 0.4995061159133911, Accuracy: 0.826171875\n",
      "Batch: 33, Loss: 0.5480232238769531, Accuracy: 0.8388671875\n",
      "Batch: 34, Loss: 0.6042215824127197, Accuracy: 0.794921875\n",
      "Batch: 35, Loss: 0.5310302972793579, Accuracy: 0.830078125\n",
      "Batch: 36, Loss: 0.5667494535446167, Accuracy: 0.810546875\n",
      "Batch: 37, Loss: 0.5539727807044983, Accuracy: 0.8154296875\n",
      "Batch: 38, Loss: 0.5577645301818848, Accuracy: 0.814453125\n",
      "Batch: 39, Loss: 0.548111617565155, Accuracy: 0.814453125\n",
      "Batch: 40, Loss: 0.5275759100914001, Accuracy: 0.8388671875\n",
      "Batch: 41, Loss: 0.49802303314208984, Accuracy: 0.8359375\n",
      "Batch: 42, Loss: 0.4348713159561157, Accuracy: 0.85546875\n",
      "Batch: 43, Loss: 0.5050368309020996, Accuracy: 0.8203125\n",
      "Batch: 44, Loss: 0.5289891958236694, Accuracy: 0.828125\n",
      "Batch: 45, Loss: 0.464141845703125, Accuracy: 0.845703125\n",
      "Batch: 46, Loss: 0.4904714524745941, Accuracy: 0.83203125\n",
      "Batch: 47, Loss: 0.47694966197013855, Accuracy: 0.8544921875\n",
      "Batch: 48, Loss: 0.47913819551467896, Accuracy: 0.8427734375\n",
      "Batch: 49, Loss: 0.5200386643409729, Accuracy: 0.8388671875\n",
      "Batch: 50, Loss: 0.5578120946884155, Accuracy: 0.8173828125\n",
      "Batch: 51, Loss: 0.5326752662658691, Accuracy: 0.8310546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 52, Loss: 0.5196505784988403, Accuracy: 0.828125\n",
      "Batch: 53, Loss: 0.4651379883289337, Accuracy: 0.8369140625\n",
      "Batch: 54, Loss: 0.5256521105766296, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.5679574608802795, Accuracy: 0.8193359375\n",
      "Batch: 56, Loss: 0.5510567426681519, Accuracy: 0.814453125\n",
      "Batch: 57, Loss: 0.5363917350769043, Accuracy: 0.828125\n",
      "Batch: 58, Loss: 0.5705801248550415, Accuracy: 0.7958984375\n",
      "Batch: 59, Loss: 0.5101124048233032, Accuracy: 0.83984375\n",
      "Batch: 60, Loss: 0.5038940906524658, Accuracy: 0.8369140625\n",
      "Batch: 61, Loss: 0.5452136993408203, Accuracy: 0.8134765625\n",
      "Batch: 62, Loss: 0.46909648180007935, Accuracy: 0.845703125\n",
      "Batch: 63, Loss: 0.515413761138916, Accuracy: 0.830078125\n",
      "Batch: 64, Loss: 0.5069425702095032, Accuracy: 0.837890625\n",
      "Batch: 65, Loss: 0.5117093324661255, Accuracy: 0.8232421875\n",
      "Batch: 66, Loss: 0.5464292168617249, Accuracy: 0.82421875\n",
      "Batch: 67, Loss: 0.5602697730064392, Accuracy: 0.8125\n",
      "Batch: 68, Loss: 0.6232584714889526, Accuracy: 0.79296875\n",
      "Batch: 69, Loss: 0.5603300333023071, Accuracy: 0.8232421875\n",
      "Batch: 70, Loss: 0.5511475205421448, Accuracy: 0.8251953125\n",
      "Batch: 71, Loss: 0.5851765871047974, Accuracy: 0.794921875\n",
      "Batch: 72, Loss: 0.521462082862854, Accuracy: 0.8212890625\n",
      "Batch: 73, Loss: 0.4916798174381256, Accuracy: 0.8466796875\n",
      "Batch: 74, Loss: 0.41209590435028076, Accuracy: 0.8779296875\n",
      "Batch: 75, Loss: 0.44667816162109375, Accuracy: 0.853515625\n",
      "Batch: 76, Loss: 0.5419489145278931, Accuracy: 0.81640625\n",
      "Batch: 77, Loss: 0.4911825656890869, Accuracy: 0.8427734375\n",
      "Batch: 78, Loss: 0.46518486738204956, Accuracy: 0.8525390625\n",
      "Batch: 79, Loss: 0.48248016834259033, Accuracy: 0.845703125\n",
      "Batch: 80, Loss: 0.49661457538604736, Accuracy: 0.83203125\n",
      "Batch: 81, Loss: 0.535668134689331, Accuracy: 0.8134765625\n",
      "Batch: 82, Loss: 0.5153763294219971, Accuracy: 0.841796875\n",
      "Batch: 83, Loss: 0.47270992398262024, Accuracy: 0.84375\n",
      "Batch: 84, Loss: 0.5154696702957153, Accuracy: 0.8486328125\n",
      "Batch: 85, Loss: 0.49372681975364685, Accuracy: 0.841796875\n",
      "Batch: 86, Loss: 0.623949408531189, Accuracy: 0.8037109375\n",
      "Batch: 87, Loss: 0.4601626992225647, Accuracy: 0.8515625\n",
      "Batch: 88, Loss: 0.5785595178604126, Accuracy: 0.8212890625\n",
      "Batch: 89, Loss: 0.5302150249481201, Accuracy: 0.8291015625\n",
      "Batch: 90, Loss: 0.4968327283859253, Accuracy: 0.8388671875\n",
      "Batch: 91, Loss: 0.47999244928359985, Accuracy: 0.8359375\n",
      "Batch: 92, Loss: 0.5299148559570312, Accuracy: 0.828125\n",
      "Batch: 93, Loss: 0.5028124451637268, Accuracy: 0.849609375\n",
      "Batch: 94, Loss: 0.5407422780990601, Accuracy: 0.8271484375\n",
      "Batch: 95, Loss: 0.5685032606124878, Accuracy: 0.8046875\n",
      "Batch: 96, Loss: 0.5001503229141235, Accuracy: 0.8330078125\n",
      "Batch: 97, Loss: 0.388139009475708, Accuracy: 0.8642578125\n",
      "Batch: 98, Loss: 0.5045969486236572, Accuracy: 0.8330078125\n",
      "Batch: 99, Loss: 0.5371565818786621, Accuracy: 0.8232421875\n",
      "Batch: 100, Loss: 0.5458478927612305, Accuracy: 0.81640625\n",
      "Batch: 101, Loss: 0.5786095857620239, Accuracy: 0.806640625\n",
      "Batch: 102, Loss: 0.516691267490387, Accuracy: 0.8193359375\n",
      "Batch: 103, Loss: 0.5346418023109436, Accuracy: 0.8271484375\n",
      "Batch: 104, Loss: 0.4759029746055603, Accuracy: 0.833984375\n",
      "Batch: 105, Loss: 0.5367917418479919, Accuracy: 0.826171875\n",
      "Batch: 106, Loss: 0.4578498601913452, Accuracy: 0.8447265625\n",
      "Batch: 107, Loss: 0.5159457921981812, Accuracy: 0.833984375\n",
      "Batch: 108, Loss: 0.5227751731872559, Accuracy: 0.833984375\n",
      "Batch: 109, Loss: 0.6120808124542236, Accuracy: 0.7919921875\n",
      "Batch: 110, Loss: 0.46866223216056824, Accuracy: 0.8408203125\n",
      "Batch: 111, Loss: 0.5414047241210938, Accuracy: 0.8203125\n",
      "Batch: 112, Loss: 0.5344300866127014, Accuracy: 0.8203125\n",
      "Batch: 113, Loss: 0.5346220135688782, Accuracy: 0.8271484375\n",
      "Batch: 114, Loss: 0.563857913017273, Accuracy: 0.82421875\n",
      "Batch: 115, Loss: 0.5733257532119751, Accuracy: 0.8115234375\n",
      "Batch: 116, Loss: 0.5221280455589294, Accuracy: 0.818359375\n",
      "Batch: 117, Loss: 0.5477033853530884, Accuracy: 0.8134765625\n",
      "Batch: 118, Loss: 0.48121756315231323, Accuracy: 0.8447265625\n",
      "Batch: 119, Loss: 0.4425693154335022, Accuracy: 0.8505859375\n",
      "Batch: 120, Loss: 0.5350459814071655, Accuracy: 0.8251953125\n",
      "Batch: 121, Loss: 0.5664528608322144, Accuracy: 0.8046875\n",
      "Batch: 122, Loss: 0.43992701172828674, Accuracy: 0.8525390625\n",
      "Batch: 123, Loss: 0.4815555810928345, Accuracy: 0.8466796875\n",
      "Batch: 124, Loss: 0.5061416029930115, Accuracy: 0.8369140625\n",
      "Batch: 125, Loss: 0.5342860817909241, Accuracy: 0.818359375\n",
      "Batch: 126, Loss: 0.5564596652984619, Accuracy: 0.8251953125\n",
      "Batch: 127, Loss: 0.4501080811023712, Accuracy: 0.8505859375\n",
      "Batch: 128, Loss: 0.5315793752670288, Accuracy: 0.8271484375\n",
      "Batch: 129, Loss: 0.45741111040115356, Accuracy: 0.849609375\n",
      "Batch: 130, Loss: 0.5486233234405518, Accuracy: 0.81640625\n",
      "Batch: 131, Loss: 0.48071998357772827, Accuracy: 0.8388671875\n",
      "Batch: 132, Loss: 0.4954494535923004, Accuracy: 0.845703125\n",
      "Batch: 133, Loss: 0.5041162967681885, Accuracy: 0.826171875\n",
      "Batch: 134, Loss: 0.5119530558586121, Accuracy: 0.8203125\n",
      "Batch: 135, Loss: 0.5054024457931519, Accuracy: 0.83203125\n",
      "Batch: 136, Loss: 0.515740156173706, Accuracy: 0.8193359375\n",
      "Batch: 137, Loss: 0.5435330867767334, Accuracy: 0.8173828125\n",
      "Batch: 138, Loss: 0.4922044277191162, Accuracy: 0.828125\n",
      "Batch: 139, Loss: 0.5519898533821106, Accuracy: 0.82421875\n",
      "Batch: 140, Loss: 0.5414561033248901, Accuracy: 0.8154296875\n",
      "Batch: 141, Loss: 0.5919966101646423, Accuracy: 0.8046875\n",
      "Batch: 142, Loss: 0.56413733959198, Accuracy: 0.802734375\n",
      "Batch: 143, Loss: 0.4992421865463257, Accuracy: 0.8349609375\n",
      "Batch: 144, Loss: 0.5441880226135254, Accuracy: 0.8173828125\n",
      "Batch: 145, Loss: 0.5126794576644897, Accuracy: 0.82421875\n",
      "Batch: 146, Loss: 0.5434383153915405, Accuracy: 0.8203125\n",
      "Batch: 147, Loss: 0.49470341205596924, Accuracy: 0.8427734375\n",
      "Batch: 148, Loss: 0.6026976108551025, Accuracy: 0.802734375\n",
      "Batch: 149, Loss: 0.48743119835853577, Accuracy: 0.83984375\n",
      "Batch: 150, Loss: 0.523309588432312, Accuracy: 0.8232421875\n",
      "Batch: 151, Loss: 0.5074422359466553, Accuracy: 0.8291015625\n",
      "Epoch 66/80\n",
      "Batch: 1, Loss: 0.7408722639083862, Accuracy: 0.7724609375\n",
      "Batch: 2, Loss: 0.559180498123169, Accuracy: 0.8037109375\n",
      "Batch: 3, Loss: 0.5160695314407349, Accuracy: 0.828125\n",
      "Batch: 4, Loss: 0.49654722213745117, Accuracy: 0.8310546875\n",
      "Batch: 5, Loss: 0.5339443683624268, Accuracy: 0.8193359375\n",
      "Batch: 6, Loss: 0.5611190795898438, Accuracy: 0.8125\n",
      "Batch: 7, Loss: 0.5477020740509033, Accuracy: 0.8193359375\n",
      "Batch: 8, Loss: 0.5012628436088562, Accuracy: 0.837890625\n",
      "Batch: 9, Loss: 0.5487578511238098, Accuracy: 0.8251953125\n",
      "Batch: 10, Loss: 0.5213658809661865, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.5833545327186584, Accuracy: 0.7958984375\n",
      "Batch: 12, Loss: 0.5103143453598022, Accuracy: 0.8310546875\n",
      "Batch: 13, Loss: 0.47282540798187256, Accuracy: 0.83984375\n",
      "Batch: 14, Loss: 0.5861217975616455, Accuracy: 0.8115234375\n",
      "Batch: 15, Loss: 0.4767239987850189, Accuracy: 0.853515625\n",
      "Batch: 16, Loss: 0.4959923326969147, Accuracy: 0.8447265625\n",
      "Batch: 17, Loss: 0.5431816577911377, Accuracy: 0.8251953125\n",
      "Batch: 18, Loss: 0.5159428715705872, Accuracy: 0.8291015625\n",
      "Batch: 19, Loss: 0.5650205612182617, Accuracy: 0.81640625\n",
      "Batch: 20, Loss: 0.49112144112586975, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.5541011095046997, Accuracy: 0.8134765625\n",
      "Batch: 22, Loss: 0.6216716766357422, Accuracy: 0.794921875\n",
      "Batch: 23, Loss: 0.5738601684570312, Accuracy: 0.798828125\n",
      "Batch: 24, Loss: 0.568917989730835, Accuracy: 0.8095703125\n",
      "Batch: 25, Loss: 0.5373326539993286, Accuracy: 0.82421875\n",
      "Batch: 26, Loss: 0.43612906336784363, Accuracy: 0.84765625\n",
      "Batch: 27, Loss: 0.512120246887207, Accuracy: 0.81640625\n",
      "Batch: 28, Loss: 0.5104005336761475, Accuracy: 0.8271484375\n",
      "Batch: 29, Loss: 0.4859144389629364, Accuracy: 0.8388671875\n",
      "Batch: 30, Loss: 0.4233136773109436, Accuracy: 0.869140625\n",
      "Batch: 31, Loss: 0.45793595910072327, Accuracy: 0.849609375\n",
      "Batch: 32, Loss: 0.4830220341682434, Accuracy: 0.83203125\n",
      "Batch: 33, Loss: 0.5394492149353027, Accuracy: 0.8251953125\n",
      "Batch: 34, Loss: 0.6389181613922119, Accuracy: 0.787109375\n",
      "Batch: 35, Loss: 0.5335921049118042, Accuracy: 0.8271484375\n",
      "Batch: 36, Loss: 0.5549305081367493, Accuracy: 0.81640625\n",
      "Batch: 37, Loss: 0.5453481674194336, Accuracy: 0.8193359375\n",
      "Batch: 38, Loss: 0.5086691379547119, Accuracy: 0.8388671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 39, Loss: 0.5473691821098328, Accuracy: 0.8056640625\n",
      "Batch: 40, Loss: 0.530768096446991, Accuracy: 0.81640625\n",
      "Batch: 41, Loss: 0.4853931665420532, Accuracy: 0.8583984375\n",
      "Batch: 42, Loss: 0.41800805926322937, Accuracy: 0.86328125\n",
      "Batch: 43, Loss: 0.5140146017074585, Accuracy: 0.82421875\n",
      "Batch: 44, Loss: 0.47297802567481995, Accuracy: 0.8388671875\n",
      "Batch: 45, Loss: 0.45530572533607483, Accuracy: 0.859375\n",
      "Batch: 46, Loss: 0.4452090263366699, Accuracy: 0.8583984375\n",
      "Batch: 47, Loss: 0.4520537853240967, Accuracy: 0.849609375\n",
      "Batch: 48, Loss: 0.4565501809120178, Accuracy: 0.849609375\n",
      "Batch: 49, Loss: 0.5340204238891602, Accuracy: 0.830078125\n",
      "Batch: 50, Loss: 0.5199618935585022, Accuracy: 0.8193359375\n",
      "Batch: 51, Loss: 0.5032062530517578, Accuracy: 0.8388671875\n",
      "Batch: 52, Loss: 0.530436635017395, Accuracy: 0.8271484375\n",
      "Batch: 53, Loss: 0.45151185989379883, Accuracy: 0.845703125\n",
      "Batch: 54, Loss: 0.5084218382835388, Accuracy: 0.8193359375\n",
      "Batch: 55, Loss: 0.5507491827011108, Accuracy: 0.8251953125\n",
      "Batch: 56, Loss: 0.5915220379829407, Accuracy: 0.8056640625\n",
      "Batch: 57, Loss: 0.5349394083023071, Accuracy: 0.8017578125\n",
      "Batch: 58, Loss: 0.581597089767456, Accuracy: 0.8134765625\n",
      "Batch: 59, Loss: 0.4900658428668976, Accuracy: 0.83984375\n",
      "Batch: 60, Loss: 0.46775728464126587, Accuracy: 0.8330078125\n",
      "Batch: 61, Loss: 0.5311204195022583, Accuracy: 0.8193359375\n",
      "Batch: 62, Loss: 0.4523583650588989, Accuracy: 0.84765625\n",
      "Batch: 63, Loss: 0.5328311324119568, Accuracy: 0.822265625\n",
      "Batch: 64, Loss: 0.5032954216003418, Accuracy: 0.8359375\n",
      "Batch: 65, Loss: 0.5275600552558899, Accuracy: 0.8291015625\n",
      "Batch: 66, Loss: 0.5183327794075012, Accuracy: 0.83203125\n",
      "Batch: 67, Loss: 0.5490643382072449, Accuracy: 0.818359375\n",
      "Batch: 68, Loss: 0.5855390429496765, Accuracy: 0.8212890625\n",
      "Batch: 69, Loss: 0.5548170804977417, Accuracy: 0.82421875\n",
      "Batch: 70, Loss: 0.5232923030853271, Accuracy: 0.826171875\n",
      "Batch: 71, Loss: 0.5770778656005859, Accuracy: 0.7958984375\n",
      "Batch: 72, Loss: 0.48902884125709534, Accuracy: 0.8486328125\n",
      "Batch: 73, Loss: 0.4719570279121399, Accuracy: 0.8427734375\n",
      "Batch: 74, Loss: 0.4467726945877075, Accuracy: 0.8525390625\n",
      "Batch: 75, Loss: 0.41849881410598755, Accuracy: 0.8662109375\n",
      "Batch: 76, Loss: 0.5315155982971191, Accuracy: 0.8193359375\n",
      "Batch: 77, Loss: 0.46615684032440186, Accuracy: 0.841796875\n",
      "Batch: 78, Loss: 0.4857872724533081, Accuracy: 0.837890625\n",
      "Batch: 79, Loss: 0.4624391198158264, Accuracy: 0.86328125\n",
      "Batch: 80, Loss: 0.47587141394615173, Accuracy: 0.84765625\n",
      "Batch: 81, Loss: 0.5387608408927917, Accuracy: 0.814453125\n",
      "Batch: 82, Loss: 0.5043945908546448, Accuracy: 0.8212890625\n",
      "Batch: 83, Loss: 0.44231149554252625, Accuracy: 0.859375\n",
      "Batch: 84, Loss: 0.5290757417678833, Accuracy: 0.822265625\n",
      "Batch: 85, Loss: 0.49242356419563293, Accuracy: 0.845703125\n",
      "Batch: 86, Loss: 0.6147542595863342, Accuracy: 0.8212890625\n",
      "Batch: 87, Loss: 0.490284264087677, Accuracy: 0.8525390625\n",
      "Batch: 88, Loss: 0.5423564910888672, Accuracy: 0.8349609375\n",
      "Batch: 89, Loss: 0.5217016935348511, Accuracy: 0.8251953125\n",
      "Batch: 90, Loss: 0.5000309944152832, Accuracy: 0.841796875\n",
      "Batch: 91, Loss: 0.519080400466919, Accuracy: 0.8271484375\n",
      "Batch: 92, Loss: 0.5301703214645386, Accuracy: 0.8349609375\n",
      "Batch: 93, Loss: 0.5092875957489014, Accuracy: 0.830078125\n",
      "Batch: 94, Loss: 0.529867947101593, Accuracy: 0.8291015625\n",
      "Batch: 95, Loss: 0.5272068977355957, Accuracy: 0.818359375\n",
      "Batch: 96, Loss: 0.513100266456604, Accuracy: 0.8349609375\n",
      "Batch: 97, Loss: 0.4308146834373474, Accuracy: 0.85546875\n",
      "Batch: 98, Loss: 0.5079165101051331, Accuracy: 0.8310546875\n",
      "Batch: 99, Loss: 0.5110202431678772, Accuracy: 0.8330078125\n",
      "Batch: 100, Loss: 0.5301859974861145, Accuracy: 0.8359375\n",
      "Batch: 101, Loss: 0.5370998382568359, Accuracy: 0.81640625\n",
      "Batch: 102, Loss: 0.5038811564445496, Accuracy: 0.833984375\n",
      "Batch: 103, Loss: 0.5184218883514404, Accuracy: 0.8349609375\n",
      "Batch: 104, Loss: 0.4868747591972351, Accuracy: 0.8349609375\n",
      "Batch: 105, Loss: 0.5648825168609619, Accuracy: 0.8076171875\n",
      "Batch: 106, Loss: 0.46486687660217285, Accuracy: 0.8525390625\n",
      "Batch: 107, Loss: 0.5107648372650146, Accuracy: 0.8427734375\n",
      "Batch: 108, Loss: 0.5329618453979492, Accuracy: 0.8212890625\n",
      "Batch: 109, Loss: 0.58237624168396, Accuracy: 0.8134765625\n",
      "Batch: 110, Loss: 0.46722882986068726, Accuracy: 0.8330078125\n",
      "Batch: 111, Loss: 0.5023872256278992, Accuracy: 0.8271484375\n",
      "Batch: 112, Loss: 0.49810171127319336, Accuracy: 0.8369140625\n",
      "Batch: 113, Loss: 0.5249278545379639, Accuracy: 0.8291015625\n",
      "Batch: 114, Loss: 0.5672634840011597, Accuracy: 0.8154296875\n",
      "Batch: 115, Loss: 0.5757428407669067, Accuracy: 0.810546875\n",
      "Batch: 116, Loss: 0.5078728199005127, Accuracy: 0.82421875\n",
      "Batch: 117, Loss: 0.5183265209197998, Accuracy: 0.8193359375\n",
      "Batch: 118, Loss: 0.4915587604045868, Accuracy: 0.8349609375\n",
      "Batch: 119, Loss: 0.43675047159194946, Accuracy: 0.8515625\n",
      "Batch: 120, Loss: 0.5063151717185974, Accuracy: 0.833984375\n",
      "Batch: 121, Loss: 0.5773006677627563, Accuracy: 0.822265625\n",
      "Batch: 122, Loss: 0.47548824548721313, Accuracy: 0.84765625\n",
      "Batch: 123, Loss: 0.4748641848564148, Accuracy: 0.8486328125\n",
      "Batch: 124, Loss: 0.493891179561615, Accuracy: 0.8447265625\n",
      "Batch: 125, Loss: 0.5035538077354431, Accuracy: 0.8271484375\n",
      "Batch: 126, Loss: 0.551352858543396, Accuracy: 0.8310546875\n",
      "Batch: 127, Loss: 0.4708518385887146, Accuracy: 0.8525390625\n",
      "Batch: 128, Loss: 0.569591760635376, Accuracy: 0.822265625\n",
      "Batch: 129, Loss: 0.49880731105804443, Accuracy: 0.833984375\n",
      "Batch: 130, Loss: 0.5652905702590942, Accuracy: 0.802734375\n",
      "Batch: 131, Loss: 0.49175113439559937, Accuracy: 0.837890625\n",
      "Batch: 132, Loss: 0.5476038455963135, Accuracy: 0.837890625\n",
      "Batch: 133, Loss: 0.5395718812942505, Accuracy: 0.8251953125\n",
      "Batch: 134, Loss: 0.527611255645752, Accuracy: 0.8203125\n",
      "Batch: 135, Loss: 0.5172951221466064, Accuracy: 0.82421875\n",
      "Batch: 136, Loss: 0.5147570967674255, Accuracy: 0.8408203125\n",
      "Batch: 137, Loss: 0.5479108691215515, Accuracy: 0.8046875\n",
      "Batch: 138, Loss: 0.49045729637145996, Accuracy: 0.8427734375\n",
      "Batch: 139, Loss: 0.5835063457489014, Accuracy: 0.80859375\n",
      "Batch: 140, Loss: 0.5065463781356812, Accuracy: 0.8193359375\n",
      "Batch: 141, Loss: 0.5984172224998474, Accuracy: 0.8115234375\n",
      "Batch: 142, Loss: 0.5955549478530884, Accuracy: 0.8056640625\n",
      "Batch: 143, Loss: 0.5298332571983337, Accuracy: 0.8359375\n",
      "Batch: 144, Loss: 0.5380122065544128, Accuracy: 0.8212890625\n",
      "Batch: 145, Loss: 0.49460530281066895, Accuracy: 0.8388671875\n",
      "Batch: 146, Loss: 0.5644124746322632, Accuracy: 0.814453125\n",
      "Batch: 147, Loss: 0.5259484052658081, Accuracy: 0.8330078125\n",
      "Batch: 148, Loss: 0.5711025595664978, Accuracy: 0.822265625\n",
      "Batch: 149, Loss: 0.5001388788223267, Accuracy: 0.8466796875\n",
      "Batch: 150, Loss: 0.5119609236717224, Accuracy: 0.8271484375\n",
      "Batch: 151, Loss: 0.4672093987464905, Accuracy: 0.8583984375\n",
      "Epoch 67/80\n",
      "Batch: 1, Loss: 0.6937872171401978, Accuracy: 0.775390625\n",
      "Batch: 2, Loss: 0.613686740398407, Accuracy: 0.78125\n",
      "Batch: 3, Loss: 0.5011927485466003, Accuracy: 0.830078125\n",
      "Batch: 4, Loss: 0.49665331840515137, Accuracy: 0.830078125\n",
      "Batch: 5, Loss: 0.521065890789032, Accuracy: 0.8515625\n",
      "Batch: 6, Loss: 0.511206865310669, Accuracy: 0.8310546875\n",
      "Batch: 7, Loss: 0.5539551377296448, Accuracy: 0.8134765625\n",
      "Batch: 8, Loss: 0.48846864700317383, Accuracy: 0.8349609375\n",
      "Batch: 9, Loss: 0.5124979019165039, Accuracy: 0.8232421875\n",
      "Batch: 10, Loss: 0.5261314511299133, Accuracy: 0.8203125\n",
      "Batch: 11, Loss: 0.5553209781646729, Accuracy: 0.822265625\n",
      "Batch: 12, Loss: 0.5125793218612671, Accuracy: 0.8310546875\n",
      "Batch: 13, Loss: 0.44244110584259033, Accuracy: 0.8564453125\n",
      "Batch: 14, Loss: 0.5565469861030579, Accuracy: 0.833984375\n",
      "Batch: 15, Loss: 0.44790369272232056, Accuracy: 0.87109375\n",
      "Batch: 16, Loss: 0.4608483910560608, Accuracy: 0.8505859375\n",
      "Batch: 17, Loss: 0.5322611331939697, Accuracy: 0.826171875\n",
      "Batch: 18, Loss: 0.5166975259780884, Accuracy: 0.8369140625\n",
      "Batch: 19, Loss: 0.5624310374259949, Accuracy: 0.826171875\n",
      "Batch: 20, Loss: 0.48005539178848267, Accuracy: 0.8369140625\n",
      "Batch: 21, Loss: 0.5278979539871216, Accuracy: 0.8291015625\n",
      "Batch: 22, Loss: 0.616413414478302, Accuracy: 0.8046875\n",
      "Batch: 23, Loss: 0.5532824397087097, Accuracy: 0.810546875\n",
      "Batch: 24, Loss: 0.5477204918861389, Accuracy: 0.8203125\n",
      "Batch: 25, Loss: 0.5225695371627808, Accuracy: 0.83984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 0.44160985946655273, Accuracy: 0.853515625\n",
      "Batch: 27, Loss: 0.4500536322593689, Accuracy: 0.849609375\n",
      "Batch: 28, Loss: 0.5187076330184937, Accuracy: 0.828125\n",
      "Batch: 29, Loss: 0.49647170305252075, Accuracy: 0.845703125\n",
      "Batch: 30, Loss: 0.45539867877960205, Accuracy: 0.849609375\n",
      "Batch: 31, Loss: 0.494878351688385, Accuracy: 0.8349609375\n",
      "Batch: 32, Loss: 0.4763910174369812, Accuracy: 0.845703125\n",
      "Batch: 33, Loss: 0.5199516415596008, Accuracy: 0.8349609375\n",
      "Batch: 34, Loss: 0.6057302951812744, Accuracy: 0.79296875\n",
      "Batch: 35, Loss: 0.5358234643936157, Accuracy: 0.8388671875\n",
      "Batch: 36, Loss: 0.5370291471481323, Accuracy: 0.822265625\n",
      "Batch: 37, Loss: 0.5122126936912537, Accuracy: 0.826171875\n",
      "Batch: 38, Loss: 0.5274723768234253, Accuracy: 0.8203125\n",
      "Batch: 39, Loss: 0.511186420917511, Accuracy: 0.8349609375\n",
      "Batch: 40, Loss: 0.5275865793228149, Accuracy: 0.837890625\n",
      "Batch: 41, Loss: 0.5011167526245117, Accuracy: 0.826171875\n",
      "Batch: 42, Loss: 0.38615718483924866, Accuracy: 0.8681640625\n",
      "Batch: 43, Loss: 0.5039352178573608, Accuracy: 0.828125\n",
      "Batch: 44, Loss: 0.5097384452819824, Accuracy: 0.8369140625\n",
      "Batch: 45, Loss: 0.45941752195358276, Accuracy: 0.8505859375\n",
      "Batch: 46, Loss: 0.432778000831604, Accuracy: 0.853515625\n",
      "Batch: 47, Loss: 0.48412343859672546, Accuracy: 0.84375\n",
      "Batch: 48, Loss: 0.46854710578918457, Accuracy: 0.837890625\n",
      "Batch: 49, Loss: 0.5335653424263, Accuracy: 0.82421875\n",
      "Batch: 50, Loss: 0.528859555721283, Accuracy: 0.826171875\n",
      "Batch: 51, Loss: 0.5300209522247314, Accuracy: 0.8330078125\n",
      "Batch: 52, Loss: 0.5003611445426941, Accuracy: 0.8388671875\n",
      "Batch: 53, Loss: 0.4631650149822235, Accuracy: 0.8486328125\n",
      "Batch: 54, Loss: 0.498710572719574, Accuracy: 0.8359375\n",
      "Batch: 55, Loss: 0.556770920753479, Accuracy: 0.8173828125\n",
      "Batch: 56, Loss: 0.5555981993675232, Accuracy: 0.8125\n",
      "Batch: 57, Loss: 0.5616327524185181, Accuracy: 0.8017578125\n",
      "Batch: 58, Loss: 0.570175290107727, Accuracy: 0.8095703125\n",
      "Batch: 59, Loss: 0.506053626537323, Accuracy: 0.828125\n",
      "Batch: 60, Loss: 0.5057386159896851, Accuracy: 0.8427734375\n",
      "Batch: 61, Loss: 0.5160568952560425, Accuracy: 0.8154296875\n",
      "Batch: 62, Loss: 0.4450830817222595, Accuracy: 0.857421875\n",
      "Batch: 63, Loss: 0.5004236698150635, Accuracy: 0.8251953125\n",
      "Batch: 64, Loss: 0.4963642358779907, Accuracy: 0.8359375\n",
      "Batch: 65, Loss: 0.5308475494384766, Accuracy: 0.8154296875\n",
      "Batch: 66, Loss: 0.5083086490631104, Accuracy: 0.8359375\n",
      "Batch: 67, Loss: 0.5514317154884338, Accuracy: 0.8115234375\n",
      "Batch: 68, Loss: 0.5762083530426025, Accuracy: 0.8125\n",
      "Batch: 69, Loss: 0.5473930835723877, Accuracy: 0.82421875\n",
      "Batch: 70, Loss: 0.5342873334884644, Accuracy: 0.8251953125\n",
      "Batch: 71, Loss: 0.5846663117408752, Accuracy: 0.7958984375\n",
      "Batch: 72, Loss: 0.4900563955307007, Accuracy: 0.8310546875\n",
      "Batch: 73, Loss: 0.48684975504875183, Accuracy: 0.8427734375\n",
      "Batch: 74, Loss: 0.4550796151161194, Accuracy: 0.859375\n",
      "Batch: 75, Loss: 0.4313567280769348, Accuracy: 0.849609375\n",
      "Batch: 76, Loss: 0.5373696684837341, Accuracy: 0.8173828125\n",
      "Batch: 77, Loss: 0.4918152093887329, Accuracy: 0.83984375\n",
      "Batch: 78, Loss: 0.47334688901901245, Accuracy: 0.8447265625\n",
      "Batch: 79, Loss: 0.476104736328125, Accuracy: 0.84765625\n",
      "Batch: 80, Loss: 0.5074284076690674, Accuracy: 0.83203125\n",
      "Batch: 81, Loss: 0.5022956728935242, Accuracy: 0.818359375\n",
      "Batch: 82, Loss: 0.4987204968929291, Accuracy: 0.81640625\n",
      "Batch: 83, Loss: 0.45953434705734253, Accuracy: 0.8486328125\n",
      "Batch: 84, Loss: 0.5272033214569092, Accuracy: 0.82421875\n",
      "Batch: 85, Loss: 0.483466237783432, Accuracy: 0.8544921875\n",
      "Batch: 86, Loss: 0.5799921751022339, Accuracy: 0.818359375\n",
      "Batch: 87, Loss: 0.4728747606277466, Accuracy: 0.84375\n",
      "Batch: 88, Loss: 0.5379214286804199, Accuracy: 0.8330078125\n",
      "Batch: 89, Loss: 0.48003774881362915, Accuracy: 0.8447265625\n",
      "Batch: 90, Loss: 0.5183236598968506, Accuracy: 0.83984375\n",
      "Batch: 91, Loss: 0.5062912702560425, Accuracy: 0.822265625\n",
      "Batch: 92, Loss: 0.5240209698677063, Accuracy: 0.83203125\n",
      "Batch: 93, Loss: 0.4858704209327698, Accuracy: 0.84765625\n",
      "Batch: 94, Loss: 0.5101668834686279, Accuracy: 0.8291015625\n",
      "Batch: 95, Loss: 0.536185085773468, Accuracy: 0.8173828125\n",
      "Batch: 96, Loss: 0.5000205636024475, Accuracy: 0.8369140625\n",
      "Batch: 97, Loss: 0.3810422718524933, Accuracy: 0.865234375\n",
      "Batch: 98, Loss: 0.49692344665527344, Accuracy: 0.837890625\n",
      "Batch: 99, Loss: 0.48309463262557983, Accuracy: 0.841796875\n",
      "Batch: 100, Loss: 0.515508234500885, Accuracy: 0.837890625\n",
      "Batch: 101, Loss: 0.5026981830596924, Accuracy: 0.83203125\n",
      "Batch: 102, Loss: 0.487272173166275, Accuracy: 0.8349609375\n",
      "Batch: 103, Loss: 0.5385861992835999, Accuracy: 0.830078125\n",
      "Batch: 104, Loss: 0.4931405484676361, Accuracy: 0.8349609375\n",
      "Batch: 105, Loss: 0.548514723777771, Accuracy: 0.8056640625\n",
      "Batch: 106, Loss: 0.4402870237827301, Accuracy: 0.85546875\n",
      "Batch: 107, Loss: 0.48618000745773315, Accuracy: 0.8525390625\n",
      "Batch: 108, Loss: 0.5231325626373291, Accuracy: 0.826171875\n",
      "Batch: 109, Loss: 0.5921969413757324, Accuracy: 0.8076171875\n",
      "Batch: 110, Loss: 0.46553292870521545, Accuracy: 0.84375\n",
      "Batch: 111, Loss: 0.5183411836624146, Accuracy: 0.822265625\n",
      "Batch: 112, Loss: 0.5127632021903992, Accuracy: 0.826171875\n",
      "Batch: 113, Loss: 0.5279535055160522, Accuracy: 0.84375\n",
      "Batch: 114, Loss: 0.6290900707244873, Accuracy: 0.7900390625\n",
      "Batch: 115, Loss: 0.5641017556190491, Accuracy: 0.8212890625\n",
      "Batch: 116, Loss: 0.5145712494850159, Accuracy: 0.830078125\n",
      "Batch: 117, Loss: 0.5093938112258911, Accuracy: 0.8134765625\n",
      "Batch: 118, Loss: 0.49186789989471436, Accuracy: 0.845703125\n",
      "Batch: 119, Loss: 0.42387819290161133, Accuracy: 0.8505859375\n",
      "Batch: 120, Loss: 0.5011153817176819, Accuracy: 0.837890625\n",
      "Batch: 121, Loss: 0.5280569195747375, Accuracy: 0.8251953125\n",
      "Batch: 122, Loss: 0.4613887667655945, Accuracy: 0.8505859375\n",
      "Batch: 123, Loss: 0.4790627956390381, Accuracy: 0.8427734375\n",
      "Batch: 124, Loss: 0.5093712210655212, Accuracy: 0.8369140625\n",
      "Batch: 125, Loss: 0.5303230881690979, Accuracy: 0.82421875\n",
      "Batch: 126, Loss: 0.4975796341896057, Accuracy: 0.8408203125\n",
      "Batch: 127, Loss: 0.47930148243904114, Accuracy: 0.841796875\n",
      "Batch: 128, Loss: 0.5492753386497498, Accuracy: 0.8203125\n",
      "Batch: 129, Loss: 0.4528963267803192, Accuracy: 0.8505859375\n",
      "Batch: 130, Loss: 0.5596057176589966, Accuracy: 0.8203125\n",
      "Batch: 131, Loss: 0.47288864850997925, Accuracy: 0.845703125\n",
      "Batch: 132, Loss: 0.5100575685501099, Accuracy: 0.8330078125\n",
      "Batch: 133, Loss: 0.5198318958282471, Accuracy: 0.833984375\n",
      "Batch: 134, Loss: 0.5384329557418823, Accuracy: 0.8203125\n",
      "Batch: 135, Loss: 0.49742186069488525, Accuracy: 0.8349609375\n",
      "Batch: 136, Loss: 0.5179905891418457, Accuracy: 0.8291015625\n",
      "Batch: 137, Loss: 0.5494270324707031, Accuracy: 0.810546875\n",
      "Batch: 138, Loss: 0.49618908762931824, Accuracy: 0.8291015625\n",
      "Batch: 139, Loss: 0.519481897354126, Accuracy: 0.822265625\n",
      "Batch: 140, Loss: 0.5378333926200867, Accuracy: 0.814453125\n",
      "Batch: 141, Loss: 0.5463908910751343, Accuracy: 0.8203125\n",
      "Batch: 142, Loss: 0.5435789227485657, Accuracy: 0.80859375\n",
      "Batch: 143, Loss: 0.5291785001754761, Accuracy: 0.837890625\n",
      "Batch: 144, Loss: 0.5071120262145996, Accuracy: 0.83984375\n",
      "Batch: 145, Loss: 0.5017286539077759, Accuracy: 0.8447265625\n",
      "Batch: 146, Loss: 0.5540097951889038, Accuracy: 0.8154296875\n",
      "Batch: 147, Loss: 0.5205518007278442, Accuracy: 0.8359375\n",
      "Batch: 148, Loss: 0.6229174137115479, Accuracy: 0.8056640625\n",
      "Batch: 149, Loss: 0.5065053701400757, Accuracy: 0.84765625\n",
      "Batch: 150, Loss: 0.5148822069168091, Accuracy: 0.8349609375\n",
      "Batch: 151, Loss: 0.5036544799804688, Accuracy: 0.8359375\n",
      "Epoch 68/80\n",
      "Batch: 1, Loss: 0.6920554637908936, Accuracy: 0.7783203125\n",
      "Batch: 2, Loss: 0.6039873361587524, Accuracy: 0.7890625\n",
      "Batch: 3, Loss: 0.5195176601409912, Accuracy: 0.8154296875\n",
      "Batch: 4, Loss: 0.5208147168159485, Accuracy: 0.8349609375\n",
      "Batch: 5, Loss: 0.4997202157974243, Accuracy: 0.8359375\n",
      "Batch: 6, Loss: 0.5116905570030212, Accuracy: 0.8359375\n",
      "Batch: 7, Loss: 0.5116077661514282, Accuracy: 0.82421875\n",
      "Batch: 8, Loss: 0.5195658802986145, Accuracy: 0.8193359375\n",
      "Batch: 9, Loss: 0.5436992645263672, Accuracy: 0.8271484375\n",
      "Batch: 10, Loss: 0.49733608961105347, Accuracy: 0.8291015625\n",
      "Batch: 11, Loss: 0.5685980916023254, Accuracy: 0.8076171875\n",
      "Batch: 12, Loss: 0.5387320518493652, Accuracy: 0.8115234375\n",
      "Batch: 13, Loss: 0.4175523519515991, Accuracy: 0.85546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.5420933961868286, Accuracy: 0.81640625\n",
      "Batch: 15, Loss: 0.4612659811973572, Accuracy: 0.8525390625\n",
      "Batch: 16, Loss: 0.47939345240592957, Accuracy: 0.845703125\n",
      "Batch: 17, Loss: 0.5038507580757141, Accuracy: 0.8232421875\n",
      "Batch: 18, Loss: 0.5197427868843079, Accuracy: 0.8330078125\n",
      "Batch: 19, Loss: 0.5723296403884888, Accuracy: 0.8154296875\n",
      "Batch: 20, Loss: 0.4408245086669922, Accuracy: 0.8564453125\n",
      "Batch: 21, Loss: 0.5042476654052734, Accuracy: 0.83203125\n",
      "Batch: 22, Loss: 0.590031087398529, Accuracy: 0.806640625\n",
      "Batch: 23, Loss: 0.5366274118423462, Accuracy: 0.80078125\n",
      "Batch: 24, Loss: 0.5779653191566467, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5051091909408569, Accuracy: 0.841796875\n",
      "Batch: 26, Loss: 0.44480112195014954, Accuracy: 0.8466796875\n",
      "Batch: 27, Loss: 0.45127004384994507, Accuracy: 0.8505859375\n",
      "Batch: 28, Loss: 0.5195722579956055, Accuracy: 0.828125\n",
      "Batch: 29, Loss: 0.506729006767273, Accuracy: 0.8359375\n",
      "Batch: 30, Loss: 0.4437924027442932, Accuracy: 0.8583984375\n",
      "Batch: 31, Loss: 0.4923244118690491, Accuracy: 0.837890625\n",
      "Batch: 32, Loss: 0.4656160771846771, Accuracy: 0.8408203125\n",
      "Batch: 33, Loss: 0.542151689529419, Accuracy: 0.826171875\n",
      "Batch: 34, Loss: 0.5898962616920471, Accuracy: 0.828125\n",
      "Batch: 35, Loss: 0.5202473402023315, Accuracy: 0.8203125\n",
      "Batch: 36, Loss: 0.5221216678619385, Accuracy: 0.841796875\n",
      "Batch: 37, Loss: 0.5343652367591858, Accuracy: 0.8232421875\n",
      "Batch: 38, Loss: 0.47728797793388367, Accuracy: 0.8388671875\n",
      "Batch: 39, Loss: 0.561374306678772, Accuracy: 0.8173828125\n",
      "Batch: 40, Loss: 0.5277194976806641, Accuracy: 0.8271484375\n",
      "Batch: 41, Loss: 0.46369266510009766, Accuracy: 0.849609375\n",
      "Batch: 42, Loss: 0.3887163996696472, Accuracy: 0.875\n",
      "Batch: 43, Loss: 0.48597776889801025, Accuracy: 0.8291015625\n",
      "Batch: 44, Loss: 0.49151143431663513, Accuracy: 0.826171875\n",
      "Batch: 45, Loss: 0.43102335929870605, Accuracy: 0.8583984375\n",
      "Batch: 46, Loss: 0.45397627353668213, Accuracy: 0.849609375\n",
      "Batch: 47, Loss: 0.4478554427623749, Accuracy: 0.857421875\n",
      "Batch: 48, Loss: 0.4516078233718872, Accuracy: 0.84765625\n",
      "Batch: 49, Loss: 0.49999627470970154, Accuracy: 0.8408203125\n",
      "Batch: 50, Loss: 0.5208758115768433, Accuracy: 0.830078125\n",
      "Batch: 51, Loss: 0.4828682541847229, Accuracy: 0.8447265625\n",
      "Batch: 52, Loss: 0.4839421510696411, Accuracy: 0.8408203125\n",
      "Batch: 53, Loss: 0.4320595860481262, Accuracy: 0.8447265625\n",
      "Batch: 54, Loss: 0.4910829961299896, Accuracy: 0.8212890625\n",
      "Batch: 55, Loss: 0.5611732006072998, Accuracy: 0.8095703125\n",
      "Batch: 56, Loss: 0.5500216484069824, Accuracy: 0.8037109375\n",
      "Batch: 57, Loss: 0.5406812429428101, Accuracy: 0.8212890625\n",
      "Batch: 58, Loss: 0.5583510398864746, Accuracy: 0.810546875\n",
      "Batch: 59, Loss: 0.5203479528427124, Accuracy: 0.83203125\n",
      "Batch: 60, Loss: 0.4730101227760315, Accuracy: 0.8349609375\n",
      "Batch: 61, Loss: 0.5324351191520691, Accuracy: 0.814453125\n",
      "Batch: 62, Loss: 0.4677240550518036, Accuracy: 0.8515625\n",
      "Batch: 63, Loss: 0.5023048520088196, Accuracy: 0.83203125\n",
      "Batch: 64, Loss: 0.5202856063842773, Accuracy: 0.8330078125\n",
      "Batch: 65, Loss: 0.5405145287513733, Accuracy: 0.8134765625\n",
      "Batch: 66, Loss: 0.5234060883522034, Accuracy: 0.8388671875\n",
      "Batch: 67, Loss: 0.5689535140991211, Accuracy: 0.8076171875\n",
      "Batch: 68, Loss: 0.6064594388008118, Accuracy: 0.798828125\n",
      "Batch: 69, Loss: 0.5901803970336914, Accuracy: 0.81640625\n",
      "Batch: 70, Loss: 0.5475543141365051, Accuracy: 0.8212890625\n",
      "Batch: 71, Loss: 0.5393127799034119, Accuracy: 0.814453125\n",
      "Batch: 72, Loss: 0.4940873384475708, Accuracy: 0.8388671875\n",
      "Batch: 73, Loss: 0.4907294809818268, Accuracy: 0.8505859375\n",
      "Batch: 74, Loss: 0.4372648298740387, Accuracy: 0.8662109375\n",
      "Batch: 75, Loss: 0.4372885227203369, Accuracy: 0.8603515625\n",
      "Batch: 76, Loss: 0.5386123657226562, Accuracy: 0.8173828125\n",
      "Batch: 77, Loss: 0.48056066036224365, Accuracy: 0.8408203125\n",
      "Batch: 78, Loss: 0.48334163427352905, Accuracy: 0.8388671875\n",
      "Batch: 79, Loss: 0.48421338200569153, Accuracy: 0.8486328125\n",
      "Batch: 80, Loss: 0.49745887517929077, Accuracy: 0.8359375\n",
      "Batch: 81, Loss: 0.5245615243911743, Accuracy: 0.8193359375\n",
      "Batch: 82, Loss: 0.46638181805610657, Accuracy: 0.84765625\n",
      "Batch: 83, Loss: 0.4532856345176697, Accuracy: 0.857421875\n",
      "Batch: 84, Loss: 0.49598097801208496, Accuracy: 0.837890625\n",
      "Batch: 85, Loss: 0.48493242263793945, Accuracy: 0.84375\n",
      "Batch: 86, Loss: 0.5798232555389404, Accuracy: 0.822265625\n",
      "Batch: 87, Loss: 0.44741496443748474, Accuracy: 0.859375\n",
      "Batch: 88, Loss: 0.5598229765892029, Accuracy: 0.826171875\n",
      "Batch: 89, Loss: 0.5257102251052856, Accuracy: 0.8232421875\n",
      "Batch: 90, Loss: 0.5077868700027466, Accuracy: 0.841796875\n",
      "Batch: 91, Loss: 0.46770724654197693, Accuracy: 0.8349609375\n",
      "Batch: 92, Loss: 0.5213627815246582, Accuracy: 0.8115234375\n",
      "Batch: 93, Loss: 0.4815605878829956, Accuracy: 0.8427734375\n",
      "Batch: 94, Loss: 0.514446496963501, Accuracy: 0.8359375\n",
      "Batch: 95, Loss: 0.5610414743423462, Accuracy: 0.814453125\n",
      "Batch: 96, Loss: 0.5194904804229736, Accuracy: 0.8291015625\n",
      "Batch: 97, Loss: 0.4102366268634796, Accuracy: 0.8564453125\n",
      "Batch: 98, Loss: 0.47467589378356934, Accuracy: 0.8408203125\n",
      "Batch: 99, Loss: 0.46218881011009216, Accuracy: 0.837890625\n",
      "Batch: 100, Loss: 0.5401309728622437, Accuracy: 0.8193359375\n",
      "Batch: 101, Loss: 0.5017852783203125, Accuracy: 0.82421875\n",
      "Batch: 102, Loss: 0.5096307992935181, Accuracy: 0.826171875\n",
      "Batch: 103, Loss: 0.5138001441955566, Accuracy: 0.8466796875\n",
      "Batch: 104, Loss: 0.46964842081069946, Accuracy: 0.8408203125\n",
      "Batch: 105, Loss: 0.5332260727882385, Accuracy: 0.826171875\n",
      "Batch: 106, Loss: 0.5052317380905151, Accuracy: 0.83203125\n",
      "Batch: 107, Loss: 0.4702646732330322, Accuracy: 0.8466796875\n",
      "Batch: 108, Loss: 0.4970727264881134, Accuracy: 0.8310546875\n",
      "Batch: 109, Loss: 0.5685244798660278, Accuracy: 0.8251953125\n",
      "Batch: 110, Loss: 0.4424886703491211, Accuracy: 0.849609375\n",
      "Batch: 111, Loss: 0.48416754603385925, Accuracy: 0.8486328125\n",
      "Batch: 112, Loss: 0.4859048128128052, Accuracy: 0.8408203125\n",
      "Batch: 113, Loss: 0.5190804600715637, Accuracy: 0.837890625\n",
      "Batch: 114, Loss: 0.57178795337677, Accuracy: 0.818359375\n",
      "Batch: 115, Loss: 0.5563259720802307, Accuracy: 0.8154296875\n",
      "Batch: 116, Loss: 0.5027856826782227, Accuracy: 0.8369140625\n",
      "Batch: 117, Loss: 0.5191681981086731, Accuracy: 0.8388671875\n",
      "Batch: 118, Loss: 0.5075321793556213, Accuracy: 0.8408203125\n",
      "Batch: 119, Loss: 0.41030800342559814, Accuracy: 0.876953125\n",
      "Batch: 120, Loss: 0.4797695279121399, Accuracy: 0.84375\n",
      "Batch: 121, Loss: 0.5867507457733154, Accuracy: 0.7978515625\n",
      "Batch: 122, Loss: 0.4390496611595154, Accuracy: 0.8623046875\n",
      "Batch: 123, Loss: 0.49546122550964355, Accuracy: 0.84375\n",
      "Batch: 124, Loss: 0.4956963062286377, Accuracy: 0.8466796875\n",
      "Batch: 125, Loss: 0.5181195735931396, Accuracy: 0.826171875\n",
      "Batch: 126, Loss: 0.5553156733512878, Accuracy: 0.8232421875\n",
      "Batch: 127, Loss: 0.5011169910430908, Accuracy: 0.849609375\n",
      "Batch: 128, Loss: 0.5459326505661011, Accuracy: 0.8251953125\n",
      "Batch: 129, Loss: 0.4925684332847595, Accuracy: 0.8427734375\n",
      "Batch: 130, Loss: 0.5310457944869995, Accuracy: 0.8359375\n",
      "Batch: 131, Loss: 0.4948194921016693, Accuracy: 0.83984375\n",
      "Batch: 132, Loss: 0.5382563471794128, Accuracy: 0.828125\n",
      "Batch: 133, Loss: 0.48927515745162964, Accuracy: 0.8359375\n",
      "Batch: 134, Loss: 0.5240474939346313, Accuracy: 0.826171875\n",
      "Batch: 135, Loss: 0.4398072063922882, Accuracy: 0.857421875\n",
      "Batch: 136, Loss: 0.5165987014770508, Accuracy: 0.8349609375\n",
      "Batch: 137, Loss: 0.5493040680885315, Accuracy: 0.8037109375\n",
      "Batch: 138, Loss: 0.4894534945487976, Accuracy: 0.82421875\n",
      "Batch: 139, Loss: 0.5674593448638916, Accuracy: 0.828125\n",
      "Batch: 140, Loss: 0.4798981249332428, Accuracy: 0.833984375\n",
      "Batch: 141, Loss: 0.5401604175567627, Accuracy: 0.8232421875\n",
      "Batch: 142, Loss: 0.5171750783920288, Accuracy: 0.8193359375\n",
      "Batch: 143, Loss: 0.5245725512504578, Accuracy: 0.828125\n",
      "Batch: 144, Loss: 0.543820858001709, Accuracy: 0.81640625\n",
      "Batch: 145, Loss: 0.4746233820915222, Accuracy: 0.845703125\n",
      "Batch: 146, Loss: 0.5210765600204468, Accuracy: 0.830078125\n",
      "Batch: 147, Loss: 0.46229636669158936, Accuracy: 0.8447265625\n",
      "Batch: 148, Loss: 0.5930213928222656, Accuracy: 0.8046875\n",
      "Batch: 149, Loss: 0.47159937024116516, Accuracy: 0.85546875\n",
      "Batch: 150, Loss: 0.5144782066345215, Accuracy: 0.8212890625\n",
      "Batch: 151, Loss: 0.5069504380226135, Accuracy: 0.83203125\n",
      "Epoch 69/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 0.6904306411743164, Accuracy: 0.7939453125\n",
      "Batch: 2, Loss: 0.6170691251754761, Accuracy: 0.7919921875\n",
      "Batch: 3, Loss: 0.529281497001648, Accuracy: 0.8193359375\n",
      "Batch: 4, Loss: 0.5111418962478638, Accuracy: 0.8291015625\n",
      "Batch: 5, Loss: 0.47632116079330444, Accuracy: 0.8330078125\n",
      "Batch: 6, Loss: 0.5126791000366211, Accuracy: 0.8232421875\n",
      "Batch: 7, Loss: 0.5411942601203918, Accuracy: 0.828125\n",
      "Batch: 8, Loss: 0.4899691343307495, Accuracy: 0.8369140625\n",
      "Batch: 9, Loss: 0.4926897883415222, Accuracy: 0.8408203125\n",
      "Batch: 10, Loss: 0.4930497407913208, Accuracy: 0.8330078125\n",
      "Batch: 11, Loss: 0.5313483476638794, Accuracy: 0.83203125\n",
      "Batch: 12, Loss: 0.538902759552002, Accuracy: 0.8212890625\n",
      "Batch: 13, Loss: 0.4302200675010681, Accuracy: 0.8662109375\n",
      "Batch: 14, Loss: 0.5541743040084839, Accuracy: 0.82421875\n",
      "Batch: 15, Loss: 0.4878230690956116, Accuracy: 0.8388671875\n",
      "Batch: 16, Loss: 0.47047001123428345, Accuracy: 0.845703125\n",
      "Batch: 17, Loss: 0.5076454877853394, Accuracy: 0.84375\n",
      "Batch: 18, Loss: 0.5322678089141846, Accuracy: 0.8193359375\n",
      "Batch: 19, Loss: 0.5332093238830566, Accuracy: 0.833984375\n",
      "Batch: 20, Loss: 0.4490090608596802, Accuracy: 0.84765625\n",
      "Batch: 21, Loss: 0.4934406876564026, Accuracy: 0.8310546875\n",
      "Batch: 22, Loss: 0.6025712490081787, Accuracy: 0.8125\n",
      "Batch: 23, Loss: 0.5456523895263672, Accuracy: 0.8203125\n",
      "Batch: 24, Loss: 0.5547981262207031, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5120517015457153, Accuracy: 0.83984375\n",
      "Batch: 26, Loss: 0.44055891036987305, Accuracy: 0.8505859375\n",
      "Batch: 27, Loss: 0.49626147747039795, Accuracy: 0.83203125\n",
      "Batch: 28, Loss: 0.4765687584877014, Accuracy: 0.833984375\n",
      "Batch: 29, Loss: 0.4659775495529175, Accuracy: 0.8447265625\n",
      "Batch: 30, Loss: 0.4341757893562317, Accuracy: 0.8603515625\n",
      "Batch: 31, Loss: 0.4580494165420532, Accuracy: 0.849609375\n",
      "Batch: 32, Loss: 0.45002734661102295, Accuracy: 0.8515625\n",
      "Batch: 33, Loss: 0.5292661190032959, Accuracy: 0.8291015625\n",
      "Batch: 34, Loss: 0.6026706695556641, Accuracy: 0.80078125\n",
      "Batch: 35, Loss: 0.5330264568328857, Accuracy: 0.81640625\n",
      "Batch: 36, Loss: 0.492326557636261, Accuracy: 0.8408203125\n",
      "Batch: 37, Loss: 0.5347284078598022, Accuracy: 0.8173828125\n",
      "Batch: 38, Loss: 0.5112840533256531, Accuracy: 0.822265625\n",
      "Batch: 39, Loss: 0.493040531873703, Accuracy: 0.841796875\n",
      "Batch: 40, Loss: 0.5290029048919678, Accuracy: 0.8134765625\n",
      "Batch: 41, Loss: 0.4635944068431854, Accuracy: 0.841796875\n",
      "Batch: 42, Loss: 0.39131462574005127, Accuracy: 0.865234375\n",
      "Batch: 43, Loss: 0.486383855342865, Accuracy: 0.8349609375\n",
      "Batch: 44, Loss: 0.4992704689502716, Accuracy: 0.8251953125\n",
      "Batch: 45, Loss: 0.4832944869995117, Accuracy: 0.8369140625\n",
      "Batch: 46, Loss: 0.43147528171539307, Accuracy: 0.853515625\n",
      "Batch: 47, Loss: 0.4508900046348572, Accuracy: 0.859375\n",
      "Batch: 48, Loss: 0.439590722322464, Accuracy: 0.8583984375\n",
      "Batch: 49, Loss: 0.4614830017089844, Accuracy: 0.8544921875\n",
      "Batch: 50, Loss: 0.5208809971809387, Accuracy: 0.8193359375\n",
      "Batch: 51, Loss: 0.46420425176620483, Accuracy: 0.8486328125\n",
      "Batch: 52, Loss: 0.5135928392410278, Accuracy: 0.8212890625\n",
      "Batch: 53, Loss: 0.44179508090019226, Accuracy: 0.8515625\n",
      "Batch: 54, Loss: 0.4632812738418579, Accuracy: 0.8408203125\n",
      "Batch: 55, Loss: 0.5539443492889404, Accuracy: 0.82421875\n",
      "Batch: 56, Loss: 0.5962954759597778, Accuracy: 0.80078125\n",
      "Batch: 57, Loss: 0.5092877149581909, Accuracy: 0.83203125\n",
      "Batch: 58, Loss: 0.577629029750824, Accuracy: 0.8017578125\n",
      "Batch: 59, Loss: 0.489449143409729, Accuracy: 0.8330078125\n",
      "Batch: 60, Loss: 0.44752830266952515, Accuracy: 0.8515625\n",
      "Batch: 61, Loss: 0.4946860074996948, Accuracy: 0.845703125\n",
      "Batch: 62, Loss: 0.45663851499557495, Accuracy: 0.841796875\n",
      "Batch: 63, Loss: 0.4391170144081116, Accuracy: 0.8466796875\n",
      "Batch: 64, Loss: 0.4907166659832001, Accuracy: 0.8408203125\n",
      "Batch: 65, Loss: 0.4932190179824829, Accuracy: 0.8408203125\n",
      "Batch: 66, Loss: 0.513498067855835, Accuracy: 0.8310546875\n",
      "Batch: 67, Loss: 0.5426291823387146, Accuracy: 0.810546875\n",
      "Batch: 68, Loss: 0.5916463136672974, Accuracy: 0.802734375\n",
      "Batch: 69, Loss: 0.5497533679008484, Accuracy: 0.81640625\n",
      "Batch: 70, Loss: 0.5297907590866089, Accuracy: 0.8271484375\n",
      "Batch: 71, Loss: 0.5440950393676758, Accuracy: 0.796875\n",
      "Batch: 72, Loss: 0.496774286031723, Accuracy: 0.837890625\n",
      "Batch: 73, Loss: 0.4563990831375122, Accuracy: 0.8583984375\n",
      "Batch: 74, Loss: 0.433002233505249, Accuracy: 0.8583984375\n",
      "Batch: 75, Loss: 0.4321041405200958, Accuracy: 0.869140625\n",
      "Batch: 76, Loss: 0.5049203634262085, Accuracy: 0.837890625\n",
      "Batch: 77, Loss: 0.47746598720550537, Accuracy: 0.8466796875\n",
      "Batch: 78, Loss: 0.4934547543525696, Accuracy: 0.84375\n",
      "Batch: 79, Loss: 0.44586390256881714, Accuracy: 0.84765625\n",
      "Batch: 80, Loss: 0.4842516779899597, Accuracy: 0.8515625\n",
      "Batch: 81, Loss: 0.5490066409111023, Accuracy: 0.8115234375\n",
      "Batch: 82, Loss: 0.47162550687789917, Accuracy: 0.841796875\n",
      "Batch: 83, Loss: 0.45262205600738525, Accuracy: 0.86328125\n",
      "Batch: 84, Loss: 0.5376697778701782, Accuracy: 0.8173828125\n",
      "Batch: 85, Loss: 0.47026002407073975, Accuracy: 0.8525390625\n",
      "Batch: 86, Loss: 0.5605039596557617, Accuracy: 0.8203125\n",
      "Batch: 87, Loss: 0.4347461462020874, Accuracy: 0.8564453125\n",
      "Batch: 88, Loss: 0.5412929058074951, Accuracy: 0.83203125\n",
      "Batch: 89, Loss: 0.5009101629257202, Accuracy: 0.833984375\n",
      "Batch: 90, Loss: 0.5519274473190308, Accuracy: 0.822265625\n",
      "Batch: 91, Loss: 0.5013590455055237, Accuracy: 0.8291015625\n",
      "Batch: 92, Loss: 0.5456273555755615, Accuracy: 0.8125\n",
      "Batch: 93, Loss: 0.48439013957977295, Accuracy: 0.853515625\n",
      "Batch: 94, Loss: 0.49756115674972534, Accuracy: 0.833984375\n",
      "Batch: 95, Loss: 0.5315989255905151, Accuracy: 0.8251953125\n",
      "Batch: 96, Loss: 0.5099425315856934, Accuracy: 0.8330078125\n",
      "Batch: 97, Loss: 0.3862568736076355, Accuracy: 0.8701171875\n",
      "Batch: 98, Loss: 0.5088456869125366, Accuracy: 0.8291015625\n",
      "Batch: 99, Loss: 0.49021434783935547, Accuracy: 0.8271484375\n",
      "Batch: 100, Loss: 0.5234166383743286, Accuracy: 0.826171875\n",
      "Batch: 101, Loss: 0.4979415237903595, Accuracy: 0.8369140625\n",
      "Batch: 102, Loss: 0.48482316732406616, Accuracy: 0.841796875\n",
      "Batch: 103, Loss: 0.5273433923721313, Accuracy: 0.826171875\n",
      "Batch: 104, Loss: 0.44410842657089233, Accuracy: 0.84765625\n",
      "Batch: 105, Loss: 0.5561027526855469, Accuracy: 0.80859375\n",
      "Batch: 106, Loss: 0.46003100275993347, Accuracy: 0.84765625\n",
      "Batch: 107, Loss: 0.45832526683807373, Accuracy: 0.8583984375\n",
      "Batch: 108, Loss: 0.5059633851051331, Accuracy: 0.8251953125\n",
      "Batch: 109, Loss: 0.5514960885047913, Accuracy: 0.814453125\n",
      "Batch: 110, Loss: 0.4320356845855713, Accuracy: 0.8505859375\n",
      "Batch: 111, Loss: 0.5103350877761841, Accuracy: 0.8310546875\n",
      "Batch: 112, Loss: 0.46497225761413574, Accuracy: 0.8525390625\n",
      "Batch: 113, Loss: 0.4714752435684204, Accuracy: 0.85546875\n",
      "Batch: 114, Loss: 0.5488569736480713, Accuracy: 0.828125\n",
      "Batch: 115, Loss: 0.5305200815200806, Accuracy: 0.8330078125\n",
      "Batch: 116, Loss: 0.5100239515304565, Accuracy: 0.8310546875\n",
      "Batch: 117, Loss: 0.5553725957870483, Accuracy: 0.82421875\n",
      "Batch: 118, Loss: 0.4772128462791443, Accuracy: 0.84375\n",
      "Batch: 119, Loss: 0.3879830837249756, Accuracy: 0.8740234375\n",
      "Batch: 120, Loss: 0.4951595962047577, Accuracy: 0.8349609375\n",
      "Batch: 121, Loss: 0.5331671237945557, Accuracy: 0.8271484375\n",
      "Batch: 122, Loss: 0.47538435459136963, Accuracy: 0.8447265625\n",
      "Batch: 123, Loss: 0.49140042066574097, Accuracy: 0.8427734375\n",
      "Batch: 124, Loss: 0.4754244089126587, Accuracy: 0.8369140625\n",
      "Batch: 125, Loss: 0.5167614221572876, Accuracy: 0.83203125\n",
      "Batch: 126, Loss: 0.5350908041000366, Accuracy: 0.82421875\n",
      "Batch: 127, Loss: 0.4424251914024353, Accuracy: 0.8525390625\n",
      "Batch: 128, Loss: 0.5587191581726074, Accuracy: 0.826171875\n",
      "Batch: 129, Loss: 0.43480873107910156, Accuracy: 0.8583984375\n",
      "Batch: 130, Loss: 0.5454562902450562, Accuracy: 0.8212890625\n",
      "Batch: 131, Loss: 0.47489872574806213, Accuracy: 0.83984375\n",
      "Batch: 132, Loss: 0.5339070558547974, Accuracy: 0.8203125\n",
      "Batch: 133, Loss: 0.4987144470214844, Accuracy: 0.8408203125\n",
      "Batch: 134, Loss: 0.49196213483810425, Accuracy: 0.84375\n",
      "Batch: 135, Loss: 0.4888816773891449, Accuracy: 0.8408203125\n",
      "Batch: 136, Loss: 0.5082025527954102, Accuracy: 0.826171875\n",
      "Batch: 137, Loss: 0.5363622307777405, Accuracy: 0.82421875\n",
      "Batch: 138, Loss: 0.4915810227394104, Accuracy: 0.833984375\n",
      "Batch: 139, Loss: 0.5472780466079712, Accuracy: 0.8173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 0.5034894943237305, Accuracy: 0.8251953125\n",
      "Batch: 141, Loss: 0.5370084047317505, Accuracy: 0.814453125\n",
      "Batch: 142, Loss: 0.5331276655197144, Accuracy: 0.81640625\n",
      "Batch: 143, Loss: 0.5085323452949524, Accuracy: 0.830078125\n",
      "Batch: 144, Loss: 0.5568969249725342, Accuracy: 0.8291015625\n",
      "Batch: 145, Loss: 0.5415200591087341, Accuracy: 0.8115234375\n",
      "Batch: 146, Loss: 0.5146036148071289, Accuracy: 0.822265625\n",
      "Batch: 147, Loss: 0.5276881456375122, Accuracy: 0.8310546875\n",
      "Batch: 148, Loss: 0.6108230352401733, Accuracy: 0.7939453125\n",
      "Batch: 149, Loss: 0.48371878266334534, Accuracy: 0.84765625\n",
      "Batch: 150, Loss: 0.46787142753601074, Accuracy: 0.8466796875\n",
      "Batch: 151, Loss: 0.49121102690696716, Accuracy: 0.8408203125\n",
      "Epoch 70/80\n",
      "Batch: 1, Loss: 0.681198000907898, Accuracy: 0.798828125\n",
      "Batch: 2, Loss: 0.6121188402175903, Accuracy: 0.775390625\n",
      "Batch: 3, Loss: 0.5232193470001221, Accuracy: 0.83203125\n",
      "Batch: 4, Loss: 0.485644668340683, Accuracy: 0.8486328125\n",
      "Batch: 5, Loss: 0.4836530089378357, Accuracy: 0.84765625\n",
      "Batch: 6, Loss: 0.5021257400512695, Accuracy: 0.8349609375\n",
      "Batch: 7, Loss: 0.5226355791091919, Accuracy: 0.8291015625\n",
      "Batch: 8, Loss: 0.49370482563972473, Accuracy: 0.8369140625\n",
      "Batch: 9, Loss: 0.5267617702484131, Accuracy: 0.828125\n",
      "Batch: 10, Loss: 0.5130488872528076, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.5523431897163391, Accuracy: 0.80078125\n",
      "Batch: 12, Loss: 0.5221045613288879, Accuracy: 0.826171875\n",
      "Batch: 13, Loss: 0.4243755340576172, Accuracy: 0.8671875\n",
      "Batch: 14, Loss: 0.5816699266433716, Accuracy: 0.8134765625\n",
      "Batch: 15, Loss: 0.45218756794929504, Accuracy: 0.849609375\n",
      "Batch: 16, Loss: 0.4877697229385376, Accuracy: 0.83984375\n",
      "Batch: 17, Loss: 0.5122984647750854, Accuracy: 0.8349609375\n",
      "Batch: 18, Loss: 0.49928951263427734, Accuracy: 0.845703125\n",
      "Batch: 19, Loss: 0.5557270050048828, Accuracy: 0.814453125\n",
      "Batch: 20, Loss: 0.4467114210128784, Accuracy: 0.84765625\n",
      "Batch: 21, Loss: 0.5109618306159973, Accuracy: 0.8173828125\n",
      "Batch: 22, Loss: 0.5736507773399353, Accuracy: 0.80859375\n",
      "Batch: 23, Loss: 0.548536479473114, Accuracy: 0.8046875\n",
      "Batch: 24, Loss: 0.577846884727478, Accuracy: 0.8115234375\n",
      "Batch: 25, Loss: 0.4891026020050049, Accuracy: 0.8505859375\n",
      "Batch: 26, Loss: 0.4459587335586548, Accuracy: 0.8486328125\n",
      "Batch: 27, Loss: 0.4859544038772583, Accuracy: 0.82421875\n",
      "Batch: 28, Loss: 0.5265340209007263, Accuracy: 0.8310546875\n",
      "Batch: 29, Loss: 0.4704752564430237, Accuracy: 0.8408203125\n",
      "Batch: 30, Loss: 0.4220343232154846, Accuracy: 0.8623046875\n",
      "Batch: 31, Loss: 0.45870155096054077, Accuracy: 0.8369140625\n",
      "Batch: 32, Loss: 0.46406131982803345, Accuracy: 0.849609375\n",
      "Batch: 33, Loss: 0.5238478183746338, Accuracy: 0.8203125\n",
      "Batch: 34, Loss: 0.6296288967132568, Accuracy: 0.7978515625\n",
      "Batch: 35, Loss: 0.502037525177002, Accuracy: 0.83203125\n",
      "Batch: 36, Loss: 0.525449812412262, Accuracy: 0.83984375\n",
      "Batch: 37, Loss: 0.5213353633880615, Accuracy: 0.8095703125\n",
      "Batch: 38, Loss: 0.49031874537467957, Accuracy: 0.833984375\n",
      "Batch: 39, Loss: 0.5331937670707703, Accuracy: 0.8173828125\n",
      "Batch: 40, Loss: 0.4874342083930969, Accuracy: 0.8388671875\n",
      "Batch: 41, Loss: 0.4516541361808777, Accuracy: 0.8505859375\n",
      "Batch: 42, Loss: 0.37251579761505127, Accuracy: 0.8798828125\n",
      "Batch: 43, Loss: 0.5057973861694336, Accuracy: 0.8310546875\n",
      "Batch: 44, Loss: 0.4624979496002197, Accuracy: 0.8525390625\n",
      "Batch: 45, Loss: 0.43229401111602783, Accuracy: 0.8564453125\n",
      "Batch: 46, Loss: 0.41351887583732605, Accuracy: 0.8583984375\n",
      "Batch: 47, Loss: 0.4474223554134369, Accuracy: 0.8671875\n",
      "Batch: 48, Loss: 0.4425939619541168, Accuracy: 0.8681640625\n",
      "Batch: 49, Loss: 0.513783872127533, Accuracy: 0.8388671875\n",
      "Batch: 50, Loss: 0.48273855447769165, Accuracy: 0.849609375\n",
      "Batch: 51, Loss: 0.46123528480529785, Accuracy: 0.8515625\n",
      "Batch: 52, Loss: 0.4899351894855499, Accuracy: 0.841796875\n",
      "Batch: 53, Loss: 0.4272516369819641, Accuracy: 0.8515625\n",
      "Batch: 54, Loss: 0.4936676025390625, Accuracy: 0.8291015625\n",
      "Batch: 55, Loss: 0.4893096387386322, Accuracy: 0.8486328125\n",
      "Batch: 56, Loss: 0.5698220133781433, Accuracy: 0.798828125\n",
      "Batch: 57, Loss: 0.5073505640029907, Accuracy: 0.8408203125\n",
      "Batch: 58, Loss: 0.5701904892921448, Accuracy: 0.8056640625\n",
      "Batch: 59, Loss: 0.4765663743019104, Accuracy: 0.83984375\n",
      "Batch: 60, Loss: 0.46566271781921387, Accuracy: 0.83984375\n",
      "Batch: 61, Loss: 0.5208132863044739, Accuracy: 0.828125\n",
      "Batch: 62, Loss: 0.41100144386291504, Accuracy: 0.8671875\n",
      "Batch: 63, Loss: 0.4737381339073181, Accuracy: 0.8388671875\n",
      "Batch: 64, Loss: 0.5056314468383789, Accuracy: 0.83984375\n",
      "Batch: 65, Loss: 0.4978187680244446, Accuracy: 0.8291015625\n",
      "Batch: 66, Loss: 0.4652212858200073, Accuracy: 0.8505859375\n",
      "Batch: 67, Loss: 0.5412797927856445, Accuracy: 0.8271484375\n",
      "Batch: 68, Loss: 0.5620115995407104, Accuracy: 0.81640625\n",
      "Batch: 69, Loss: 0.5156253576278687, Accuracy: 0.8291015625\n",
      "Batch: 70, Loss: 0.5137672424316406, Accuracy: 0.8359375\n",
      "Batch: 71, Loss: 0.5397152900695801, Accuracy: 0.8173828125\n",
      "Batch: 72, Loss: 0.4881521463394165, Accuracy: 0.83203125\n",
      "Batch: 73, Loss: 0.46780064702033997, Accuracy: 0.8447265625\n",
      "Batch: 74, Loss: 0.39429229497909546, Accuracy: 0.87109375\n",
      "Batch: 75, Loss: 0.4067378640174866, Accuracy: 0.8603515625\n",
      "Batch: 76, Loss: 0.487653911113739, Accuracy: 0.845703125\n",
      "Batch: 77, Loss: 0.4756118357181549, Accuracy: 0.8447265625\n",
      "Batch: 78, Loss: 0.44228389859199524, Accuracy: 0.8515625\n",
      "Batch: 79, Loss: 0.43552491068840027, Accuracy: 0.857421875\n",
      "Batch: 80, Loss: 0.4460766315460205, Accuracy: 0.849609375\n",
      "Batch: 81, Loss: 0.5107506513595581, Accuracy: 0.8134765625\n",
      "Batch: 82, Loss: 0.453642874956131, Accuracy: 0.84375\n",
      "Batch: 83, Loss: 0.4177221357822418, Accuracy: 0.87109375\n",
      "Batch: 84, Loss: 0.4955819845199585, Accuracy: 0.8291015625\n",
      "Batch: 85, Loss: 0.4848613440990448, Accuracy: 0.8447265625\n",
      "Batch: 86, Loss: 0.5943911671638489, Accuracy: 0.8134765625\n",
      "Batch: 87, Loss: 0.4479016661643982, Accuracy: 0.8544921875\n",
      "Batch: 88, Loss: 0.523095428943634, Accuracy: 0.83203125\n",
      "Batch: 89, Loss: 0.49258410930633545, Accuracy: 0.83203125\n",
      "Batch: 90, Loss: 0.5327948927879333, Accuracy: 0.8271484375\n",
      "Batch: 91, Loss: 0.46478965878486633, Accuracy: 0.8369140625\n",
      "Batch: 92, Loss: 0.5133590698242188, Accuracy: 0.8388671875\n",
      "Batch: 93, Loss: 0.4478025436401367, Accuracy: 0.84375\n",
      "Batch: 94, Loss: 0.5210593342781067, Accuracy: 0.8291015625\n",
      "Batch: 95, Loss: 0.5272238254547119, Accuracy: 0.830078125\n",
      "Batch: 96, Loss: 0.49973076581954956, Accuracy: 0.8349609375\n",
      "Batch: 97, Loss: 0.3975623846054077, Accuracy: 0.8701171875\n",
      "Batch: 98, Loss: 0.4806421101093292, Accuracy: 0.845703125\n",
      "Batch: 99, Loss: 0.48576366901397705, Accuracy: 0.83984375\n",
      "Batch: 100, Loss: 0.4888688921928406, Accuracy: 0.833984375\n",
      "Batch: 101, Loss: 0.49335479736328125, Accuracy: 0.845703125\n",
      "Batch: 102, Loss: 0.4993184804916382, Accuracy: 0.8330078125\n",
      "Batch: 103, Loss: 0.5412843227386475, Accuracy: 0.830078125\n",
      "Batch: 104, Loss: 0.47405150532722473, Accuracy: 0.83203125\n",
      "Batch: 105, Loss: 0.5028676986694336, Accuracy: 0.8173828125\n",
      "Batch: 106, Loss: 0.45734888315200806, Accuracy: 0.8515625\n",
      "Batch: 107, Loss: 0.44579583406448364, Accuracy: 0.857421875\n",
      "Batch: 108, Loss: 0.5139034986495972, Accuracy: 0.8349609375\n",
      "Batch: 109, Loss: 0.5242135524749756, Accuracy: 0.826171875\n",
      "Batch: 110, Loss: 0.4506676495075226, Accuracy: 0.8505859375\n",
      "Batch: 111, Loss: 0.4892231225967407, Accuracy: 0.8486328125\n",
      "Batch: 112, Loss: 0.498472660779953, Accuracy: 0.8291015625\n",
      "Batch: 113, Loss: 0.5163443684577942, Accuracy: 0.8447265625\n",
      "Batch: 114, Loss: 0.5719830989837646, Accuracy: 0.8203125\n",
      "Batch: 115, Loss: 0.5490599870681763, Accuracy: 0.826171875\n",
      "Batch: 116, Loss: 0.5000792741775513, Accuracy: 0.833984375\n",
      "Batch: 117, Loss: 0.5137854814529419, Accuracy: 0.822265625\n",
      "Batch: 118, Loss: 0.4354199767112732, Accuracy: 0.8671875\n",
      "Batch: 119, Loss: 0.3876016139984131, Accuracy: 0.869140625\n",
      "Batch: 120, Loss: 0.457405149936676, Accuracy: 0.8525390625\n",
      "Batch: 121, Loss: 0.5549317598342896, Accuracy: 0.818359375\n",
      "Batch: 122, Loss: 0.44703060388565063, Accuracy: 0.85546875\n",
      "Batch: 123, Loss: 0.465104341506958, Accuracy: 0.8388671875\n",
      "Batch: 124, Loss: 0.5232599973678589, Accuracy: 0.8310546875\n",
      "Batch: 125, Loss: 0.5296945571899414, Accuracy: 0.8193359375\n",
      "Batch: 126, Loss: 0.5406481623649597, Accuracy: 0.8310546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127, Loss: 0.46912330389022827, Accuracy: 0.84765625\n",
      "Batch: 128, Loss: 0.5582026243209839, Accuracy: 0.8134765625\n",
      "Batch: 129, Loss: 0.4433351159095764, Accuracy: 0.8447265625\n",
      "Batch: 130, Loss: 0.5656640529632568, Accuracy: 0.8251953125\n",
      "Batch: 131, Loss: 0.4938293397426605, Accuracy: 0.83203125\n",
      "Batch: 132, Loss: 0.4804125428199768, Accuracy: 0.830078125\n",
      "Batch: 133, Loss: 0.4935191571712494, Accuracy: 0.8369140625\n",
      "Batch: 134, Loss: 0.5045143961906433, Accuracy: 0.8251953125\n",
      "Batch: 135, Loss: 0.4458753764629364, Accuracy: 0.849609375\n",
      "Batch: 136, Loss: 0.524142324924469, Accuracy: 0.81640625\n",
      "Batch: 137, Loss: 0.5371335744857788, Accuracy: 0.8154296875\n",
      "Batch: 138, Loss: 0.48055410385131836, Accuracy: 0.83203125\n",
      "Batch: 139, Loss: 0.5547747611999512, Accuracy: 0.8115234375\n",
      "Batch: 140, Loss: 0.5307567119598389, Accuracy: 0.82421875\n",
      "Batch: 141, Loss: 0.5750625133514404, Accuracy: 0.8037109375\n",
      "Batch: 142, Loss: 0.5286902189254761, Accuracy: 0.828125\n",
      "Batch: 143, Loss: 0.490898996591568, Accuracy: 0.826171875\n",
      "Batch: 144, Loss: 0.5290119647979736, Accuracy: 0.8232421875\n",
      "Batch: 145, Loss: 0.4910898208618164, Accuracy: 0.8388671875\n",
      "Batch: 146, Loss: 0.5021944046020508, Accuracy: 0.8330078125\n",
      "Batch: 147, Loss: 0.4672824740409851, Accuracy: 0.8486328125\n",
      "Batch: 148, Loss: 0.56556236743927, Accuracy: 0.8154296875\n",
      "Batch: 149, Loss: 0.4873776435852051, Accuracy: 0.837890625\n",
      "Batch: 150, Loss: 0.5271444320678711, Accuracy: 0.8193359375\n",
      "Batch: 151, Loss: 0.4741365909576416, Accuracy: 0.8359375\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/80\n",
      "Batch: 1, Loss: 0.6399305462837219, Accuracy: 0.7978515625\n",
      "Batch: 2, Loss: 0.548099160194397, Accuracy: 0.8095703125\n",
      "Batch: 3, Loss: 0.5366300344467163, Accuracy: 0.830078125\n",
      "Batch: 4, Loss: 0.47718289494514465, Accuracy: 0.841796875\n",
      "Batch: 5, Loss: 0.4867748022079468, Accuracy: 0.8447265625\n",
      "Batch: 6, Loss: 0.5138295888900757, Accuracy: 0.8212890625\n",
      "Batch: 7, Loss: 0.5147780179977417, Accuracy: 0.8232421875\n",
      "Batch: 8, Loss: 0.5001831650733948, Accuracy: 0.8359375\n",
      "Batch: 9, Loss: 0.5159511566162109, Accuracy: 0.8232421875\n",
      "Batch: 10, Loss: 0.4740336537361145, Accuracy: 0.833984375\n",
      "Batch: 11, Loss: 0.5486146211624146, Accuracy: 0.8203125\n",
      "Batch: 12, Loss: 0.5160022974014282, Accuracy: 0.826171875\n",
      "Batch: 13, Loss: 0.443693608045578, Accuracy: 0.8544921875\n",
      "Batch: 14, Loss: 0.5523092746734619, Accuracy: 0.8212890625\n",
      "Batch: 15, Loss: 0.48019441962242126, Accuracy: 0.845703125\n",
      "Batch: 16, Loss: 0.4807533621788025, Accuracy: 0.8505859375\n",
      "Batch: 17, Loss: 0.494343101978302, Accuracy: 0.8310546875\n",
      "Batch: 18, Loss: 0.51121586561203, Accuracy: 0.822265625\n",
      "Batch: 19, Loss: 0.5178182125091553, Accuracy: 0.8388671875\n",
      "Batch: 20, Loss: 0.4410969018936157, Accuracy: 0.853515625\n",
      "Batch: 21, Loss: 0.5097370147705078, Accuracy: 0.82421875\n",
      "Batch: 22, Loss: 0.5870655179023743, Accuracy: 0.8076171875\n",
      "Batch: 23, Loss: 0.5533849000930786, Accuracy: 0.82421875\n",
      "Batch: 24, Loss: 0.5565242767333984, Accuracy: 0.8232421875\n",
      "Batch: 25, Loss: 0.5175386667251587, Accuracy: 0.853515625\n",
      "Batch: 26, Loss: 0.43566277623176575, Accuracy: 0.853515625\n",
      "Batch: 27, Loss: 0.4646129012107849, Accuracy: 0.845703125\n",
      "Batch: 28, Loss: 0.4960089921951294, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.48102980852127075, Accuracy: 0.8408203125\n",
      "Batch: 30, Loss: 0.4359893798828125, Accuracy: 0.8544921875\n",
      "Batch: 31, Loss: 0.4585877060890198, Accuracy: 0.8515625\n",
      "Batch: 32, Loss: 0.45046988129615784, Accuracy: 0.841796875\n",
      "Batch: 33, Loss: 0.4888886511325836, Accuracy: 0.8544921875\n",
      "Batch: 34, Loss: 0.5774668455123901, Accuracy: 0.8173828125\n",
      "Batch: 35, Loss: 0.4833633303642273, Accuracy: 0.841796875\n",
      "Batch: 36, Loss: 0.4988507330417633, Accuracy: 0.84375\n",
      "Batch: 37, Loss: 0.5304392576217651, Accuracy: 0.818359375\n",
      "Batch: 38, Loss: 0.47763437032699585, Accuracy: 0.830078125\n",
      "Batch: 39, Loss: 0.5115602612495422, Accuracy: 0.8232421875\n",
      "Batch: 40, Loss: 0.49375802278518677, Accuracy: 0.830078125\n",
      "Batch: 41, Loss: 0.4636421501636505, Accuracy: 0.8525390625\n",
      "Batch: 42, Loss: 0.41334542632102966, Accuracy: 0.859375\n",
      "Batch: 43, Loss: 0.4831928014755249, Accuracy: 0.837890625\n",
      "Batch: 44, Loss: 0.47461336851119995, Accuracy: 0.8427734375\n",
      "Batch: 45, Loss: 0.4649880528450012, Accuracy: 0.84765625\n",
      "Batch: 46, Loss: 0.4490353465080261, Accuracy: 0.849609375\n",
      "Batch: 47, Loss: 0.4703265428543091, Accuracy: 0.849609375\n",
      "Batch: 48, Loss: 0.43402156233787537, Accuracy: 0.8525390625\n",
      "Batch: 49, Loss: 0.4692104458808899, Accuracy: 0.87109375\n",
      "Batch: 50, Loss: 0.4781963527202606, Accuracy: 0.8603515625\n",
      "Batch: 51, Loss: 0.46825850009918213, Accuracy: 0.84765625\n",
      "Batch: 52, Loss: 0.4791692793369293, Accuracy: 0.8427734375\n",
      "Batch: 53, Loss: 0.43545281887054443, Accuracy: 0.84765625\n",
      "Batch: 54, Loss: 0.45821040868759155, Accuracy: 0.8505859375\n",
      "Batch: 55, Loss: 0.5523926019668579, Accuracy: 0.8173828125\n",
      "Batch: 56, Loss: 0.519450306892395, Accuracy: 0.8193359375\n",
      "Batch: 57, Loss: 0.5014477968215942, Accuracy: 0.8369140625\n",
      "Batch: 58, Loss: 0.5391660928726196, Accuracy: 0.8203125\n",
      "Batch: 59, Loss: 0.46848663687705994, Accuracy: 0.841796875\n",
      "Batch: 60, Loss: 0.48678460717201233, Accuracy: 0.8427734375\n",
      "Batch: 61, Loss: 0.5317832827568054, Accuracy: 0.8173828125\n",
      "Batch: 62, Loss: 0.4386295676231384, Accuracy: 0.859375\n",
      "Batch: 63, Loss: 0.493066668510437, Accuracy: 0.8486328125\n",
      "Batch: 64, Loss: 0.4658178687095642, Accuracy: 0.8408203125\n",
      "Batch: 65, Loss: 0.5010339021682739, Accuracy: 0.833984375\n",
      "Batch: 66, Loss: 0.4845956265926361, Accuracy: 0.849609375\n",
      "Batch: 67, Loss: 0.5570853352546692, Accuracy: 0.8232421875\n",
      "Batch: 68, Loss: 0.5665971040725708, Accuracy: 0.8193359375\n",
      "Batch: 69, Loss: 0.5288278460502625, Accuracy: 0.822265625\n",
      "Batch: 70, Loss: 0.5420041084289551, Accuracy: 0.8251953125\n",
      "Batch: 71, Loss: 0.5426591634750366, Accuracy: 0.8154296875\n",
      "Batch: 72, Loss: 0.4862726628780365, Accuracy: 0.8427734375\n",
      "Batch: 73, Loss: 0.44813451170921326, Accuracy: 0.85546875\n",
      "Batch: 74, Loss: 0.40347108244895935, Accuracy: 0.873046875\n",
      "Batch: 75, Loss: 0.4360589385032654, Accuracy: 0.84375\n",
      "Batch: 76, Loss: 0.5226010680198669, Accuracy: 0.8134765625\n",
      "Batch: 77, Loss: 0.45712044835090637, Accuracy: 0.8486328125\n",
      "Batch: 78, Loss: 0.48982882499694824, Accuracy: 0.8544921875\n",
      "Batch: 79, Loss: 0.45185503363609314, Accuracy: 0.8642578125\n",
      "Batch: 80, Loss: 0.42497992515563965, Accuracy: 0.8583984375\n",
      "Batch: 81, Loss: 0.5535770654678345, Accuracy: 0.7958984375\n",
      "Batch: 82, Loss: 0.47511816024780273, Accuracy: 0.8447265625\n",
      "Batch: 83, Loss: 0.4344615340232849, Accuracy: 0.845703125\n",
      "Batch: 84, Loss: 0.5209304094314575, Accuracy: 0.81640625\n",
      "Batch: 85, Loss: 0.4840540289878845, Accuracy: 0.8466796875\n",
      "Batch: 86, Loss: 0.5643584728240967, Accuracy: 0.8173828125\n",
      "Batch: 87, Loss: 0.4226544201374054, Accuracy: 0.86328125\n",
      "Batch: 88, Loss: 0.5068085193634033, Accuracy: 0.8427734375\n",
      "Batch: 89, Loss: 0.4666064977645874, Accuracy: 0.845703125\n",
      "Batch: 90, Loss: 0.4777156114578247, Accuracy: 0.8525390625\n",
      "Batch: 91, Loss: 0.48075875639915466, Accuracy: 0.8369140625\n",
      "Batch: 92, Loss: 0.492311954498291, Accuracy: 0.84765625\n",
      "Batch: 93, Loss: 0.4656626582145691, Accuracy: 0.8486328125\n",
      "Batch: 94, Loss: 0.493490993976593, Accuracy: 0.837890625\n",
      "Batch: 95, Loss: 0.5181971192359924, Accuracy: 0.83203125\n",
      "Batch: 96, Loss: 0.48228779435157776, Accuracy: 0.84765625\n",
      "Batch: 97, Loss: 0.3795754909515381, Accuracy: 0.8779296875\n",
      "Batch: 98, Loss: 0.5072665214538574, Accuracy: 0.8330078125\n",
      "Batch: 99, Loss: 0.4689759612083435, Accuracy: 0.837890625\n",
      "Batch: 100, Loss: 0.5034304857254028, Accuracy: 0.837890625\n",
      "Batch: 101, Loss: 0.49909454584121704, Accuracy: 0.8291015625\n",
      "Batch: 102, Loss: 0.48556774854660034, Accuracy: 0.83984375\n",
      "Batch: 103, Loss: 0.4919143319129944, Accuracy: 0.849609375\n",
      "Batch: 104, Loss: 0.4860774278640747, Accuracy: 0.8359375\n",
      "Batch: 105, Loss: 0.5342916250228882, Accuracy: 0.8271484375\n",
      "Batch: 106, Loss: 0.41923987865448, Accuracy: 0.8583984375\n",
      "Batch: 107, Loss: 0.4621831476688385, Accuracy: 0.849609375\n",
      "Batch: 108, Loss: 0.48926064372062683, Accuracy: 0.830078125\n",
      "Batch: 109, Loss: 0.5507683753967285, Accuracy: 0.8203125\n",
      "Batch: 110, Loss: 0.4426961839199066, Accuracy: 0.849609375\n",
      "Batch: 111, Loss: 0.4820040166378021, Accuracy: 0.8330078125\n",
      "Batch: 112, Loss: 0.47920534014701843, Accuracy: 0.8271484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 113, Loss: 0.5055171251296997, Accuracy: 0.8330078125\n",
      "Batch: 114, Loss: 0.5418610572814941, Accuracy: 0.8056640625\n",
      "Batch: 115, Loss: 0.5367871522903442, Accuracy: 0.8203125\n",
      "Batch: 116, Loss: 0.5332807302474976, Accuracy: 0.822265625\n",
      "Batch: 117, Loss: 0.49223247170448303, Accuracy: 0.8447265625\n",
      "Batch: 118, Loss: 0.45864608883857727, Accuracy: 0.849609375\n",
      "Batch: 119, Loss: 0.4344382882118225, Accuracy: 0.8603515625\n",
      "Batch: 120, Loss: 0.4999186396598816, Accuracy: 0.8369140625\n",
      "Batch: 121, Loss: 0.5296247005462646, Accuracy: 0.833984375\n",
      "Batch: 122, Loss: 0.4669860601425171, Accuracy: 0.8408203125\n",
      "Batch: 123, Loss: 0.4628341495990753, Accuracy: 0.8515625\n",
      "Batch: 124, Loss: 0.4928225874900818, Accuracy: 0.830078125\n",
      "Batch: 125, Loss: 0.5197529196739197, Accuracy: 0.83203125\n",
      "Batch: 126, Loss: 0.5316442251205444, Accuracy: 0.830078125\n",
      "Batch: 127, Loss: 0.4911514222621918, Accuracy: 0.8408203125\n",
      "Batch: 128, Loss: 0.5294843316078186, Accuracy: 0.8330078125\n",
      "Batch: 129, Loss: 0.46607932448387146, Accuracy: 0.8515625\n",
      "Batch: 130, Loss: 0.5390072464942932, Accuracy: 0.8251953125\n",
      "Batch: 131, Loss: 0.4636847674846649, Accuracy: 0.8505859375\n",
      "Batch: 132, Loss: 0.5111939907073975, Accuracy: 0.841796875\n",
      "Batch: 133, Loss: 0.49819427728652954, Accuracy: 0.8408203125\n",
      "Batch: 134, Loss: 0.514096736907959, Accuracy: 0.82421875\n",
      "Batch: 135, Loss: 0.45341867208480835, Accuracy: 0.8525390625\n",
      "Batch: 136, Loss: 0.5141149759292603, Accuracy: 0.833984375\n",
      "Batch: 137, Loss: 0.5308766961097717, Accuracy: 0.8232421875\n",
      "Batch: 138, Loss: 0.5177409648895264, Accuracy: 0.8232421875\n",
      "Batch: 139, Loss: 0.6068419218063354, Accuracy: 0.7998046875\n",
      "Batch: 140, Loss: 0.5438424944877625, Accuracy: 0.8291015625\n",
      "Batch: 141, Loss: 0.5759614706039429, Accuracy: 0.8115234375\n",
      "Batch: 142, Loss: 0.5380825996398926, Accuracy: 0.8076171875\n",
      "Batch: 143, Loss: 0.508651614189148, Accuracy: 0.8271484375\n",
      "Batch: 144, Loss: 0.5590118169784546, Accuracy: 0.8125\n",
      "Batch: 145, Loss: 0.48648178577423096, Accuracy: 0.84375\n",
      "Batch: 146, Loss: 0.49692684412002563, Accuracy: 0.837890625\n",
      "Batch: 147, Loss: 0.49308955669403076, Accuracy: 0.8369140625\n",
      "Batch: 148, Loss: 0.551323413848877, Accuracy: 0.828125\n",
      "Batch: 149, Loss: 0.46486443281173706, Accuracy: 0.841796875\n",
      "Batch: 150, Loss: 0.4959374964237213, Accuracy: 0.8310546875\n",
      "Batch: 151, Loss: 0.4812443256378174, Accuracy: 0.83203125\n",
      "Epoch 72/80\n",
      "Batch: 1, Loss: 0.6551461815834045, Accuracy: 0.7978515625\n",
      "Batch: 2, Loss: 0.5547916293144226, Accuracy: 0.8125\n",
      "Batch: 3, Loss: 0.5018073320388794, Accuracy: 0.8271484375\n",
      "Batch: 4, Loss: 0.4544496536254883, Accuracy: 0.845703125\n",
      "Batch: 5, Loss: 0.4836938679218292, Accuracy: 0.8369140625\n",
      "Batch: 6, Loss: 0.5336076021194458, Accuracy: 0.818359375\n",
      "Batch: 7, Loss: 0.5143059492111206, Accuracy: 0.818359375\n",
      "Batch: 8, Loss: 0.4749721884727478, Accuracy: 0.84375\n",
      "Batch: 9, Loss: 0.5163917541503906, Accuracy: 0.8271484375\n",
      "Batch: 10, Loss: 0.46025267243385315, Accuracy: 0.84375\n",
      "Batch: 11, Loss: 0.5156992077827454, Accuracy: 0.830078125\n",
      "Batch: 12, Loss: 0.4926944971084595, Accuracy: 0.8427734375\n",
      "Batch: 13, Loss: 0.4093945026397705, Accuracy: 0.8623046875\n",
      "Batch: 14, Loss: 0.538432240486145, Accuracy: 0.8330078125\n",
      "Batch: 15, Loss: 0.45462507009506226, Accuracy: 0.8515625\n",
      "Batch: 16, Loss: 0.4796109199523926, Accuracy: 0.83984375\n",
      "Batch: 17, Loss: 0.49262815713882446, Accuracy: 0.8408203125\n",
      "Batch: 18, Loss: 0.47299593687057495, Accuracy: 0.853515625\n",
      "Batch: 19, Loss: 0.49532103538513184, Accuracy: 0.849609375\n",
      "Batch: 20, Loss: 0.4401404857635498, Accuracy: 0.8486328125\n",
      "Batch: 21, Loss: 0.510459840297699, Accuracy: 0.84375\n",
      "Batch: 22, Loss: 0.5876308679580688, Accuracy: 0.8212890625\n",
      "Batch: 23, Loss: 0.5145069360733032, Accuracy: 0.8251953125\n",
      "Batch: 24, Loss: 0.5585190057754517, Accuracy: 0.8203125\n",
      "Batch: 25, Loss: 0.5141960978507996, Accuracy: 0.8349609375\n",
      "Batch: 26, Loss: 0.42965853214263916, Accuracy: 0.853515625\n",
      "Batch: 27, Loss: 0.4850844740867615, Accuracy: 0.83984375\n",
      "Batch: 28, Loss: 0.49060776829719543, Accuracy: 0.814453125\n",
      "Batch: 29, Loss: 0.4693043529987335, Accuracy: 0.8447265625\n",
      "Batch: 30, Loss: 0.41223347187042236, Accuracy: 0.857421875\n",
      "Batch: 31, Loss: 0.4732148051261902, Accuracy: 0.83203125\n",
      "Batch: 32, Loss: 0.4327002465724945, Accuracy: 0.857421875\n",
      "Batch: 33, Loss: 0.5428188443183899, Accuracy: 0.828125\n",
      "Batch: 34, Loss: 0.5773354768753052, Accuracy: 0.806640625\n",
      "Batch: 35, Loss: 0.4876932203769684, Accuracy: 0.8408203125\n",
      "Batch: 36, Loss: 0.48627936840057373, Accuracy: 0.841796875\n",
      "Batch: 37, Loss: 0.4993610382080078, Accuracy: 0.8369140625\n",
      "Batch: 38, Loss: 0.4840378165245056, Accuracy: 0.8369140625\n",
      "Batch: 39, Loss: 0.4976930022239685, Accuracy: 0.8408203125\n",
      "Batch: 40, Loss: 0.4987202286720276, Accuracy: 0.8271484375\n",
      "Batch: 41, Loss: 0.4612807631492615, Accuracy: 0.8505859375\n",
      "Batch: 42, Loss: 0.3681638836860657, Accuracy: 0.869140625\n",
      "Batch: 43, Loss: 0.4813447594642639, Accuracy: 0.833984375\n",
      "Batch: 44, Loss: 0.4802559018135071, Accuracy: 0.8359375\n",
      "Batch: 45, Loss: 0.4415794610977173, Accuracy: 0.8564453125\n",
      "Batch: 46, Loss: 0.43817567825317383, Accuracy: 0.8544921875\n",
      "Batch: 47, Loss: 0.42250847816467285, Accuracy: 0.8779296875\n",
      "Batch: 48, Loss: 0.4360930323600769, Accuracy: 0.8515625\n",
      "Batch: 49, Loss: 0.5088973641395569, Accuracy: 0.83203125\n",
      "Batch: 50, Loss: 0.4893451929092407, Accuracy: 0.837890625\n",
      "Batch: 51, Loss: 0.47833406925201416, Accuracy: 0.849609375\n",
      "Batch: 52, Loss: 0.47700849175453186, Accuracy: 0.857421875\n",
      "Batch: 53, Loss: 0.424623966217041, Accuracy: 0.8544921875\n",
      "Batch: 54, Loss: 0.48546040058135986, Accuracy: 0.8271484375\n",
      "Batch: 55, Loss: 0.528073787689209, Accuracy: 0.8369140625\n",
      "Batch: 56, Loss: 0.553587019443512, Accuracy: 0.81640625\n",
      "Batch: 57, Loss: 0.4942302703857422, Accuracy: 0.83984375\n",
      "Batch: 58, Loss: 0.5533844232559204, Accuracy: 0.8193359375\n",
      "Batch: 59, Loss: 0.49748772382736206, Accuracy: 0.837890625\n",
      "Batch: 60, Loss: 0.48139727115631104, Accuracy: 0.8466796875\n",
      "Batch: 61, Loss: 0.5354578495025635, Accuracy: 0.8173828125\n",
      "Batch: 62, Loss: 0.41945454478263855, Accuracy: 0.865234375\n",
      "Batch: 63, Loss: 0.4855375289916992, Accuracy: 0.83984375\n",
      "Batch: 64, Loss: 0.4856230914592743, Accuracy: 0.8408203125\n",
      "Batch: 65, Loss: 0.4690999984741211, Accuracy: 0.830078125\n",
      "Batch: 66, Loss: 0.4987730085849762, Accuracy: 0.837890625\n",
      "Batch: 67, Loss: 0.5384637117385864, Accuracy: 0.81640625\n",
      "Batch: 68, Loss: 0.5708904266357422, Accuracy: 0.8134765625\n",
      "Batch: 69, Loss: 0.5386725664138794, Accuracy: 0.8212890625\n",
      "Batch: 70, Loss: 0.5441389083862305, Accuracy: 0.8203125\n",
      "Batch: 71, Loss: 0.5253912210464478, Accuracy: 0.814453125\n",
      "Batch: 72, Loss: 0.4704035520553589, Accuracy: 0.84765625\n",
      "Batch: 73, Loss: 0.4349401593208313, Accuracy: 0.8564453125\n",
      "Batch: 74, Loss: 0.42087626457214355, Accuracy: 0.873046875\n",
      "Batch: 75, Loss: 0.42093947529792786, Accuracy: 0.8564453125\n",
      "Batch: 76, Loss: 0.46600890159606934, Accuracy: 0.845703125\n",
      "Batch: 77, Loss: 0.48705124855041504, Accuracy: 0.83984375\n",
      "Batch: 78, Loss: 0.4504537582397461, Accuracy: 0.8505859375\n",
      "Batch: 79, Loss: 0.46148091554641724, Accuracy: 0.849609375\n",
      "Batch: 80, Loss: 0.4613507390022278, Accuracy: 0.837890625\n",
      "Batch: 81, Loss: 0.5050768256187439, Accuracy: 0.8232421875\n",
      "Batch: 82, Loss: 0.45728838443756104, Accuracy: 0.8486328125\n",
      "Batch: 83, Loss: 0.43801015615463257, Accuracy: 0.8564453125\n",
      "Batch: 84, Loss: 0.4957749843597412, Accuracy: 0.8349609375\n",
      "Batch: 85, Loss: 0.4789753556251526, Accuracy: 0.84765625\n",
      "Batch: 86, Loss: 0.5616092681884766, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.4705387353897095, Accuracy: 0.849609375\n",
      "Batch: 88, Loss: 0.5639776587486267, Accuracy: 0.8212890625\n",
      "Batch: 89, Loss: 0.4616578221321106, Accuracy: 0.8515625\n",
      "Batch: 90, Loss: 0.5052803158760071, Accuracy: 0.845703125\n",
      "Batch: 91, Loss: 0.45516008138656616, Accuracy: 0.84375\n",
      "Batch: 92, Loss: 0.478584885597229, Accuracy: 0.849609375\n",
      "Batch: 93, Loss: 0.4740546941757202, Accuracy: 0.8447265625\n",
      "Batch: 94, Loss: 0.5329195857048035, Accuracy: 0.8330078125\n",
      "Batch: 95, Loss: 0.519930362701416, Accuracy: 0.8349609375\n",
      "Batch: 96, Loss: 0.48194533586502075, Accuracy: 0.8408203125\n",
      "Batch: 97, Loss: 0.3751829266548157, Accuracy: 0.8720703125\n",
      "Batch: 98, Loss: 0.47035112977027893, Accuracy: 0.833984375\n",
      "Batch: 99, Loss: 0.481662780046463, Accuracy: 0.8271484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.5110354423522949, Accuracy: 0.82421875\n",
      "Batch: 101, Loss: 0.512165904045105, Accuracy: 0.8525390625\n",
      "Batch: 102, Loss: 0.5009364485740662, Accuracy: 0.83203125\n",
      "Batch: 103, Loss: 0.5102665424346924, Accuracy: 0.8359375\n",
      "Batch: 104, Loss: 0.46366235613822937, Accuracy: 0.830078125\n",
      "Batch: 105, Loss: 0.5581722259521484, Accuracy: 0.8115234375\n",
      "Batch: 106, Loss: 0.4458330273628235, Accuracy: 0.849609375\n",
      "Batch: 107, Loss: 0.46913832426071167, Accuracy: 0.8447265625\n",
      "Batch: 108, Loss: 0.4851076006889343, Accuracy: 0.8359375\n",
      "Batch: 109, Loss: 0.5181760787963867, Accuracy: 0.82421875\n",
      "Batch: 110, Loss: 0.45226430892944336, Accuracy: 0.8505859375\n",
      "Batch: 111, Loss: 0.5054444670677185, Accuracy: 0.8349609375\n",
      "Batch: 112, Loss: 0.4930468797683716, Accuracy: 0.8408203125\n",
      "Batch: 113, Loss: 0.4908379912376404, Accuracy: 0.8359375\n",
      "Batch: 114, Loss: 0.5247765779495239, Accuracy: 0.8310546875\n",
      "Batch: 115, Loss: 0.5367622375488281, Accuracy: 0.8232421875\n",
      "Batch: 116, Loss: 0.4977639615535736, Accuracy: 0.830078125\n",
      "Batch: 117, Loss: 0.521780252456665, Accuracy: 0.8310546875\n",
      "Batch: 118, Loss: 0.4838673770427704, Accuracy: 0.857421875\n",
      "Batch: 119, Loss: 0.3884521424770355, Accuracy: 0.87109375\n",
      "Batch: 120, Loss: 0.45122969150543213, Accuracy: 0.849609375\n",
      "Batch: 121, Loss: 0.54243004322052, Accuracy: 0.822265625\n",
      "Batch: 122, Loss: 0.4491341710090637, Accuracy: 0.8564453125\n",
      "Batch: 123, Loss: 0.437349796295166, Accuracy: 0.8603515625\n",
      "Batch: 124, Loss: 0.47063159942626953, Accuracy: 0.8466796875\n",
      "Batch: 125, Loss: 0.49718064069747925, Accuracy: 0.8310546875\n",
      "Batch: 126, Loss: 0.5325813293457031, Accuracy: 0.8203125\n",
      "Batch: 127, Loss: 0.47461605072021484, Accuracy: 0.84765625\n",
      "Batch: 128, Loss: 0.563591480255127, Accuracy: 0.810546875\n",
      "Batch: 129, Loss: 0.4666474759578705, Accuracy: 0.845703125\n",
      "Batch: 130, Loss: 0.546971321105957, Accuracy: 0.8154296875\n",
      "Batch: 131, Loss: 0.4594550132751465, Accuracy: 0.84765625\n",
      "Batch: 132, Loss: 0.5058178901672363, Accuracy: 0.83203125\n",
      "Batch: 133, Loss: 0.5215160846710205, Accuracy: 0.8251953125\n",
      "Batch: 134, Loss: 0.5016518831253052, Accuracy: 0.826171875\n",
      "Batch: 135, Loss: 0.4636107087135315, Accuracy: 0.86328125\n",
      "Batch: 136, Loss: 0.5024443864822388, Accuracy: 0.8505859375\n",
      "Batch: 137, Loss: 0.5118957757949829, Accuracy: 0.8251953125\n",
      "Batch: 138, Loss: 0.4988020062446594, Accuracy: 0.8349609375\n",
      "Batch: 139, Loss: 0.5404583215713501, Accuracy: 0.828125\n",
      "Batch: 140, Loss: 0.535671591758728, Accuracy: 0.8173828125\n",
      "Batch: 141, Loss: 0.5186316967010498, Accuracy: 0.8291015625\n",
      "Batch: 142, Loss: 0.5173020362854004, Accuracy: 0.822265625\n",
      "Batch: 143, Loss: 0.5073865652084351, Accuracy: 0.8251953125\n",
      "Batch: 144, Loss: 0.5138434171676636, Accuracy: 0.833984375\n",
      "Batch: 145, Loss: 0.5035400390625, Accuracy: 0.8232421875\n",
      "Batch: 146, Loss: 0.558318018913269, Accuracy: 0.8046875\n",
      "Batch: 147, Loss: 0.5070682168006897, Accuracy: 0.8369140625\n",
      "Batch: 148, Loss: 0.5514481663703918, Accuracy: 0.8193359375\n",
      "Batch: 149, Loss: 0.4654824137687683, Accuracy: 0.8525390625\n",
      "Batch: 150, Loss: 0.5232584476470947, Accuracy: 0.8310546875\n",
      "Batch: 151, Loss: 0.46185174584388733, Accuracy: 0.8515625\n",
      "Epoch 73/80\n",
      "Batch: 1, Loss: 0.6522594690322876, Accuracy: 0.7919921875\n",
      "Batch: 2, Loss: 0.5847280025482178, Accuracy: 0.80078125\n",
      "Batch: 3, Loss: 0.5184388756752014, Accuracy: 0.828125\n",
      "Batch: 4, Loss: 0.4687463343143463, Accuracy: 0.845703125\n",
      "Batch: 5, Loss: 0.45584774017333984, Accuracy: 0.84765625\n",
      "Batch: 6, Loss: 0.5240750312805176, Accuracy: 0.82421875\n",
      "Batch: 7, Loss: 0.5212611556053162, Accuracy: 0.822265625\n",
      "Batch: 8, Loss: 0.48245131969451904, Accuracy: 0.8232421875\n",
      "Batch: 9, Loss: 0.5385338068008423, Accuracy: 0.8154296875\n",
      "Batch: 10, Loss: 0.5228646993637085, Accuracy: 0.8076171875\n",
      "Batch: 11, Loss: 0.5464082956314087, Accuracy: 0.828125\n",
      "Batch: 12, Loss: 0.4994116723537445, Accuracy: 0.8486328125\n",
      "Batch: 13, Loss: 0.41840943694114685, Accuracy: 0.8642578125\n",
      "Batch: 14, Loss: 0.530899167060852, Accuracy: 0.8154296875\n",
      "Batch: 15, Loss: 0.45252254605293274, Accuracy: 0.8583984375\n",
      "Batch: 16, Loss: 0.4674738645553589, Accuracy: 0.8642578125\n",
      "Batch: 17, Loss: 0.5161596536636353, Accuracy: 0.8330078125\n",
      "Batch: 18, Loss: 0.5394493937492371, Accuracy: 0.82421875\n",
      "Batch: 19, Loss: 0.5329859256744385, Accuracy: 0.8232421875\n",
      "Batch: 20, Loss: 0.43833738565444946, Accuracy: 0.869140625\n",
      "Batch: 21, Loss: 0.5413144826889038, Accuracy: 0.810546875\n",
      "Batch: 22, Loss: 0.5774033069610596, Accuracy: 0.818359375\n",
      "Batch: 23, Loss: 0.5433812737464905, Accuracy: 0.822265625\n",
      "Batch: 24, Loss: 0.536428689956665, Accuracy: 0.826171875\n",
      "Batch: 25, Loss: 0.5025529861450195, Accuracy: 0.84765625\n",
      "Batch: 26, Loss: 0.4250684976577759, Accuracy: 0.8544921875\n",
      "Batch: 27, Loss: 0.4697874188423157, Accuracy: 0.8369140625\n",
      "Batch: 28, Loss: 0.5252103805541992, Accuracy: 0.8427734375\n",
      "Batch: 29, Loss: 0.5008600950241089, Accuracy: 0.83203125\n",
      "Batch: 30, Loss: 0.4413423538208008, Accuracy: 0.845703125\n",
      "Batch: 31, Loss: 0.47276192903518677, Accuracy: 0.8466796875\n",
      "Batch: 32, Loss: 0.47022348642349243, Accuracy: 0.8349609375\n",
      "Batch: 33, Loss: 0.4964679777622223, Accuracy: 0.8544921875\n",
      "Batch: 34, Loss: 0.5659686923027039, Accuracy: 0.8203125\n",
      "Batch: 35, Loss: 0.47692710161209106, Accuracy: 0.83984375\n",
      "Batch: 36, Loss: 0.4782239496707916, Accuracy: 0.8525390625\n",
      "Batch: 37, Loss: 0.5305711030960083, Accuracy: 0.8095703125\n",
      "Batch: 38, Loss: 0.4652285575866699, Accuracy: 0.8369140625\n",
      "Batch: 39, Loss: 0.5027795433998108, Accuracy: 0.837890625\n",
      "Batch: 40, Loss: 0.4943210780620575, Accuracy: 0.84375\n",
      "Batch: 41, Loss: 0.4714166820049286, Accuracy: 0.853515625\n",
      "Batch: 42, Loss: 0.3906116783618927, Accuracy: 0.8671875\n",
      "Batch: 43, Loss: 0.4856142997741699, Accuracy: 0.83203125\n",
      "Batch: 44, Loss: 0.45799896121025085, Accuracy: 0.841796875\n",
      "Batch: 45, Loss: 0.4633334279060364, Accuracy: 0.857421875\n",
      "Batch: 46, Loss: 0.4165162146091461, Accuracy: 0.8564453125\n",
      "Batch: 47, Loss: 0.42336493730545044, Accuracy: 0.8583984375\n",
      "Batch: 48, Loss: 0.4329238533973694, Accuracy: 0.8681640625\n",
      "Batch: 49, Loss: 0.5012103319168091, Accuracy: 0.8310546875\n",
      "Batch: 50, Loss: 0.5098353028297424, Accuracy: 0.8408203125\n",
      "Batch: 51, Loss: 0.4759511649608612, Accuracy: 0.853515625\n",
      "Batch: 52, Loss: 0.48418039083480835, Accuracy: 0.83984375\n",
      "Batch: 53, Loss: 0.44221487641334534, Accuracy: 0.8515625\n",
      "Batch: 54, Loss: 0.476176381111145, Accuracy: 0.84375\n",
      "Batch: 55, Loss: 0.5522421598434448, Accuracy: 0.8232421875\n",
      "Batch: 56, Loss: 0.4999144673347473, Accuracy: 0.8369140625\n",
      "Batch: 57, Loss: 0.5295979976654053, Accuracy: 0.8251953125\n",
      "Batch: 58, Loss: 0.548999547958374, Accuracy: 0.8251953125\n",
      "Batch: 59, Loss: 0.48989272117614746, Accuracy: 0.84375\n",
      "Batch: 60, Loss: 0.4780712127685547, Accuracy: 0.83203125\n",
      "Batch: 61, Loss: 0.5206558704376221, Accuracy: 0.818359375\n",
      "Batch: 62, Loss: 0.4328860342502594, Accuracy: 0.8525390625\n",
      "Batch: 63, Loss: 0.4927248954772949, Accuracy: 0.8349609375\n",
      "Batch: 64, Loss: 0.4718656539916992, Accuracy: 0.845703125\n",
      "Batch: 65, Loss: 0.48845747113227844, Accuracy: 0.8251953125\n",
      "Batch: 66, Loss: 0.5038747787475586, Accuracy: 0.8291015625\n",
      "Batch: 67, Loss: 0.5163788795471191, Accuracy: 0.8291015625\n",
      "Batch: 68, Loss: 0.5571929216384888, Accuracy: 0.8154296875\n",
      "Batch: 69, Loss: 0.5366780161857605, Accuracy: 0.8193359375\n",
      "Batch: 70, Loss: 0.5306777954101562, Accuracy: 0.818359375\n",
      "Batch: 71, Loss: 0.5084468126296997, Accuracy: 0.8193359375\n",
      "Batch: 72, Loss: 0.4586258828639984, Accuracy: 0.8525390625\n",
      "Batch: 73, Loss: 0.45837029814720154, Accuracy: 0.8447265625\n",
      "Batch: 74, Loss: 0.4027653932571411, Accuracy: 0.8759765625\n",
      "Batch: 75, Loss: 0.39661896228790283, Accuracy: 0.8623046875\n",
      "Batch: 76, Loss: 0.5018309950828552, Accuracy: 0.830078125\n",
      "Batch: 77, Loss: 0.48510074615478516, Accuracy: 0.8427734375\n",
      "Batch: 78, Loss: 0.4779062569141388, Accuracy: 0.84375\n",
      "Batch: 79, Loss: 0.46714818477630615, Accuracy: 0.8466796875\n",
      "Batch: 80, Loss: 0.4801424443721771, Accuracy: 0.833984375\n",
      "Batch: 81, Loss: 0.545974850654602, Accuracy: 0.81640625\n",
      "Batch: 82, Loss: 0.4888881742954254, Accuracy: 0.8330078125\n",
      "Batch: 83, Loss: 0.429381787776947, Accuracy: 0.85546875\n",
      "Batch: 84, Loss: 0.49200719594955444, Accuracy: 0.8388671875\n",
      "Batch: 85, Loss: 0.48531320691108704, Accuracy: 0.8505859375\n",
      "Batch: 86, Loss: 0.5315847396850586, Accuracy: 0.8388671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 87, Loss: 0.42326274514198303, Accuracy: 0.865234375\n",
      "Batch: 88, Loss: 0.54594886302948, Accuracy: 0.8232421875\n",
      "Batch: 89, Loss: 0.47373485565185547, Accuracy: 0.8369140625\n",
      "Batch: 90, Loss: 0.4793549180030823, Accuracy: 0.8330078125\n",
      "Batch: 91, Loss: 0.4611489772796631, Accuracy: 0.845703125\n",
      "Batch: 92, Loss: 0.5091090202331543, Accuracy: 0.8330078125\n",
      "Batch: 93, Loss: 0.4661336839199066, Accuracy: 0.837890625\n",
      "Batch: 94, Loss: 0.5056549906730652, Accuracy: 0.8388671875\n",
      "Batch: 95, Loss: 0.49518394470214844, Accuracy: 0.8251953125\n",
      "Batch: 96, Loss: 0.4706515967845917, Accuracy: 0.8447265625\n",
      "Batch: 97, Loss: 0.4105890691280365, Accuracy: 0.8701171875\n",
      "Batch: 98, Loss: 0.4694903790950775, Accuracy: 0.841796875\n",
      "Batch: 99, Loss: 0.47169238328933716, Accuracy: 0.8408203125\n",
      "Batch: 100, Loss: 0.4996775984764099, Accuracy: 0.841796875\n",
      "Batch: 101, Loss: 0.4867810606956482, Accuracy: 0.8408203125\n",
      "Batch: 102, Loss: 0.46186336874961853, Accuracy: 0.8544921875\n",
      "Batch: 103, Loss: 0.5032106637954712, Accuracy: 0.8447265625\n",
      "Batch: 104, Loss: 0.4463360607624054, Accuracy: 0.8466796875\n",
      "Batch: 105, Loss: 0.5435221791267395, Accuracy: 0.8193359375\n",
      "Batch: 106, Loss: 0.44045212864875793, Accuracy: 0.859375\n",
      "Batch: 107, Loss: 0.4399930238723755, Accuracy: 0.85546875\n",
      "Batch: 108, Loss: 0.47841915488243103, Accuracy: 0.8447265625\n",
      "Batch: 109, Loss: 0.5457618832588196, Accuracy: 0.8134765625\n",
      "Batch: 110, Loss: 0.4319661557674408, Accuracy: 0.853515625\n",
      "Batch: 111, Loss: 0.4867156744003296, Accuracy: 0.8427734375\n",
      "Batch: 112, Loss: 0.4737040400505066, Accuracy: 0.83984375\n",
      "Batch: 113, Loss: 0.47381502389907837, Accuracy: 0.8466796875\n",
      "Batch: 114, Loss: 0.5453331470489502, Accuracy: 0.8251953125\n",
      "Batch: 115, Loss: 0.5469757318496704, Accuracy: 0.822265625\n",
      "Batch: 116, Loss: 0.5133485794067383, Accuracy: 0.81640625\n",
      "Batch: 117, Loss: 0.5143014192581177, Accuracy: 0.822265625\n",
      "Batch: 118, Loss: 0.45696377754211426, Accuracy: 0.8583984375\n",
      "Batch: 119, Loss: 0.4387355446815491, Accuracy: 0.841796875\n",
      "Batch: 120, Loss: 0.48497292399406433, Accuracy: 0.84375\n",
      "Batch: 121, Loss: 0.5359344482421875, Accuracy: 0.8115234375\n",
      "Batch: 122, Loss: 0.454682320356369, Accuracy: 0.8515625\n",
      "Batch: 123, Loss: 0.4528951048851013, Accuracy: 0.849609375\n",
      "Batch: 124, Loss: 0.48499253392219543, Accuracy: 0.84375\n",
      "Batch: 125, Loss: 0.5359960794448853, Accuracy: 0.8291015625\n",
      "Batch: 126, Loss: 0.4925421476364136, Accuracy: 0.8408203125\n",
      "Batch: 127, Loss: 0.4498136639595032, Accuracy: 0.8564453125\n",
      "Batch: 128, Loss: 0.5423821210861206, Accuracy: 0.8203125\n",
      "Batch: 129, Loss: 0.48009994626045227, Accuracy: 0.8408203125\n",
      "Batch: 130, Loss: 0.5100092887878418, Accuracy: 0.849609375\n",
      "Batch: 131, Loss: 0.46312859654426575, Accuracy: 0.8408203125\n",
      "Batch: 132, Loss: 0.5290666818618774, Accuracy: 0.8359375\n",
      "Batch: 133, Loss: 0.5289715528488159, Accuracy: 0.8359375\n",
      "Batch: 134, Loss: 0.5156282186508179, Accuracy: 0.82421875\n",
      "Batch: 135, Loss: 0.47811439633369446, Accuracy: 0.837890625\n",
      "Batch: 136, Loss: 0.5382625460624695, Accuracy: 0.8203125\n",
      "Batch: 137, Loss: 0.5196689367294312, Accuracy: 0.814453125\n",
      "Batch: 138, Loss: 0.4769403040409088, Accuracy: 0.8349609375\n",
      "Batch: 139, Loss: 0.5505943894386292, Accuracy: 0.8232421875\n",
      "Batch: 140, Loss: 0.5134669542312622, Accuracy: 0.8388671875\n",
      "Batch: 141, Loss: 0.507097601890564, Accuracy: 0.8486328125\n",
      "Batch: 142, Loss: 0.52724689245224, Accuracy: 0.826171875\n",
      "Batch: 143, Loss: 0.4833657145500183, Accuracy: 0.84375\n",
      "Batch: 144, Loss: 0.5236157178878784, Accuracy: 0.837890625\n",
      "Batch: 145, Loss: 0.4681501090526581, Accuracy: 0.84765625\n",
      "Batch: 146, Loss: 0.5031062364578247, Accuracy: 0.8330078125\n",
      "Batch: 147, Loss: 0.49590495228767395, Accuracy: 0.837890625\n",
      "Batch: 148, Loss: 0.5904995799064636, Accuracy: 0.798828125\n",
      "Batch: 149, Loss: 0.4668411910533905, Accuracy: 0.8505859375\n",
      "Batch: 150, Loss: 0.4905644953250885, Accuracy: 0.837890625\n",
      "Batch: 151, Loss: 0.4773893356323242, Accuracy: 0.8359375\n",
      "Epoch 74/80\n",
      "Batch: 1, Loss: 0.6505389213562012, Accuracy: 0.7978515625\n",
      "Batch: 2, Loss: 0.5744913220405579, Accuracy: 0.80078125\n",
      "Batch: 3, Loss: 0.49839746952056885, Accuracy: 0.8310546875\n",
      "Batch: 4, Loss: 0.4756369888782501, Accuracy: 0.8447265625\n",
      "Batch: 5, Loss: 0.46830660104751587, Accuracy: 0.8486328125\n",
      "Batch: 6, Loss: 0.5019768476486206, Accuracy: 0.8330078125\n",
      "Batch: 7, Loss: 0.5033301115036011, Accuracy: 0.828125\n",
      "Batch: 8, Loss: 0.46910879015922546, Accuracy: 0.84765625\n",
      "Batch: 9, Loss: 0.47994664311408997, Accuracy: 0.8486328125\n",
      "Batch: 10, Loss: 0.48699572682380676, Accuracy: 0.833984375\n",
      "Batch: 11, Loss: 0.5288175344467163, Accuracy: 0.8291015625\n",
      "Batch: 12, Loss: 0.5079045295715332, Accuracy: 0.8310546875\n",
      "Batch: 13, Loss: 0.39164015650749207, Accuracy: 0.8740234375\n",
      "Batch: 14, Loss: 0.5682047605514526, Accuracy: 0.8115234375\n",
      "Batch: 15, Loss: 0.44114047288894653, Accuracy: 0.8583984375\n",
      "Batch: 16, Loss: 0.4549146890640259, Accuracy: 0.8583984375\n",
      "Batch: 17, Loss: 0.4964860677719116, Accuracy: 0.845703125\n",
      "Batch: 18, Loss: 0.5029705166816711, Accuracy: 0.8330078125\n",
      "Batch: 19, Loss: 0.5624584555625916, Accuracy: 0.818359375\n",
      "Batch: 20, Loss: 0.4290226995944977, Accuracy: 0.865234375\n",
      "Batch: 21, Loss: 0.48579880595207214, Accuracy: 0.837890625\n",
      "Batch: 22, Loss: 0.5571814775466919, Accuracy: 0.810546875\n",
      "Batch: 23, Loss: 0.5263845324516296, Accuracy: 0.8271484375\n",
      "Batch: 24, Loss: 0.5734042525291443, Accuracy: 0.826171875\n",
      "Batch: 25, Loss: 0.5019114017486572, Accuracy: 0.845703125\n",
      "Batch: 26, Loss: 0.4329020380973816, Accuracy: 0.8486328125\n",
      "Batch: 27, Loss: 0.4445110261440277, Accuracy: 0.8505859375\n",
      "Batch: 28, Loss: 0.48068803548812866, Accuracy: 0.8232421875\n",
      "Batch: 29, Loss: 0.46319738030433655, Accuracy: 0.8486328125\n",
      "Batch: 30, Loss: 0.4248782992362976, Accuracy: 0.8642578125\n",
      "Batch: 31, Loss: 0.44656872749328613, Accuracy: 0.861328125\n",
      "Batch: 32, Loss: 0.44869285821914673, Accuracy: 0.8603515625\n",
      "Batch: 33, Loss: 0.4850124418735504, Accuracy: 0.8447265625\n",
      "Batch: 34, Loss: 0.5780105590820312, Accuracy: 0.8046875\n",
      "Batch: 35, Loss: 0.4915000796318054, Accuracy: 0.830078125\n",
      "Batch: 36, Loss: 0.4853806495666504, Accuracy: 0.8515625\n",
      "Batch: 37, Loss: 0.4808272123336792, Accuracy: 0.84375\n",
      "Batch: 38, Loss: 0.4588666558265686, Accuracy: 0.8525390625\n",
      "Batch: 39, Loss: 0.5019189119338989, Accuracy: 0.84375\n",
      "Batch: 40, Loss: 0.48031771183013916, Accuracy: 0.8427734375\n",
      "Batch: 41, Loss: 0.449158251285553, Accuracy: 0.8466796875\n",
      "Batch: 42, Loss: 0.35242539644241333, Accuracy: 0.8876953125\n",
      "Batch: 43, Loss: 0.4596952795982361, Accuracy: 0.845703125\n",
      "Batch: 44, Loss: 0.4803703725337982, Accuracy: 0.8359375\n",
      "Batch: 45, Loss: 0.4186382293701172, Accuracy: 0.857421875\n",
      "Batch: 46, Loss: 0.4219970405101776, Accuracy: 0.8642578125\n",
      "Batch: 47, Loss: 0.4462895393371582, Accuracy: 0.8603515625\n",
      "Batch: 48, Loss: 0.4309682250022888, Accuracy: 0.8642578125\n",
      "Batch: 49, Loss: 0.4903619885444641, Accuracy: 0.83203125\n",
      "Batch: 50, Loss: 0.4949852228164673, Accuracy: 0.849609375\n",
      "Batch: 51, Loss: 0.45265841484069824, Accuracy: 0.8564453125\n",
      "Batch: 52, Loss: 0.47565507888793945, Accuracy: 0.8447265625\n",
      "Batch: 53, Loss: 0.41151678562164307, Accuracy: 0.859375\n",
      "Batch: 54, Loss: 0.4331427216529846, Accuracy: 0.861328125\n",
      "Batch: 55, Loss: 0.5287033915519714, Accuracy: 0.8212890625\n",
      "Batch: 56, Loss: 0.5349917411804199, Accuracy: 0.8232421875\n",
      "Batch: 57, Loss: 0.5231647491455078, Accuracy: 0.8232421875\n",
      "Batch: 58, Loss: 0.5372347831726074, Accuracy: 0.8212890625\n",
      "Batch: 59, Loss: 0.46219465136528015, Accuracy: 0.8466796875\n",
      "Batch: 60, Loss: 0.45594143867492676, Accuracy: 0.84765625\n",
      "Batch: 61, Loss: 0.5225892066955566, Accuracy: 0.8349609375\n",
      "Batch: 62, Loss: 0.4200538396835327, Accuracy: 0.859375\n",
      "Batch: 63, Loss: 0.48921453952789307, Accuracy: 0.841796875\n",
      "Batch: 64, Loss: 0.46406060457229614, Accuracy: 0.8515625\n",
      "Batch: 65, Loss: 0.4730314016342163, Accuracy: 0.849609375\n",
      "Batch: 66, Loss: 0.4934420883655548, Accuracy: 0.828125\n",
      "Batch: 67, Loss: 0.5555460453033447, Accuracy: 0.8134765625\n",
      "Batch: 68, Loss: 0.558791995048523, Accuracy: 0.81640625\n",
      "Batch: 69, Loss: 0.5478465557098389, Accuracy: 0.8173828125\n",
      "Batch: 70, Loss: 0.5228503346443176, Accuracy: 0.8271484375\n",
      "Batch: 71, Loss: 0.5323076844215393, Accuracy: 0.8154296875\n",
      "Batch: 72, Loss: 0.4812241792678833, Accuracy: 0.8349609375\n",
      "Batch: 73, Loss: 0.45100831985473633, Accuracy: 0.8505859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 0.4143680930137634, Accuracy: 0.8662109375\n",
      "Batch: 75, Loss: 0.3936254382133484, Accuracy: 0.8740234375\n",
      "Batch: 76, Loss: 0.4920075535774231, Accuracy: 0.83203125\n",
      "Batch: 77, Loss: 0.4922041893005371, Accuracy: 0.8369140625\n",
      "Batch: 78, Loss: 0.46522974967956543, Accuracy: 0.845703125\n",
      "Batch: 79, Loss: 0.464380145072937, Accuracy: 0.841796875\n",
      "Batch: 80, Loss: 0.446707546710968, Accuracy: 0.857421875\n",
      "Batch: 81, Loss: 0.5172043442726135, Accuracy: 0.8232421875\n",
      "Batch: 82, Loss: 0.4403023421764374, Accuracy: 0.8544921875\n",
      "Batch: 83, Loss: 0.41318368911743164, Accuracy: 0.8603515625\n",
      "Batch: 84, Loss: 0.4909982681274414, Accuracy: 0.83203125\n",
      "Batch: 85, Loss: 0.4979109764099121, Accuracy: 0.8369140625\n",
      "Batch: 86, Loss: 0.5748010873794556, Accuracy: 0.8125\n",
      "Batch: 87, Loss: 0.4363594651222229, Accuracy: 0.8681640625\n",
      "Batch: 88, Loss: 0.5271635055541992, Accuracy: 0.8330078125\n",
      "Batch: 89, Loss: 0.45448631048202515, Accuracy: 0.8466796875\n",
      "Batch: 90, Loss: 0.47125673294067383, Accuracy: 0.8369140625\n",
      "Batch: 91, Loss: 0.44585365056991577, Accuracy: 0.8369140625\n",
      "Batch: 92, Loss: 0.5301568508148193, Accuracy: 0.8212890625\n",
      "Batch: 93, Loss: 0.48545408248901367, Accuracy: 0.8427734375\n",
      "Batch: 94, Loss: 0.5041303634643555, Accuracy: 0.8310546875\n",
      "Batch: 95, Loss: 0.5277217626571655, Accuracy: 0.82421875\n",
      "Batch: 96, Loss: 0.4839114844799042, Accuracy: 0.83984375\n",
      "Batch: 97, Loss: 0.39470088481903076, Accuracy: 0.8740234375\n",
      "Batch: 98, Loss: 0.5042200088500977, Accuracy: 0.8310546875\n",
      "Batch: 99, Loss: 0.4660272002220154, Accuracy: 0.841796875\n",
      "Batch: 100, Loss: 0.47527211904525757, Accuracy: 0.84375\n",
      "Batch: 101, Loss: 0.4891742765903473, Accuracy: 0.833984375\n",
      "Batch: 102, Loss: 0.49320584535598755, Accuracy: 0.8466796875\n",
      "Batch: 103, Loss: 0.47379204630851746, Accuracy: 0.8466796875\n",
      "Batch: 104, Loss: 0.45678654313087463, Accuracy: 0.8583984375\n",
      "Batch: 105, Loss: 0.5183078050613403, Accuracy: 0.8310546875\n",
      "Batch: 106, Loss: 0.4357622265815735, Accuracy: 0.86328125\n",
      "Batch: 107, Loss: 0.4570891857147217, Accuracy: 0.857421875\n",
      "Batch: 108, Loss: 0.48498013615608215, Accuracy: 0.83984375\n",
      "Batch: 109, Loss: 0.5216087698936462, Accuracy: 0.8115234375\n",
      "Batch: 110, Loss: 0.41670936346054077, Accuracy: 0.861328125\n",
      "Batch: 111, Loss: 0.49018749594688416, Accuracy: 0.84375\n",
      "Batch: 112, Loss: 0.4852370619773865, Accuracy: 0.841796875\n",
      "Batch: 113, Loss: 0.4900837540626526, Accuracy: 0.8447265625\n",
      "Batch: 114, Loss: 0.521944522857666, Accuracy: 0.83203125\n",
      "Batch: 115, Loss: 0.5057899951934814, Accuracy: 0.826171875\n",
      "Batch: 116, Loss: 0.4935448169708252, Accuracy: 0.84375\n",
      "Batch: 117, Loss: 0.5227710604667664, Accuracy: 0.8232421875\n",
      "Batch: 118, Loss: 0.4708092212677002, Accuracy: 0.8515625\n",
      "Batch: 119, Loss: 0.4082208275794983, Accuracy: 0.8544921875\n",
      "Batch: 120, Loss: 0.4754871726036072, Accuracy: 0.8408203125\n",
      "Batch: 121, Loss: 0.5449867248535156, Accuracy: 0.82421875\n",
      "Batch: 122, Loss: 0.48405468463897705, Accuracy: 0.8505859375\n",
      "Batch: 123, Loss: 0.4606287479400635, Accuracy: 0.8525390625\n",
      "Batch: 124, Loss: 0.48484283685684204, Accuracy: 0.845703125\n",
      "Batch: 125, Loss: 0.5089245438575745, Accuracy: 0.83984375\n",
      "Batch: 126, Loss: 0.5162110924720764, Accuracy: 0.8291015625\n",
      "Batch: 127, Loss: 0.47317570447921753, Accuracy: 0.849609375\n",
      "Batch: 128, Loss: 0.531352162361145, Accuracy: 0.82421875\n",
      "Batch: 129, Loss: 0.458896279335022, Accuracy: 0.8525390625\n",
      "Batch: 130, Loss: 0.5502289533615112, Accuracy: 0.810546875\n",
      "Batch: 131, Loss: 0.4763502776622772, Accuracy: 0.830078125\n",
      "Batch: 132, Loss: 0.5273512601852417, Accuracy: 0.833984375\n",
      "Batch: 133, Loss: 0.5016636252403259, Accuracy: 0.8310546875\n",
      "Batch: 134, Loss: 0.47994738817214966, Accuracy: 0.8330078125\n",
      "Batch: 135, Loss: 0.46173030138015747, Accuracy: 0.85546875\n",
      "Batch: 136, Loss: 0.5086542367935181, Accuracy: 0.83203125\n",
      "Batch: 137, Loss: 0.5317094326019287, Accuracy: 0.8115234375\n",
      "Batch: 138, Loss: 0.4695453643798828, Accuracy: 0.837890625\n",
      "Batch: 139, Loss: 0.5470340847969055, Accuracy: 0.814453125\n",
      "Batch: 140, Loss: 0.5038244128227234, Accuracy: 0.837890625\n",
      "Batch: 141, Loss: 0.5616029500961304, Accuracy: 0.81640625\n",
      "Batch: 142, Loss: 0.5444431900978088, Accuracy: 0.810546875\n",
      "Batch: 143, Loss: 0.49861472845077515, Accuracy: 0.837890625\n",
      "Batch: 144, Loss: 0.5391894578933716, Accuracy: 0.8291015625\n",
      "Batch: 145, Loss: 0.457060843706131, Accuracy: 0.8525390625\n",
      "Batch: 146, Loss: 0.5145671367645264, Accuracy: 0.83203125\n",
      "Batch: 147, Loss: 0.4519321322441101, Accuracy: 0.8525390625\n",
      "Batch: 148, Loss: 0.5514545440673828, Accuracy: 0.82421875\n",
      "Batch: 149, Loss: 0.4639397859573364, Accuracy: 0.8447265625\n",
      "Batch: 150, Loss: 0.4646804928779602, Accuracy: 0.83203125\n",
      "Batch: 151, Loss: 0.48048582673072815, Accuracy: 0.84375\n",
      "Epoch 75/80\n",
      "Batch: 1, Loss: 0.6306881904602051, Accuracy: 0.8017578125\n",
      "Batch: 2, Loss: 0.572837233543396, Accuracy: 0.8095703125\n",
      "Batch: 3, Loss: 0.5113208293914795, Accuracy: 0.8359375\n",
      "Batch: 4, Loss: 0.48456525802612305, Accuracy: 0.83984375\n",
      "Batch: 5, Loss: 0.4539407193660736, Accuracy: 0.8623046875\n",
      "Batch: 6, Loss: 0.5078125, Accuracy: 0.8330078125\n",
      "Batch: 7, Loss: 0.5538291931152344, Accuracy: 0.8193359375\n",
      "Batch: 8, Loss: 0.4555860161781311, Accuracy: 0.8408203125\n",
      "Batch: 9, Loss: 0.5044568181037903, Accuracy: 0.830078125\n",
      "Batch: 10, Loss: 0.47499337792396545, Accuracy: 0.8359375\n",
      "Batch: 11, Loss: 0.5441969633102417, Accuracy: 0.8037109375\n",
      "Batch: 12, Loss: 0.5054898262023926, Accuracy: 0.8369140625\n",
      "Batch: 13, Loss: 0.4296052157878876, Accuracy: 0.857421875\n",
      "Batch: 14, Loss: 0.5486239194869995, Accuracy: 0.8173828125\n",
      "Batch: 15, Loss: 0.40772494673728943, Accuracy: 0.8740234375\n",
      "Batch: 16, Loss: 0.44026637077331543, Accuracy: 0.865234375\n",
      "Batch: 17, Loss: 0.47520017623901367, Accuracy: 0.841796875\n",
      "Batch: 18, Loss: 0.4981543719768524, Accuracy: 0.841796875\n",
      "Batch: 19, Loss: 0.495119571685791, Accuracy: 0.8486328125\n",
      "Batch: 20, Loss: 0.42581602931022644, Accuracy: 0.859375\n",
      "Batch: 21, Loss: 0.4852176010608673, Accuracy: 0.849609375\n",
      "Batch: 22, Loss: 0.5452433824539185, Accuracy: 0.8232421875\n",
      "Batch: 23, Loss: 0.4848748445510864, Accuracy: 0.8271484375\n",
      "Batch: 24, Loss: 0.5913968682289124, Accuracy: 0.8076171875\n",
      "Batch: 25, Loss: 0.5192369222640991, Accuracy: 0.8447265625\n",
      "Batch: 26, Loss: 0.41494160890579224, Accuracy: 0.845703125\n",
      "Batch: 27, Loss: 0.45209765434265137, Accuracy: 0.84765625\n",
      "Batch: 28, Loss: 0.46446216106414795, Accuracy: 0.8515625\n",
      "Batch: 29, Loss: 0.45489057898521423, Accuracy: 0.84765625\n",
      "Batch: 30, Loss: 0.4265095889568329, Accuracy: 0.8544921875\n",
      "Batch: 31, Loss: 0.4746803045272827, Accuracy: 0.84765625\n",
      "Batch: 32, Loss: 0.4173274040222168, Accuracy: 0.8681640625\n",
      "Batch: 33, Loss: 0.5042892098426819, Accuracy: 0.8349609375\n",
      "Batch: 34, Loss: 0.5473206639289856, Accuracy: 0.8349609375\n",
      "Batch: 35, Loss: 0.48686158657073975, Accuracy: 0.84765625\n",
      "Batch: 36, Loss: 0.5042226910591125, Accuracy: 0.83984375\n",
      "Batch: 37, Loss: 0.5437322854995728, Accuracy: 0.8154296875\n",
      "Batch: 38, Loss: 0.4893921911716461, Accuracy: 0.83203125\n",
      "Batch: 39, Loss: 0.5281522274017334, Accuracy: 0.8232421875\n",
      "Batch: 40, Loss: 0.4792323112487793, Accuracy: 0.845703125\n",
      "Batch: 41, Loss: 0.453510582447052, Accuracy: 0.8603515625\n",
      "Batch: 42, Loss: 0.37075111269950867, Accuracy: 0.869140625\n",
      "Batch: 43, Loss: 0.47970545291900635, Accuracy: 0.8310546875\n",
      "Batch: 44, Loss: 0.47540414333343506, Accuracy: 0.8486328125\n",
      "Batch: 45, Loss: 0.4277697801589966, Accuracy: 0.859375\n",
      "Batch: 46, Loss: 0.40103140473365784, Accuracy: 0.873046875\n",
      "Batch: 47, Loss: 0.43973416090011597, Accuracy: 0.8603515625\n",
      "Batch: 48, Loss: 0.4588409662246704, Accuracy: 0.8525390625\n",
      "Batch: 49, Loss: 0.47342097759246826, Accuracy: 0.837890625\n",
      "Batch: 50, Loss: 0.4751660227775574, Accuracy: 0.841796875\n",
      "Batch: 51, Loss: 0.4745333194732666, Accuracy: 0.83984375\n",
      "Batch: 52, Loss: 0.4421047866344452, Accuracy: 0.859375\n",
      "Batch: 53, Loss: 0.40299415588378906, Accuracy: 0.86328125\n",
      "Batch: 54, Loss: 0.4320967197418213, Accuracy: 0.853515625\n",
      "Batch: 55, Loss: 0.5297702550888062, Accuracy: 0.822265625\n",
      "Batch: 56, Loss: 0.5721184611320496, Accuracy: 0.8251953125\n",
      "Batch: 57, Loss: 0.4981417655944824, Accuracy: 0.8330078125\n",
      "Batch: 58, Loss: 0.5283992290496826, Accuracy: 0.8310546875\n",
      "Batch: 59, Loss: 0.46271705627441406, Accuracy: 0.8466796875\n",
      "Batch: 60, Loss: 0.45837828516960144, Accuracy: 0.8544921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 61, Loss: 0.46862706542015076, Accuracy: 0.8349609375\n",
      "Batch: 62, Loss: 0.4301021695137024, Accuracy: 0.8671875\n",
      "Batch: 63, Loss: 0.4906862676143646, Accuracy: 0.837890625\n",
      "Batch: 64, Loss: 0.46957677602767944, Accuracy: 0.849609375\n",
      "Batch: 65, Loss: 0.4493142068386078, Accuracy: 0.833984375\n",
      "Batch: 66, Loss: 0.43794888257980347, Accuracy: 0.8544921875\n",
      "Batch: 67, Loss: 0.5223475694656372, Accuracy: 0.8330078125\n",
      "Batch: 68, Loss: 0.5959790945053101, Accuracy: 0.796875\n",
      "Batch: 69, Loss: 0.49368196725845337, Accuracy: 0.8369140625\n",
      "Batch: 70, Loss: 0.4917713701725006, Accuracy: 0.8349609375\n",
      "Batch: 71, Loss: 0.524172306060791, Accuracy: 0.8203125\n",
      "Batch: 72, Loss: 0.4521719515323639, Accuracy: 0.857421875\n",
      "Batch: 73, Loss: 0.43156951665878296, Accuracy: 0.8544921875\n",
      "Batch: 74, Loss: 0.39519625902175903, Accuracy: 0.8779296875\n",
      "Batch: 75, Loss: 0.3886798918247223, Accuracy: 0.875\n",
      "Batch: 76, Loss: 0.49516528844833374, Accuracy: 0.8291015625\n",
      "Batch: 77, Loss: 0.4432075619697571, Accuracy: 0.85546875\n",
      "Batch: 78, Loss: 0.4228557348251343, Accuracy: 0.853515625\n",
      "Batch: 79, Loss: 0.42796438932418823, Accuracy: 0.861328125\n",
      "Batch: 80, Loss: 0.4752007722854614, Accuracy: 0.841796875\n",
      "Batch: 81, Loss: 0.49491772055625916, Accuracy: 0.8310546875\n",
      "Batch: 82, Loss: 0.4618799090385437, Accuracy: 0.8525390625\n",
      "Batch: 83, Loss: 0.4047855734825134, Accuracy: 0.861328125\n",
      "Batch: 84, Loss: 0.48471203446388245, Accuracy: 0.8447265625\n",
      "Batch: 85, Loss: 0.4638743996620178, Accuracy: 0.8525390625\n",
      "Batch: 86, Loss: 0.5220710039138794, Accuracy: 0.830078125\n",
      "Batch: 87, Loss: 0.41985249519348145, Accuracy: 0.8583984375\n",
      "Batch: 88, Loss: 0.5100516080856323, Accuracy: 0.8291015625\n",
      "Batch: 89, Loss: 0.4833218455314636, Accuracy: 0.84765625\n",
      "Batch: 90, Loss: 0.4824311137199402, Accuracy: 0.84375\n",
      "Batch: 91, Loss: 0.44711318612098694, Accuracy: 0.84375\n",
      "Batch: 92, Loss: 0.5135544538497925, Accuracy: 0.8232421875\n",
      "Batch: 93, Loss: 0.4426763653755188, Accuracy: 0.8466796875\n",
      "Batch: 94, Loss: 0.4815537631511688, Accuracy: 0.841796875\n",
      "Batch: 95, Loss: 0.5232317447662354, Accuracy: 0.8212890625\n",
      "Batch: 96, Loss: 0.4824221730232239, Accuracy: 0.84765625\n",
      "Batch: 97, Loss: 0.36109209060668945, Accuracy: 0.8798828125\n",
      "Batch: 98, Loss: 0.502099871635437, Accuracy: 0.83984375\n",
      "Batch: 99, Loss: 0.4673042893409729, Accuracy: 0.8359375\n",
      "Batch: 100, Loss: 0.5196992754936218, Accuracy: 0.8203125\n",
      "Batch: 101, Loss: 0.47300201654434204, Accuracy: 0.8330078125\n",
      "Batch: 102, Loss: 0.4907023310661316, Accuracy: 0.8408203125\n",
      "Batch: 103, Loss: 0.5068923830986023, Accuracy: 0.841796875\n",
      "Batch: 104, Loss: 0.4118833839893341, Accuracy: 0.869140625\n",
      "Batch: 105, Loss: 0.5341136455535889, Accuracy: 0.8046875\n",
      "Batch: 106, Loss: 0.4221433997154236, Accuracy: 0.8623046875\n",
      "Batch: 107, Loss: 0.43708536028862, Accuracy: 0.8681640625\n",
      "Batch: 108, Loss: 0.4906849265098572, Accuracy: 0.8369140625\n",
      "Batch: 109, Loss: 0.49837255477905273, Accuracy: 0.8359375\n",
      "Batch: 110, Loss: 0.4323059916496277, Accuracy: 0.8564453125\n",
      "Batch: 111, Loss: 0.48413532972335815, Accuracy: 0.8583984375\n",
      "Batch: 112, Loss: 0.49055856466293335, Accuracy: 0.8388671875\n",
      "Batch: 113, Loss: 0.463225394487381, Accuracy: 0.8486328125\n",
      "Batch: 114, Loss: 0.5325478315353394, Accuracy: 0.8291015625\n",
      "Batch: 115, Loss: 0.5157636404037476, Accuracy: 0.81640625\n",
      "Batch: 116, Loss: 0.4917420744895935, Accuracy: 0.828125\n",
      "Batch: 117, Loss: 0.5231879949569702, Accuracy: 0.8193359375\n",
      "Batch: 118, Loss: 0.45536112785339355, Accuracy: 0.8662109375\n",
      "Batch: 119, Loss: 0.38522982597351074, Accuracy: 0.8828125\n",
      "Batch: 120, Loss: 0.4224458634853363, Accuracy: 0.8623046875\n",
      "Batch: 121, Loss: 0.4935714602470398, Accuracy: 0.8466796875\n",
      "Batch: 122, Loss: 0.4614180028438568, Accuracy: 0.83984375\n",
      "Batch: 123, Loss: 0.4674016833305359, Accuracy: 0.8525390625\n",
      "Batch: 124, Loss: 0.4625198245048523, Accuracy: 0.861328125\n",
      "Batch: 125, Loss: 0.5063129663467407, Accuracy: 0.830078125\n",
      "Batch: 126, Loss: 0.5383172631263733, Accuracy: 0.8251953125\n",
      "Batch: 127, Loss: 0.4460950791835785, Accuracy: 0.8505859375\n",
      "Batch: 128, Loss: 0.5007848143577576, Accuracy: 0.826171875\n",
      "Batch: 129, Loss: 0.4358920753002167, Accuracy: 0.8603515625\n",
      "Batch: 130, Loss: 0.5161927938461304, Accuracy: 0.8427734375\n",
      "Batch: 131, Loss: 0.457955539226532, Accuracy: 0.8408203125\n",
      "Batch: 132, Loss: 0.5095667839050293, Accuracy: 0.8486328125\n",
      "Batch: 133, Loss: 0.5060715675354004, Accuracy: 0.830078125\n",
      "Batch: 134, Loss: 0.4879724979400635, Accuracy: 0.8388671875\n",
      "Batch: 135, Loss: 0.4642871618270874, Accuracy: 0.8447265625\n",
      "Batch: 136, Loss: 0.5004192590713501, Accuracy: 0.8369140625\n",
      "Batch: 137, Loss: 0.5363698601722717, Accuracy: 0.802734375\n",
      "Batch: 138, Loss: 0.453338086605072, Accuracy: 0.849609375\n",
      "Batch: 139, Loss: 0.5388485789299011, Accuracy: 0.826171875\n",
      "Batch: 140, Loss: 0.4715275764465332, Accuracy: 0.8388671875\n",
      "Batch: 141, Loss: 0.5237416625022888, Accuracy: 0.8251953125\n",
      "Batch: 142, Loss: 0.5475761294364929, Accuracy: 0.8095703125\n",
      "Batch: 143, Loss: 0.48205217719078064, Accuracy: 0.8369140625\n",
      "Batch: 144, Loss: 0.5123079419136047, Accuracy: 0.826171875\n",
      "Batch: 145, Loss: 0.4538846015930176, Accuracy: 0.8525390625\n",
      "Batch: 146, Loss: 0.46576887369155884, Accuracy: 0.8525390625\n",
      "Batch: 147, Loss: 0.470697283744812, Accuracy: 0.8583984375\n",
      "Batch: 148, Loss: 0.5688053369522095, Accuracy: 0.8115234375\n",
      "Batch: 149, Loss: 0.4862973988056183, Accuracy: 0.8486328125\n",
      "Batch: 150, Loss: 0.4587774872779846, Accuracy: 0.845703125\n",
      "Batch: 151, Loss: 0.4615587592124939, Accuracy: 0.845703125\n",
      "Epoch 76/80\n",
      "Batch: 1, Loss: 0.6529684066772461, Accuracy: 0.8046875\n",
      "Batch: 2, Loss: 0.5460452437400818, Accuracy: 0.82421875\n",
      "Batch: 3, Loss: 0.5070693492889404, Accuracy: 0.822265625\n",
      "Batch: 4, Loss: 0.4521541893482208, Accuracy: 0.8525390625\n",
      "Batch: 5, Loss: 0.4867732524871826, Accuracy: 0.849609375\n",
      "Batch: 6, Loss: 0.5159323215484619, Accuracy: 0.837890625\n",
      "Batch: 7, Loss: 0.4869418144226074, Accuracy: 0.83984375\n",
      "Batch: 8, Loss: 0.45664694905281067, Accuracy: 0.853515625\n",
      "Batch: 9, Loss: 0.4630424678325653, Accuracy: 0.85546875\n",
      "Batch: 10, Loss: 0.44909918308258057, Accuracy: 0.845703125\n",
      "Batch: 11, Loss: 0.5242756605148315, Accuracy: 0.810546875\n",
      "Batch: 12, Loss: 0.4845702052116394, Accuracy: 0.8427734375\n",
      "Batch: 13, Loss: 0.39418596029281616, Accuracy: 0.865234375\n",
      "Batch: 14, Loss: 0.5332863330841064, Accuracy: 0.826171875\n",
      "Batch: 15, Loss: 0.43323153257369995, Accuracy: 0.861328125\n",
      "Batch: 16, Loss: 0.4303857684135437, Accuracy: 0.8671875\n",
      "Batch: 17, Loss: 0.44590064883232117, Accuracy: 0.86328125\n",
      "Batch: 18, Loss: 0.4879452586174011, Accuracy: 0.84765625\n",
      "Batch: 19, Loss: 0.4791637659072876, Accuracy: 0.8505859375\n",
      "Batch: 20, Loss: 0.42994803190231323, Accuracy: 0.8642578125\n",
      "Batch: 21, Loss: 0.47034576535224915, Accuracy: 0.8525390625\n",
      "Batch: 22, Loss: 0.5511788129806519, Accuracy: 0.8212890625\n",
      "Batch: 23, Loss: 0.5195362567901611, Accuracy: 0.8232421875\n",
      "Batch: 24, Loss: 0.5303837656974792, Accuracy: 0.8291015625\n",
      "Batch: 25, Loss: 0.4808535575866699, Accuracy: 0.845703125\n",
      "Batch: 26, Loss: 0.43030303716659546, Accuracy: 0.8525390625\n",
      "Batch: 27, Loss: 0.4608485996723175, Accuracy: 0.8427734375\n",
      "Batch: 28, Loss: 0.46476274728775024, Accuracy: 0.8388671875\n",
      "Batch: 29, Loss: 0.4587516188621521, Accuracy: 0.8447265625\n",
      "Batch: 30, Loss: 0.4048596918582916, Accuracy: 0.859375\n",
      "Batch: 31, Loss: 0.4519932270050049, Accuracy: 0.849609375\n",
      "Batch: 32, Loss: 0.4313758611679077, Accuracy: 0.853515625\n",
      "Batch: 33, Loss: 0.4750475585460663, Accuracy: 0.8408203125\n",
      "Batch: 34, Loss: 0.5354264378547668, Accuracy: 0.83203125\n",
      "Batch: 35, Loss: 0.5178086757659912, Accuracy: 0.830078125\n",
      "Batch: 36, Loss: 0.487411767244339, Accuracy: 0.8408203125\n",
      "Batch: 37, Loss: 0.48022547364234924, Accuracy: 0.83203125\n",
      "Batch: 38, Loss: 0.48259010910987854, Accuracy: 0.8349609375\n",
      "Batch: 39, Loss: 0.49118906259536743, Accuracy: 0.845703125\n",
      "Batch: 40, Loss: 0.4695403575897217, Accuracy: 0.8505859375\n",
      "Batch: 41, Loss: 0.4498891830444336, Accuracy: 0.84765625\n",
      "Batch: 42, Loss: 0.3520628809928894, Accuracy: 0.873046875\n",
      "Batch: 43, Loss: 0.44596993923187256, Accuracy: 0.8525390625\n",
      "Batch: 44, Loss: 0.4359804391860962, Accuracy: 0.841796875\n",
      "Batch: 45, Loss: 0.43336212635040283, Accuracy: 0.853515625\n",
      "Batch: 46, Loss: 0.4119613766670227, Accuracy: 0.8681640625\n",
      "Batch: 47, Loss: 0.4232759177684784, Accuracy: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 48, Loss: 0.435896635055542, Accuracy: 0.859375\n",
      "Batch: 49, Loss: 0.4935005307197571, Accuracy: 0.8388671875\n",
      "Batch: 50, Loss: 0.5034449100494385, Accuracy: 0.837890625\n",
      "Batch: 51, Loss: 0.4752849042415619, Accuracy: 0.845703125\n",
      "Batch: 52, Loss: 0.47022122144699097, Accuracy: 0.8544921875\n",
      "Batch: 53, Loss: 0.4275549352169037, Accuracy: 0.8603515625\n",
      "Batch: 54, Loss: 0.49032747745513916, Accuracy: 0.8291015625\n",
      "Batch: 55, Loss: 0.5402215719223022, Accuracy: 0.83203125\n",
      "Batch: 56, Loss: 0.5213420391082764, Accuracy: 0.828125\n",
      "Batch: 57, Loss: 0.4910437762737274, Accuracy: 0.84765625\n",
      "Batch: 58, Loss: 0.5301448702812195, Accuracy: 0.822265625\n",
      "Batch: 59, Loss: 0.4814907908439636, Accuracy: 0.8408203125\n",
      "Batch: 60, Loss: 0.4410751461982727, Accuracy: 0.8583984375\n",
      "Batch: 61, Loss: 0.5002917051315308, Accuracy: 0.826171875\n",
      "Batch: 62, Loss: 0.4238588809967041, Accuracy: 0.8544921875\n",
      "Batch: 63, Loss: 0.4643811583518982, Accuracy: 0.84375\n",
      "Batch: 64, Loss: 0.467059850692749, Accuracy: 0.8447265625\n",
      "Batch: 65, Loss: 0.4459705650806427, Accuracy: 0.837890625\n",
      "Batch: 66, Loss: 0.4751678705215454, Accuracy: 0.8330078125\n",
      "Batch: 67, Loss: 0.5215035676956177, Accuracy: 0.8349609375\n",
      "Batch: 68, Loss: 0.5109735727310181, Accuracy: 0.830078125\n",
      "Batch: 69, Loss: 0.5226379036903381, Accuracy: 0.826171875\n",
      "Batch: 70, Loss: 0.48772376775741577, Accuracy: 0.8505859375\n",
      "Batch: 71, Loss: 0.505717396736145, Accuracy: 0.8349609375\n",
      "Batch: 72, Loss: 0.4888044595718384, Accuracy: 0.837890625\n",
      "Batch: 73, Loss: 0.4129009246826172, Accuracy: 0.859375\n",
      "Batch: 74, Loss: 0.41019952297210693, Accuracy: 0.8623046875\n",
      "Batch: 75, Loss: 0.3511420786380768, Accuracy: 0.8916015625\n",
      "Batch: 76, Loss: 0.47351589798927307, Accuracy: 0.83984375\n",
      "Batch: 77, Loss: 0.4341595470905304, Accuracy: 0.857421875\n",
      "Batch: 78, Loss: 0.429412841796875, Accuracy: 0.8642578125\n",
      "Batch: 79, Loss: 0.43006786704063416, Accuracy: 0.8603515625\n",
      "Batch: 80, Loss: 0.4680539667606354, Accuracy: 0.83203125\n",
      "Batch: 81, Loss: 0.5250487327575684, Accuracy: 0.810546875\n",
      "Batch: 82, Loss: 0.4690750539302826, Accuracy: 0.8544921875\n",
      "Batch: 83, Loss: 0.4087393581867218, Accuracy: 0.8671875\n",
      "Batch: 84, Loss: 0.4513833224773407, Accuracy: 0.8466796875\n",
      "Batch: 85, Loss: 0.48667797446250916, Accuracy: 0.8466796875\n",
      "Batch: 86, Loss: 0.5341383814811707, Accuracy: 0.8232421875\n",
      "Batch: 87, Loss: 0.4140983819961548, Accuracy: 0.8720703125\n",
      "Batch: 88, Loss: 0.5048726201057434, Accuracy: 0.841796875\n",
      "Batch: 89, Loss: 0.4714718461036682, Accuracy: 0.8486328125\n",
      "Batch: 90, Loss: 0.4615238308906555, Accuracy: 0.853515625\n",
      "Batch: 91, Loss: 0.4343694746494293, Accuracy: 0.849609375\n",
      "Batch: 92, Loss: 0.4850720763206482, Accuracy: 0.841796875\n",
      "Batch: 93, Loss: 0.43486541509628296, Accuracy: 0.84765625\n",
      "Batch: 94, Loss: 0.5024032592773438, Accuracy: 0.828125\n",
      "Batch: 95, Loss: 0.48729202151298523, Accuracy: 0.8330078125\n",
      "Batch: 96, Loss: 0.4774104356765747, Accuracy: 0.8544921875\n",
      "Batch: 97, Loss: 0.36391299962997437, Accuracy: 0.8798828125\n",
      "Batch: 98, Loss: 0.4676419794559479, Accuracy: 0.8408203125\n",
      "Batch: 99, Loss: 0.45892834663391113, Accuracy: 0.84765625\n",
      "Batch: 100, Loss: 0.5112358331680298, Accuracy: 0.826171875\n",
      "Batch: 101, Loss: 0.488711953163147, Accuracy: 0.83203125\n",
      "Batch: 102, Loss: 0.45345890522003174, Accuracy: 0.8515625\n",
      "Batch: 103, Loss: 0.49825066328048706, Accuracy: 0.8359375\n",
      "Batch: 104, Loss: 0.46665874123573303, Accuracy: 0.8525390625\n",
      "Batch: 105, Loss: 0.5050496459007263, Accuracy: 0.8369140625\n",
      "Batch: 106, Loss: 0.4181939363479614, Accuracy: 0.8564453125\n",
      "Batch: 107, Loss: 0.4377271831035614, Accuracy: 0.8759765625\n",
      "Batch: 108, Loss: 0.48596200346946716, Accuracy: 0.83984375\n",
      "Batch: 109, Loss: 0.5234206914901733, Accuracy: 0.8408203125\n",
      "Batch: 110, Loss: 0.41670316457748413, Accuracy: 0.8603515625\n",
      "Batch: 111, Loss: 0.47660017013549805, Accuracy: 0.8515625\n",
      "Batch: 112, Loss: 0.4602775573730469, Accuracy: 0.845703125\n",
      "Batch: 113, Loss: 0.4304409921169281, Accuracy: 0.873046875\n",
      "Batch: 114, Loss: 0.4934142231941223, Accuracy: 0.8427734375\n",
      "Batch: 115, Loss: 0.4930391013622284, Accuracy: 0.84375\n",
      "Batch: 116, Loss: 0.5299396514892578, Accuracy: 0.8271484375\n",
      "Batch: 117, Loss: 0.5303128957748413, Accuracy: 0.814453125\n",
      "Batch: 118, Loss: 0.46773838996887207, Accuracy: 0.8466796875\n",
      "Batch: 119, Loss: 0.4105881452560425, Accuracy: 0.865234375\n",
      "Batch: 120, Loss: 0.4392472505569458, Accuracy: 0.85546875\n",
      "Batch: 121, Loss: 0.534559428691864, Accuracy: 0.8291015625\n",
      "Batch: 122, Loss: 0.44512492418289185, Accuracy: 0.8447265625\n",
      "Batch: 123, Loss: 0.4394473433494568, Accuracy: 0.85546875\n",
      "Batch: 124, Loss: 0.4472705125808716, Accuracy: 0.8623046875\n",
      "Batch: 125, Loss: 0.47967803478240967, Accuracy: 0.85546875\n",
      "Batch: 126, Loss: 0.5028612017631531, Accuracy: 0.830078125\n",
      "Batch: 127, Loss: 0.472053587436676, Accuracy: 0.845703125\n",
      "Batch: 128, Loss: 0.5043905973434448, Accuracy: 0.8291015625\n",
      "Batch: 129, Loss: 0.42153996229171753, Accuracy: 0.8681640625\n",
      "Batch: 130, Loss: 0.4786788821220398, Accuracy: 0.859375\n",
      "Batch: 131, Loss: 0.4408916234970093, Accuracy: 0.8505859375\n",
      "Batch: 132, Loss: 0.4869700074195862, Accuracy: 0.8388671875\n",
      "Batch: 133, Loss: 0.4452255368232727, Accuracy: 0.8564453125\n",
      "Batch: 134, Loss: 0.4794100522994995, Accuracy: 0.8359375\n",
      "Batch: 135, Loss: 0.45280754566192627, Accuracy: 0.8515625\n",
      "Batch: 136, Loss: 0.4836379289627075, Accuracy: 0.8388671875\n",
      "Batch: 137, Loss: 0.5090407729148865, Accuracy: 0.8203125\n",
      "Batch: 138, Loss: 0.4594495892524719, Accuracy: 0.84375\n",
      "Batch: 139, Loss: 0.5211288928985596, Accuracy: 0.8369140625\n",
      "Batch: 140, Loss: 0.46433025598526, Accuracy: 0.853515625\n",
      "Batch: 141, Loss: 0.5094693899154663, Accuracy: 0.8291015625\n",
      "Batch: 142, Loss: 0.5080994367599487, Accuracy: 0.8349609375\n",
      "Batch: 143, Loss: 0.46706974506378174, Accuracy: 0.8525390625\n",
      "Batch: 144, Loss: 0.5064153671264648, Accuracy: 0.8505859375\n",
      "Batch: 145, Loss: 0.4703827500343323, Accuracy: 0.8427734375\n",
      "Batch: 146, Loss: 0.4767971932888031, Accuracy: 0.8359375\n",
      "Batch: 147, Loss: 0.47154271602630615, Accuracy: 0.84375\n",
      "Batch: 148, Loss: 0.5467824935913086, Accuracy: 0.822265625\n",
      "Batch: 149, Loss: 0.4628552794456482, Accuracy: 0.8564453125\n",
      "Batch: 150, Loss: 0.48967117071151733, Accuracy: 0.83203125\n",
      "Batch: 151, Loss: 0.4865603744983673, Accuracy: 0.841796875\n",
      "Epoch 77/80\n",
      "Batch: 1, Loss: 0.6860611438751221, Accuracy: 0.78515625\n",
      "Batch: 2, Loss: 0.5725424289703369, Accuracy: 0.8076171875\n",
      "Batch: 3, Loss: 0.47554275393486023, Accuracy: 0.8330078125\n",
      "Batch: 4, Loss: 0.4310571253299713, Accuracy: 0.859375\n",
      "Batch: 5, Loss: 0.4804045557975769, Accuracy: 0.849609375\n",
      "Batch: 6, Loss: 0.48630112409591675, Accuracy: 0.837890625\n",
      "Batch: 7, Loss: 0.5090904831886292, Accuracy: 0.837890625\n",
      "Batch: 8, Loss: 0.4485101103782654, Accuracy: 0.8486328125\n",
      "Batch: 9, Loss: 0.45757409930229187, Accuracy: 0.8505859375\n",
      "Batch: 10, Loss: 0.45519664883613586, Accuracy: 0.853515625\n",
      "Batch: 11, Loss: 0.5428601503372192, Accuracy: 0.8271484375\n",
      "Batch: 12, Loss: 0.4683901071548462, Accuracy: 0.84765625\n",
      "Batch: 13, Loss: 0.4018556475639343, Accuracy: 0.8583984375\n",
      "Batch: 14, Loss: 0.4971792995929718, Accuracy: 0.8369140625\n",
      "Batch: 15, Loss: 0.44677239656448364, Accuracy: 0.8583984375\n",
      "Batch: 16, Loss: 0.4459461569786072, Accuracy: 0.853515625\n",
      "Batch: 17, Loss: 0.460457980632782, Accuracy: 0.849609375\n",
      "Batch: 18, Loss: 0.45430970191955566, Accuracy: 0.8525390625\n",
      "Batch: 19, Loss: 0.5137077569961548, Accuracy: 0.8408203125\n",
      "Batch: 20, Loss: 0.4147908091545105, Accuracy: 0.859375\n",
      "Batch: 21, Loss: 0.44656193256378174, Accuracy: 0.8583984375\n",
      "Batch: 22, Loss: 0.5502156019210815, Accuracy: 0.8115234375\n",
      "Batch: 23, Loss: 0.502065896987915, Accuracy: 0.8251953125\n",
      "Batch: 24, Loss: 0.5385453701019287, Accuracy: 0.830078125\n",
      "Batch: 25, Loss: 0.46987754106521606, Accuracy: 0.85546875\n",
      "Batch: 26, Loss: 0.3938114047050476, Accuracy: 0.87890625\n",
      "Batch: 27, Loss: 0.44372832775115967, Accuracy: 0.8466796875\n",
      "Batch: 28, Loss: 0.47521376609802246, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.440732479095459, Accuracy: 0.84765625\n",
      "Batch: 30, Loss: 0.43521031737327576, Accuracy: 0.859375\n",
      "Batch: 31, Loss: 0.4327824115753174, Accuracy: 0.8505859375\n",
      "Batch: 32, Loss: 0.44947153329849243, Accuracy: 0.8515625\n",
      "Batch: 33, Loss: 0.49149805307388306, Accuracy: 0.841796875\n",
      "Batch: 34, Loss: 0.5338256359100342, Accuracy: 0.818359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 35, Loss: 0.4817250967025757, Accuracy: 0.8408203125\n",
      "Batch: 36, Loss: 0.4880206882953644, Accuracy: 0.85546875\n",
      "Batch: 37, Loss: 0.48989927768707275, Accuracy: 0.830078125\n",
      "Batch: 38, Loss: 0.45381999015808105, Accuracy: 0.8515625\n",
      "Batch: 39, Loss: 0.4841492474079132, Accuracy: 0.8408203125\n",
      "Batch: 40, Loss: 0.463823139667511, Accuracy: 0.8408203125\n",
      "Batch: 41, Loss: 0.42976370453834534, Accuracy: 0.8544921875\n",
      "Batch: 42, Loss: 0.3606160879135132, Accuracy: 0.8779296875\n",
      "Batch: 43, Loss: 0.4361276626586914, Accuracy: 0.84375\n",
      "Batch: 44, Loss: 0.42778992652893066, Accuracy: 0.8564453125\n",
      "Batch: 45, Loss: 0.414026141166687, Accuracy: 0.8623046875\n",
      "Batch: 46, Loss: 0.40365105867385864, Accuracy: 0.861328125\n",
      "Batch: 47, Loss: 0.3979443609714508, Accuracy: 0.8662109375\n",
      "Batch: 48, Loss: 0.43126678466796875, Accuracy: 0.87109375\n",
      "Batch: 49, Loss: 0.4437916874885559, Accuracy: 0.8583984375\n",
      "Batch: 50, Loss: 0.478709876537323, Accuracy: 0.8369140625\n",
      "Batch: 51, Loss: 0.47224920988082886, Accuracy: 0.8466796875\n",
      "Batch: 52, Loss: 0.44741812348365784, Accuracy: 0.8525390625\n",
      "Batch: 53, Loss: 0.4422658085823059, Accuracy: 0.845703125\n",
      "Batch: 54, Loss: 0.44640734791755676, Accuracy: 0.84765625\n",
      "Batch: 55, Loss: 0.48882874846458435, Accuracy: 0.84375\n",
      "Batch: 56, Loss: 0.5427515506744385, Accuracy: 0.828125\n",
      "Batch: 57, Loss: 0.4958033561706543, Accuracy: 0.8271484375\n",
      "Batch: 58, Loss: 0.5228585004806519, Accuracy: 0.8349609375\n",
      "Batch: 59, Loss: 0.45424142479896545, Accuracy: 0.84375\n",
      "Batch: 60, Loss: 0.43172550201416016, Accuracy: 0.853515625\n",
      "Batch: 61, Loss: 0.4527248740196228, Accuracy: 0.8505859375\n",
      "Batch: 62, Loss: 0.4096527099609375, Accuracy: 0.865234375\n",
      "Batch: 63, Loss: 0.4592743515968323, Accuracy: 0.845703125\n",
      "Batch: 64, Loss: 0.4589650630950928, Accuracy: 0.833984375\n",
      "Batch: 65, Loss: 0.48008036613464355, Accuracy: 0.8525390625\n",
      "Batch: 66, Loss: 0.46724897623062134, Accuracy: 0.8564453125\n",
      "Batch: 67, Loss: 0.5146784782409668, Accuracy: 0.8193359375\n",
      "Batch: 68, Loss: 0.528544008731842, Accuracy: 0.8271484375\n",
      "Batch: 69, Loss: 0.5074126720428467, Accuracy: 0.8388671875\n",
      "Batch: 70, Loss: 0.49324142932891846, Accuracy: 0.8388671875\n",
      "Batch: 71, Loss: 0.5070056915283203, Accuracy: 0.828125\n",
      "Batch: 72, Loss: 0.4237833321094513, Accuracy: 0.853515625\n",
      "Batch: 73, Loss: 0.41612035036087036, Accuracy: 0.8623046875\n",
      "Batch: 74, Loss: 0.399972140789032, Accuracy: 0.8720703125\n",
      "Batch: 75, Loss: 0.3854382038116455, Accuracy: 0.8740234375\n",
      "Batch: 76, Loss: 0.4738231599330902, Accuracy: 0.8359375\n",
      "Batch: 77, Loss: 0.4294635057449341, Accuracy: 0.861328125\n",
      "Batch: 78, Loss: 0.43438881635665894, Accuracy: 0.8583984375\n",
      "Batch: 79, Loss: 0.4040740728378296, Accuracy: 0.87109375\n",
      "Batch: 80, Loss: 0.43666258454322815, Accuracy: 0.8701171875\n",
      "Batch: 81, Loss: 0.4939459562301636, Accuracy: 0.8291015625\n",
      "Batch: 82, Loss: 0.43304842710494995, Accuracy: 0.857421875\n",
      "Batch: 83, Loss: 0.3867371678352356, Accuracy: 0.8759765625\n",
      "Batch: 84, Loss: 0.4765104055404663, Accuracy: 0.8369140625\n",
      "Batch: 85, Loss: 0.4658709466457367, Accuracy: 0.859375\n",
      "Batch: 86, Loss: 0.5199975967407227, Accuracy: 0.841796875\n",
      "Batch: 87, Loss: 0.4085298180580139, Accuracy: 0.87890625\n",
      "Batch: 88, Loss: 0.48993775248527527, Accuracy: 0.83984375\n",
      "Batch: 89, Loss: 0.4464186429977417, Accuracy: 0.8642578125\n",
      "Batch: 90, Loss: 0.4867374897003174, Accuracy: 0.837890625\n",
      "Batch: 91, Loss: 0.42947161197662354, Accuracy: 0.8623046875\n",
      "Batch: 92, Loss: 0.480646550655365, Accuracy: 0.8486328125\n",
      "Batch: 93, Loss: 0.43142861127853394, Accuracy: 0.857421875\n",
      "Batch: 94, Loss: 0.48466044664382935, Accuracy: 0.8466796875\n",
      "Batch: 95, Loss: 0.48895639181137085, Accuracy: 0.828125\n",
      "Batch: 96, Loss: 0.46064794063568115, Accuracy: 0.845703125\n",
      "Batch: 97, Loss: 0.3538321852684021, Accuracy: 0.8857421875\n",
      "Batch: 98, Loss: 0.46346205472946167, Accuracy: 0.8388671875\n",
      "Batch: 99, Loss: 0.45142316818237305, Accuracy: 0.8505859375\n",
      "Batch: 100, Loss: 0.5022584199905396, Accuracy: 0.8359375\n",
      "Batch: 101, Loss: 0.4662541151046753, Accuracy: 0.8388671875\n",
      "Batch: 102, Loss: 0.44404441118240356, Accuracy: 0.8544921875\n",
      "Batch: 103, Loss: 0.48366767168045044, Accuracy: 0.8408203125\n",
      "Batch: 104, Loss: 0.4326493740081787, Accuracy: 0.845703125\n",
      "Batch: 105, Loss: 0.46906107664108276, Accuracy: 0.845703125\n",
      "Batch: 106, Loss: 0.41897082328796387, Accuracy: 0.8623046875\n",
      "Batch: 107, Loss: 0.4280804693698883, Accuracy: 0.8505859375\n",
      "Batch: 108, Loss: 0.47117939591407776, Accuracy: 0.8486328125\n",
      "Batch: 109, Loss: 0.5153530836105347, Accuracy: 0.8251953125\n",
      "Batch: 110, Loss: 0.40022528171539307, Accuracy: 0.8642578125\n",
      "Batch: 111, Loss: 0.45128923654556274, Accuracy: 0.8515625\n",
      "Batch: 112, Loss: 0.47744128108024597, Accuracy: 0.8564453125\n",
      "Batch: 113, Loss: 0.4377591013908386, Accuracy: 0.8583984375\n",
      "Batch: 114, Loss: 0.5420957803726196, Accuracy: 0.8251953125\n",
      "Batch: 115, Loss: 0.5365235805511475, Accuracy: 0.826171875\n",
      "Batch: 116, Loss: 0.5085851550102234, Accuracy: 0.828125\n",
      "Batch: 117, Loss: 0.4678076505661011, Accuracy: 0.8486328125\n",
      "Batch: 118, Loss: 0.46019798517227173, Accuracy: 0.8623046875\n",
      "Batch: 119, Loss: 0.3984435200691223, Accuracy: 0.861328125\n",
      "Batch: 120, Loss: 0.47676271200180054, Accuracy: 0.83203125\n",
      "Batch: 121, Loss: 0.5372240543365479, Accuracy: 0.828125\n",
      "Batch: 122, Loss: 0.42734968662261963, Accuracy: 0.8603515625\n",
      "Batch: 123, Loss: 0.4477170407772064, Accuracy: 0.853515625\n",
      "Batch: 124, Loss: 0.4454437494277954, Accuracy: 0.861328125\n",
      "Batch: 125, Loss: 0.5040557384490967, Accuracy: 0.8349609375\n",
      "Batch: 126, Loss: 0.4857041537761688, Accuracy: 0.8427734375\n",
      "Batch: 127, Loss: 0.42906564474105835, Accuracy: 0.8623046875\n",
      "Batch: 128, Loss: 0.51224684715271, Accuracy: 0.83984375\n",
      "Batch: 129, Loss: 0.45347464084625244, Accuracy: 0.8486328125\n",
      "Batch: 130, Loss: 0.5072288513183594, Accuracy: 0.8388671875\n",
      "Batch: 131, Loss: 0.4518375098705292, Accuracy: 0.845703125\n",
      "Batch: 132, Loss: 0.495505154132843, Accuracy: 0.8330078125\n",
      "Batch: 133, Loss: 0.46008366346359253, Accuracy: 0.8505859375\n",
      "Batch: 134, Loss: 0.509221613407135, Accuracy: 0.8212890625\n",
      "Batch: 135, Loss: 0.4386274218559265, Accuracy: 0.845703125\n",
      "Batch: 136, Loss: 0.4952467679977417, Accuracy: 0.8310546875\n",
      "Batch: 137, Loss: 0.49330300092697144, Accuracy: 0.822265625\n",
      "Batch: 138, Loss: 0.43904292583465576, Accuracy: 0.8525390625\n",
      "Batch: 139, Loss: 0.5228511095046997, Accuracy: 0.828125\n",
      "Batch: 140, Loss: 0.5227004885673523, Accuracy: 0.8212890625\n",
      "Batch: 141, Loss: 0.514739990234375, Accuracy: 0.8212890625\n",
      "Batch: 142, Loss: 0.5229189991950989, Accuracy: 0.826171875\n",
      "Batch: 143, Loss: 0.4877622723579407, Accuracy: 0.8505859375\n",
      "Batch: 144, Loss: 0.48685044050216675, Accuracy: 0.85546875\n",
      "Batch: 145, Loss: 0.46083375811576843, Accuracy: 0.845703125\n",
      "Batch: 146, Loss: 0.48131704330444336, Accuracy: 0.8349609375\n",
      "Batch: 147, Loss: 0.4813103675842285, Accuracy: 0.857421875\n",
      "Batch: 148, Loss: 0.5261350870132446, Accuracy: 0.8408203125\n",
      "Batch: 149, Loss: 0.43807491660118103, Accuracy: 0.845703125\n",
      "Batch: 150, Loss: 0.46984726190567017, Accuracy: 0.83984375\n",
      "Batch: 151, Loss: 0.46134039759635925, Accuracy: 0.84765625\n",
      "Epoch 78/80\n",
      "Batch: 1, Loss: 0.6207840442657471, Accuracy: 0.80859375\n",
      "Batch: 2, Loss: 0.5336002111434937, Accuracy: 0.80859375\n",
      "Batch: 3, Loss: 0.5361254215240479, Accuracy: 0.8125\n",
      "Batch: 4, Loss: 0.4948320686817169, Accuracy: 0.84765625\n",
      "Batch: 5, Loss: 0.47909486293792725, Accuracy: 0.8447265625\n",
      "Batch: 6, Loss: 0.4771191477775574, Accuracy: 0.83203125\n",
      "Batch: 7, Loss: 0.48818111419677734, Accuracy: 0.8251953125\n",
      "Batch: 8, Loss: 0.46370184421539307, Accuracy: 0.8359375\n",
      "Batch: 9, Loss: 0.47422051429748535, Accuracy: 0.8388671875\n",
      "Batch: 10, Loss: 0.4487154483795166, Accuracy: 0.84765625\n",
      "Batch: 11, Loss: 0.5094793438911438, Accuracy: 0.8203125\n",
      "Batch: 12, Loss: 0.43375569581985474, Accuracy: 0.8486328125\n",
      "Batch: 13, Loss: 0.4061775505542755, Accuracy: 0.87890625\n",
      "Batch: 14, Loss: 0.5152634382247925, Accuracy: 0.8212890625\n",
      "Batch: 15, Loss: 0.4174143970012665, Accuracy: 0.884765625\n",
      "Batch: 16, Loss: 0.4181414246559143, Accuracy: 0.8701171875\n",
      "Batch: 17, Loss: 0.5009448528289795, Accuracy: 0.830078125\n",
      "Batch: 18, Loss: 0.4599470794200897, Accuracy: 0.8427734375\n",
      "Batch: 19, Loss: 0.49327200651168823, Accuracy: 0.841796875\n",
      "Batch: 20, Loss: 0.4179198741912842, Accuracy: 0.8544921875\n",
      "Batch: 21, Loss: 0.4923848807811737, Accuracy: 0.833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 0.5113568305969238, Accuracy: 0.8330078125\n",
      "Batch: 23, Loss: 0.4891752600669861, Accuracy: 0.8271484375\n",
      "Batch: 24, Loss: 0.5410126447677612, Accuracy: 0.818359375\n",
      "Batch: 25, Loss: 0.48464420437812805, Accuracy: 0.83984375\n",
      "Batch: 26, Loss: 0.4128234386444092, Accuracy: 0.857421875\n",
      "Batch: 27, Loss: 0.41259825229644775, Accuracy: 0.8583984375\n",
      "Batch: 28, Loss: 0.483277827501297, Accuracy: 0.841796875\n",
      "Batch: 29, Loss: 0.4740712642669678, Accuracy: 0.8388671875\n",
      "Batch: 30, Loss: 0.40598517656326294, Accuracy: 0.8671875\n",
      "Batch: 31, Loss: 0.43231505155563354, Accuracy: 0.865234375\n",
      "Batch: 32, Loss: 0.424957275390625, Accuracy: 0.8486328125\n",
      "Batch: 33, Loss: 0.500510036945343, Accuracy: 0.84375\n",
      "Batch: 34, Loss: 0.5316116809844971, Accuracy: 0.8212890625\n",
      "Batch: 35, Loss: 0.46905505657196045, Accuracy: 0.85546875\n",
      "Batch: 36, Loss: 0.47865068912506104, Accuracy: 0.8525390625\n",
      "Batch: 37, Loss: 0.4827432632446289, Accuracy: 0.84375\n",
      "Batch: 38, Loss: 0.48316964507102966, Accuracy: 0.8388671875\n",
      "Batch: 39, Loss: 0.4520862102508545, Accuracy: 0.84765625\n",
      "Batch: 40, Loss: 0.46131980419158936, Accuracy: 0.8447265625\n",
      "Batch: 41, Loss: 0.4355827271938324, Accuracy: 0.8486328125\n",
      "Batch: 42, Loss: 0.3439071774482727, Accuracy: 0.87109375\n",
      "Batch: 43, Loss: 0.4217972755432129, Accuracy: 0.8544921875\n",
      "Batch: 44, Loss: 0.4196467101573944, Accuracy: 0.8486328125\n",
      "Batch: 45, Loss: 0.39514076709747314, Accuracy: 0.873046875\n",
      "Batch: 46, Loss: 0.3883934020996094, Accuracy: 0.865234375\n",
      "Batch: 47, Loss: 0.41354483366012573, Accuracy: 0.87890625\n",
      "Batch: 48, Loss: 0.4318591356277466, Accuracy: 0.85546875\n",
      "Batch: 49, Loss: 0.4610447287559509, Accuracy: 0.841796875\n",
      "Batch: 50, Loss: 0.4742070734500885, Accuracy: 0.8515625\n",
      "Batch: 51, Loss: 0.43594610691070557, Accuracy: 0.853515625\n",
      "Batch: 52, Loss: 0.43366435170173645, Accuracy: 0.859375\n",
      "Batch: 53, Loss: 0.39341670274734497, Accuracy: 0.8662109375\n",
      "Batch: 54, Loss: 0.42504793405532837, Accuracy: 0.87109375\n",
      "Batch: 55, Loss: 0.5413697957992554, Accuracy: 0.818359375\n",
      "Batch: 56, Loss: 0.4798159599304199, Accuracy: 0.8427734375\n",
      "Batch: 57, Loss: 0.4953759014606476, Accuracy: 0.826171875\n",
      "Batch: 58, Loss: 0.5419747829437256, Accuracy: 0.828125\n",
      "Batch: 59, Loss: 0.46053346991539, Accuracy: 0.828125\n",
      "Batch: 60, Loss: 0.41141143441200256, Accuracy: 0.859375\n",
      "Batch: 61, Loss: 0.4687138497829437, Accuracy: 0.8310546875\n",
      "Batch: 62, Loss: 0.42213621735572815, Accuracy: 0.8623046875\n",
      "Batch: 63, Loss: 0.44129225611686707, Accuracy: 0.861328125\n",
      "Batch: 64, Loss: 0.4619811773300171, Accuracy: 0.8486328125\n",
      "Batch: 65, Loss: 0.43381267786026, Accuracy: 0.837890625\n",
      "Batch: 66, Loss: 0.4860658645629883, Accuracy: 0.8408203125\n",
      "Batch: 67, Loss: 0.521849513053894, Accuracy: 0.833984375\n",
      "Batch: 68, Loss: 0.5215333700180054, Accuracy: 0.828125\n",
      "Batch: 69, Loss: 0.5051994323730469, Accuracy: 0.8408203125\n",
      "Batch: 70, Loss: 0.46706080436706543, Accuracy: 0.8447265625\n",
      "Batch: 71, Loss: 0.48128730058670044, Accuracy: 0.83203125\n",
      "Batch: 72, Loss: 0.44589006900787354, Accuracy: 0.8447265625\n",
      "Batch: 73, Loss: 0.4109748601913452, Accuracy: 0.873046875\n",
      "Batch: 74, Loss: 0.38223662972450256, Accuracy: 0.8779296875\n",
      "Batch: 75, Loss: 0.3815964460372925, Accuracy: 0.8740234375\n",
      "Batch: 76, Loss: 0.4823722243309021, Accuracy: 0.8271484375\n",
      "Batch: 77, Loss: 0.45171424746513367, Accuracy: 0.8583984375\n",
      "Batch: 78, Loss: 0.42343148589134216, Accuracy: 0.8623046875\n",
      "Batch: 79, Loss: 0.43777358531951904, Accuracy: 0.857421875\n",
      "Batch: 80, Loss: 0.42023664712905884, Accuracy: 0.8505859375\n",
      "Batch: 81, Loss: 0.47763511538505554, Accuracy: 0.8251953125\n",
      "Batch: 82, Loss: 0.43004128336906433, Accuracy: 0.853515625\n",
      "Batch: 83, Loss: 0.3840961456298828, Accuracy: 0.8681640625\n",
      "Batch: 84, Loss: 0.47335097193717957, Accuracy: 0.8427734375\n",
      "Batch: 85, Loss: 0.46443015336990356, Accuracy: 0.8583984375\n",
      "Batch: 86, Loss: 0.5148311853408813, Accuracy: 0.8388671875\n",
      "Batch: 87, Loss: 0.41667431592941284, Accuracy: 0.8642578125\n",
      "Batch: 88, Loss: 0.4945927858352661, Accuracy: 0.8388671875\n",
      "Batch: 89, Loss: 0.4782828092575073, Accuracy: 0.8505859375\n",
      "Batch: 90, Loss: 0.4542412757873535, Accuracy: 0.83984375\n",
      "Batch: 91, Loss: 0.4249173402786255, Accuracy: 0.8544921875\n",
      "Batch: 92, Loss: 0.4634610712528229, Accuracy: 0.8486328125\n",
      "Batch: 93, Loss: 0.4507727026939392, Accuracy: 0.8427734375\n",
      "Batch: 94, Loss: 0.46652501821517944, Accuracy: 0.8427734375\n",
      "Batch: 95, Loss: 0.4626462459564209, Accuracy: 0.8515625\n",
      "Batch: 96, Loss: 0.4448561668395996, Accuracy: 0.857421875\n",
      "Batch: 97, Loss: 0.3388049006462097, Accuracy: 0.892578125\n",
      "Batch: 98, Loss: 0.4705260694026947, Accuracy: 0.8466796875\n",
      "Batch: 99, Loss: 0.46401697397232056, Accuracy: 0.826171875\n",
      "Batch: 100, Loss: 0.4917963147163391, Accuracy: 0.83984375\n",
      "Batch: 101, Loss: 0.4444401264190674, Accuracy: 0.8544921875\n",
      "Batch: 102, Loss: 0.44685232639312744, Accuracy: 0.8564453125\n",
      "Batch: 103, Loss: 0.4749782681465149, Accuracy: 0.8505859375\n",
      "Batch: 104, Loss: 0.4318610727787018, Accuracy: 0.85546875\n",
      "Batch: 105, Loss: 0.4806225299835205, Accuracy: 0.8388671875\n",
      "Batch: 106, Loss: 0.4144548773765564, Accuracy: 0.873046875\n",
      "Batch: 107, Loss: 0.45382028818130493, Accuracy: 0.84765625\n",
      "Batch: 108, Loss: 0.46131062507629395, Accuracy: 0.8505859375\n",
      "Batch: 109, Loss: 0.4888519048690796, Accuracy: 0.83203125\n",
      "Batch: 110, Loss: 0.42234355211257935, Accuracy: 0.8603515625\n",
      "Batch: 111, Loss: 0.4724678695201874, Accuracy: 0.8388671875\n",
      "Batch: 112, Loss: 0.4508276879787445, Accuracy: 0.8427734375\n",
      "Batch: 113, Loss: 0.47170644998550415, Accuracy: 0.837890625\n",
      "Batch: 114, Loss: 0.5237358212471008, Accuracy: 0.8232421875\n",
      "Batch: 115, Loss: 0.5184208750724792, Accuracy: 0.8154296875\n",
      "Batch: 116, Loss: 0.47664546966552734, Accuracy: 0.8359375\n",
      "Batch: 117, Loss: 0.48103630542755127, Accuracy: 0.8427734375\n",
      "Batch: 118, Loss: 0.4645688235759735, Accuracy: 0.853515625\n",
      "Batch: 119, Loss: 0.39894625544548035, Accuracy: 0.8603515625\n",
      "Batch: 120, Loss: 0.4468003213405609, Accuracy: 0.8515625\n",
      "Batch: 121, Loss: 0.5026277303695679, Accuracy: 0.8330078125\n",
      "Batch: 122, Loss: 0.4464951753616333, Accuracy: 0.84765625\n",
      "Batch: 123, Loss: 0.43243902921676636, Accuracy: 0.8681640625\n",
      "Batch: 124, Loss: 0.4767066240310669, Accuracy: 0.8359375\n",
      "Batch: 125, Loss: 0.48493385314941406, Accuracy: 0.8408203125\n",
      "Batch: 126, Loss: 0.5222815275192261, Accuracy: 0.8310546875\n",
      "Batch: 127, Loss: 0.45870241522789, Accuracy: 0.8515625\n",
      "Batch: 128, Loss: 0.4925273060798645, Accuracy: 0.845703125\n",
      "Batch: 129, Loss: 0.44219160079956055, Accuracy: 0.8427734375\n",
      "Batch: 130, Loss: 0.5381735563278198, Accuracy: 0.828125\n",
      "Batch: 131, Loss: 0.45852863788604736, Accuracy: 0.83984375\n",
      "Batch: 132, Loss: 0.4784995913505554, Accuracy: 0.84375\n",
      "Batch: 133, Loss: 0.46247875690460205, Accuracy: 0.8408203125\n",
      "Batch: 134, Loss: 0.4434032738208771, Accuracy: 0.8466796875\n",
      "Batch: 135, Loss: 0.42620426416397095, Accuracy: 0.8623046875\n",
      "Batch: 136, Loss: 0.4872494339942932, Accuracy: 0.8515625\n",
      "Batch: 137, Loss: 0.46025550365448, Accuracy: 0.83984375\n",
      "Batch: 138, Loss: 0.4469953775405884, Accuracy: 0.8486328125\n",
      "Batch: 139, Loss: 0.525004506111145, Accuracy: 0.830078125\n",
      "Batch: 140, Loss: 0.4881097078323364, Accuracy: 0.8427734375\n",
      "Batch: 141, Loss: 0.534587025642395, Accuracy: 0.822265625\n",
      "Batch: 142, Loss: 0.5013444423675537, Accuracy: 0.8251953125\n",
      "Batch: 143, Loss: 0.4567425549030304, Accuracy: 0.8486328125\n",
      "Batch: 144, Loss: 0.5080496072769165, Accuracy: 0.83203125\n",
      "Batch: 145, Loss: 0.44932395219802856, Accuracy: 0.837890625\n",
      "Batch: 146, Loss: 0.5159407258033752, Accuracy: 0.8203125\n",
      "Batch: 147, Loss: 0.44550108909606934, Accuracy: 0.8623046875\n",
      "Batch: 148, Loss: 0.5533835887908936, Accuracy: 0.822265625\n",
      "Batch: 149, Loss: 0.4862701892852783, Accuracy: 0.83203125\n",
      "Batch: 150, Loss: 0.48242098093032837, Accuracy: 0.8349609375\n",
      "Batch: 151, Loss: 0.45049741864204407, Accuracy: 0.859375\n",
      "Epoch 79/80\n",
      "Batch: 1, Loss: 0.6345168352127075, Accuracy: 0.796875\n",
      "Batch: 2, Loss: 0.5228068828582764, Accuracy: 0.8212890625\n",
      "Batch: 3, Loss: 0.5417314767837524, Accuracy: 0.8203125\n",
      "Batch: 4, Loss: 0.45780885219573975, Accuracy: 0.8515625\n",
      "Batch: 5, Loss: 0.44837456941604614, Accuracy: 0.861328125\n",
      "Batch: 6, Loss: 0.48150089383125305, Accuracy: 0.8330078125\n",
      "Batch: 7, Loss: 0.49122968316078186, Accuracy: 0.828125\n",
      "Batch: 8, Loss: 0.4906052350997925, Accuracy: 0.8330078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9, Loss: 0.4874427020549774, Accuracy: 0.83203125\n",
      "Batch: 10, Loss: 0.4480842649936676, Accuracy: 0.833984375\n",
      "Batch: 11, Loss: 0.5072295665740967, Accuracy: 0.82421875\n",
      "Batch: 12, Loss: 0.4572807550430298, Accuracy: 0.84375\n",
      "Batch: 13, Loss: 0.4182606339454651, Accuracy: 0.859375\n",
      "Batch: 14, Loss: 0.48700156807899475, Accuracy: 0.8369140625\n",
      "Batch: 15, Loss: 0.45442283153533936, Accuracy: 0.8623046875\n",
      "Batch: 16, Loss: 0.4282756447792053, Accuracy: 0.8603515625\n",
      "Batch: 17, Loss: 0.4730927348136902, Accuracy: 0.828125\n",
      "Batch: 18, Loss: 0.46243053674697876, Accuracy: 0.8427734375\n",
      "Batch: 19, Loss: 0.505537748336792, Accuracy: 0.83984375\n",
      "Batch: 20, Loss: 0.40910837054252625, Accuracy: 0.876953125\n",
      "Batch: 21, Loss: 0.47452759742736816, Accuracy: 0.837890625\n",
      "Batch: 22, Loss: 0.5253796577453613, Accuracy: 0.8310546875\n",
      "Batch: 23, Loss: 0.5274539589881897, Accuracy: 0.8212890625\n",
      "Batch: 24, Loss: 0.5043020248413086, Accuracy: 0.8349609375\n",
      "Batch: 25, Loss: 0.4591420888900757, Accuracy: 0.84765625\n",
      "Batch: 26, Loss: 0.40974846482276917, Accuracy: 0.8671875\n",
      "Batch: 27, Loss: 0.4238393306732178, Accuracy: 0.8603515625\n",
      "Batch: 28, Loss: 0.4561522901058197, Accuracy: 0.8544921875\n",
      "Batch: 29, Loss: 0.4449937343597412, Accuracy: 0.859375\n",
      "Batch: 30, Loss: 0.42612212896347046, Accuracy: 0.865234375\n",
      "Batch: 31, Loss: 0.4302939176559448, Accuracy: 0.861328125\n",
      "Batch: 32, Loss: 0.4003831148147583, Accuracy: 0.865234375\n",
      "Batch: 33, Loss: 0.49679747223854065, Accuracy: 0.8408203125\n",
      "Batch: 34, Loss: 0.5078132748603821, Accuracy: 0.826171875\n",
      "Batch: 35, Loss: 0.4407619535923004, Accuracy: 0.8447265625\n",
      "Batch: 36, Loss: 0.46997207403182983, Accuracy: 0.8515625\n",
      "Batch: 37, Loss: 0.5120416879653931, Accuracy: 0.828125\n",
      "Batch: 38, Loss: 0.43976032733917236, Accuracy: 0.8583984375\n",
      "Batch: 39, Loss: 0.4887617230415344, Accuracy: 0.8447265625\n",
      "Batch: 40, Loss: 0.45885175466537476, Accuracy: 0.8671875\n",
      "Batch: 41, Loss: 0.4477161169052124, Accuracy: 0.8486328125\n",
      "Batch: 42, Loss: 0.36221957206726074, Accuracy: 0.8876953125\n",
      "Batch: 43, Loss: 0.4337623119354248, Accuracy: 0.8583984375\n",
      "Batch: 44, Loss: 0.444415807723999, Accuracy: 0.8486328125\n",
      "Batch: 45, Loss: 0.4038081467151642, Accuracy: 0.865234375\n",
      "Batch: 46, Loss: 0.4150339961051941, Accuracy: 0.865234375\n",
      "Batch: 47, Loss: 0.39045217633247375, Accuracy: 0.8837890625\n",
      "Batch: 48, Loss: 0.43447402119636536, Accuracy: 0.85546875\n",
      "Batch: 49, Loss: 0.4853285551071167, Accuracy: 0.837890625\n",
      "Batch: 50, Loss: 0.4658326506614685, Accuracy: 0.8486328125\n",
      "Batch: 51, Loss: 0.45163989067077637, Accuracy: 0.853515625\n",
      "Batch: 52, Loss: 0.4748340845108032, Accuracy: 0.8447265625\n",
      "Batch: 53, Loss: 0.4013725519180298, Accuracy: 0.8623046875\n",
      "Batch: 54, Loss: 0.4382636249065399, Accuracy: 0.83984375\n",
      "Batch: 55, Loss: 0.48085707426071167, Accuracy: 0.8466796875\n",
      "Batch: 56, Loss: 0.5041508674621582, Accuracy: 0.8349609375\n",
      "Batch: 57, Loss: 0.47578632831573486, Accuracy: 0.8408203125\n",
      "Batch: 58, Loss: 0.533073902130127, Accuracy: 0.8310546875\n",
      "Batch: 59, Loss: 0.43577927350997925, Accuracy: 0.853515625\n",
      "Batch: 60, Loss: 0.45518869161605835, Accuracy: 0.84375\n",
      "Batch: 61, Loss: 0.46626168489456177, Accuracy: 0.849609375\n",
      "Batch: 62, Loss: 0.4243582785129547, Accuracy: 0.857421875\n",
      "Batch: 63, Loss: 0.4618343412876129, Accuracy: 0.8544921875\n",
      "Batch: 64, Loss: 0.4520736634731293, Accuracy: 0.8515625\n",
      "Batch: 65, Loss: 0.47682738304138184, Accuracy: 0.84375\n",
      "Batch: 66, Loss: 0.43146371841430664, Accuracy: 0.857421875\n",
      "Batch: 67, Loss: 0.5212540626525879, Accuracy: 0.828125\n",
      "Batch: 68, Loss: 0.5452530384063721, Accuracy: 0.8310546875\n",
      "Batch: 69, Loss: 0.49106159806251526, Accuracy: 0.8369140625\n",
      "Batch: 70, Loss: 0.4878658056259155, Accuracy: 0.845703125\n",
      "Batch: 71, Loss: 0.5077431201934814, Accuracy: 0.822265625\n",
      "Batch: 72, Loss: 0.4771307706832886, Accuracy: 0.845703125\n",
      "Batch: 73, Loss: 0.4336414337158203, Accuracy: 0.86328125\n",
      "Batch: 74, Loss: 0.4052995443344116, Accuracy: 0.8671875\n",
      "Batch: 75, Loss: 0.3763822913169861, Accuracy: 0.8916015625\n",
      "Batch: 76, Loss: 0.4460645020008087, Accuracy: 0.8544921875\n",
      "Batch: 77, Loss: 0.433089017868042, Accuracy: 0.859375\n",
      "Batch: 78, Loss: 0.4534996747970581, Accuracy: 0.845703125\n",
      "Batch: 79, Loss: 0.4384668171405792, Accuracy: 0.857421875\n",
      "Batch: 80, Loss: 0.45655718445777893, Accuracy: 0.8427734375\n",
      "Batch: 81, Loss: 0.4560241401195526, Accuracy: 0.837890625\n",
      "Batch: 82, Loss: 0.46110084652900696, Accuracy: 0.8486328125\n",
      "Batch: 83, Loss: 0.3965972363948822, Accuracy: 0.873046875\n",
      "Batch: 84, Loss: 0.45421239733695984, Accuracy: 0.8505859375\n",
      "Batch: 85, Loss: 0.44402024149894714, Accuracy: 0.8564453125\n",
      "Batch: 86, Loss: 0.55039381980896, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.4149627089500427, Accuracy: 0.873046875\n",
      "Batch: 88, Loss: 0.5053865313529968, Accuracy: 0.8427734375\n",
      "Batch: 89, Loss: 0.4569888710975647, Accuracy: 0.8515625\n",
      "Batch: 90, Loss: 0.4539445638656616, Accuracy: 0.84375\n",
      "Batch: 91, Loss: 0.4408559203147888, Accuracy: 0.8544921875\n",
      "Batch: 92, Loss: 0.48630353808403015, Accuracy: 0.837890625\n",
      "Batch: 93, Loss: 0.44730043411254883, Accuracy: 0.8505859375\n",
      "Batch: 94, Loss: 0.4631904363632202, Accuracy: 0.845703125\n",
      "Batch: 95, Loss: 0.4994126558303833, Accuracy: 0.8466796875\n",
      "Batch: 96, Loss: 0.4770403504371643, Accuracy: 0.8369140625\n",
      "Batch: 97, Loss: 0.3372935354709625, Accuracy: 0.89453125\n",
      "Batch: 98, Loss: 0.48729097843170166, Accuracy: 0.857421875\n",
      "Batch: 99, Loss: 0.4243404269218445, Accuracy: 0.8525390625\n",
      "Batch: 100, Loss: 0.474939227104187, Accuracy: 0.85546875\n",
      "Batch: 101, Loss: 0.48222997784614563, Accuracy: 0.845703125\n",
      "Batch: 102, Loss: 0.45119279623031616, Accuracy: 0.8427734375\n",
      "Batch: 103, Loss: 0.44929981231689453, Accuracy: 0.857421875\n",
      "Batch: 104, Loss: 0.44813406467437744, Accuracy: 0.841796875\n",
      "Batch: 105, Loss: 0.47137928009033203, Accuracy: 0.8349609375\n",
      "Batch: 106, Loss: 0.4079126715660095, Accuracy: 0.8515625\n",
      "Batch: 107, Loss: 0.41408443450927734, Accuracy: 0.8623046875\n",
      "Batch: 108, Loss: 0.4507138431072235, Accuracy: 0.859375\n",
      "Batch: 109, Loss: 0.47986239194869995, Accuracy: 0.8427734375\n",
      "Batch: 110, Loss: 0.39269524812698364, Accuracy: 0.8623046875\n",
      "Batch: 111, Loss: 0.4748225808143616, Accuracy: 0.8427734375\n",
      "Batch: 112, Loss: 0.4812278747558594, Accuracy: 0.833984375\n",
      "Batch: 113, Loss: 0.4425678253173828, Accuracy: 0.8525390625\n",
      "Batch: 114, Loss: 0.5298933386802673, Accuracy: 0.8291015625\n",
      "Batch: 115, Loss: 0.4692770838737488, Accuracy: 0.83984375\n",
      "Batch: 116, Loss: 0.4408116042613983, Accuracy: 0.841796875\n",
      "Batch: 117, Loss: 0.4662354588508606, Accuracy: 0.845703125\n",
      "Batch: 118, Loss: 0.44734910130500793, Accuracy: 0.8603515625\n",
      "Batch: 119, Loss: 0.4015158414840698, Accuracy: 0.865234375\n",
      "Batch: 120, Loss: 0.4172467589378357, Accuracy: 0.87109375\n",
      "Batch: 121, Loss: 0.5213990211486816, Accuracy: 0.8251953125\n",
      "Batch: 122, Loss: 0.4595910310745239, Accuracy: 0.8466796875\n",
      "Batch: 123, Loss: 0.425321102142334, Accuracy: 0.8525390625\n",
      "Batch: 124, Loss: 0.46039384603500366, Accuracy: 0.8505859375\n",
      "Batch: 125, Loss: 0.4980922341346741, Accuracy: 0.8330078125\n",
      "Batch: 126, Loss: 0.5297698974609375, Accuracy: 0.8193359375\n",
      "Batch: 127, Loss: 0.41703763604164124, Accuracy: 0.865234375\n",
      "Batch: 128, Loss: 0.49218350648880005, Accuracy: 0.833984375\n",
      "Batch: 129, Loss: 0.44575875997543335, Accuracy: 0.845703125\n",
      "Batch: 130, Loss: 0.5123438239097595, Accuracy: 0.8359375\n",
      "Batch: 131, Loss: 0.47119802236557007, Accuracy: 0.8564453125\n",
      "Batch: 132, Loss: 0.4734530448913574, Accuracy: 0.83984375\n",
      "Batch: 133, Loss: 0.48662135004997253, Accuracy: 0.83984375\n",
      "Batch: 134, Loss: 0.45778709650039673, Accuracy: 0.841796875\n",
      "Batch: 135, Loss: 0.44429686665534973, Accuracy: 0.8505859375\n",
      "Batch: 136, Loss: 0.469316303730011, Accuracy: 0.841796875\n",
      "Batch: 137, Loss: 0.4841018319129944, Accuracy: 0.8251953125\n",
      "Batch: 138, Loss: 0.439929723739624, Accuracy: 0.8544921875\n",
      "Batch: 139, Loss: 0.5153734683990479, Accuracy: 0.8359375\n",
      "Batch: 140, Loss: 0.4946012794971466, Accuracy: 0.83203125\n",
      "Batch: 141, Loss: 0.4869842231273651, Accuracy: 0.826171875\n",
      "Batch: 142, Loss: 0.497161865234375, Accuracy: 0.8388671875\n",
      "Batch: 143, Loss: 0.49259307980537415, Accuracy: 0.8330078125\n",
      "Batch: 144, Loss: 0.4526250958442688, Accuracy: 0.85546875\n",
      "Batch: 145, Loss: 0.44155409932136536, Accuracy: 0.85546875\n",
      "Batch: 146, Loss: 0.47236528992652893, Accuracy: 0.8408203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 147, Loss: 0.4395917057991028, Accuracy: 0.8525390625\n",
      "Batch: 148, Loss: 0.5370088815689087, Accuracy: 0.8349609375\n",
      "Batch: 149, Loss: 0.4612531363964081, Accuracy: 0.8427734375\n",
      "Batch: 150, Loss: 0.49950775504112244, Accuracy: 0.8388671875\n",
      "Batch: 151, Loss: 0.4476983845233917, Accuracy: 0.853515625\n",
      "Epoch 80/80\n",
      "Batch: 1, Loss: 0.6252017021179199, Accuracy: 0.806640625\n",
      "Batch: 2, Loss: 0.5453973412513733, Accuracy: 0.8095703125\n",
      "Batch: 3, Loss: 0.5045788884162903, Accuracy: 0.8330078125\n",
      "Batch: 4, Loss: 0.44380176067352295, Accuracy: 0.857421875\n",
      "Batch: 5, Loss: 0.48037242889404297, Accuracy: 0.8427734375\n",
      "Batch: 6, Loss: 0.4947843849658966, Accuracy: 0.830078125\n",
      "Batch: 7, Loss: 0.497312068939209, Accuracy: 0.8291015625\n",
      "Batch: 8, Loss: 0.4479140043258667, Accuracy: 0.8427734375\n",
      "Batch: 9, Loss: 0.4572582244873047, Accuracy: 0.8515625\n",
      "Batch: 10, Loss: 0.45365074276924133, Accuracy: 0.8408203125\n",
      "Batch: 11, Loss: 0.515255331993103, Accuracy: 0.8203125\n",
      "Batch: 12, Loss: 0.44455355405807495, Accuracy: 0.8466796875\n",
      "Batch: 13, Loss: 0.3825541138648987, Accuracy: 0.875\n",
      "Batch: 14, Loss: 0.49688035249710083, Accuracy: 0.826171875\n",
      "Batch: 15, Loss: 0.4206976890563965, Accuracy: 0.85546875\n",
      "Batch: 16, Loss: 0.3903619050979614, Accuracy: 0.8701171875\n",
      "Batch: 17, Loss: 0.49045082926750183, Accuracy: 0.8427734375\n",
      "Batch: 18, Loss: 0.46971064805984497, Accuracy: 0.833984375\n",
      "Batch: 19, Loss: 0.4958299696445465, Accuracy: 0.83984375\n",
      "Batch: 20, Loss: 0.4252462685108185, Accuracy: 0.8603515625\n",
      "Batch: 21, Loss: 0.4904400110244751, Accuracy: 0.8359375\n",
      "Batch: 22, Loss: 0.5673930644989014, Accuracy: 0.814453125\n",
      "Batch: 23, Loss: 0.521172821521759, Accuracy: 0.8115234375\n",
      "Batch: 24, Loss: 0.5217961072921753, Accuracy: 0.8291015625\n",
      "Batch: 25, Loss: 0.46906155347824097, Accuracy: 0.84765625\n",
      "Batch: 26, Loss: 0.3910301923751831, Accuracy: 0.8701171875\n",
      "Batch: 27, Loss: 0.46348071098327637, Accuracy: 0.8486328125\n",
      "Batch: 28, Loss: 0.4881402254104614, Accuracy: 0.8515625\n",
      "Batch: 29, Loss: 0.4337553381919861, Accuracy: 0.865234375\n",
      "Batch: 30, Loss: 0.4119254946708679, Accuracy: 0.8623046875\n",
      "Batch: 31, Loss: 0.41723400354385376, Accuracy: 0.859375\n",
      "Batch: 32, Loss: 0.40942949056625366, Accuracy: 0.8662109375\n",
      "Batch: 33, Loss: 0.45068156719207764, Accuracy: 0.84765625\n",
      "Batch: 34, Loss: 0.5417516231536865, Accuracy: 0.833984375\n",
      "Batch: 35, Loss: 0.4776129126548767, Accuracy: 0.8447265625\n",
      "Batch: 36, Loss: 0.46687209606170654, Accuracy: 0.8466796875\n",
      "Batch: 37, Loss: 0.477716326713562, Accuracy: 0.8427734375\n",
      "Batch: 38, Loss: 0.45630383491516113, Accuracy: 0.849609375\n",
      "Batch: 39, Loss: 0.4828425645828247, Accuracy: 0.8388671875\n",
      "Batch: 40, Loss: 0.45930004119873047, Accuracy: 0.8544921875\n",
      "Batch: 41, Loss: 0.4204665422439575, Accuracy: 0.8662109375\n",
      "Batch: 42, Loss: 0.38195621967315674, Accuracy: 0.8759765625\n",
      "Batch: 43, Loss: 0.4297943711280823, Accuracy: 0.8603515625\n",
      "Batch: 44, Loss: 0.4381992220878601, Accuracy: 0.849609375\n",
      "Batch: 45, Loss: 0.39512544870376587, Accuracy: 0.8662109375\n",
      "Batch: 46, Loss: 0.3971629738807678, Accuracy: 0.8662109375\n",
      "Batch: 47, Loss: 0.423397958278656, Accuracy: 0.8671875\n",
      "Batch: 48, Loss: 0.4035000801086426, Accuracy: 0.8623046875\n",
      "Batch: 49, Loss: 0.4662587642669678, Accuracy: 0.8447265625\n",
      "Batch: 50, Loss: 0.4689095616340637, Accuracy: 0.83984375\n",
      "Batch: 51, Loss: 0.44485655426979065, Accuracy: 0.8505859375\n",
      "Batch: 52, Loss: 0.43425294756889343, Accuracy: 0.86328125\n",
      "Batch: 53, Loss: 0.42754340171813965, Accuracy: 0.857421875\n",
      "Batch: 54, Loss: 0.4223633408546448, Accuracy: 0.861328125\n",
      "Batch: 55, Loss: 0.5319662690162659, Accuracy: 0.8203125\n",
      "Batch: 56, Loss: 0.5042405724525452, Accuracy: 0.828125\n",
      "Batch: 57, Loss: 0.46508097648620605, Accuracy: 0.8447265625\n",
      "Batch: 58, Loss: 0.4955223798751831, Accuracy: 0.830078125\n",
      "Batch: 59, Loss: 0.47111445665359497, Accuracy: 0.849609375\n",
      "Batch: 60, Loss: 0.4622492790222168, Accuracy: 0.8330078125\n",
      "Batch: 61, Loss: 0.494897723197937, Accuracy: 0.8203125\n",
      "Batch: 62, Loss: 0.4323946535587311, Accuracy: 0.8681640625\n",
      "Batch: 63, Loss: 0.4476359486579895, Accuracy: 0.8369140625\n",
      "Batch: 64, Loss: 0.4294873774051666, Accuracy: 0.857421875\n",
      "Batch: 65, Loss: 0.43144699931144714, Accuracy: 0.845703125\n",
      "Batch: 66, Loss: 0.43953976035118103, Accuracy: 0.865234375\n",
      "Batch: 67, Loss: 0.5183160901069641, Accuracy: 0.828125\n",
      "Batch: 68, Loss: 0.5389314889907837, Accuracy: 0.8359375\n",
      "Batch: 69, Loss: 0.50923752784729, Accuracy: 0.8388671875\n",
      "Batch: 70, Loss: 0.4845653176307678, Accuracy: 0.8388671875\n",
      "Batch: 71, Loss: 0.4833763837814331, Accuracy: 0.8251953125\n",
      "Batch: 72, Loss: 0.4296766221523285, Accuracy: 0.857421875\n",
      "Batch: 73, Loss: 0.4022510051727295, Accuracy: 0.869140625\n",
      "Batch: 74, Loss: 0.38367384672164917, Accuracy: 0.875\n",
      "Batch: 75, Loss: 0.42394402623176575, Accuracy: 0.8544921875\n",
      "Batch: 76, Loss: 0.49467208981513977, Accuracy: 0.8173828125\n",
      "Batch: 77, Loss: 0.4407379627227783, Accuracy: 0.8564453125\n",
      "Batch: 78, Loss: 0.4009268283843994, Accuracy: 0.86328125\n",
      "Batch: 79, Loss: 0.41270768642425537, Accuracy: 0.857421875\n",
      "Batch: 80, Loss: 0.4481141269207001, Accuracy: 0.849609375\n",
      "Batch: 81, Loss: 0.5035606622695923, Accuracy: 0.833984375\n",
      "Batch: 82, Loss: 0.46979212760925293, Accuracy: 0.84375\n",
      "Batch: 83, Loss: 0.4612671732902527, Accuracy: 0.8486328125\n",
      "Batch: 84, Loss: 0.542931318283081, Accuracy: 0.8271484375\n",
      "Batch: 85, Loss: 0.48699668049812317, Accuracy: 0.8447265625\n",
      "Batch: 86, Loss: 0.5214171409606934, Accuracy: 0.822265625\n",
      "Batch: 87, Loss: 0.4350891411304474, Accuracy: 0.853515625\n",
      "Batch: 88, Loss: 0.503939151763916, Accuracy: 0.830078125\n",
      "Batch: 89, Loss: 0.4680559039115906, Accuracy: 0.849609375\n",
      "Batch: 90, Loss: 0.47642508149147034, Accuracy: 0.8486328125\n",
      "Batch: 91, Loss: 0.4358176290988922, Accuracy: 0.8603515625\n",
      "Batch: 92, Loss: 0.46473607420921326, Accuracy: 0.8486328125\n",
      "Batch: 93, Loss: 0.4669409692287445, Accuracy: 0.83203125\n",
      "Batch: 94, Loss: 0.46366873383522034, Accuracy: 0.833984375\n",
      "Batch: 95, Loss: 0.47972071170806885, Accuracy: 0.8359375\n",
      "Batch: 96, Loss: 0.45970749855041504, Accuracy: 0.859375\n",
      "Batch: 97, Loss: 0.36131179332733154, Accuracy: 0.8837890625\n",
      "Batch: 98, Loss: 0.4537901282310486, Accuracy: 0.8388671875\n",
      "Batch: 99, Loss: 0.4484494924545288, Accuracy: 0.8388671875\n",
      "Batch: 100, Loss: 0.4914622902870178, Accuracy: 0.8427734375\n",
      "Batch: 101, Loss: 0.45978498458862305, Accuracy: 0.8505859375\n",
      "Batch: 102, Loss: 0.47187045216560364, Accuracy: 0.8291015625\n",
      "Batch: 103, Loss: 0.4861549139022827, Accuracy: 0.84375\n",
      "Batch: 104, Loss: 0.4559147357940674, Accuracy: 0.8466796875\n",
      "Batch: 105, Loss: 0.49006202816963196, Accuracy: 0.8251953125\n",
      "Batch: 106, Loss: 0.41034698486328125, Accuracy: 0.873046875\n",
      "Batch: 107, Loss: 0.44777294993400574, Accuracy: 0.8525390625\n",
      "Batch: 108, Loss: 0.47068527340888977, Accuracy: 0.83984375\n",
      "Batch: 109, Loss: 0.48738914728164673, Accuracy: 0.8369140625\n",
      "Batch: 110, Loss: 0.37250858545303345, Accuracy: 0.869140625\n",
      "Batch: 111, Loss: 0.48560288548469543, Accuracy: 0.8310546875\n",
      "Batch: 112, Loss: 0.4459719657897949, Accuracy: 0.8486328125\n",
      "Batch: 113, Loss: 0.47315120697021484, Accuracy: 0.8525390625\n",
      "Batch: 114, Loss: 0.5112951993942261, Accuracy: 0.841796875\n",
      "Batch: 115, Loss: 0.49669039249420166, Accuracy: 0.837890625\n",
      "Batch: 116, Loss: 0.49988824129104614, Accuracy: 0.8251953125\n",
      "Batch: 117, Loss: 0.470419317483902, Accuracy: 0.84765625\n",
      "Batch: 118, Loss: 0.4497588872909546, Accuracy: 0.857421875\n",
      "Batch: 119, Loss: 0.39454132318496704, Accuracy: 0.875\n",
      "Batch: 120, Loss: 0.4822995662689209, Accuracy: 0.83984375\n",
      "Batch: 121, Loss: 0.4977346360683441, Accuracy: 0.8427734375\n",
      "Batch: 122, Loss: 0.41852807998657227, Accuracy: 0.8603515625\n",
      "Batch: 123, Loss: 0.4374324381351471, Accuracy: 0.865234375\n",
      "Batch: 124, Loss: 0.43787556886672974, Accuracy: 0.8583984375\n",
      "Batch: 125, Loss: 0.46688055992126465, Accuracy: 0.8603515625\n",
      "Batch: 126, Loss: 0.4657573103904724, Accuracy: 0.8603515625\n",
      "Batch: 127, Loss: 0.4625987410545349, Accuracy: 0.8505859375\n",
      "Batch: 128, Loss: 0.49311164021492004, Accuracy: 0.837890625\n",
      "Batch: 129, Loss: 0.4376353621482849, Accuracy: 0.8486328125\n",
      "Batch: 130, Loss: 0.49695104360580444, Accuracy: 0.833984375\n",
      "Batch: 131, Loss: 0.4667249023914337, Accuracy: 0.84765625\n",
      "Batch: 132, Loss: 0.4690413475036621, Accuracy: 0.849609375\n",
      "Batch: 133, Loss: 0.4907245337963104, Accuracy: 0.83203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 134, Loss: 0.4702020287513733, Accuracy: 0.833984375\n",
      "Batch: 135, Loss: 0.4212133288383484, Accuracy: 0.861328125\n",
      "Batch: 136, Loss: 0.47045063972473145, Accuracy: 0.8349609375\n",
      "Batch: 137, Loss: 0.48452287912368774, Accuracy: 0.8212890625\n",
      "Batch: 138, Loss: 0.43101686239242554, Accuracy: 0.85546875\n",
      "Batch: 139, Loss: 0.4941263198852539, Accuracy: 0.83984375\n",
      "Batch: 140, Loss: 0.48511528968811035, Accuracy: 0.8369140625\n",
      "Batch: 141, Loss: 0.5163055658340454, Accuracy: 0.8271484375\n",
      "Batch: 142, Loss: 0.49444669485092163, Accuracy: 0.830078125\n",
      "Batch: 143, Loss: 0.44614630937576294, Accuracy: 0.857421875\n",
      "Batch: 144, Loss: 0.4926169216632843, Accuracy: 0.8369140625\n",
      "Batch: 145, Loss: 0.43183720111846924, Accuracy: 0.8525390625\n",
      "Batch: 146, Loss: 0.47125592827796936, Accuracy: 0.837890625\n",
      "Batch: 147, Loss: 0.4637753963470459, Accuracy: 0.8525390625\n",
      "Batch: 148, Loss: 0.5029866695404053, Accuracy: 0.84375\n",
      "Batch: 149, Loss: 0.4478471875190735, Accuracy: 0.859375\n",
      "Batch: 150, Loss: 0.456634521484375, Accuracy: 0.84375\n",
      "Batch: 151, Loss: 0.46156835556030273, Accuracy: 0.8408203125\n",
      "Saved Weights at epoch 80 to file Weights_80.h5\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.721238</td>\n",
       "      <td>0.285156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.932443</td>\n",
       "      <td>0.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.624641</td>\n",
       "      <td>0.543945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.458915</td>\n",
       "      <td>0.559570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.369484</td>\n",
       "      <td>0.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.289247</td>\n",
       "      <td>0.607422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.227129</td>\n",
       "      <td>0.625977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.177866</td>\n",
       "      <td>0.633789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.123210</td>\n",
       "      <td>0.653320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.084698</td>\n",
       "      <td>0.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.061213</td>\n",
       "      <td>0.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.039639</td>\n",
       "      <td>0.681641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.988042</td>\n",
       "      <td>0.678711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.964766</td>\n",
       "      <td>0.686523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.966593</td>\n",
       "      <td>0.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.933311</td>\n",
       "      <td>0.696289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.922318</td>\n",
       "      <td>0.711914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.867218</td>\n",
       "      <td>0.707031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.865734</td>\n",
       "      <td>0.724609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.840743</td>\n",
       "      <td>0.737305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.840995</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.805552</td>\n",
       "      <td>0.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.817481</td>\n",
       "      <td>0.739258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.786452</td>\n",
       "      <td>0.745117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.785605</td>\n",
       "      <td>0.747070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.750977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.783077</td>\n",
       "      <td>0.736328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.747239</td>\n",
       "      <td>0.752930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>0.749023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.726197</td>\n",
       "      <td>0.763672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.537401</td>\n",
       "      <td>0.821289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.546795</td>\n",
       "      <td>0.825195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.545891</td>\n",
       "      <td>0.815430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.519619</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.836914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.529570</td>\n",
       "      <td>0.817383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.826172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.514324</td>\n",
       "      <td>0.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.518598</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.489665</td>\n",
       "      <td>0.837891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.521974</td>\n",
       "      <td>0.826172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.511232</td>\n",
       "      <td>0.832031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.460443</td>\n",
       "      <td>0.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.500298</td>\n",
       "      <td>0.829102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.507442</td>\n",
       "      <td>0.829102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.467209</td>\n",
       "      <td>0.858398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.503654</td>\n",
       "      <td>0.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.506950</td>\n",
       "      <td>0.832031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.491211</td>\n",
       "      <td>0.840820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.474137</td>\n",
       "      <td>0.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.481244</td>\n",
       "      <td>0.832031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.461852</td>\n",
       "      <td>0.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.477389</td>\n",
       "      <td>0.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.480486</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.461559</td>\n",
       "      <td>0.845703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.486560</td>\n",
       "      <td>0.841797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.461340</td>\n",
       "      <td>0.847656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.450497</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.447698</td>\n",
       "      <td>0.853516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.461568</td>\n",
       "      <td>0.840820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  2.721238  0.285156\n",
       "1       2  1.932443  0.476562\n",
       "2       3  1.624641  0.543945\n",
       "3       4  1.458915  0.559570\n",
       "4       5  1.369484  0.580078\n",
       "5       6  1.289247  0.607422\n",
       "6       7  1.227129  0.625977\n",
       "7       8  1.177866  0.633789\n",
       "8       9  1.123210  0.653320\n",
       "9      10  1.084698  0.663086\n",
       "10     11  1.061213  0.664062\n",
       "11     12  1.039639  0.681641\n",
       "12     13  0.988042  0.678711\n",
       "13     14  0.964766  0.686523\n",
       "14     15  0.966593  0.692383\n",
       "15     16  0.933311  0.696289\n",
       "16     17  0.922318  0.711914\n",
       "17     18  0.867218  0.707031\n",
       "18     19  0.865734  0.724609\n",
       "19     20  0.840743  0.737305\n",
       "20     21  0.840995  0.734375\n",
       "21     22  0.805552  0.732422\n",
       "22     23  0.817481  0.739258\n",
       "23     24  0.786452  0.745117\n",
       "24     25  0.785605  0.747070\n",
       "25     26  0.749717  0.750977\n",
       "26     27  0.783077  0.736328\n",
       "27     28  0.747239  0.752930\n",
       "28     29  0.747667  0.749023\n",
       "29     30  0.726197  0.763672\n",
       "..    ...       ...       ...\n",
       "50     51  0.537401  0.821289\n",
       "51     52  0.546795  0.825195\n",
       "52     53  0.545891  0.815430\n",
       "53     54  0.519619  0.811523\n",
       "54     55  0.503500  0.836914\n",
       "55     56  0.529570  0.817383\n",
       "56     57  0.506068  0.826172\n",
       "57     58  0.514324  0.835938\n",
       "58     59  0.518598  0.828125\n",
       "59     60  0.489665  0.837891\n",
       "60     61  0.521974  0.826172\n",
       "61     62  0.511232  0.832031\n",
       "62     63  0.460443  0.851562\n",
       "63     64  0.500298  0.829102\n",
       "64     65  0.507442  0.829102\n",
       "65     66  0.467209  0.858398\n",
       "66     67  0.503654  0.835938\n",
       "67     68  0.506950  0.832031\n",
       "68     69  0.491211  0.840820\n",
       "69     70  0.474137  0.835938\n",
       "70     71  0.481244  0.832031\n",
       "71     72  0.461852  0.851562\n",
       "72     73  0.477389  0.835938\n",
       "73     74  0.480486  0.843750\n",
       "74     75  0.461559  0.845703\n",
       "75     76  0.486560  0.841797\n",
       "76     77  0.461340  0.847656\n",
       "77     78  0.450497  0.859375\n",
       "78     79  0.447698  0.853516\n",
       "79     80  0.461568  0.840820\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
